FCNs cannot be used for segmentation of variable size images after training.

Yann LeCun pointed,  ConvNets don't need to have a fixed-size input.
One can train Fully-convolutional network using small images, and than use the model (without scaling or cropping) and feed it with large images for segmentation.
It works right away with Keras+Theano.
If one trains the same model with TensorFlow as Keras'es backend, during application of pretrained model on image larger than the images used for training, he will get A ValueError due to tensor shape mismatch (same for manual model definition directly in TF).
The shape check needs to be disabled and the convolution layers need to work properly with variable size during model using/testing phase if the framework is to be competitive.
What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://www.facebook.com/yann.lecun/posts/10152820758292143
http://stackoverflow.com/questions/39050557/fully-convolutional-network-training-image-size
https://www.quora.com/How-does-the-conversion-of-last-layers-of-CNN-from-fully-connected-to-fully-convolutional-allow-it-to-process-images-of-different-size
http://tutorial.caffe.berkeleyvision.org/caffe-cvpr15-pixels.pdf
Environment info
Operating System:  Ubuntu 14.04.4 LTS
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
cuda_config.txt
Error log:
ValueError: Cannot feed value of shape (1, 3, 350, 600) for Tensor u'convolution2d_input_2:0', which has shape '(?, 3, 15, 15)'