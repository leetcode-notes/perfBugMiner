Slow Hessian

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I have written custom code
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 4.4.0-47-generic #68-Ubuntu and Also macOS Sierra 10.12.3 (CPU only)
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 1
Python version: 3.6
Bazel version (if compiling from source):
CUDA/cuDNN version: cuda/8.0 and cudnn/5.1
GPU model and memory: 12GB, memory:100GB
Exact command to reproduce: tf.hessians(ys,xs)

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
You can obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the problem
The command tf.hessians(ys, xs) is used to add nodes to the graph in order to compute hessians of ys with respect to xs where both ys and xs are list of tensors. Currently computing hessian with respect to a vector is not possible. The trick is to unstack the input tensor (x) into a list of one dimensional tensors (xs) and compute hessian with respect to each of them separately then stack them together. Tensorflow gets stuck in the phase of graph construction even when the dimension of x (length of list xs) is about one hundred. In the implementation of Hessian in gradients_impl.py the second derivative is implemented as the derivative of partial derivative with respect to each member of xs. I guess the slowness of graph construction is due to this line:
_hess = [gradients(_gradient, x, **kwargs)[0] for _gradient in _gradients]
which may add several unnecessary intermediate nodes with overlapping functionality to the graph due to the for loop. Is there any way other than looping over input dimensions that efficiently constructs the graph in a reasonable time?
Source code / logs
This source code can simulate the problem:
import tensorflow as tf
import numpy as np
in_dimension = 256
x = tf.placeholder(tf.float32, shape=(1, in_dimension))
x_list = tf.unstack(x, axis=1)
xx= tf.stack(x_list, axis=1)
y = tf.pow(xx,3)
hess = tf.hessians(y, x_list)
sess = tf.Session()
print(sess.run(hess, feed_dict={x : np.random.normal(0, 1, size=(1, in_dimension))}))