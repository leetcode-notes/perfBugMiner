Enable use of cuDNN RNNs with optimizers other than GradientDescentOptimizer

Currently cuDNN-based RNNs in TF are limited to GradientDescentOptimizer (#6620). This is a serious limitation given the widespread use of other optimizers. The claim that this cannot be supported in TF because cuDNN RNN don't have known shapes at static time seems overly pessimistic. Just like RNNParamsSaver provides a mechanism to convert between canonical shaped variables and the parameter buffer, a simple wrapper can be provided that does this automatically for cuDNN RNNs, so that the size of the parameter buffer is statically calculated and then used to define the variable, especially since the shape of the parameter buffer is just a 1D vector anyway.