Optimizer got only float32?

Got some big number so thought dtype float64 must be able to embrace a larger range. Everything looks fine until it comes to define the optimisation. I got this error:
site-packages/tensorflow/python/training/optimizer.py(343)_assert_valid_dtypes()
    342             "Invalid type %r for %s, expected: %s." % (
--> 343                 dtype, t.name, [v for v in valid_dtypes]))
    344 

ipdb> l
    338     for t in tensors:
    339       dtype = t.dtype.base_dtype
    340       if dtype not in valid_dtypes:
    341         raise ValueError(
    342             "Invalid type %r for %s, expected: %s." % (
--> 343                 dtype, t.name, [v for v in valid_dtypes]))
    344 
    345   # --------------
    346   # Methods to be implemented by subclasses if they want to use the
    347   # inherited implementation of apply_gradients() or compute_gradients().
    348   # --------------

ipdb> t
<tensorflow.python.framework.ops.Tensor object at 0x110b40630>
ipdb> t.dtype.base_dtype
tf.float64
ipdb> t.dtype
tf.float64

Looks like only tf.float32 accepted in this snippet? Can this be fixed?