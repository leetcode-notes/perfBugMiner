[feature request]recomputable operation annotation

'Training Deep Nets with Sublinear Memory Cost' and 'Memory-Efficient Implementation of DenseNets' indicate that use drop intermediate feature map and recompute it if needed can save memory(while add computation burden),
so we need some mechanism to annotate some op's inputs  recomputable , and drop this input memory after op finish(set input's reference count to 0), when need this op again, recompute it.
a = tf.get_varible(shape=[None,10])
b = tf.get_varible(shape=[None,10])
c = tf.get_varible(shape=[None,10])
d = a*b
d_recomputable = tf.recomputable(d)
e = d_recomputable+c
relate issue

#1934
#12948

in short, normal reference add reference count, recomputable reference do not add reference count