[inputs] instead of inputs for rnn_cell?

In current rnn_cell implementation, It gets inputs as 2-d tensor for cell inputs,
Hence embedding layer before the actual rnn_cell gets a little bit annoying for making 'decoder'.
I really like the "wrapper" concept in current implementation that expand by each layer with embedding, residual net, or dropouts.
If rnn_cell gets list of '2-d' tensor like [inputs1, inputs2, ...], then the concept of wrapper can be fully used in decoder as well as simple rnn or encoder;
for a little more concretely,
if "embedding wrapped cell" gets input list [inputs, context_inputs_from_attention],
then the "embedding wrapped cell" can just pass [embedded_inputs, context_inputs_from_attention] to the real "LSTM_cell" and "LSTM_cell" can weight sum those inputs in inputs list.
what do you think about this idea?