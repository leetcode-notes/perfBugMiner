tf.metrics.accuracy maintains a running accuracy?

I use the tf.metrics.accuracy, however it is a bit counter-intuitive in that it maintains a running accuracy (the doc agrees with this).  The following simple script illustrates the situation
import os
# supress tensorflow logging other than errors
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import numpy as np
import tensorflow as tf


print(tf.__version__)
# 1.1.0

x = tf.placeholder(tf.int32, [5])
y = tf.placeholder(tf.int32, [5])
acc, acc_op = tf.metrics.accuracy(labels=x, predictions=y)

sess = tf.InteractiveSession()
sess.run(tf.global_variables_initializer())
sess.run(tf.local_variables_initializer())

v = sess.run([acc, acc_op], feed_dict={x: [1, 0, 0, 0, 0],
                                       y: [1, 0, 0, 0, 1]})
print(v)
# [0.0, 0.8]

v = sess.run(acc)
print(v)
# 0.8

v = sess.run([acc, acc_op], feed_dict={x: [1, 0, 0, 0, 0],
                                       y: [0, 1, 1, 1, 1]})
print(v)
# [0.8, 0.4]

v = sess.run(acc)
print(v)
# 0.4
My concerns are

the use of accuracy is bit surprising, are we supposed to manually construct the normal accuracy?
IMHO, it is better to

implement the normal accuracy behavior or
provide a clean way to reset the local variables created by tf.metrics.accuracy, i.e., the count and total.