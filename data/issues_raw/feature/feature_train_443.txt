Feature Request: LogSoftmax layer

Torch has a LogSoftmax layer, that does what the name imply: it is the equivalent of a softmax followed by a log. However, I could not find a similar layer in tensorflow.
LogSoftmax is quite convenient because I am often more interested in log-probabilities (eg for computing a log-likelihood) than in the probabilities themselves.
Further, I suspect a LogSoftmax can be implemented more efficiently than a Softmax (it should at least saves a log call, if one is interested in the log-probabilities; plus it is less sensitive to underflow/overflows). Indeed Torch documentation indicates it is faster when one need the log-probabilities.
Would you consider adding such a layer at some point?