tf.estimator generator_input_fn no padding queue?

Hello again!
While I was examining TF source code for 10597 issue solution, I found another bug or lack of important feature, such as PaddingFIFOQueue for all of tf.estimator input pipelines. Such option is very important for seq2seq tasks with dynamic shapes.
As a solution I found a hacky way to generate [1, batch_size, time] batches and squeeze them to [batch_size, time] in the model. Source code: tensorflow, model, notebook.
As you can understand, I am not very happy with such solution, that's why I am asking for help to solve it in more correct and tensorflow way. Any suggestions?