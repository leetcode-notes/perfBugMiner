dynamic_rnn time_major=False does not support rank>3 input

tensorflow/tensorflow/python/ops/rnn.py
    
    
         Line 782
      in
      33b336a
    
    
    
    

        
          
           flat_input = tuple(array_ops.transpose(input_, [1, 0, 2]) 
        
    
  


flat_input = tuple(array_ops.transpose(input_, [1, 0, 2])
for input_ in flat_input)

Here seems we can only transpose matrix of size batch_size * time_size * input_size. It doesn't work if my input at each time step is a matrix.
In torch you can just specify the two dimensions (0 and 1 here) to be swapped instead of perm. Is there a similar functionality?