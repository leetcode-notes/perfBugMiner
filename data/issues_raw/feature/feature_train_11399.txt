Let string_split support splitting utf-8 characters

Describe the problem
Type of issue: feature request
The string_split function has (mostly) good behavior when splitting utf-8 strings by single-character delimiter, but fails to do it properly on null-width delimiter because of its documented behavior:

If delimiter is an empty string, each element of the source is split into individual strings, each containing one byte. (This includes splitting multibyte sequences of UTF-8.)

For models like seq2seq one needs a split function that can split utf-8 strings into individual characters that can be processed by model as units, also embeddings having properly of being easily joined as utf-8 strings.
Could tensorflow provide alternative implementation of string_split that is utf-8 - aware?