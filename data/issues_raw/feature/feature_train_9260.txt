Sampling from a categorical distribution without replacement

Both tf.multinomial() and tf.contrib.distributions.Categorical.sample() allow to sample from a multinomial distribution. However, they only allow sampling with replacement.
In constrast, Numpy's numpy.random.choice() has a replace parameter that allows sampling without replacement. Would it be possible to add a similar functionality to TensorFlow?
One use case is sampling examples from the dataset proportional to the model's last loss on them. When an example generates a very large loss, the next batch will mainly consist of that example. Using sampling without replacement, we can avoid this problem.
I see that sampling with replacement can be parallelized and implemented in a vectorized way, but I don't think sampling speed is a bottleneck in most people's programs.