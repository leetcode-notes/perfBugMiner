sparse lookup tables for tf.nn.embedding_lookup_sparse

Hope that “params” of tf.nn.embedding_lookup_sparse support SparseTensor!!!
tf.nn.embedding_lookup_sparse(params, sp_ids, sp_weights, partition_strategy='mod', name=None, combiner='mean')
The efficiency of sparse lookup tables is low,  but it is very useful for large-scale linear regression system, especially when designing a prototype.
For example, the wide part of "wide and deep learning" use sparse features.
Although I don't know when the hashing function is applied, using sparse lookup table is more accurate than hashing.  The hashing function may merge two features into one bin (share the same weight), or discard new features when the lookup table is full.