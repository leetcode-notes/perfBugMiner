tf.summary.FileWriter crashes with AlreadyExistsError

We have a cluster with ~20 GPUs that we often use to train multiple networks in parallel, and we use tf.summary.Filewriter to keep track of the networks' progress. However, some jobs are crashing when they attempt to create their FileWriters with the following stack trace:
[...]
  File "/ubc/cs/research/tracking-raid/julm/eyescream/tensorflow/pose_estimation/linear_model.py", line 141, in __init__
    self.train_writer = tf.summary.FileWriter( os.path.join(summaries_dir, 'train' ))
  File "/ubc/cs/research/tracking-raid/julm/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/summary/writer/writer.py", line 308, in __init__
    event_writer = EventFileWriter(logdir, max_queue, flush_secs)
  File "/ubc/cs/research/tracking-raid/julm/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/summary/writer/event_file_writer.py", line 69, in __init__
    gfile.MakeDirs(self._logdir)
  File "/ubc/cs/research/tracking-raid/julm/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py", line 299, in recursive_create_dir
    pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)
  File "/ubc/cs/research/tracking-raid/julm/anaconda/envs/tensorflow/lib/python2.7/contextlib.py", line 24, in __exit__
    self.gen.next()
  File "/ubc/cs/research/tracking-raid/julm/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.AlreadyExistsError: /global/scratch/julm/3d_experiments

I am writing the Filewriters' progress under /global/scratch/julm/3d_experiments/, and creating multiple subdirectories depending on the hyperparameters that each network is using.
The error seems to suggest that the FileWriter is trying to create the directory /global/scratch/julm/3d_experiments/ and crashing because the directory already exists. Moreover, only around 1 in 5 jobs crashes with this error.
Do you know if I could somehow ignore this error? I don't think the fact that the directory exists should trigger an error for the user.
Our cluster runs under OpenSUSE 42.2.