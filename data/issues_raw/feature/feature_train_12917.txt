SVD on GPU: complex values, interface cleanup (Discussion)

Hi,
pull request #11878 brought an implementation of the SVD on the GPU. But at the moment, only real values are supported.
The current status when applying the SVD (M=USV') on a complex matrix M:

The python interface declares U,V as complex, S as real
The C++ kernel definition declares both U,V and S as complex
(This simplified the CPU implementation using Eigen)
The python code then immediately casts S to the reals
The GPU solver (cuSolver) would, however, output the singular values directly as reals

This leads to the following questions / ideas / suggestions
(credit goes also to @rmlarsen for discussion this the first time with me)

Change the kernel definition: Add a new kernel (V2 suffix) that returns S as a real type
Implement the complex support on GPUs
Adopt the CPU code to also use the new kernel definition
OR
Keep both definitions and let the python wrapper to choose between the two versions based on the target device (CPU vs GPU)
...?

What do you think?