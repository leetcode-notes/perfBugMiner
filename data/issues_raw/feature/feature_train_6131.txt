tf.get_session_tensor awkwardness

tf.get_session_tensor() op constructor is unique in that it needs to be passed output of a session.run call. IE, when you are setting up your graph structure and don't have a relevant handle, you need to do something like this
dummy_handle = sess.run(tf.get_session_handle(tf.constant(1, dtype=dt)))
tensor_holder, tensor = tf.get_session_tensor(dummy_handle, dtype=dt)


This means that it's incompatible with workflow of "create graph -> finalize graph -> run ops" (like when using Supervisor which finalizes graph at the end of init). It seems the reason was to figure out which device the tensor would live on. Would it make sense to have it take device from the current graph context instead of a live tensor handle?
@yuanbyu @keveman