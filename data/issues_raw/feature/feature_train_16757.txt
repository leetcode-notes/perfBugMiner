tf.contrib.layers.optimize_loss() to support mixed precision training

ISSUE: Referring to source code,  it is evident that mixed precision gradients is not supported in tf.contrib.layers.optimize_loss.
Here is the snip of assertion…
opt = tf.contrib.layers.optimize_loss(
    base_loss, global_step=global_step,
    clip_gradients=clip_grad, increment_global_step=True, **train_params)

TypeError: Tensors in list passed to 'values' of 'Pack' Op have types [float16, float32, float32, float16, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float32, float32, float16, float16] that don't all match.

Description:
This was observed during training resnet50 (this involves mixed precision batch_norm). Just curious to know whether there is a roadmap to have mixed precision gradients support in tf.contrib.layers.optimize_loss.
System information
•	**OS Platform and Distribution *: Linux Centos 7.2
•	TensorFlow installed from (source or binary): 1.5.0
•	TensorFlow version (use command below):  v1.5.0-0-g37aa430d84 1.5.0
•	Python version: 3.4.5
•	Bazel version (if compiling from source): No
•	CUDA/CUDAnn version: CUDA 9.1 and CUDAnn 7.0 with latest Nvidia driver
•	GPU model and memory: Volta 100, 16GiB