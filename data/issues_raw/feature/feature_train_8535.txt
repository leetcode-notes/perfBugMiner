Feature request: add support for float16/float64 to tf.contrib.layers.batch_norm()

NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.
For general support from the community, see StackOverflow.
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.
For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
tf.contrib.layers.batch_norm does not support float16 due to defaulting to dtype=tf.float32 for get_variable().

  
    
      tensorflow/tensorflow/python/layers/normalization.py
    
    
         Line 141
      in
      067cba5
    
    
    
    

        
          
           self.moving_mean = vs.get_variable( 
        
    
  


Environment info
Operating System:
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*):

Ubuntu 16.04 Docker container
Ubuntu 16.10 Docker host
Dockerfile base nvidia/cuda:8.0-cudnn5-devel-ubuntu16.04
CUDA 8.0.61
CUDNN 5.1.10
NVidia driver version 378.13

$ uname -a
Linux 97fca57d7bb6 4.8.0-41-generic #44-Ubuntu SMP Fri Mar 3 15:27:17 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root    556000 Jan 26 23:48 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Jan 26 23:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root        19 Jan 26 23:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61
-rw-r--r-- 1 root root    415432 Jan 26 23:48 /usr/local/cuda/lib64/libcudart.so.8.0.61
-rw-r--r-- 1 root root    775162 Jan 26 23:48 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 jake users       13 Nov  7 07:00 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 jake users       18 Nov  7 07:00 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10
-rwxr-xr-x 1 jake users 84163560 Nov  7 06:47 /usr/local/cuda/lib64/libcudnn.so.5.1.10
-rw-r--r-- 1 jake users 70364814 Nov  7 06:47 /usr/local/cuda/lib64/libcudnn_static.a

$ conda -V
conda 4.3.14
If installed from binary pip package, provide:

A link to the pip package you installed:
The output from python -c "import tensorflow; print(tensorflow.__version__)".

If installed from source, provide

The commit hash (git rev-parse HEAD)
The output of bazel version

$ python -c "import tensorflow; print(tensorflow.__version__)"
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally
1.0.1
Conda environment.yml:
name: root

channels:
- defaults
- conda-forge
- menpo

dependencies:
- ipyparallel==5.2.0
- opencv3=3.1.0
- pip:
  - keras==1.2.2
  - pydicom==0.9.9
  - tensorflow-gpu==1.0.1
  - tflearn==0.3
If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
import tensorflow as tf
from tensorflow.contrib.layers import batch_norm
# from normalization import batch_norm
with tf.Session() as sess, tf.device('/cpu'):
  inputs = tf.convert_to_tensor([1., 2.], dtype=tf.float16)
  norm = batch_norm(inputs)
  sess.run(tf.global_variables_initializer())
  sess.run(norm)
Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-10-f094f32eca33> in <module>()
      1 a = tf.convert_to_tensor([1., 2.], dtype=tf.float16)
----> 2 tf.contrib.layers.batch_norm(a).eval()

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)
    175       current_args = current_scope[key_func].copy()
    176       current_args.update(kwargs)
--> 177     return func(*args, **current_args)
    178   _add_op(func)
    179   setattr(func_with_args, '_key_op', _key_op(func))

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py in batch_norm(inputs, decay, center, scale, epsilon, activation_fn, param_initializers, updates_collections, is_training, reuse, variables_collections, outputs_collections, trainable, batch_weights, fused, data_format, zero_debias_moving_mean, scope)
    516           _scope=sc,
    517           _reuse=reuse)
--> 518       outputs = layer.apply(inputs, training=is_training)
    519 
    520       # Add variables to collections.

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)
    301       Output tensor(s).
    302     """
--> 303     return self.__call__(inputs, **kwargs)
    304 
    305 

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)
    271             self.build(input_shapes)
    272           self._built = True
--> 273         outputs = self.call(inputs, **kwargs)
    274 
    275         # Apply activity regularization.

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/normalization.py in call(self, inputs, training)
    191       if not self.updates:
    192         mean_update = moving_averages.assign_moving_average(
--> 193             self.moving_mean, mean, self.momentum, zero_debias=False)
    194         variance_update = moving_averages.assign_moving_average(
    195             self.moving_variance, variance, self.momentum, zero_debias=False)

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/moving_averages.py in assign_moving_average(variable, value, decay, zero_debias, name)
     70         update_delta = _zero_debias(variable, value, decay)
     71       else:
---> 72         update_delta = (variable - value) * decay
     73       return state_ops.assign_sub(variable, update_delta, name=scope)
     74 

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in _run_op(a, *args)
    675     def _run_op(a, *args):
    676       # pylint: disable=protected-access
--> 677       return getattr(ops.Tensor, operator)(a._AsTensor(), *args)
    678     # Propagate __doc__ to wrapper
    679     try:

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py in binary_op_wrapper(x, y)
    791     with ops.name_scope(None, op_name, [x, y]) as name:
    792       if not isinstance(y, sparse_tensor.SparseTensor):
--> 793         y = ops.convert_to_tensor(y, dtype=x.dtype.base_dtype, name="y")
    794       return func(x, y, name=name)
    795 

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype)
    635       name=name,
    636       preferred_dtype=preferred_dtype,
--> 637       as_ref=False)
    638 
    639 

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype)
    700 
    701         if ret is None:
--> 702           ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    703 
    704         if ret is NotImplemented:

/opt/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _TensorTensorConversionFunction(t, dtype, name, as_ref)
    573     raise ValueError(
    574         "Tensor conversion requested dtype %s for Tensor with dtype %s: %r"
--> 575         % (dtype.name, t.dtype.name, str(t)))
    576   return t
    577 

ValueError: Tensor conversion requested dtype float32 for Tensor with dtype float16: 'Tensor("BatchNorm_2/Reshape_1:0", shape=(2,), dtype=float16)'

What other attempted solutions have you tried?
Use a modified tensorflow/python/layers/normalization.py which passes dtype=inputs.dtype.base_dtype.