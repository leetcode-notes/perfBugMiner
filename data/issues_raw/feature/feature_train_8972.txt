conv2d_transpose output shape more undefined than input shape

I have posted this on StackOverflow already but haven't gotten an answer yet, plus it feels like a bug very similar to #5807 which is why I'm posting it here as well.
Basically the problem is that the output shape of tf.nn.conv2d_transpose is entirely undefined, even if e.g. only one dimension in the input is unknown. So in the following code snippet, the shape of out is [3, 10, 5, 5] as expected if using the static shape to get the size of the first dimension. However if you use the dynamic shape (commented line in the snippet below), then the shape of out is [?, ?, ?, ?] instead of [?, 10, 5, 5].
This is a problem for me because I am using out in a batch-normalization layer with tf.contrib.layers.python.layers.batch_norm for which certain dimensions must be defined.
import tensorflow as tf

input_ = tf.Variable(tf.random_normal([3, 10, 5, 1]))
w = tf.get_variable('w', initializer=tf.truncated_normal([3, 3, 5, 1], mean=0.0, stddev=0.01, dtype=tf.float32))

# output_shape = [tf.shape(input_)[0], 10, 5, 5]
output_shape = [input_.get_shape()[0].value, 10, 5, 5]
out = tf.nn.conv2d_transpose(input_,
                             filter=w,
                             output_shape=tf.pack(output_shape),
                             strides=[1, 1, 1, 1],
                             padding='SAME')

I am using TF v0.12 on Ubuntu 14.04, Python 3.5.2, installed in Anaconda environment through pip.