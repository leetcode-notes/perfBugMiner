[Feature request] Adding scaffold parameter estimator heads

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): 1.4
Python version: 3.6.3
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:

Describe the problem
When creating custom estimators, using the Heads defined here reduces an important part of the boilerplate as well as guarantee uniform evaluation against canned estimator instances. However, one key parameter is missing in in create_estimator_spec function, which is the scaffold that one can pass into an EstimatorSpec. One example where that is needed is if you want to initialize a large tensor with a numpy array, for example for loading an embedding file from word2vec. This StackOverflow question also describes the issue.
Source code / logs
This is my normal code, currently impossible to use with heads. Actually, it might not be impossible, but this seems to me like the cleaner solution. I have the tiny PR ready if you think this is a valuable change. Thanks a lot for your time!
def model_fn(mode, features, labels, hparams):
  embed_ph = tf.placeholder(
      shape=[hparams.vocab_size, hparams.embedding_size], 
      dtype=tf.float32)
  embeddings = tf.Variable(embed_ph)
  # Define your model
  return tf.estimator.EstimatorSpec(
      ..., # normal EstimatorSpec args
      scaffold=tf.train.Scaffold(init_feed_dict={embed_ph: my_embedding_numpy_array})
  )