MaskedAutoregressiveFlow example (tf.contrib.distributions) raises ValueError

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (also tried on a Windows 10 machine with TF 1.6)
TensorFlow installed from (source or binary): defaults from Colab
TensorFlow version (use command below): 1.6.0
Python version: 3.6.3 (default, Oct  3 2017, 21:45:48)
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: see attached file

Describe the problem
I'm new to tf.contrib.distributions. I've just copied the example for MaskedAutoregressiveFlow from https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/bijectors/MaskedAutoregressiveFlow. Running the example fails with a ValueError at maf.sample(). See the attached file and error log below.  Running tf.global_variables_initializer() in the session doesn't solve it either. It looks like masked_autoregressive_default_template expects a tensor with ndim>1 but MaskedAutoregressiveFlow.forward() passes a tensor with ndim=1.
masked_autoregressive_issue.txt
Source code / logs
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-3-646c58f4e818> in <module>()
     12 sess.run(tf.global_variables_initializer())
     13 
---> 14 x = maf.sample()  # Expensive; uses `tf.while_loop`, no Bijector caching.
     15 maf.log_prob(x)   # Almost free; uses Bijector caching.
     16 maf.log_prob(0.)  # Cheap; no `tf.while_loop` despite no Bijector caching.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/distribution.py in sample(self, sample_shape, seed, name)
    687       samples: a `Tensor` with prepended dimensions `sample_shape`.
    688     """
--> 689     return self._call_sample_n(sample_shape, seed, name)
    690 
    691   def _log_prob(self, value):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/transformed_distribution.py in _call_sample_n(self, sample_shape, seed, name, **kwargs)
    411       # work, it is imperative that this is the last modification to the
    412       # returned result.
--> 413       y = self.bijector.forward(x, **kwargs)
    414       y = self._set_sample_static_shape(y, sample_shape)
    415 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bijector_impl.py in forward(self, x, name)
    618       NotImplementedError: if `_forward` is not implemented.
    619     """
--> 620     return self._call_forward(x, name)
    621 
    622   def _inverse(self, y):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/distributions/bijector_impl.py in _call_forward(self, x, name, **kwargs)
    599       if mapping.y is not None:
    600         return mapping.y
--> 601       mapping = mapping.merge(y=self._forward(x, **kwargs))
    602       self._cache(mapping)
    603       return mapping.y

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py in _forward(self, x)
    245     y0 = array_ops.zeros_like(x, name="y0")
    246     # call the template once to ensure creation
--> 247     _ = self._shift_and_log_scale_fn(y0)
    248     def _loop_body(index, y0):
    249       """While-loop body for autoregression calculation."""

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/template.py in __call__(self, *args, **kwargs)
    358           custom_getter=self._custom_getter) as vs:
    359         self._variable_scope = vs
--> 360         result = self._call_func(args, kwargs)
    361         return result
    362 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/template.py in _call_func(self, args, kwargs)
    300       trainable_at_start = len(
    301           ops.get_collection(ops.GraphKeys.TRAINABLE_VARIABLES))
--> 302       result = self._func(*args, **kwargs)
    303 
    304       if self._variables_created:

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py in _fn(x)
    478             activation=activation,
    479             *args,
--> 480             **kwargs)
    481       x = masked_dense(
    482           inputs=x,

/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py in masked_dense(inputs, units, num_blocks, exclusive, kernel_initializer, reuse, name, *args, **kwargs)
    386         *args,
    387         **kwargs)
--> 388     return layer.apply(inputs)
    389 
    390 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in apply(self, inputs, *args, **kwargs)
    807       Output tensor(s).
    808     """
--> 809     return self.__call__(inputs, *args, **kwargs)
    810 
    811   def _add_inbound_node(self,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, *args, **kwargs)
    671 
    672           # Check input assumptions set before layer building, e.g. input rank.
--> 673           self._assert_input_compatibility(inputs)
    674           if input_list and self._dtype is None:
    675             try:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py in _assert_input_compatibility(self, inputs)
   1195                            ', found ndim=' + str(ndim) +
   1196                            '. Full shape received: ' +
-> 1197                            str(x.get_shape().as_list()))
   1198       # Check dtype.
   1199       if spec.dtype is not None:

ValueError: Input 0 of layer dense_1 is incompatible with the layer: : expected min_ndim=2, found ndim=1. Full shape received: [5]

originally defined at:
  File "<ipython-input-3-646c58f4e818>", line 10, in <module>
    hidden_layers=[512,512])),
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/distributions/python/ops/bijectors/masked_autoregressive.py", line 499, in masked_autoregressive_default_template
    "masked_autoregressive_default_template", _fn)
  File "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/template.py", line 152, in make_template
    **kwargs)

edit: fixed link to TF doc