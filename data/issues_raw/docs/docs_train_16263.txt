losses.softmax_cross_entropy documentation on tensor rank

Documentation Issue
It seems losses.softmax_cross_entropy() works just fine with any tensor rank/shape (as long as the last dimension is classes) and not just shapes of [batch_size, num_classes] as the documentation indicates. (The documentation also indicates weights should be rank 0 or 1; also not true)
If this is the expected behavior, fixing the documentation would help people avoid doing unnecessary reshapes.