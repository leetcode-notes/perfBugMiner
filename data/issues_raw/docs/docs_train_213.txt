tensorflow howto for sharing variable is confusing

at here:
http://tensorflow.org/how_tos/variable_scope/index.md
The tutorial talk about using "two sets of variables" and talk about their duplication, however the network itself uses 2 layers of convolution. So there's 2 different things that can be the quantity of 2.

The number of layers is 2, being conv1 and conv2, these 2 should be distinct
The number of image filters, applied once to each image, these 2 should be identical

I was having a hard time understanding at first and thought we're attempting to use the same weights for both of the conv layers. It didn't help that the definition for "variables_dict" only explicitly states the existence for the weights for the first conv layer, leading me to believe that the weights of the 2 layers are actually shared as well.
I think a simple fix is to make the network have say 5 conv layers instead of 2, this way you get to demonstrate variable_scope as well in the later section
Just my 2 cents, I starred at this for much longer than I should have because of this confusion.