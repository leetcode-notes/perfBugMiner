missing Documentation of the method AttentionWrapper.zero_state(...)

Hello ,
I have noticed that the method AttentionWrapper.zero_state( batch_size,dtype) does not have any description of its functionality in the  documentation website , below is a reference link :
https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/AttentionWrapper
I really hope that this gets fixed , I have spent a couple of days trying to debug a code that I have written until I realized that I was misusing the method .
thank you