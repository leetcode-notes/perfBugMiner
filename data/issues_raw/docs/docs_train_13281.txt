Non-working example in documentation, with recommendations for how to fix

== cat /etc/issue ===============================================
Linux EricDesktop 4.4.0-96-generic #119-Ubuntu SMP Tue Sep 12 14:59:54 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION="16.04.2 LTS (Xenial Xerus)"
VERSION_ID="16.04"
VERSION_CODENAME=xenial
== are we in docker =============================================
No
== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
== uname -a =====================================================
Linux EricDesktop 4.4.0-96-generic #119-Ubuntu SMP Tue Sep 12 14:59:54 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
== check pips ===================================================
numpy (1.13.1)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.6)
== check for virtualenv =========================================
False
== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc1-2409-g5ee3804
tf.COMPILER_VERSION = v1.3.0-rc1-2409-g5ee3804
Sanity check: array([1], dtype=int32)
== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda-8.0/lib64
DYLD_LIBRARY_PATH is unset
== nvidia-smi ===================================================
Sun Sep 24 14:08:03 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 375.82                 Driver Version: 375.82                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 670     Off  | 0000:03:00.0     N/A |                  N/A |
| 33%   50C    P0    N/A /  N/A |    254MiB /  4031MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 670     Off  | 0000:04:00.0     N/A |                  N/A |
| 32%   48C    P0    N/A /  N/A |    253MiB /  4036MiB |     N/A      Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0                  Not Supported                                         |
|    1                  Not Supported                                         |
+-----------------------------------------------------------------------------+
== cuda libs  ===================================================
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61
Describe the problem
I have been trying to get a custom op working for many hours, and have finally collected enough information to know that it isn't entirely my fault, and I can help you improve the custom op documentation to save others such effort.  

Walkthrough to see what the problem is:

Following the instructions on the documentation page (https://www.tensorflow.org/extend/adding_an_op) I copy the zero_out.cc code
Compile with Bazel
Test with python.  Everything works, this example behaves exactly as it should.
But I want a GPU kernel, so now I try the "example" example.
Copy the example.h, example.cc and example.cu.cc files on the documentation page.  Didn't make any changes.
Now I hit some problems.  The documentation isn't very clear on how to compile this more complicated op with bazel.  I managed to figure it out, but I would strongly recommend notifying users about the "gpu_srcs" argument that can be used inside the BUILD file, since this took me quite a while to discover.

Working BUILD file:
load("//tensorflow:tensorflow.bzl", "tf_custom_op_library")
tf_custom_op_library(
name = "example.so",
srcs = ["example.cc", "example.h"],
gpu_srcs = ["example.cu.cc", "example.h"],
)
Working Bazel command to invoke the BUILD file:
bazel build --config opt --config=cuda --cxxopt="-D_GLIBCXX_USE_CXX11_ABI=0" //tensorflow/core/user_ops:example.so


Now it compiles.  But the op does not load properly in python; the module created by tf.load_op_library does not contain the actual op, as you can see by my tests under the source code section.


After a long time, I discover the extremely obvious problem: the example code in the documentation does not have any REGISTER_OP macro call.  This is clearly an omission in the documentation.


I try copying the REGISTER_OP macro call from the zero_out example, and it doesn't really work since the "example" example is more complicated, but python now at least recognizes the op.  I am sure if I were to spend the time to figure out how to correctly call the REGISTER_OP macro in example.cc, the example would work correctly for me.
I could make some other recommendations about changing the "Adding a New Op" documentation page, though I will refrain for now since I am not sure this is the appropriate place to do so.  I would be happy to take a stab at editing the doc page myself, though since I am very new to github I am concerned that I would end up creating more problems than I would fix, so it might be better to have someone with more experience do it.  I would be happy to help though.
One thing I will say though: I would really love it if some TF expert would add a fully fleshed out template op to the user op documentation page with all the bells and whistles, and with clear instructions on exactly how to compile and run it.  It should have both GPU support and a gradient implementation.  And ideally it would be multi-threaded (if the "example" example isn't already - its not obvious to me either way).  The template would be provided with everything you need, and would have a clearly labeled code block where the user can add their own code:  "here is a for loop that iterates over every element in the tensor.  write whatever you want here."  If you can make it really easy for users to add their own, high-quality operators, you might be able to cut down on your workload responding to problems with custom ops and with users requesting new ops.  And I think that a template that we can fill in would be enough to do that for many people.


Source code / logs
=========================================== start test.py:
import tensorflow as tf
zero_out_module = tf.load_op_library('./zero_out.so')
with tf.Session(''):
print "zero_out:"
print(zero_out_module.zero_out([[1, 2], [3, 4]]).eval())
example_module = tf.load_op_library('./example.so')
with tf.Session(''):
print "example:"
try:
print(example_module.example([[1, 2], [3, 4]]).eval())
except AttributeError as err:
print "Error: ", err
print "Analysis of zero_out_module:"
print zero_out_module.dict.keys()
print zero_out_module.OP_LIST
print "Analysis of example_module:"
print example_module.dict.keys()
print example_module.OP_LIST
====================================== end test.py
Output of running test.py
eric@EricDesktop:~/tensorflow/tensorflow/core/user_ops$ python test.py2017-09-24 14:14:08.183509: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-09-24 14:14:08.183794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 0 with properties:
name: GeForce GTX 670 major: 3 minor: 0 memoryClockRate(GHz): 1.0455
pciBusID: 0000:04:00.0
totalMemory: 3.94GiB freeMemory: 3.66GiB
2017-09-24 14:14:08.208238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-09-24 14:14:08.208514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Found device 1 with properties:
name: GeForce GTX 670 major: 3 minor: 0 memoryClockRate(GHz): 1.0455
pciBusID: 0000:03:00.0
totalMemory: 3.94GiB freeMemory: 3.66GiB
2017-09-24 14:14:08.208964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:980] Device peer to peer matrix
2017-09-24 14:14:08.208988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] DMA: 0 1
2017-09-24 14:14:08.208994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] 0:   Y Y
2017-09-24 14:14:08.209000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:996] 1:   Y Y
2017-09-24 14:14:08.209012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:04:00.0, compute capability: 3.0)
2017-09-24 14:14:08.209020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 670, pci bus id: 0000:03:00.0, compute capability: 3.0)
zero_out:
[[1 0]
[0 0]]
2017-09-24 14:14:08.239952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 670, pci bus id: 0000:04:00.0, compute capability: 3.0)
2017-09-24 14:14:08.239970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1055] Creating TensorFlow device (/device:GPU:1) -> (device: 1, name: GeForce GTX 670, pci bus id: 0000:03:00.0, compute capability: 3.0)
example:
Error:  'module' object has no attribute 'example'
Analysis of zero_out_module:
['_op_def_pb2', '_op_def_lib', '_op_def_registry', '_ops', '_collections', '_common_shapes', 'builtins', 'zero_out', 'package', '_op_def_library', 'OP_LIST', 'LIB_HANDLE', 'name', '_InitOpDefLibrary', 'doc']
op {
name: "ZeroOut"
input_arg {
name: "to_zero"
type: DT_INT32
}
output_arg {
name: "zeroed"
type: DT_INT32
}
}
Analysis of example_module:
['_op_def_pb2', '_op_def_lib', '_op_def_registry', '_ops', '_collections', '_common_shapes', 'builtins', 'package', '_op_def_library', 'OP_LIST', 'LIB_HANDLE', 'name', '_InitOpDefLibrary', 'doc']