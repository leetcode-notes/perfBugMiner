Portability of TensorFlow Meta graph file

OS Platform and Distribution : CentOS
TensorFlow installed from : Sources
TensorFlow version : 1.4
Bazel version : N/A
CUDA/cuDNN version 8.0 (CUDA) and 6.0 (CuDNN)
GPU model and memory : N/A
Exact command to reproduce : N/A
The .meta file from TensorFlow contains device information. Although I can use clear_devices=False to prevent device information getting logged, I beg to ask the relevance of the .meta file with respect to portability.


If I have the code for the generation of the TensorFlow graph, then I do not need the .meta file as per this answer.


What is the applicability of transferring only the .meta file to someone ?


Assuming that I train the graph with 4 GPUs, and then provide .meta file to someone with 8 or possibly only 1 GPU. For someone with 8 GPUs, would this not prevent him/her from actually running the graph for training/inference over 8 GPUs ? In the case of someone with only 1 GPU, what would happen to entities with device numbers 1-3 ?


And finally, what are the implications of point 3, when clear_devices=True ?