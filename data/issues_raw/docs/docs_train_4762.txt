Request for documentation: Loop implementation

I am trying to understand the implementation of tf.while_loop and everything that is built on top of it, because I am implementing a custom tf.Graph subclass, and finding that the way tf.while_loop is handled during gradient computation is important for what I am doing.
However, I cannot find any documentation on the ops that comprise tf.while_loop â€“ is there any internal documentation on this implementation?
I am finding myself confused about some of the following concepts:

WhileContext, and, in general, the stack of contexts
Flows vs tensors
Frames

So far I've gotten quite a bit by just reading the source code, but it's pretty hard to build yourself a good mental model by going completely bottom up without having any high level picture of how the entire thing is organized.
If there is no intention to document these things (which would be completely understandable) please feel free to close this issue (although I would definitely appreciate some help or pointers as to where I can figure out the high-level overview of looping implementation).