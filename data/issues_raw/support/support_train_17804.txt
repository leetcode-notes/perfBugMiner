How to read `feature_lists` from tfrecord.

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 17.10
TensorFlow version (use command below): v1.3.0-rc2-20-g0787eee 1.3.0
Python version: 3.6.2

Describe the problem
I save idex of chars to tfrecords, but i cant know how to read it.
Source code / logs
def make_example(words, chars, labels):
    # print(chars)
    ex = tf.train.SequenceExample()
    ex.context.feature["len"].int64_list.value.append(len(words))

    for w, char_of_a_word, l in zip(words, chars, labels):
        ex.feature_lists.feature_list["words"].feature.add().int64_list.value.append(w)
        ex.feature_lists.feature_list["label"].feature.add().int64_list.value.append(l)

        chars_feature = ex.feature_lists.feature_list["chars"].feature.add()
        for c in char_of_a_word:
            chars_feature.int64_list.value.append(c)

    return ex
words is a list of indexing, example: [1, 2, 3]
chars is list of character indexing, example: [[1,2,3], [2], [2,3,4]]
Parsing function:
def _parse_function(example_proto):
    context_features = {
        "len": tf.FixedLenFeature((), dtype=tf.int64),
    }
    sequence_features = {
        "words": tf.FixedLenSequenceFeature((), dtype=tf.int64),
        "chars": tf.FixedLenSequenceFeature((1,35), dtype=tf.int64),
        "label": tf.FixedLenSequenceFeature((), dtype=tf.int64),
    }

    context_parsed, sequence_parsed = tf.parse_single_sequence_example(
        serialized=example_proto,
        context_features=context_features,
        sequence_features=sequence_features
    )

    len_ = tf.cast(context_parsed['len'], dtype=tf.int32)
    word = tf.cast(sequence_parsed['words'], dtype=tf.int32)
    chars = tf.cast(sequence_parsed['chars'], dtype=tf.int32)
    print("word.shape", word.shape)
    print("chars.shape", chars.shape)
    label = tf.cast(sequence_parsed['label'], dtype=tf.int32)

    return {"words": word, "chars": chars, "len": len_}, label
Input function:
def inputs(file_names, batch_size, num_epochs):
    dataset = tf.contrib.data.TFRecordDataset(file_names)
    dataset = dataset.map(_parse_function)
    dataset = dataset.padded_batch(batch_size=batch_size,
                                   padded_shapes=({"word": [None], "chars": [None], "len": []}, [None]),
                                   padding_values=(
                                       {"word": word_lookup.idx_of_pad,
                                        "chars": 0,
                                        "len": 0}, 0))
    # dataset = dataset.filter(lambda f, l: tf.equal(tf.shape(l)[0], batch_size))
    dataset = dataset.repeat(num_epochs)
    iterator = dataset.make_one_shot_iterator()
    features, label = iterator.get_next()
    return features, label
Error log:
Traceback (most recent call last):
  File "/home/binhnq/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/173.4301.16/helpers/pydev/pydev_run_in_console.py", line 53, in run_file
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/binhnq/.local/share/JetBrains/Toolbox/apps/PyCharm-P/ch-0/173.4301.16/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/binhnq/hitelli/pyvltk2/tfvltk/data_set.py", line 62, in <module>
    _result = inputs_test(['/home/binhnq/hitelli/WordSegmentation/data/test-ws.tfrecords', ])
  File "/home/binhnq/hitelli/pyvltk2/tfvltk/data_set.py", line 55, in inputs_test
    "features": features}, n=1)
  File "/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 128, in new_func
    return func(*args, **kwargs)
  File "/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py", line 644, in run_n
    restore_checkpoint_path=restore_checkpoint_path)
  File "/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 128, in new_func
    return func(*args, **kwargs)
  File "/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py", line 702, in run_feeds
    return list(run_feeds_iter(*args, **kwargs))
  File "/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py", line 692, in run_feeds_iter
    yield session.run(output_dict, f)
  File "/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 895, in run
    run_metadata_ptr)
  File "/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1321, in _do_run
    options, run_metadata)
  File "/home/binhnq/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Name: , Key: chars, Index: 1.  Number of int64 values != expected.  values size: 2 but output shape: [1]
	 [[Node: ParseSingleSequenceExample/ParseSingleSequenceExample = ParseSingleSequenceExample[Ncontext_dense=1, Ncontext_sparse=0, Nfeature_list_dense=3, Nfeature_list_sparse=0, Tcontext_dense=[DT_INT64], context_dense_shapes=[[]], context_sparse_types=[], feature_list_dense_shapes=[[1], [], []], feature_list_dense_types=[DT_INT64, DT_INT64, DT_INT64], feature_list_sparse_types=[]](arg0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty, ParseSingleSequenceExample/ParseSingleSequenceExample/context_dense_keys_0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_0, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_1, ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_keys_2, ParseSingleSequenceExample/Const, ParseSingleSequenceExample/ParseSingleSequenceExample/debug_name)]]