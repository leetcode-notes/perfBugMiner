Tensorflow Lite demo app with inception-v3/Mobilenet_v1 (float) model crashes

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 14.04
Python version: 3.4.3
Bazel version (if compiling from source): 0.5.4

Describe the problem
Device: Galaxy S8
I downloaded the "Inception V3 Slim 2016" from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/models.md . I pushed the imagenet_2015_label_strings.txt and the "inceptionv3_non_slim_2015.tflite" to the asset folder
I edited the ImageClassifier.java of tflite demo app. The changes are the followings:
private static final String MODEL_PATH = "/inceptionv3_non_slim_2015.tflite";
static final int DIM_IMG_SIZE_X = 299;
static final int DIM_IMG_SIZE_Y = 299;
The app hangs when it starts! (I could run the app with the default mobilenet quantized graph).
Similar is the case with mobilenet_v1_224_Float graph as well (the app hangs or crashes). I assume, the float model graph is not yet supported by TF Lite. However, in the documentation its written that it does support float for most operations. I am thinking the error is due to image pre-processing output and input size of float model grpah. The error log is stated below:
The Error log:
11-21 14:31:43.034 2111-2416/android.example.com.tflitecamerademo E/AndroidRuntime: FATAL EXCEPTION: CameraBackground
Process: android.example.com.tflitecamerademo, PID: 2111
java.lang.IllegalArgumentException: Failed to get input dimensions. 0-th input should have 1072812 bytes, but found 268203 bytes.
at org.tensorflow.lite.NativeInterpreterWrapper.getInputDims(Native Method)
at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:82)
at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)
at org.tensorflow.lite.Interpreter.run(Interpreter.java:93)
at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:112)
at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)
at com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)
at com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:558)
at android.os.Handler.handleCallback(Handler.java:751)
at android.os.Handler.dispatchMessage(Handler.java:95)
at android.os.Looper.loop(Looper.java:154)
at android.os.HandlerThread.run(HandlerThread.java:61)
Additional Questions:

On the app the the tensorflow lite graph format is ".tflite". However, on the documentation https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/g3doc/cmdline_examples.md the format is written as ".lite"