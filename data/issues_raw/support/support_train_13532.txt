tf.contrib.data.Dataset generated by slicing and dicing very large images

Hi
(writing here as requested by @mrry for further tf.contrib.data feature requests)
I would like to create a Dataset by cutting up and preprocessing very large images. I did this:
dataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(img_filelist))
dataset = dataset.flat_map(load_cut_up_and_process)

This goes out of memory because my function load_cut_up_and_process creates too many pieces from one image, all in memory. If I try to make a function that returns fewer pieces for an image and then want to call it repeatedly on the same image to get more, how can I achieve that with Dataset, without replicating the huge image in memory? The only thing I can think of is:
dataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(img_filelist))
dataset = dataset.flat_map(load_and_replicate_each_image) # Dataset is [im1, im1, im1, im2, im2, im2, im3, im3, im3, ...]
dataset = dataset.flat_map(cut_up_and_process_gently)

Now the second step goes out of memory because the implementation of load_and_replicate_each_image necessarily involves a tensor like [im, im, im] and multiple copies of the image will not fit. I also thought of this:
dataset = tf.contrib.data.Dataset.from_tensor_slices(tf.constant(img_filelist))
dataset = dataset.flat_map(replicate_each_filename) # Dataset is [imfname1, imfname1, imfname1, imfname2, imfname2, imfname2, imfname3, imfname3, imfname3, ...]
dataset = dataset.flat_map(load_cut_up_and_process_gently)

Which works, does not go out of memory, but now I am loading the same huge image multiple times in a row which is slow.
Any ideas ?