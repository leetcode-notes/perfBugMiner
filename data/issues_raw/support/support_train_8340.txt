How to adjust verbosity to suppress thousands of lines of informational logs?

Per #1258, here's my current import:
import os
os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '3'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
from keras.constraints import maxnorm
from keras.layers import Dense, Dropout
from keras.models import Sequential
from keras.wrappers.scikit_learn import KerasRegressor, KerasClassifier
However, as you can see if you look at a recent Travis build, there are still tens of thousands of lines of informational logs, like so:
Level 1:tensorflow:Registering Pack (<function _PackGrad at 0x7fc9c4ab3b70>) in gradient.
Level 1:tensorflow:Registering Unpack (<function _UnpackGrad at 0x7fc9c490d730>) in gradient.
Level 1:tensorflow:Registering Concat (<function _ConcatGrad at 0x7fc9c490d840>) in gradient.
Level 1:tensorflow:Registering ConcatV2 (<function _ConcatGradV2 at 0x7fc9c490d8c8>) in gradient.
Level 1:tensorflow:Registering ConcatOffset (None) in gradient.
Level 1:tensorflow:Registering Slice (<function _SliceGrad at 0x7fc9c490d9d8>) in gradient.

...

Level 1:tensorflow:  in  --> gradients_49/Relu_86_grad/ReluGrad:0
Level 1:tensorflow:  out --> gradients_49/add_896_grad/Reshape:0, gradients_49/add_896_grad/Reshape_1:0
Level 1:tensorflow:Gradient for 'MatMul_135'
Level 1:tensorflow:  in  --> gradients_49/add_896_grad/Reshape:0
Level 1:tensorflow:  out --> gradients_49/MatMul_135_grad/MatMul:0, gradients_49/MatMul_135_grad/MatMul_1:0
Level 1:tensorflow:Gradient for 'Relu_85'
Level 1:tensorflow:  in  --> gradients_49/MatMul_135_grad/MatMul:0
Level 1:tensorflow:  out --> gradients_49/Relu_85_grad/ReluGrad:0
Level 1:tensorflow:Gradient for 'add_895'

The docs are not obvious for how to adjust this.
Using Python and Keras, how can I adjust verbosity to ignore these logs?
Environment info
Operating System:
Linux and Mac
Using v1.0.1 on both platforms, installed directly from binary URLs