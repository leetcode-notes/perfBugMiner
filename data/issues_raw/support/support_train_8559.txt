forward pass projection

Hi,
Is there any way to define a layer that for forward-pass calculates its output by projecting the weight values into a different value range, but for the back-propagation uses the real weight values? i.e., as an example from the mnist.py file, if for the hidden layer 1 forward pass we could have hidden1 = tf.nn.relu(tf.matmul(images, projection_func(weights)) + biases), but for the gradient calculation during back-propagation the weights were updated without projection_func().
This would be useful to implement BNNs, to apply functions such as the ones mentioned by @Jony101K here.
Thanks.
Alexandre