Bug: Compile Tensorflow 1.5.0 Java from source failed on NVIDIA Jetson TX2 with error "'@bazel_tools//tools/jdk:singlejar' must produce a single file"

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04 aarch64
TensorFlow installed from (source or binary):
source on branch r1.5
TensorFlow version (use command below):
v1.5.0-1934-g9e7ce91 1.5.0
Python version:
Python 3.5
Bazel version (if compiling from source):
0.9.0 and 0.10.0 (both tried with clean installation)
GCC/Compiler version (if compiling from source):
gcc (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609
CUDA/cuDNN version:
CUDA 9.0, cuDNN 7.0
GPU model and memory:
NVIDIA Tegra X2 major (Pascalâ„¢ architecture) 8G
JDK Version:

root@tegra-ubuntu:/usr/src# java -version
openjdk version "1.8.0_151"
OpenJDK Runtime Environment (build 1.8.0_151-8u151-b12-0ubuntu0.16.04.2-b12)
OpenJDK 64-Bit Server VM (build 25.151-b12, mixed mode)

root@tegra-ubuntu:/usr/src# javac -version
javac 1.8.0_151


Exact command to reproduce:

root@tegra-ubuntu:/usr/src/tensorflow# ./configure
Extracting Bazel installation...
You have bazel 0.9.0- (@non-git) installed.
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3


Found possible Python library paths:
  /usr/local/lib/python3.5/dist-packages
  /usr/lib/python3/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]

Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: 
jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n
No Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: 
Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: 
No Apache Kafka Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: 
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: 
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: 
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 


Please specify the location where CUDA 9.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 


Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:


Do you wish to build TensorFlow with TensorRT support? [y/N]: 
No TensorRT support will be enabled for TensorFlow.

Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]6.2


Do you want to use clang as CUDA compiler? [y/N]: 
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 


Do you wish to build TensorFlow with MPI support? [y/N]: 
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding "--config=<>" to your build command. See tools/bazel.rc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=tensorrt    	# Build with TensorRT support.
Configuration finished
The output from compile procedure is
root@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni
.........................
ERROR: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/bazel_tools/tools/jdk/BUILD:193:17: in singlejar attribute of java_toolchain rule @bazel_tools//tools/jdk:toolchain: '@bazel_tools//tools/jdk:singlejar' must produce a single file
ERROR: Analysis of target '//tensorflow/java:tensorflow' failed; build aborted: Analysis of target '@bazel_tools//tools/jdk:toolchain' failed; build aborted
INFO: Elapsed time: 57.138s
FAILED: Build did NOT complete successfully (7 packages loaded)
    currently loading: tensorflow
You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
root@tegra-ubuntu:/usr/src# tensorflow/tools/tf_env_collect.sh
Collecting system information...
2018-02-03 09:51:47.561112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:865] ARM64 does not support NUMA - returning NUMA node zero
2018-02-03 09:51:47.561338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 0 with properties: 
name: NVIDIA Tegra X2 major: 6 minor: 2 memoryClockRate(GHz): 1.3005
pciBusID: 0000:00:00.0
totalMemory: 7.66GiB freeMemory: 465.56MiB
2018-02-03 09:51:47.561450: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1308] Adding visible gpu devices: 0
2018-02-03 09:51:48.341988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 52 MB memory) -> physical GPU (device: 0, name: NVIDIA Tegra X2, pci bus id: 0000:00:00.0, compute capability: 6.2)
Wrote environment to tf_env.txt. You can review the contents of that file.
and use it to populate the fields in the github issue template.

cat tf_env.txt

root@tegra-ubuntu:/usr/src# cat tf_env.txt

== cat /etc/issue ===============================================
Linux tegra-ubuntu 4.4.38-tegra #1 SMP PREEMPT Fri Dec 1 06:08:28 PST 2017 aarch64 aarch64 aarch64 GNU/Linux
VERSION="16.04.3 LTS (Xenial Xerus)"
VERSION_ID="16.04"
VERSION_CODENAME=xenial

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux tegra-ubuntu 4.4.38-tegra #1 SMP PREEMPT Fri Dec 1 06:08:28 PST 2017 aarch64 aarch64 aarch64 GNU/Linux

== check pips ===================================================
numpy (1.14.0)
protobuf (3.5.1)
tensorflow (1.5.0)
tensorflow-tensorboard (1.5.0)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.5.0
tf.GIT_VERSION = v1.5.0-1934-g9e7ce91
tf.COMPILER_VERSION = v1.5.0-1934-g9e7ce91
Sanity check: array([1], dtype=int32)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tensorflow/tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================
/usr/local/cuda-9.0/targets/aarch64-linux/lib/libcudart_static.a
/usr/local/cuda-9.0/targets/aarch64-linux/lib/libcudart.so.9.0.252
/usr/local/cuda-9.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7

You can obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
root@tegra-ubuntu:/usr/src# python3 -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
v1.5.0-1934-g9e7ce91 1.5.0

Describe the problem
I have successfully compiled tensorflow python from source using same configure procedure as above with the following command:
root@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

There is no error in output and I can install the .whl file with pip.
After that, I tried to compile the Java native library without the configure step (because I already configured it when compiling python version) using the command:
root@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni

It failed with errors:
root@tegra-ubuntu:/usr/src/tensorflow# bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni
.........................
ERROR: /root/.cache/bazel/_bazel_root/cbe8b06b94787a6b39e59564d90f2497/external/bazel_tools/tools/jdk/BUILD:193:17: in singlejar attribute of java_toolchain rule @bazel_tools//tools/jdk:toolchain: '@bazel_tools//tools/jdk:singlejar' must produce a single file
ERROR: Analysis of target '//tensorflow/java:tensorflow' failed; build aborted: Analysis of target '@bazel_tools//tools/jdk:toolchain' failed; build aborted
INFO: Elapsed time: 57.138s
FAILED: Build did NOT complete successfully (7 packages loaded)
    currently loading: tensorflow
Here are some ways I tried but faild with same error:

Configure again (With same configure settings) and compile
Remove the directory ~/.cache and do the step 1
Remove the directory ~/.cache and tensorflow source directory, git clone tensorflow from r1.5 branch then do step 1
Remove ~/.cache and the bazel binary, compile and install bazel from latest source release (0.10.0) without error. Then I use bazel 0.10.0 to compile tensorflow java. This produced same error.