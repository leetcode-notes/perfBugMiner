Behavior of SVM in tensorflow.contrib.learn.python.learn.estimators inconsistent between dense and sparse inputs

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Arch Linux
TensorFlow installed from (source or binary):
Binary (community arch linux repo)
TensorFlow version (use command below):
1.3.0-1
Python version:
3.6.2
Bazel version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:

Describe the problem
I'm trying to use the SVM in tensorflow.contrib.learn with sparse input. The minimal test with real dense valued column works. However when I try to reproduce the exact same classification problem but wrapped in sparse feature columns with sparse_columns_with_integerized_features and weighted_sparse_columns, it fails. It might be a misuse of the sparse columns from me but I've spent a good amount of time reading the doc and the source code without understanding why.
Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
# TEST WITH REAL VALUED COLUMNS THAT WORKS
def input_fn():
  return {
      'example_id': constant_op.constant(['1', '2', '3']),
      'feature1': constant_op.constant([[0.0], [1.0], [3.0]]),
      'feature2': constant_op.constant([[1.0], [-1.2], [1.0]]),
  }, constant_op.constant([[1], [0], [1]])

feature1 = feature_column.real_valued_column('feature1')
feature2 = feature_column.real_valued_column('feature2')
svm_classifier = svm.SVM(feature_columns=[feature1, feature2],
                         example_id_column='example_id',
                         l1_regularization=0.0,
                         l2_regularization=0.0)
svm_classifier.fit(input_fn=input_fn, steps=30)
metrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)
loss = metrics['loss']  # 0 as expected
accuracy = metrics['accuracy']  # 1 as expected

# TEST WITH SAME VALUES BUT SPARSE COLUMNS, FAILS
def input_fn():
  return {
      'example_id': constant_op.constant(['1', '2', '3']),
      'feature1_id': tf.SparseTensor(
                      indices=tf.constant([[0,0],[1,0],[2,0]], dtype=tf.int64),
                      values=tf.constant([0, 0, 0], dtype=tf.int64),
                      dense_shape=[3,1],
                      ),
      'feature2_id': tf.SparseTensor(
                      indices=tf.constant([[0,0],[1,0],[2,0]], dtype=tf.int64),
                      values=tf.constant([0, 0, 0], dtype=tf.int64),
                      dense_shape=[3,1],
                      ),
      'feature1_w': tf.SparseTensor(
                      indices=[[0,0],[1,0],[2,0]],
                      values=[0.0, 1.0, 3.0],
                      dense_shape=[3,1]
                      ),
      'feature2_w': tf.SparseTensor(
                      indices=[[0,0],[1,0],[2,0]],
                      values=[1.0, -1.2, 1.0],
                      dense_shape=[3,1]
                      )
      }, constant_op.constant([[1], [0], [1]])

feature1_id = feature_column.sparse_column_with_integerized_feature('feature1_id',
                                                                    bucket_size=2,)
feature2_id = feature_column.sparse_column_with_integerized_feature('feature2_id',
                                                                    bucket_size=2,)
feature1_w = feature_column.weighted_sparse_column(feature1_id, 'feature1_w')
feature2_w = feature_column.weighted_sparse_column(feature2_id, 'feature2_w')

svm_classifier = svm.SVM(feature_columns=[feature1_w, feature2_w],
                         example_id_column='example_id',
                         l1_regularization=0.0,
                         l2_regularization=0.0)
svm_classifier.fit(input_fn=input_fn, steps=30)
metrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)
loss = metrics['loss'] # should be 0 but is 0.36363636
accuracy = metrics['accuracy'] # should be 1 but is 0.666667

# TEST WITH SPARSE COLUMNS IN ONE FEATURE COLUMN, SAME RESULTS
def input_fn():
  return {
      'example_id': constant_op.constant(['1', '2', '3']),
      'feature1_id': tf.SparseTensor(
                      indices=tf.constant([[0,0],[0,1],[1,0],[1,1],[2,0],[2,1]], dtype=tf.int64),
                      values=tf.constant([0, 1, 0, 1, 0, 1], dtype=tf.int64),
                      dense_shape=[3,2],
                      ),
      'feature1_w': tf.SparseTensor(
                      indices=[[0,0],[0,1],[1,0],[1,1],[2,0],[2,1]],
                      values=[0.0, 1.0, 1.0, -1.2, 3.0, 1.0],
                      dense_shape=[3,2],
                      )
      }, constant_op.constant([[1], [0], [1]])

feature1_id = feature_column.sparse_column_with_integerized_feature('feature1_id',
                                                                    bucket_size=2,)
feature1_w = feature_column.weighted_sparse_column(feature1_id, 'feature1_w')

svm_classifier = svm.SVM(feature_columns=[feature1_w],
                         example_id_column='example_id',
                         l1_regularization=0.0,
                         l2_regularization=0.0)
svm_classifier.fit(input_fn=input_fn, steps=30)
metrics = svm_classifier.evaluate(input_fn=input_fn, steps=1)
loss = metrics['loss']
accuracy = metrics['accuracy']