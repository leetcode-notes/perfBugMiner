Saving Estimators, loading from checkpoints and accessing placeholders.

I posted this question here on stackoverflow (https://stackoverflow.com/questions/50011969/tensorflow-estimator-api-input-tensor-names) and someone else posted a similar question earlier (https://stackoverflow.com/questions/48335699/tensorflow-what-are-the-input-nodes-for-tf-estimator-models), yet no satisfying answers.
When using an estimator in tensorflow and passing the inputs using tf.estimator.inputs.numpy_input_function(), I would like to find a way to access the input placeholders (one for features and one for labels).
I train the model using tf.estimator.estimator.train() and save the checkpoint files in model_dir.
Later, I would like to load the model and variables using the following snippet:
sess = tf.Session()
saver = tf.train.import_meta_graph(model_dir+'/model.ckpt-1.meta')
saver.restore(sess, tf.train.latest_checkpoint(model_dir))
predictions = graph.get_tensor_by_name('softmax_tensor:0')
Then do sess.run(predictions,....). But there's no way to pull out the inputs' placeholder for the feed_dict parameter of sess.run().
Another related issue I have: I would also like to add placeholders to an estimator other than the features and labels placeholders. For example if I have dropout, I would like the dropout_rate or the tf.layers.dropout() function's training param to be placeholders. This way after loading the model from chkpt as above, I can turn off dropout.
Have I written custom code Y
OS Platform and Distribution Ubuntu 18.04
TensorFlow installed from pip
TensorFlow version r1.8.0
Bazel version N/A
CUDA/cuDNN version 9.0/7.0.1
GPU model and memory GTX 1080TI
Exact command to reproduce N/A