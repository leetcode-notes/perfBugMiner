Distributed inception stuck at tf.initialize_all_variables()

I'm running distributed training of Inception but its behavior is unpredictable and time to time the chief node stuck at (I found out the line through adding logs for every line):
tensorflow/tensorflow/python/training/session_manager.py:233
sess.run(init_op, feed_dict=init_feed_dict)

The init_op is assigned to tf.initialize_all_variables() in Inception distributed training. As I mentioned, the behavior is random and it only happens time to time.
Has anyone else has this issues?
I'm running the latest version of TF compiled from source + cuda 7.5 + cudnn 5.1.3