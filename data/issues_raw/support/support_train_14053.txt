Bug when using estimator with tf.data.Dataset.from_tensor_slices

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10
TensorFlow installed from (source or binary):binary
TensorFlow version (use command below):1.5.0-dev20171026
Python version: 3.6.3

Describe the problem
When I use tf.data and from_tensor_slices with estimator to build dataset from ndarray, tf.estimator will use much memory(peak 6900MB, final 4600MB with simple mnist cnn) and create very huge event filesï¼š
events.out.tfevents 1.28GB
graph.pbtxt: 1.20GB
model.ckpt-1.meta: 370MB
Then I use cifar10 input pipeline from resnet as input_fn, everything back to normal.
Source code / logs
replace code in notebook cell 6 with code below.
def ndarray_iters(datas,
                batch_size):
    dataset = tf.data.Dataset.from_tensor_slices(tuple(datas))
    batched_dataset = dataset.batch(batch_size)
    iterator = batched_dataset.make_one_shot_iterator()
    next_iters = list(iterator.get_next())
    return next_iters
def train_input_fn():
    imgs, labels = ndarray_iters([mnist.train.images, mnist.train.labels], 128)
    return {'images': imgs}, labels
model.train(train_input_fn, steps=1000)