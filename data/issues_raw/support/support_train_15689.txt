TensorFlowInferenceInterface: readNodeFloat error

This is part of my Tensorflow frozen graph, I have named the input and output nodes.
>>> g.ParseFromString(open('frozen_graph.pb','rb').read())
>>> g
node {
  name: "input"
  op: "Placeholder"
  attr {
    key: "dtype"
    value {
      type: DT_FLOAT
    }
  }
  attr {
    key: "shape"
    value {
      shape {
        dim {
          size: -1
        }
        dim {
          size: 68
        }
      }
    }
  }
}
...
node {
  name: "output"
  op: "Softmax"
  input: "add"
  attr {
    key: "T"
    value {
      type: DT_FLOAT
    }
  }
}

I ran this model by the following code
(CELL is name of directory where my file is located)
final String MODEL_FILE = "file:///android_asset/" + CELL + "/optimized_graph.pb" ;
final String INPUT_NODE = "input" ;
final String OUTPUT_NODE = "output" ;
final int[] INPUT_SIZE = {1,68} ;
float[] RESULT = new float[8];

inferenceInterface = new TensorFlowInferenceInterface();
inferenceInterface.initializeTensorFlow(getAssets(),MODEL_FILE) ;
inferenceInterface.fillNodeFloat(INPUT_NODE,INPUT_SIZE,input);

and finally
inferenceInterface.readNodeFloat(OUTPUT_NODE,RESULT);

But I get this error in Log
12-28 16:42:48.622 9890-12178/com.getfocus.signalsimilarity I/native: tensorflow_inference_jni.cc:151 Initialization done in 52.275ms
12-28 16:42:51.048 9890-12178/com.getfocus.signalsimilarity E/native: tensorflow_inference_jni.cc:170 Output [output] not found, aborting!

I have searched a lot for the solution but nothing seems to solve this. Thanks in advance