Android tensorflow lite kernel_util.cc:34 input_product_scale < output_scale

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 7.0
TensorFlow installed from (source or binary):
TensorFlow version (use command below):
Python version: 3.0
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:

Describe the problem
1.down load Quantilized MobileNet model 0.75_224 from here
2.Transform the frozen .pb model to .tflite file:
bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=tmp/mobilenet_v1_0.75_224/frozen_graph.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=tmp/mobilenet_v1_0.75_224/mobilenet_v1_0.75_224.tflite --inference_type=QUANTIZED_UINT8  --input_type=QUANTIZED_UINT8  --input_arrays=input --default_ranges_min=0 --default_ranges_max=6 --output_arrays=MobilenetV1/Predictions/Reshape_1 --input_shapes=1,224,224,3
3.Change the "MODEL_PATH" in Tensorflow lite Android demo to "mobilenet_v1_0.75_224.tflite"
logs
4.Then run the demo, make the error:
FATAL EXCEPTION: CameraBackground
Process: android.example.com.tflitecamerademo, PID: 13909
java.lang.NullPointerException: Can not allocate memory for the given inputs: tensorflow/contrib/lite/kernels/kernel_util.cc:34 input_product_scale < output_scale was not true.
at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)
at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:95)
at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:112)
at org.tensorflow.lite.Interpreter.run(Interpreter.java:93)
at com.example.android.tflitecamerademo.ImageClassifier.classifyFrame(ImageClassifier.java:109)
at com.example.android.tflitecamerademo.Camera2BasicFragment.classifyFrame(Camera2BasicFragment.java:663)
at com.example.android.tflitecamerademo.Camera2BasicFragment.-wrap0(Camera2BasicFragment.java)
at com.example.android.tflitecamerademo.Camera2BasicFragment$4.run(Camera2BasicFragment.java:558)
at android.os.Handler.handleCallback(Handler.java:739)
at android.os.Handler.dispatchMessage(Handler.java:95)
at android.os.Looper.loop(Looper.java:135)
at android.os.HandlerThread.run(HandlerThread.java:61)
need your help?
Followed the same steps , transform other mobilenet models, only the  "mobilenet_v1_1.0_128" can run successfully.