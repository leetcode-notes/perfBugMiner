using ExponentialMovingAverage differs in CPU & GPU

I use BN in cnn,here is the code
def batch_norm(x, beta, gamma, train_phase, scope='bn', decay=0.9, eps=1e-5):

    with tf.variable_scope(scope):        
        batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], name='moments')
        ema = tf.train.ExponentialMovingAverage(decay=decay)

        def mean_var_with_update():
            ema_apply_op = ema.apply([batch_mean, batch_var])
            with tf.control_dependencies([ema_apply_op]):
                return tf.identity(batch_mean), tf.identity(batch_var)

        mean, var = tf.cond(train_phase, mean_var_with_update, lambda: (ema.average(batch_mean), ema.average(batch_var)))
        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, eps)
    return normed

when i print variables in CPU & GPU, it differs:
In CPU it shows:
bn_1/bn_1/moments/Squeeze/ExponentialMovingAverage (DT_FLOAT) [32] bn_1/bn_1/moments/Squeeze_1/ExponentialMovingAverage (DT_FLOAT) [32] bn_2/bn_2/moments/Squeeze/ExponentialMovingAverage (DT_FLOAT) [64] bn_2/bn_2/moments/Squeeze_1/ExponentialMovingAverage (DT_FLOAT) [64] bn_3/bn_3/moments/Squeeze/ExponentialMovingAverage (DT_FLOAT) [64] bn_3/bn_3/moments/Squeeze_1/ExponentialMovingAverage (DT_FLOAT) [64] bn_4/bn_4/moments/Squeeze/ExponentialMovingAverage (DT_FLOAT) [64] bn_4/bn_4/moments/Squeeze_1/ExponentialMovingAverage (DT_FLOAT) [64]
while in GPU it shows:
bn_1/bn_1/moments/moments_1/mean/ExponentialMovingAverage (DT_FLOAT) [32] bn_1/bn_1/moments/moments_1/variance/ExponentialMovingAverage (DT_FLOAT) [32] bn_2/bn_2/moments/moments_1/mean/ExponentialMovingAverage (DT_FLOAT) [64] bn_2/bn_2/moments/moments_1/variance/ExponentialMovingAverage (DT_FLOAT) [64] bn_3/bn_3/moments/moments_1/mean/ExponentialMovingAverage (DT_FLOAT) [64] bn_3/bn_3/moments/moments_1/variance/ExponentialMovingAverage (DT_FLOAT) [64] bn_4/bn_4/moments/moments_1/mean/ExponentialMovingAverage (DT_FLOAT) [64] bn_4/bn_4/moments/moments_1/variance/ExponentialMovingAverage (DT_FLOAT) [64]
therefore, when i load a CPU-trainned ckeckpoint in GPU, it turns out some errors like "variables not found in file" etc. Can someone solve this problem? thanks a lot.