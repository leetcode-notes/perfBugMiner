TFrecord reading time very high

#I have divided a dataset into 10 tfrecords files and I want to read 100 data points from each to create a batch of 10 sequence of 100 data points. I use the following function to do that. The data loading time from the tfrecords start off slow and then reaches to around 0.65s and after 100-200 sess.run calls it increases to around 10s. Can you please point out any mistake or suggestion which might help to reduce the read time ? Also, the behaviour I mentioned becomes more erratic sometimes.
def get_data(mini_batch_size):
  data = []
  for i in range(mini_batch_size):
    filename_queue = tf.train.string_input_producer([data_path + 'Features' + str(i) + '.tfrecords'])
    reader = tf.TFRecordReader()
    _, serialized_example = reader.read(filename_queue)
    batch_serialized_example = tf.train.batch([serialized_example], batch_size=step_size, num_threads=8, capacity=step_size)
    features = tf.parse_example(batch_serialized_example,features={'feature_raw': tf.VarLenFeature(dtype=tf.float32)})
    feature = features['feature_raw'].values
    feature = tf.reshape(feature,[step_size, ConvLSTM.H, ConvLSTM.W, ConvLSTM.Di])
    data.append(feature)
  return tf.stack(data)