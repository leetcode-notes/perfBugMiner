ResourceExhausted

I get the following error when running in GPU on AWS p2-xlarge:
I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1205162d00 of size 256
I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x120517b100 of size 73984
I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a5ba00 of size 96000
I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a8a800 of size 96000
I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215affb00 of size 263424
I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: 
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 24 Chunks of size 256 totalling 6.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 13 Chunks of size 512 totalling 6.5KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 12 Chunks of size 1280 totalling 15.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 1792 totalling 8.8KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2560 totalling 2.5KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 3584 totalling 17.5KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6144 totalling 6.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 25600 totalling 200.0KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 29184 totalling 28.5KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1386 Chunks of size 96000 totalling 126.89MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 131328 totalling 128.2KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 233 Chunks of size 192000 totalling 42.66MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 7 Chunks of size 204800 totalling 1.37MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 232192 totalling 226.8KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 257792 totalling 251.8KiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2640128 totalling 2.52MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 19200000 totalling 91.55MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 265.87MiB
I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: 
Limit:                   279314432
InUse:                   278784768
MaxInUse:                278976768
NumAllocs:                    4097
MaxAllocSize:             19200000

W tensorflow/core/common_runtime/bfc_allocator.cc:274] ****************************************************************************************************
W tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 375.0KiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:975] Resource exhausted: OOM when allocating tensor with shape[300,320]
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3720 get requests, put_count=1106 evicted_count=1000 eviction_rate=0.904159 and unsatisfied allocation rate=0.998387
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110

I'm using TensorFlow R0.12.1 and Session code is:
# Launch the graph
config = tf.ConfigProto(log_device_placement=True)
config.gpu_options.allocator_type = 'BFC'
sess = tf.Session(config = config)
init = tf.global_variables_initializer()
sess.run(init)
timestart = datetime.datetime.now() # Start time in seconds
timeprev  = datetime.datetime.now() # Start time in seconds
countprev = 0
ratelist = []
boxcarcount = 10
X_train = X_train.astype(np.float32)  # Cast to float32 from float64

print("Starting training...")
# Perform Training steps with "batch_size" iterations at each loop
step = 1
while step * batch_size <= training_iters:
    # Note: type(X_train) = float32
    # Note: type(y_train) = int32
    # Note: type(step)       = int
    # Note: type(batch_size) = int
    batch_xs =         extract_batch_size(X_train, step, batch_size)
    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size),LabelMax)

    # Fit training using batch data
    output, loss, acc = sess.run(
        [optimizer, cost, accuracy],
        feed_dict={
            Xin   : batch_xs, 
            Ytrue : batch_ys,
            keep_prob: DO_keep_prob
        }
    )
    train_losses.append(loss)
    train_accuracies.append(acc)

My question: is there a way to allocate more memory in the GPU?
This seems like a really small data set to be using?!?!?
Thanks.