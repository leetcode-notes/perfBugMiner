Is there a way of 'cutting' a network?

I wonder if there is a way of 'cutting' the network. What I want to achieve is fine-tuning of the whole inception v3 network and then implement transfer learning by replacing the last 2 inception modules with new layers. I did the whole fine-tuning using this code https://github.com/tensorflow/models/tree/master/inception on my own dataset taking the last checkpoint that I need but now I don't know how I can implement the transfer learning by taking the output of 8th inception module and train the new layers. Is there a standard tensorflow-way of doing this operation?