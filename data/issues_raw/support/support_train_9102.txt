Problems freezing the graph

Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?:
Please see below for how to replicate the problems. Zip attachment contains two pieces of very small code.
TensorFlow installed from (source or binary)?:
binary - 1.1
TensorFlow version:
1.1
Bazel version (if compiling from source):
Not applicable
CUDA/cuDNN version:
Recent but not latest.  8.0, V8.0.44
GPU Model and Memory:
Tesla K20 4 GB
Exact command to reproduce:
See below....

Describe the problem clearly
We have a problem related to saving the operations as constants while freezing using the algorithm in the attached files.
The problem can be easily replicated by trying to freeze the graphs generated by the toy example in textsum https://github.com/tensorflow/models/tree/master/textsum .
Models are trained with the following command:
bazel-bin/textsum/seq2seq_attention --mode=train --article_key=article --abstract_key=abstract --data_path=textsum/data/data --vocab_path=textsum/data/vocab --log_root=textsum/log_root --train_dir=textsum/log_root/train
Then freeze_2_textsum.py is called with the following syntax:
python freeze_2_textsum.py
Command in our case was:
python freeze_2_textsum.py --model_folder=./log_root/ --outputnodes=global_step
In this case, we are able to find the saved constants in the frozen_model.pb file.
But when we try the same syntax for the trained graph in our project, we could not find the constants in the frozen model.pb file, while the freeze_2_textsum.py script prints the log message that "13 ops were converted to constants"
This problem leads to the following error while running the session in our test script:
"Attempting to use uninitialized value model/generate_embedding_RNN_output/BiRNN/BW/BasicLSTMCell/Linear/Bias"
cmd line for test script:
python test_tf_frozen_txtsum.py
Source Code / Logs
Freezing_problem.zip