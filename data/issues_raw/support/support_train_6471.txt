how to custom learning rate decay policy ?

as it shown in the learning rate deay API doc , there are only 4 kinds of policies. but in caffe  policies are as follows:

//    - fixed: always return base_lr.
//    - step: return base_lr * gamma ^ (floor(iter / step))
//    - exp: return base_lr * gamma ^ iter
//    - inv: return base_lr * (1 + gamma * iter) ^ (- power)
//    - multistep: similar to step but it allows non uniform steps defined by
//      stepvalue
//    - poly: the effective learning rate follows a polynomial decay, to be
//      zero by the max_iter. return base_lr (1 - iter/max_iter) ^ (power)
//    - sigmoid: the effective learning rate follows a sigmod decay

in issue #2922 they mentioNed on write a warpper for the existing method, but they did not implemented anything new ?  for example the inv [base_lr * (1 + gamma * iter) ^ (- power)] policy in caffe.
so I wonder if there anyone who can help me out how to custom learning rate decay policy by myself, any suggestions will be sincerely gratitude.