Numeric stability CPU vs GPU

Numerical stability CPU vs GPU
My lab partner and I found that in some cases, our scripts would run into numerical instability issues when using GPU, while they would run fine using a CPU. To minimally reproduce this issue, we've come up with the following script:
import tensorflow as tf
import numpy as np

if __name__ == "__main__":

    t = tf.placeholder(tf.float32, [])
    division = tf.constant(1, dtype='float32') / tf.pow(1.5, -t)

    sess = tf.Session()
    for count in range(100000000):
        val = sess.run(division, feed_dict={t: count})

        if np.isnan(val) or np.isinf(val) or val < 0:
            print(count)
            break

If we run this with CUDA_VISIBLE_DEVICES="", we see that the script reaches 219 steps before being either nan or inf. If we use GPU instead, we see that the script reaches only 216 steps before being either nan or inf.
Operating system
Ubuntu 16.04
Installed version of CUDA and cuDNN:
-rw-r--r-- 1 root root   560184 sep 11  2016 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 sep 11  2016 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 sep 11  2016 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 sep 11  2016 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 sep 11  2016 /usr/local/cuda-8.0/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 79337624 nov  5 12:57 /usr/local/cuda-8.0/lib64/libcudnn.so
-rwxr-xr-x 1 root root 79337624 nov  5 12:57 /usr/local/cuda-8.0/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 79337624 nov  5 12:57 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 nov  5 12:57 /usr/local/cuda-8.0/lib64/libcudnn_static.a

Tensorflow version (from binary):
0.12.0