Function categorical_column_with_identity with big number as num_buckets parameter causes training hang and crash

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.12.6
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): ('v1.3.0-rc2-20-g0787eee', '1.3.0')
Python version: 2.7
Bazel version (if compiling from source):
CUDA/cuDNN version: not use GPU
GPU model and memory: no GPU
Exact command to reproduce:

Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
When I try to use use_id or item_id as an feature and process it through function categorical_column_with_identity, because of the id category will be very big out of upper limit of int32, the training job will hang a few minutes then crash.  The crash without any useful information to reminder that this problem was caused by the num_buckets=${a_big_number}.
Maybe this kinds of feature like uid or item_id should not be used like this, and I believe if there are some diagnostics information will be better.
And any suggestions about how to process this kinds of feature like uid or item_id, these features are very big number. I think this problem appeared in many cases.
Thanks
Source code / logs
# coding: utf-8
import tensorflow as tf
from tensorflow import feature_column as fc

f = fc.embedding_column(
    fc.categorical_column_with_identity(key='vid', num_buckets=1500000000),
    dimension=10)
e = tf.estimator.DNNClassifier(
    feature_columns=[f],
    hidden_units=[10])


def input_fn():
    return (
        {"vid": tf.identity(tf.constant(
            [1000, 1000, 100, 1000, 10000, 1000, 1000, 1000, 100],
            name="vid"), name="vid_trainning")},
        tf.constant([1, 0, 1, 0, 0, 0, 0, 0, 1])
    )

e.train(input_fn, steps=10)