A very weird bug of tf_debug: Non-Ok-status env->NewWritableFile(file_path, &f) status: Resource exaustated

System information

Have I written custom code:  Yes
OS Platform and Distribution: CentOS
TensorFlow installed from (source or binary): binary
TensorFlow version: 1.2
Python version:  3.4

When I run the seq2seq model, I got the nan loss. Thus I use tf_debug to find out where the problem occurs. I use tf_debug by
sv = tf.train.Supervisor(logdir=FLAGS.log_root,
                         is_chief=True,
                         saver=saver,
                         summary_op=None,
                         save_summaries_secs=60,
                         save_model_secs=FLAGS.checkpoint_secs)
sess = sv.prepare_or_wait_for_session(config=tf.ConfigProto(
    allow_soft_placement=True))
sess = tf_debug.LocalCLIDebugWrapperSession(sess)
sess.add_tensor_filter("has_inf_or_nan", tf_debug.has_inf_or_nan)

But it got such logs and exit:
tfdebug Non-OK-status: env->NewWritableFile(file_path, &f) status: Resource exaustated: /tmp/tfdbg_9_gcc3sc/gradients/output/Reshape_1_grad/Reshape_0_DebugIdentity_150023213
Aborted (core dumped)

I think it is kind of issue related to tf_debug and it may be new, since I can not find anything when I google the error.