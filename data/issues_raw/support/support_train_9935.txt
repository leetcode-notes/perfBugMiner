Unable to freeze Keras layers in a Tensorflow workflow.

I'm trying to freeze Keras layers in a Tensorflow workflow. It seems that the flag trainable does not work in tf.contrib.keras. This is how I define the graph :
sess = tf.Session()
K.set_session(sess)
labels = tf.placeholder(tf.float32, shape=(None, 1))
user_id_input = tf.placeholder(tf.float32, shape=(None, 1))
item_id_input = tf.placeholder(tf.float32, shape=(None, 1))
max_user_id = all_ratings['user_id'].max()
max_item_id = all_ratings['item_id'].max()
embedding_size = 30
user_embedding = Embedding(output_dim=embedding_size, input_dim=max_user_id+1, input_length=1, name='user_embedding', trainable=all_trainable)(user_id_input)
item_embedding = Embedding(output_dim=embedding_size, input_dim=max_item_id+1, input_length=1, name='item_embedding', trainable=all_trainable)(item_id_input)
user_vecs = Flatten()(user_embedding)
item_vecs = Flatten()(item_embedding)
input_vecs = concatenate([user_vecs, item_vecs])
x = Dense(30, activation='relu')(input_vecs)
x1 = Dropout(0.5)(x)
x2 = Dense(30, activation='relu')(x1)
y = Dense(1, activation='sigmoid')(x2)
loss = tf.reduce_mean(binary_crossentropy(labels, y))
train_step = tf.train.AdamOptimizer(0.004).minimize(loss)
Then I just train the model :
with sess.as_default():
train_step.run(..)
Everything is working fine when the trainable flag is set to True. Then when I set it to False, it does not freeze the layers.
I also tried to minimize only over the variable that I want to train by using train_step_freeze = tf.train.AdamOptimizer(0.004).minimize(loss, var_list=[user_embedding]), and I get :
('Trying to optimize unsupported type ', <tf.Tensor 'Placeholder_33:0' shape=(?, 1) dtype=float32>)
Is it possible to use Keras layers in Tensorflow and freeze them ?