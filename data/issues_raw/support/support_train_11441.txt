wide_n_deep Tutorial processing large data

I am a freshman of tensorflow, and want to use the wide & deep network.
I see the code of wide_n_deep tutorial, find that in "def train_and_eval()" function reading the total data using pandas at once.
I confuse if the data is large maybe 5 GB or more, and I cannot read all the data in memory, and how can I processing it?
Thank you~~~