Moving average and moving variance in Batchnorm aren't updated

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 1.2.1
Python version:  3.5.3
Bazel version (if compiling from source): None
CUDA/cuDNN version: 8/5.1
GPU model and memory: GeForce 1080
Exact command to reproduce:

Describe the problem
I'm using the slim wrapper, which in turn returns an instance of BatchNormalization from layers/normalisation.py. All paramers are set to default, except for scale which is set to True (i.e. adding the gamma scaler). After training, when looking the at the learned parameters, I notice that all the moving means in the network are still 0 while all the moving variances are 1, i.e. they weren't updated.
Both variables don't show up in tf.trainable_variables() which might explain the lack of updates. However, since these are not actually learned but rather calculated, I'm not sure whether they would be updated by the optimiser.