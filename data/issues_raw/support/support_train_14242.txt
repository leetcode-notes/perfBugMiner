Concert keras model to tf.Keras model

here is my original keras model
def inference(image_tensor):
# the input size is 90303
x = Conv2D(32,(3,3),name='conv1')(image_tensor)
x = MaxPool2D((2,2),name='pool1')(x)
x = BatchNormalization(name='bn1')(x)
x = Activation('relu')(x)
x = Conv2D(64,(3,3),name='conv2')(x)
x = MaxPool2D((2, 2),name='pool2')(x)
x = BatchNormalization(name='bn2')(x)
x = Activation('relu')(x)

x = Conv2D(64,(3,3), name='conv3')(x)
x = MaxPool2D((2, 2), name='pool3')(x)
x = BatchNormalization(name='bn3')(x)
x = Activation('relu')(x)

x = Flatten(name='flatte1',inputs=x)

x = Dense(256,name='fc1')(x)

# max_length of sentence
x = RepeatVector(7,name='repeat')(x)

#2*GRU the output shape is (None,7,256)
x = Bidirectional(GRU(units=128,name='GRU',return_sequences=True))(x)

#apply (None,7,256) to all GRUs output (None,7,16)
x = TimeDistributed(Dense(16,name='fc2'))(x)
x = Activation('softmax')(x)
x = Flatten(name='Flatten2',inputs=x)

when I show my summary, it print like this

Layer (type)                 Output Shape              Param #
input_1 (InputLayer)         (None, 90, 30, 3)         0

conv1 (Conv2D)               (None, 88, 28, 32)        896

pool1 (MaxPooling2D)         (None, 44, 14, 32)        0

bn1 (BatchNormalization)     (None, 44, 14, 32)        128

activation_1 (Activation)    (None, 44, 14, 32)        0

conv2 (Conv2D)               (None, 42, 12, 64)        18496

pool2 (MaxPooling2D)         (None, 21, 6, 64)         0

bn2 (BatchNormalization)     (None, 21, 6, 64)         256

activation_2 (Activation)    (None, 21, 6, 64)         0

conv3 (Conv2D)               (None, 19, 4, 64)         36928

pool3 (MaxPooling2D)         (None, 9, 2, 64)          0

bn3 (BatchNormalization)     (None, 9, 2, 64)          256

activation_3 (Activation)    (None, 9, 2, 64)          0

flatte1 (Flatten)            (None, 1152)              0

fc1 (Dense)                  (None, 256)               295168

repeat (RepeatVector)        (None, 7, 256)            0

bidirectional_1 (Bidirection (None, 7, 256)            295680

time_distributed_1 (TimeDist (None, 7, 16)             4112

Flatten2 (Flatten)           (None, 112)               0
but when I change my codes to tf.keras like this(the architecture do not change! )

repeat (RepeatVector)        (None, 7, 256)            0

bidirectional_1 (Bidirection (None, None, 256)         295680

time_distributed_1 (TimeDist (None, None, 16)          4112

activation_4 (Activation)    (None, None, 16)          0

Flatten2 (Flatten)           (None, None)              0
Total params: 651,920
Trainable params: 651,600
Non-trainable params: 320

the output of bidirectional_1 is (None, None, 256), I just wonder why the GRU output was flase.
And how can I change my code?
Thanks a lot!