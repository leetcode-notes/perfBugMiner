Incorrect GPU memory usage

with tf.device('/gpu:0') :
	with tf.variable_scope('network1') :
		x = tf.get_variable('inp1',shape = [256,50,50,3],dtype = tf.float32)
		w1 = tf.get_variable('weight1',shape = [1,1,3,256],dtype = tf.float32)
		y1 = tf.nn.conv2d(x, w1, strides=[1, 1, 1, 1], padding='VALID')
		w1 = tf.get_variable('weight2',shape = [1,1,256,256],dtype = tf.float32)
		y1 = tf.nn.conv2d(y1, w1, strides=[1, 1, 1, 1], padding='VALID')
		w1 = tf.get_variable('weight3',shape = [1,1,256,1],dtype = tf.float32)
		y1 = tf.nn.conv2d(y1, w1, strides=[1, 1, 1, 1], padding='VALID')
	

with tf.device('/gpu:0') :
	with tf.variable_scope('network2') :
		x1 = tf.get_variable('inp2',shape = [1,3],dtype = tf.float32)
		w2 = tf.get_variable('weight4',shape = [3,8192],dtype = tf.float32)
		y2 = tf.matmul(x1,w2)
		w2 = tf.get_variable('weight5',shape = [8192,8192],dtype = tf.float32)
		y2 = tf.matmul(y2,w2)
		w2 = tf.get_variable('weight6',shape = [8192,1],dtype = tf.float32)
		y2 = tf.matmul(y2,w2)

If I have the above model graph, then running it on a GPU and checking memory usage via nvidia-smi shows usage of 4200MB . However when running only the network1 and commenting out network2, nvidia-smi shows usage of 2200 MB. With only network2, it shows usage of 700MB.I have already set gpu_options.allow_growth = True
How is then the total graph using 4200 MB when it should have used only 2900(2200 + 700)MB ?
I am using Ubuntu 14.04, python version - 2.7 , tensorflow version - 1.2