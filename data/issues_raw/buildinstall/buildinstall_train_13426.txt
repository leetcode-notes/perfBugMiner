//tensorflow/contrib/android:libtensorflow_inference.so build fails when compiling @protobuf//:protobuf

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Docker image gcr.io/tensorflow/tensorflow:1.3.0-devel
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): 1.3.0
Python version: Python 2.7.12
Bazel version (if compiling from source): 0.5.0

Output from tf_env_collect.sh is at the end of this report.
Describe the problem
I'm trying to follow the instructions in print_selective_registration_header.py to create a smaller TensorFlow binary size.
Part of those instructions involves building //tensorflow/contrib/android:libtensorflow_inference.so, but that build fails every time.
I'm doing this in the gcr.io/tensorflow/tensorflow:1.3.0-devel Docker container (not sure if this is appropriate because I can't find documentation explaining what each container is for).  I tried to use the 1.3.0 container, but that doesn't contain the TensorFlow repo or git.
Source code / logs
Here are the steps I took (the first steps succeeded so I have not included their output):
$ docker run -it -v $HOME/TF:/TF gcr.io/tensorflow/tensorflow:1.3.0-devel bash

# bazel build tensorflow/python/tools:print_selective_registration_header

# bazel-bin/tensorflow/python/tools/print_selective_registration_header --graphs=/TF/mnist_model_graph.pb > ops_to_register.h

# bazel build -c opt --copt="-DSELECTIVE_REGISTRATION" --copt="-DSUPPORT_SELECTIVE_REGISTRATION" //tensorflow/contrib/android:libtensorflow_inference.so     --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --verbose_failures
INFO: Reading 'startup' options from /etc/bazel.bazelrc: --batch
WARNING: /tensorflow/tensorflow/core/BUILD:935:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.
<snip repeated warning>
WARNING: /tensorflow/tensorflow/core/BUILD:935:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there.
INFO: Found 1 target...
ERROR: /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/external/protobuf/BUILD:133:1: C++ compilation of rule '@protobuf//:protobuf' failed: false failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \
    TF_NEED_CUDA=0 \
    TF_NEED_OPENCL=0 \
  /bin/false -DSELECTIVE_REGISTRATION -DSUPPORT_SELECTIVE_REGISTRATION -MD -MF bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.d '-frandom-seed=bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.o' -fPIC -iquote external/protobuf -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/stub_armeabi-v7a-opt/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/stub_armeabi-v7a-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -c external/protobuf/src/google/protobuf/io/printer.cc -o bazel-out/stub_armeabi-v7a-opt/bin/external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/printer.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Target //tensorflow/contrib/android:libtensorflow_inference.so failed to build
INFO: Elapsed time: 202.538s, Critical Path: 11.70s

I also tried (with the same result):

bazel clean before the failing build step.
Removing the ops_to_register.h file and the --copt parameters.

Here's my full environment info (which shows an error when running pywrap_tensorflow_internal):
# cat tf_env.txt

== cat /etc/issue ===============================================
Linux 813a49ffd3e0 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION="16.04.3 LTS (Xenial Xerus)"
VERSION_ID="16.04"
VERSION_CODENAME=xenial

== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== uname -a =====================================================
Linux 813a49ffd3e0 4.9.27-moby #1 SMP Thu May 11 04:01:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux

== check pips ===================================================
numpy (1.13.1)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.2)

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "tensorflow/__init__.py", line 24, in <module>
    from tensorflow.python import *
  File "tensorflow/python/__init__.py", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File "tensorflow/python/pywrap_tensorflow.py", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File "tensorflow/python/pywrap_tensorflow.py", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
ImportError: No module named pywrap_tensorflow_internal


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tools/tf_env_collect.sh: line 105: nvidia-smi: command not found

== cuda libs  ===================================================