Ignoring visible gpu device

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux with linux kernel version 4.11
TensorFlow installed from (source or binary):source
TensorFlow version (use command below):1.2.0-rc2
Bazel version (if compiling from source):0.5.0-1
CUDA/cuDNN version:8.0.61-2/6.0.21-1
GPU model and memory:Quadro M1200, 32Gig of RAM
Exact command to reproduce:running sess = tf.session() inside the python interactive shell.

Describe the problem
I have followed the official document to install from source. The build process and the install process shows no issues, but when I run the command:
>>> import tensorflow as tf
>>> hello = tf.constant('Hello, TensorFlow!')
>>> sess = tf.Session()

It says:
>>> sess = tf.Session()
2017-06-13 00:53:55.614764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-06-13 00:53:55.614999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: 
name: Quadro M1200
major: 5 minor: 0 memoryClockRate (GHz) 1.148
pciBusID 0000:01:00.0
Total memory: 3.95GiB
Free memory: 3.92GiB
2017-06-13 00:53:55.615013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 
2017-06-13 00:53:55.615017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y 
2017-06-13 00:53:55.615022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] Ignoring visible gpu device (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0) with Cuda compute capability 5.0. The minimum required Cuda capability is 5.2.

But when I visit the nvidia website, it says that the Quadro M1200 have Compute Capability 5.2.