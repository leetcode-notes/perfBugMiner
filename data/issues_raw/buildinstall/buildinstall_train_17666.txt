iOS: Library that made for a specific model doesn't include all needed operators (RandomStandardNormal is missing)

I created a quantized PB file, here is its detail:

Then I followed the instruction here to create the iOS library for that model only. The command I used:
tensorflow/contrib/makefile/build_all_ios.sh -g mobile_quantized.pb
Here is the generated ops_to_register.h file:
// This file was autogenerated by print_selective_registration_header.py
#ifndef OPS_TO_REGISTER
#define OPS_TO_REGISTER

    namespace {
      constexpr const char* skip(const char* x) {
        return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;
      }

      constexpr bool isequal(const char* x, const char* y) {
        return (*skip(x) && *skip(y))
                   ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))
                   : (!*skip(x) && !*skip(y));
      }

      template<int N>
      struct find_in {
        static constexpr bool f(const char* x, const char* const y[N]) {
          return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);
        }
      };

      template<>
      struct find_in<0> {
        static constexpr bool f(const char* x, const char* const y[]) {
          return false;
        }
      };
    }  // end namespace
    constexpr const char* kNecessaryOpKernelClasses[] = {
"BinaryOp< CPUDevice, functor::add<float>>",
"BinaryOp< CPUDevice, functor::add<int32>>",
"BiasOp<CPUDevice, float>",
"ConstantOp",
"DequantizeOp<CPUDevice, quint8>",
"EnterOp",
"ExitOp",
"UnaryOp< CPUDevice, functor::exp<float>>",
"ExpandDimsOp<int32>",
"BinaryOp< CPUDevice, functor::greater_equal<float>>",
"IdentityOp",
"BinaryOp< CPUDevice, functor::less<int32>>",
"LoopCondOp",
"MatMulOp<CPUDevice, float, false >",
"BinaryOp< CPUDevice, functor::maximum<float>>",
"ReductionOp<CPUDevice, float, int32, Eigen::internal::MeanReducer<float>>",
"MergeOp",
"BinaryOp< CPUDevice, functor::minimum<float>>",
"BinaryOp< CPUDevice, functor::mul<float>>",
"NextIterationOp",
"NoOp",
"PlaceholderOp",
"PhiloxRandomOp<CPUDevice, random::NormalDistribution<random::PhiloxRandom, float>>",
"RangeOp<::tensorflow::int32>",
"BinaryOp< CPUDevice, functor::div<float>>",
"ReshapeOp",
"ShapeOp<int32>",
"UnaryOp< CPUDevice, functor::sigmoid<float>>",
"UnaryOp< CPUDevice, functor::square<float>>",
"StridedSliceOp<CPUDevice, ::tensorflow::int32>",
"StridedSliceOp<CPUDevice, float>",
"BinaryOp< CPUDevice, functor::sub<float>>",
"BinaryOp< CPUDevice, functor::sub<int32>>",
"ReductionOp<CPUDevice, float, int32, Eigen::internal::SumReducer<float>>",
"SwitchOp",
"UnaryOp< CPUDevice, functor::tanh<float>>",
"TensorArrayPackOrGatherOp<CPUDevice, float, false >",
"TensorArrayReadOp<CPUDevice, float>",
"TensorArrayUnpackOrScatterOp<CPUDevice, float, false >",
"TensorArraySizeOp",
"TensorArrayOp",
"TensorArrayWriteOp<CPUDevice, float>",
"TileOp<CPUDevice, int32>",
"TransposeCpuOp",
"ZerosLikeOp< CPUDevice, float>",
"RecvOp",
"SendOp",
};
#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))

constexpr inline bool ShouldRegisterOp(const char op[]) {
  return false
     || isequal(op, "Add")
     || isequal(op, "BiasAdd")
     || isequal(op, "Const")
     || isequal(op, "Dequantize")
     || isequal(op, "Enter")
     || isequal(op, "Exit")
     || isequal(op, "Exp")
     || isequal(op, "ExpandDims")
     || isequal(op, "GreaterEqual")
     || isequal(op, "Identity")
     || isequal(op, "Less")
     || isequal(op, "LoopCond")
     || isequal(op, "MatMul")
     || isequal(op, "Maximum")
     || isequal(op, "Mean")
     || isequal(op, "Merge")
     || isequal(op, "Minimum")
     || isequal(op, "Mul")
     || isequal(op, "NextIteration")
     || isequal(op, "NoOp")
     || isequal(op, "Placeholder")
     || isequal(op, "RandomStandardNormal")
     || isequal(op, "Range")
     || isequal(op, "RealDiv")
     || isequal(op, "Reshape")
     || isequal(op, "Shape")
     || isequal(op, "Sigmoid")
     || isequal(op, "Square")
     || isequal(op, "StridedSlice")
     || isequal(op, "Sub")
     || isequal(op, "Sum")
     || isequal(op, "Switch")
     || isequal(op, "Tanh")
     || isequal(op, "TensorArrayGatherV3")
     || isequal(op, "TensorArrayReadV3")
     || isequal(op, "TensorArrayScatterV3")
     || isequal(op, "TensorArraySizeV3")
     || isequal(op, "TensorArrayV3")
     || isequal(op, "TensorArrayWriteV3")
     || isequal(op, "Tile")
     || isequal(op, "Transpose")
     || isequal(op, "ZerosLike")
     || isequal(op, "_Recv")
     || isequal(op, "_Send")
  ;
}
#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)

#define SHOULD_REGISTER_OP_GRADIENT false
#endif

But when I tried it within my project, it couldn't load the mobile_quantized.pb file and thrown this

It's strange because I saw "PhiloxRandomOp<CPUDevice, random::NormalDistribution<random::PhiloxRandom, float>>" and || isequal(op, "RandomStandardNormal") in the generated header file.

OS Platform and Distribution: MacOS 10.13.3
TensorFlow installed from: Source code
TensorFlow version: 1.6.0
Bazel version: 0.11.1-homebrew
CUDA/cuDNN version: None
GPU model and memory: None
Exact command to reproduce: Described above