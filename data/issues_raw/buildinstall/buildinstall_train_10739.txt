Quantized graph using graph transform fails to work

**System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.1
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce:**
I am using a quantized graph created using following command:
bazel-bin/tensorflow/tools/graph_transforms/transform_graph
--in_graph=./frozen_model_inception_resnet_v2.pb
--out_graph=./quantized_weights_and_nodes_inception_resnet_v2.pb
--inputs='InputImage:0'
--outputs='InceptionResnetV2/Logits/Predictions'
--transforms='
add_default_attributes
strip_unused_nodes(type=float, shape="1,299,299,3")
remove_nodes(op=Identity, op=CheckNumerics)
fold_constants(ignore_errors=true)
fold_batch_norms
fold_old_batch_norms
quantize_weights
quantize_nodes
strip_unused_nodes
sort_by_execution_order'
I try to use the graph in a program as below:
graph_def = tf.GraphDef()
with open(os.path.join(FLAGS.model_dir, GRAPH_FILE), "rb") as f:
model_str = f.read()
graph_def.ParseFromString(model_str)
tf.import_graph_def(graph_def, name='')
However, I get error "ValueError: No op named QuantizedAdd in defined operations" now when tf.import_graph_def(graph_def, name='') is called.
I also tried to use :         dir(tf.contrib) as explained in one of the issues : #10130
graph_def = tf.GraphDef()
with open(os.path.join(FLAGS.model_dir, GRAPH_FILE), "rb") as f:
model_str = f.read()
graph_def.ParseFromString(model_str)
dir(tf.contrib)
tf.import_graph_def(graph_def, name='')
but this did not solve the problem for me, I still get same error.