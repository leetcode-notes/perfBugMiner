SyncReplicasOptimizer' object has no attribute 'get_clean_up_op'

python /models/slim/train_image_classifier.py \
  --worker_replicas=2 \
  --num_ps_tasks=1 \
  --sync_replicas=True \
  --replicas_to_aggregate=2 \
  --task=0 \
  --dataset_name=imagenet  \
  --train_dir=/tmp/train_logs  \
  --dataset_split_name=train \
  --dataset_dir=/imagenet/dataEgs \
  --model_name=inception_v3


Run /models/slim/train_image_classifier.py
INFO:tensorflow:SyncReplicasV2: replicas_to_aggregate=2; total_num_replicas=2
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
Traceback (most recent call last):
  File "/models/slim/train_image_classifier.py", line 583, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "/models/slim/train_image_classifier.py", line 579, in main
    sync_optimizer=optimizer if FLAGS.sync_replicas else None)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py", line 733, in train
    cleanup_op = sync_optimizer.get_clean_up_op()
AttributeError: 'SyncReplicasOptimizer' object has no attribute 'get_clean_up_op'


I confirm that more than one demos will encounter this issue if using distributed training under tensorflow 1.0.1 image.
Hope some improvements for distributed training to demo how to use distributed training.
Thanks.