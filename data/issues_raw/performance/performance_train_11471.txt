XLA crash on Wasserstein GAN

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): TensorFlow installed from source
TensorFlow version (use command below): v1.2.0-1382-g708cbaf 1.2.0
Python version:  Python 3.5.2
Bazel version (if compiling from source):
CUDA/cuDNN version: CUDA 8 / cudnn 6
GPU model and memory: 2x1080 Ti, 12 Gb

Describe the problem
When I'm running this code: https://github.com/Randl/WassersteinGAN.tensorflow with XLA, I get the following error message:
LLVM ERROR: Cannot select: 0x7f4c300d4878: i16,ch = AtomicCmpSwap<Volatile LDST1[%_fusion.typed16(addrspace=1)]> 0x7f4c30093858, 0x7f4c300d5098, 0x7f4c300d5168, 0x7f4c300e6c20
  0x7f4c300d5098: i64,ch = CopyFromReg 0x7f4c30093858, Register:i64 %vreg0
    0x7f4c300d5100: i64 = Register %vreg0
  0x7f4c300d5168: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg3
    0x7f4c300d56b0: i16 = Register %vreg3
  0x7f4c300e6c20: i16 = and 0x7f4c300d5168, 0x7f4c300d5370
    0x7f4c300d5168: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg3
      0x7f4c300d56b0: i16 = Register %vreg3
    0x7f4c300d5370: i16 = AssertZext 0x7f4c300d4c20, ValueType:ch:i1
      0x7f4c300d4c20: i16,ch = CopyFromReg 0x7f4c30093858, Register:i16 %vreg1
        0x7f4c300d4948: i16 = Register %vreg1
In function: _fusion__1
*** Error in `python3': free(): invalid size: 0x00007f4ac8091fe0 ***
======= Backtrace: =========
/lib/x86_64-linux-gnu/libc.so.6(+0x777e5)[0x7f4e6c2507e5]
/lib/x86_64-linux-gnu/libc.so.6(+0x8037a)[0x7f4e6c25937a]
/lib/x86_64-linux-gnu/libc.so.6(cfree+0x4c)[0x7f4e6c25d53c]
/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0x6b98aa)[0x7f4a9f3f48aa]
/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0xdb80e)[0x7f4a9ee1680e]
/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(+0xc034b)[0x7f4a9edfb34b]
/usr/lib/nvidia-375/libnvidia-ptxjitcompiler.so.375.66(__cuda_CallJitEntryPoint+0xdcc)[0x7f4a9edf1aec]
/usr/lib/nvidia-375/libnvidia-fatbinaryloader.so.375.66(fatBinaryCtl_Compile+0x302)[0x7f4df0b125c2]
/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a1ee2)[0x7f4e07c31ee2]
/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a2a63)[0x7f4e07c32a63]
/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0x1a3133)[0x7f4e07c33133]
/usr/lib/x86_64-linux-gnu/libcuda.so.1(+0xcf7b3)[0x7f4e07b5f7b3]
/usr/lib/x86_64-linux-gnu/libcuda.so.1(cuModuleLoadDataEx+0x75)[0x7f4e07c77055]
/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(+0x4d0b7ba)[0x7f4e1370d7ba]
/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZN5Eigen26NonBlockingThreadPoolTemplIN10tensorflow6thread16EigenEnvironmentEE10WorkerLoopEi+0xff)[0x7f4e139e998f]
/usr/local/lib/python3.5/dist-packages/tensorflow/python/_pywrap_tensorflow_internal.so(_ZNSt17_Function_handlerIFvvEZN10tensorflow6thread16EigenEnvironment12CreateThreadESt8functionIS0_EEUlvE_E9_M_invokeERKSt9_Any_data+0x2d)[0x7f4e139e977d]

Without XLA it works OK.