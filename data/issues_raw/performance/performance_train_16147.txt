Inference on V100 with TF1.5 is extremely slow.

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): Source and Virtual Env, problem doesn't change
TensorFlow version (use command below): 1.5.0-rc1 (Makes no difference on 1.4)
Python version: 3.5
Bazel version (if compiling from source): 0.9.0
GCC/Compiler version (if compiling from source): 5.4.0
CUDA/cuDNN version: CUDA 9/7.0.5
GPU model and memory: V100 - 16GB
Exact command to reproduce:

Describe the problem

Inference using the V100 is very slow. For example performing object detection with SSD Mobilenet is achieving a max frame rate of ~8, compared to ~45 on a GTX1080
Initialization with a warm up image is extremely slow - up to 2 mins for the first image.
I have tried model quantization using graph_transforms/transform_graph (in an attempt to use the FP16 mode) and various combinations of CUDA, cuDNN and Tensorflow versions with no difference.

Is there some recommended environment setup for the V100?
I am successfully running Darknet (https://pjreddie.com/darknet/) with a massive increase of speed.