[feature] Smarter Handling of Image Data Format

Right now the responsibility of choosing image data format (i.e. the representation of batches of image) is that of the data scientist (ie model writer). I suggest there should a solution in TF to move this to the optimizer (XLA perhaps?) or worst cast Op writer.
For some background:
Currently Tensorflow supports NCHW and NHWC (though other formats like CHWN might be possible down the road). Many of the Ops support both formats. That being said, the docs say:

The best practice is to build models that work with both NCHW and NHWC as it is common to train using NCHW on GPU, and then do inference with NHWC on CPU.

This requires the user to have to do some "wrangling" (e.g. loading the checkpoint of weights and re-buidling graph in Python) to map from one image format to another. Further this must be done with some knowledge of the platform on which the graph will be executed (ie which ops are defined, and if both, which is faster)?
Right now model builder must build the model to take in channel order and pass that around. Ideally the model could be written once with enough meta information attached to the graph to allow optimizers after the fact (ie at inference time on other platforms) to choose the best representation. Further even at training time, it would be great if the data scientist didn't need to be concerned with image data format (ie dimension ordering) and could use abstractions for accessing results that took care of data access.
I don't have a clear proposal of how to clean this up, but this seems like a potential pain point, or a the very least results in people leaving performance on the table both when training and at inference.
TL; DR Many data scientists just want to write CNNs without thinking about tensor layouts.