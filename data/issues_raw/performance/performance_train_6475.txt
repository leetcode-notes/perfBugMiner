Training with local variables is very slow in distributed tf

I used local variables on worker tasks in a distributed RNN training. Every update go through 3 steps: 1) assign local variables on each worker with PS variables 2) training local variables in several loops/batches, and accumulate the gradients from each loop 3) apply the accumulated gradients to the PS variables. The first and second step is very slow: for step 1, it takes about 12 seconds; for step 2, every loop takes about 6 seconds. If I combine the three steps together (not use local variable and go through one batch data every update), it only takes about 0.7 second. So, I suspect that it is due to the bad performance of local variables.
Environment info
Ubuntu 14.04, CUDA 8.0, tensorflow 0.12.0-rc1