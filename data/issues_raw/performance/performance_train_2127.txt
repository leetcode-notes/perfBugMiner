tf.nn.dynamic_rnn fails when batch_size is 0

Environment info
Operating System: Ubuntu 15.10
Installed version of CUDA and cuDNN:
-rw-r--r-- 1 root root    322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root        16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root        19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root    383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root    720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 3319 users       13 Feb  9 09:48 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.4
lrwxrwxrwx 1 3319 users       17 Feb  9 09:48 /usr/local/cuda/lib64/libcudnn.so.4 -> libcudnn.so.4.0.7
-rwxrwxr-x 1 3319 users 61453024 Feb  8 14:12 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-rw-r-- 1 3319 users 62025862 Feb  8 14:12 /usr/local/cuda/lib64/libcudnn_static.a

Commit hash: 8d310bf
Steps to reproduce
Run the following test case:
import tensorflow as tf

outputs, state = tf.nn.dynamic_rnn(
  tf.nn.rnn_cell.BasicRNNCell(1),
  tf.zeros((0, 1, 1)),
  dtype=tf.float32)

with tf.Session() as sess:
  initializer = tf.random_uniform_initializer(-0.1, 0.1)
  tf.initialize_all_variables().run()
  print sess.run([state])

When TensorFlow is compiled with -c dbg, this fails with the following message:
python: external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h:124: Eigen::internal::TensorIntDivisor<T, div_gt_one>::TensorIntDivisor(T) [with T = long int; bool div_gt_one = false]: Assertion `divider > 0' failed.

Using gdb, we get the following backtrace:
(gdb) bt
#0  0x00007ffff7826267 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:55
#1  0x00007ffff7827eca in __GI_abort () at abort.c:89
#2  0x00007ffff781f03d in __assert_fail_base (fmt=0x7ffff7980fe8 "%s%s%s:%u: %s%sAssertion `%s' failed.\n%n", assertion=assertion@entry=0x7fffeb82f7fe "divider > 0",
    file=file@entry=0x7fffeb82f738 "external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h", line=line@entry=124,
    function=function@entry=0x7fffeb860080 <Eigen::internal::TensorIntDivisor<int, false>::TensorIntDivisor(int)::__PRETTY_FUNCTION__> "Eigen::internal::TensorIntDivisor<T, div_gt_one>::TensorIntDivisor(T) [with T = int; bool div_gt_one = false]") at assert.c:92
#3  0x00007ffff781f0f2 in __GI___assert_fail (assertion=0x7fffeb82f7fe "divider > 0", file=0x7fffeb82f738 "external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h", line=124,
    function=0x7fffeb860080 <Eigen::internal::TensorIntDivisor<int, false>::TensorIntDivisor(int)::__PRETTY_FUNCTION__> "Eigen::internal::TensorIntDivisor<T, div_gt_one>::TensorIntDivisor(T) [with T = int; bool div_gt_one = false]") at assert.c:101
#4  0x00007fffe9173cf5 in Eigen::internal::TensorIntDivisor<int, false>::TensorIntDivisor (this=0x7fff3dff9e40, divider=0)
    at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorIntDiv.h:124
#5  0x00007fffe9793fd5 in Eigen::TensorEvaluator<Eigen::TensorSlicingOp<Eigen::DSizes<long, 3> const, Eigen::DSizes<long, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16> const> const, Eigen::GpuDevice>::TensorEvaluator (this=0x7fff3dff9f20, op=..., device=...) at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorMorphing.h:352
#6  0x00007fffe979370a in Eigen::TensorEvaluator<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16>, Eigen::TensorSlicingOp<Eigen::DSizes<long, 3> const, Eigen::DSizes<long, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16> const> const> const, Eigen::GpuDevice>::TensorEvaluator (this=0x7fff3dff9f00, op=..., device=...)
    at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorAssign.h:106
#7  0x00007fffe97930b3 in Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16>, Eigen::TensorSlicingOp<Eigen::DSizes<long, 3> const, Eigen::DSizes<long, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16> const> const> const, Eigen::GpuDevice, false>::run (expr=..., device=...)
    at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:233
#8  0x00007fffe9792bd2 in Eigen::TensorDevice<Eigen::TensorMap<Eigen::Tensor<float, 3, 1, int>, 16>, Eigen::GpuDevice>::operator=<Eigen::TensorSlicingOp<Eigen::DSizes<long, 3> const, Eigen::DSizes<long, 3> const, Eigen::TensorMap<Eigen::Tensor<float const, 3, 1, int>, 16> const> > (this=0x7fff3dffa040, other=...) at external/eigen_archive/eigen-eigen-0823d98fdde7/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35
#9  0x00007fffe9792570 in tensorflow::functor::Split<Eigen::GpuDevice, float>::operator() (this=0x7fff3dffa1e0, d=..., output=..., input=..., slice_indices=..., slice_sizes=...)
    at tensorflow/core/kernels/split_lib_gpu.cu.cc:37
#10 0x00007fffe96be665 in tensorflow::TensorArrayUnpackOp<Eigen::GpuDevice, float>::Compute (this=0xe44040, ctx=0x7fff3dffab20) at tensorflow/core/kernels/tensor_array_ops.cc:753
#11 0x00007fffeaf8e561 in tensorflow::BaseGPUDevice::Compute (this=0x2ba8110, op_kernel=0xe44040, context=0x7fff3dffab20) at tensorflow/core/common_runtime/gpu/gpu_device.cc:388
#12 0x00007fffeb1b22eb in tensorflow::(anonymous namespace)::ExecutorState::Process (this=0xdf4290, tagged_node=..., scheduled_usec=0) at tensorflow/core/common_runtime/executor.cc:1092
#13 0x00007fffeb1bdbeb in std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)>::operator()<tensorflow::(anonymous namespace)::ExecutorState::TaggedNode&, long long&, void> (this=0x7fff200008c0, __object=0xdf4290) at /usr/include/c++/4.9/functional:569
#14 0x00007fffeb1bd03e in std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>::__call<void, 0ul, 1ul, 2ul>(<unknown type in /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so, CU 0xf323471, DIE 0xf3a21e7>, std::_Index_tuple<0ul, 1ul, 2ul>) (this=0x7fff200008c0, __args=<unknown type in /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so, CU 0xf323471, DIE 0xf3a21e7>)
    at /usr/include/c++/4.9/functional:1264
#15 0x00007fffeb1bb69a in std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>::operator()<, void>(void) (this=0x7fff200008c0) at /usr/include/c++/4.9/functional:1323
#16 0x00007fffeb1b98b6 in std::_Function_handler<void(), std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)>(tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long int)> >::_M_invoke(const std::_Any_data &) (__functor=...) at /usr/include/c++/4.9/functional:2039
#17 0x00007fffe8e4788c in std::function<void ()>::operator()() const (this=0x7fff3dffadd0) at /usr/include/c++/4.9/functional:2439
#18 0x00007fffeb450454 in tensorflow::thread::ThreadPool::Impl::WorkerLoop (this=0x2bb28f0) at tensorflow/core/lib/core/threadpool.cc:196
#19 0x00007fffeb44fe95 in tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, tensorflow::ThreadOptions const&, std::string const&, int)::{lambda()#1}::operator()() const ()
    at tensorflow/core/lib/core/threadpool.cc:123
#20 0x00007fffeb45086d in std::_Function_handler<void(), tensorflow::thread::ThreadPool::Impl::Impl(tensorflow::Env*, const tensorflow::ThreadOptions&, const string&, int)::<lambda()> >::_M_invoke(const std::_Any_data &) (
    __functor=...) at /usr/include/c++/4.9/functional:2039
#21 0x00007fffe8e4788c in std::function<void ()>::operator()() const (this=0x2bb4c48) at /usr/include/c++/4.9/functional:2439
#22 0x00007fffeb471f5e in std::_Bind_simple<std::function<void ()> ()>::_M_invoke<>(std::_Index_tuple<>) (this=0x2bb4c48) at /usr/include/c++/4.9/functional:1700
#23 0x00007fffeb471ea3 in std::_Bind_simple<std::function<void ()> ()>::operator()() (this=0x2bb4c48) at /usr/include/c++/4.9/functional:1688
#24 0x00007fffeb471e20 in std::thread::_Impl<std::_Bind_simple<std::function<void ()> ()> >::_M_run() (this=0x2bb4c30) at /usr/include/c++/4.9/thread:115
#25 0x00007fffdc3bc030 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#26 0x00007ffff7bc26aa in start_thread (arg=0x7fff3dffb700) at pthread_create.c:333
#27 0x00007ffff78f7e9d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109

(gdb) f 10
#10 0x00007fffe96be665 in tensorflow::TensorArrayUnpackOp<Eigen::GpuDevice, float>::Compute (this=0xe44040, ctx=0x7fff3dffab20) at tensorflow/core/kernels/tensor_array_ops.cc:753
753           functor::Split<Device, T>()(ctx->eigen_device<Device>(), tensor_value_i_t,
(gdb) p this->name()
$1 = (const std::string &) @0xdc49e0: {static npos = <optimized out>, _M_dataplus = {<std::allocator<char>> = {<__gnu_cxx::new_allocator<char>> = {<No data fields>}, <No data fields>},
    _M_p = 0x2bee918 "RNN/TensorArrayUnpack"}}