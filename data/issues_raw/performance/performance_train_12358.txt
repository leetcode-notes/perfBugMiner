[Feature Request]  Add an extra argument `is_duplicated` to `scatter_sub/*` Ops and make the kernel to multi-thread for speedup.

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
ubuntu 16.04
TenorFlow installed from (source or binary):
source
TensorFlow version (use command below):
v1.3.0-rc2
Python version:
2.7
Bazel version (if compiling from source):
0.5.2
CUDA/cuDNN version:
8.0/5.1.10
GPU model and memory:
nvidia M40
CPU
32-cores

Describe the problem
I profile the embedding_lookup_sparse on single machine with tfprof, in which i put the params on cpu. So the gather and scatter_sub Op are also put on cpu.
Profiling result shows gather and scatter_sub Op takes so much time, the former takes about 33%, the latter takes about 43%. Making the gather op kernel to multi-thread gain about 10x speedup, relate to PR and 11709.
Follow the same thought, I want to make the scatter_sub to be multi-thread.

If there is no duplicate index, we can realize lock-free code which could gain about 10x speedup too.
If there are duplicate indices, use lock which can gain little speedup.

So, I think an extra argument is_duplicated is a good choice to divide the two situation.
Here is some profiling result:
tfprof
# orignial
ScatterSub                   8589.93MB (65.56%, 32.67%),       45.63ms (62.09%, 43.75%),            0us (45.25%, 0.00%),       45.63ms (62.90%, 45.87%)
# with lock
ScatterSub                   8589.93MB (65.56%, 32.67%),       38.10ms (86.95%, 54.44%),            0us (48.97%, 0.00%),       38.10ms (89.98%, 58.78%)
# without lock
ScatterSub                   8589.93MB (65.56%, 32.67%),        4.22ms (73.05%, 12.58%),            0us (48.86%, 0.00%),        4.22ms (76.99%, 14.63%)

Code
embedding_lookup_sparse