Computer freeze when feeding a large numpy array as input in MNIST tutorial

What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
None
Environment info
intel i5, 8gb ram
Operating System:
Ubuntu 14.04.5:
Linux 4.4.0-45-generic #66~14.04.1-Ubuntu SMP Wed Oct 19 15:05:38 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
Installed version of CUDA and cuDNN:
No cuda or cuDNN, running on CPU
If installed from binary pip package, provide:

A link to the pip package you installed:
TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp34-cp34m-linux_x86_64.whl
The output from python -c "import tensorflow; print(tensorflow.__version__)".
0.11.0rc2

If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
Use the mnist tutorial, replace
train_accuracy = accuracy.eval(feed_dict={ x:batch[0], y_: batch[1], keep_prob: 1.0})
with
train_accuracy = accuracy.eval(feed_dict={ x:mnist.train.images, y_: mnist.train.labels, keep_prob: 1.0})
So that the accuracy is evaluated over the entire training set. I've reproduced this using another dataset, and the problem goes away when using a smaller number of examples.
(pastebin for entire file with this modification: http://pastebin.com/THNqB4ws)
What other attempted solutions have you tried?
None, there's no error message and the computer hangs the first time it executes accuracy.eval