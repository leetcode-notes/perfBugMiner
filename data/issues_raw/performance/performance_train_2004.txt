Open source performance benchmarks

In #2001 we discussed about the performance benchmark, I suggest maybe we can have some benchmark code (in automatically tests or something else) for common NN architecture like Alex, Inception v3, ResNet  on some famous dataset like cifar10, cifar100, ImageNet.
By doing this, we can continuously trace our performance when we update our algorithms or code.
Also, we could show our benchmark test on our website or github page.