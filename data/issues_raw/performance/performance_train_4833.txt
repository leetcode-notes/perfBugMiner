Slow IDCT used in JPEG decode

This issue is related to #4807, yet a bit distinct. Regardless of whether libjpeg or libjpeg-turbo is used, I was wondering if there was a reason to choose the slow but more accurate variant of IDCT in libjpeg (code link). For human image viewing pleasure, accuracy may matter, but I was wondering if for model training, the decision was made to use the slower IDCT because that improved model convergence? In case the training is immune to using the faster but less accurate IDCT, it may be worth changing the default. Has anyone done any studies as to the trained model impact of the faster IDCT? From a performance point of view, I'm getting a significant performance gain (2x GTX 1080, 6-core high-clock Core i7, 500 MB/s SSD), around 20% for AlexNet against precomputed ImageNet AlexNet may be more CPU bound for decode since the network passes themselves are relatively cheap, so maybe the gains for Inception v3 or ResNet would be less, but they would still likely be significant.