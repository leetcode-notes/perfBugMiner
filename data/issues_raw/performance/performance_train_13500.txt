Tensorflow binary seems compiled to use SIMD instructions like AVX2 and FMA, but actually not?

I found similar issues mentioned as #8037, #7778 etc, but the issue seems not solved: the warnings did disappear after building with the necessary optimization options, but they appeared again when I followed this tutorial (https://www.tensorflow.org/performance/xla/tfcompile) to the last step. So, is the tensorflow binary compiled to use the SIMD instructions or not?
System information

Have I written custom code: No
OS Platform and Distribution: Linux Ubuntu 16.04
TensorFlow installed from: source
TensorFlow version: v1.3.0-rc1-3000-g840dcae
Python version: Python3
Bazel version: 0.6.0
CPU: Intel Core i7-4770, Haswell architecture, supporting AVX2 and FMA
GPU: No
Compiler: gcc 5.4.0

Issue reproducing:

Building tensorflow from source:



Configure: only jemalloc and XLA JIT support are ticked. The default optimization flag is -march=native, therefore was not specified;


Build pip package:


bazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt="-D_GLIBCXX_USE_CXX11_ABI=0" //tensorflow/tools/pip_package:build_pip_package


Install pip package:

sudo -H python3 -m pip install /tmp/tensorflow_pkg/tensorflow-1.3.0-cp35-cp35m-linux_x86_64.whl


The installation was validated using the "Hello, TensorFlow!" example, and no warnings are generated.


Generating tfcompile binary:

bazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt="-D_GLIBCXX_USE_CXX11_ABI=0" //tensorflow/compiler/aot:tfcompile


Follow the tutorial here https://www.tensorflow.org/performance/xla/tfcompile, in the directory //tensorflow/compiler/aot/tests:



Step 1: The config file already exists as test_graph_tfmatmul.config.pbtxt;


Step 2.1: Generate the graph file test_graph_tfmatmul.pb:


python3 ./make_test_graphs.py --out_dir=./


Step 2.2: Compile the graph using tfcompile:

~/tensorFlow_src/tensorflow/bazel-bin/tensorflow/compiler/aot/tfcompile --graph="./test_graph_tfmatmul.pb" --config="./test_graph_tfmatmul.config.pbtxt" --entry_point="test_graph_tfmatmul" --cpp_class="foo::bar::MatMulComp" --out_object="test_graph_tfmatmul.o" --out_header="test_graph_tfmatmul.h" --target_features="+avx2"


Step 3: Creating a file named my_code.cc:

#define EIGEN_USE_THREADS
#define EIGEN_USE_CUSTOM_THREAD_POOL

#include <iostream>
#include "third_party/eigen3/unsupported/Eigen/CXX11/Tensor"
#include "tensorflow/compiler/aot/tests/test_graph_tfmatmul.h" // generated

int main(int argc, char** argv) {
    Eigen::ThreadPool tp(2);  // Size the thread pool as appropriate.
    Eigen::ThreadPoolDevice device(&tp, tp.NumThreads());

    foo::bar::MatMulComp matmul;
    matmul.set_thread_pool(&device);

    // Set up args and run the computation.
    const float args[12] = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12};
    std::copy(args + 0, args + 6, matmul.arg0_data());
    std::copy(args + 6, args + 12, matmul.arg1_data());
    matmul.Run();

    // Check result
    if (matmul.result0(0, 0) == 58) {
        std::cout << "Success" << std::endl;
    } else {
        std::cout << "Failed. Expected value 58 at 0,0. Got:"
                    << matmul.result0(0, 0) << std::endl;
    }

    return 0;
}


Step 4.1: Create the BUILD file:

# Example of linking your binary
# Also see //third_party/tensorflow/compiler/aot/tests/BUILD
load("//tensorflow/compiler/aot:tfcompile.bzl", "tf_library")

# The same tf_library call from step 2 above.
tf_library(
    name = "test_graph_tfmatmul",
    cpp_class = "foo::bar::MatMulComp",
    graph = "test_graph_tfmatmul.pb",
    config = "test_graph_tfmatmul.config.pbtxt",
)

# The executable code generated by tf_library can then be linked into your code.
cc_binary(
    name = "my_binary",
    srcs = [
        "my_code.cc",  # include test_graph_tfmatmul.h to access the generated header
    ],
    deps = [
        ":test_graph_tfmatmul",  # link in the generated object file
        "//third_party/eigen3",
    ],
    linkopts = [
        "-lpthread",
    ]
)


Step 4.2: Create the final binary:

bazel build --config=opt --copt=-mavx2 --copt=-mfma --config=mkl --cxxopt="-D_GLIBCXX_USE_CXX11_ABI=0" //tensorflow/compiler/aot/tests:my_binary

Finally, it will print:
INFO: From Executing genrule //tensorflow/compiler/aot/tests:gen_test_graph_tfmatmul: 2017-10-05 15:15:29.233159: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
(An error will also occur, but that is another issue #13482).
So, is the tensorflow binary compiled to use the SIMD instructions (SSE4.1 SSE4.2 AVX AVX2 FMA) or not? May I have your advice?