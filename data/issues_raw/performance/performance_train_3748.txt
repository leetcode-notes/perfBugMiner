unexpected names in `NamedOutputs` tuples when using `outputs_collections` with some layers

We are getting unexpected names (they lack outer name scope) in NamedOutputs tuples added to collections using tf.contrib.layers outputs_collections. The following code demonstrates the issue:
import tensorflow as tf
from tensorflow.contrib import slim


with tf.name_scope("train"):
    with slim.arg_scope([slim.fully_connected, slim.flatten],
                        outputs_collections=tf.GraphKeys.ACTIVATIONS):
        ph = tf.placeholder(tf.float32, [2, 2])
        fc = slim.fully_connected(ph, 10)
        flat = slim.flatten(ph)

{print("name in tuple: ", no.name, ", tensor name:", no.outputs.name)
 for no in tf.get_collection(tf.GraphKeys.ACTIVATIONS)}

The output is:
name in tuple:  fully_connected , tensor name: train/fully_connected/Relu:0
name in tuple:  train/Flatten , tensor name: train/Flatten/Reshape:0

We have tracked the cause of this down in to tf.contrib.layers. For layers that use internal variables (fully_connected, conv2d, ...), final outputs are added to collections based on internal variable_scope name. Please see:
tensorflow/tensorflow/contrib/layers/python/layers/layers.py lines 758, 835 (version 0.10, commit 1df3fb0)
It is our understanding that activation names generally fall under name_scopes, which is consistent with actual op names in the output above.
This issue makes it impossible to retrieve items from collections filtered down with a name scope, an approach that we are trying to use for decoupling op creation and summarizing. It seems a valid use-case.