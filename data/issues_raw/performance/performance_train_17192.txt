TrainingHelper & ScheduledEmbeddingTrainingHelper  GPU Error - works on CPU

System information

**Have I written custom code **: Yes
OS Platform and Distribution:16.04.3 LTS (Xenial Xerus)
TensorFlow installed from (source or binary):source
TensorFlow version (use command below):1.4.1
Python version: Python 3.5.2
Bazel version (if compiling from source):NA
GCC/Compiler version (if compiling from source):c++ (Ubuntu 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609
CUDA/cuDNN version:CUDA 8.0 / 6.0
GPU model and memory:GeForce GTX 1080, 8G RAM, NVIDIA DRIVER: 390.25
Exact command to reproduce:NA

problem
Having trouble running an RNN dynamic decoder on GPU when using the following  decoding helpers:
tf.contrib.seq2seq.ScheduledEmbeddingTrainingHelper
tf.contrib.seq2seq.TrainingHelper
It seems that there is a problem with the sequence length stopping condition, as the problem
is not present when using  tf.contrib.seq2seq.GreedyEmbeddingHelper as a decoder helper.
On CPU all functions are working correctly, the problem arise on GPUs only.
Tried on TF-1.4 compiled from source, TF-1.4 installed from pip, and TF-1.5 installed from source.
They all fail
Error log:
NotFoundError (see above for traceback): No registered 'Switch' OpKernel for GPU devices compatible with node Decoders/StackedDecoder_text_rnn_0/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch = Switch[T=DT_RESOURCE, _class=["loc:@Decoders/StackedDecoder_text_rnn_0/ScheduledEmbeddingSamplingWrapper/TrainingHelper/TensorArray"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Decoders/StackedDecoder_text_rnn_0/ScheduledEmbeddingSamplingWrapper/TrainingHelper/TensorArray/_281, Decoders/StackedDecoder_text_rnn_0/decoder/TrainingHelperInitialize/All)
	 (OpKernel was found, but attributes didn't match)
	.  Registered:  device='GPU'; T in [DT_STRING]
  device='GPU'; T in [DT_BOOL]
  device='GPU'; T in [DT_INT32]
  device='GPU'; T in [DT_COMPLEX128]
  device='GPU'; T in [DT_COMPLEX64]
  device='GPU'; T in [DT_INT8]
  device='GPU'; T in [DT_UINT8]
  device='GPU'; T in [DT_INT16]
  device='GPU'; T in [DT_UINT16]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_HALF]
  device='CPU'; T in [DT_QINT32]
  device='CPU'; T in [DT_QUINT8]
  device='CPU'; T in [DT_QINT8]
  device='CPU'; T in [DT_RESOURCE]
  device='CPU'; T in [DT_STRING]
  device='CPU'; T in [DT_BOOL]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_INT8]
  device='CPU'; T in [DT_UINT8]
  device='CPU'; T in [DT_INT16]
  device='CPU'; T in [DT_UINT16]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_INT64]
	 [[Node: Decoders/StackedDecoder_text_rnn_0/decoder/TrainingHelperInitialize/cond/TensorArrayReadV3/Switch = Switch[T=DT_RESOURCE, _class=["loc:@Decoders/StackedDecoder_text_rnn_0/ScheduledEmbeddingSamplingWrapper/TrainingHelper/TensorArray"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](Decoders/StackedDecoder_text_rnn_0/ScheduledEmbeddingSamplingWrapper/TrainingHelper/TensorArray/_281, Decoders/StackedDecoder_text_rnn_0/decoder/TrainingHelperInitialize/All)]]