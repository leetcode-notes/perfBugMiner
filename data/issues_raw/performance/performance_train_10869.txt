GPU option allow_growth and CUDA_ERROR_OUT_OF_MEMORY

Hi,
I tried to build a LSTM model on 30G data with a aws machine p2.xlarge with 60G memory and a gpu with 12G memory. The performance is inconsistent. Sometimes we get it to work but sometimes we encounter CUDA_ERROR_OUT_OF_MEMORY. The answer at https://stackoverflow.com/questions/39465503/cuda-error-out-of-memory-in-tensorflow suggests setting a gpu option allow_growth to False. It refers to the source code where the change could be made:
https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/core/protobuf/config.proto
But in the code I notice the only line containing "allow_growth" is this:
bool allow_growth = 4;
It looks strange to me. Could you explain why allow_growth is assigned a integer value 4?