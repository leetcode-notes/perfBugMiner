Surprising behaviour with distributed Tensorflow

Hello, I'm observing some surprising behaviour with distributed Tensorflow, in terms of performance. In short, for the exact same Graph, I get a very different performance based on the machine I connect my tf.Session to.
In my experiments, I have two machines A and B in a cluster. Machine A has a GPU with cuDNN. I declare a graph that executes the cifar10 gpu example exclusively on machine A. No operators (including the variables) are declared on machine B. I log the device placement and Tensorboard does not see any operators associated with anything other device than machine A.
When I execute the graph, starting my session using tf.Session("grpc://machineA:2222", ... results in significantly better performance than using tf.Session("grpc://machineB:2222", .... It is also not just a constant overhead, as I increase the batch size, the difference seems to scale linearly:



Batch Size
Connect to machine A
Connect to machine B




128
0.19s
0.50s


256
0.38s
1.00s


512
0.74s
1.78s


1024
1.42s
3.38s

(Averaged over 10 iterations not including the first two)
When looking at the output of top on machine B, it does seem like python is doing some work when I connect to machine B as it averages around 30% CPU vs ~0% otherwise, but I cannot tell what that is/how to prevent it.
I am working with Tensorflow installed from source with commit ed1a947.