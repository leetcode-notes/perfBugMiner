Tfdbg does not work with Coordinator/QueueRunners

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 18
TensorFlow installed from (source or binary): Binary (pip)
TensorFlow version (use command below): v1.2.0-rc2-21-g12f033d 1.2.0
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

Describe the problem
The Tensorflow debugger does not seem to be working with Queues; data never seems to be fetched by the QueueRunner threads, be it from a file (using tf.TFRecordReader and tf.parse_single_example) or preloaded (using tf.train.slice_input_producer). Instead, the coordinator.should_stop() is True right away. This is only the case after wrapping the session in a tf.python.debug.LocalCLIDebugWrapperSession. The example should make things clearer.
Moreover, another error occurs at coordinator.join(threads).
I am aware of the FAQ entry on Threads, but that does not explain why the data fetching threads would not be working.
Source code / logs
To make it easiest to replicate, I simply took the example on working with preloaded data, and wrapped the session in there with the debugger. I uploaded the gist with two lines added to https://gist.github.com/rubenvereecken/079cdf1abc76866714ff6f752167481d#file-fully_connected_preloaded_debug-py-L92.
To reproduce, run the file. Once you drop in the debugger, run once. It then exits. The full output is below:
Extracting /tmp/data/train-images-idx3-ubyte.gz
Extracting /tmp/data/train-labels-idx1-ubyte.gz
Extracting /tmp/data/t10k-images-idx3-ubyte.gz
Extracting /tmp/data/t10k-labels-idx1-ubyte.gz
Traceback (most recent call last):
  File "ex.py", line 191, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File "/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "ex.py", line 143, in main
    run_training()
  File "ex.py", line 138, in run_training
    coord.join(threads)
  File "/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File "/home/ruben/anaconda3/lib/python3.6/site-packages/six.py", line 686, in reraise
    raise value
  File "/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py", line 233, in _run
    enqueue_callable = sess.make_callable(enqueue_op)
AttributeError: 'LocalCLIDebugWrapperSession' object has no attribute 'make_callable'

The stacktrace is about coord.join(threads), but this is only possible because coord.should_stop() never seems to be False, which would indicate there is data to load. Without the added debugger lines, the example simply works.