General change in batch size Performance Question

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A
TensorFlow installed from (source or binary): N/A
TensorFlow version (use command below): 1.4.1
Python version: 3.5
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

Describe the problem
I have opened a question on StackOverflow. I suspect only a developer can answer the question. The link to the question is here:
https://stackoverflow.com/questions/48099754/does-a-change-in-batch-size-impact-performance
The question is around Reinforcement Learning and if there will be a speed improvement if the batch size of the graph is not changed. RL usually has a training batch and a "next_action" type of single sample (batch size =1). The network is intermittently hit with either the training batch size or batch size of 1. Does TF take a performance hit every time the graph sees a different batch size through the feed_dict()? If this is the case, should 2 graphs be created so the batch size doesn't change from call to call?
If you post the answer here I will copy it to StackOverflow.
Thanks
Source code / logs
N/A