Incorrect gradient for categorical distribution entropy

The Categorical distribution class provides an awesome entropy operator but apparently the gradient calculation w.r.t. the input operators doesn't work.
logits = tf.Variable(initial_value=[[1., 2., 3.], [2., 5., 1.]])

probabilities = tf.nn.softmax(logits)
log_probabilities = tf.nn.log_softmax(logits)
entropy = - tf.reduce_sum(probabilities * log_probabilities, axis=-1)

# using the actual distribution would be nicer but gradients seem buggy
categorical_distribution = tf.contrib.distributions.Categorical(p=probabilities)
categorical_distribution_entropy = categorical_distribution.entropy()

# initialize
init = tf.global_variables_initializer()
sess = tf.Session()
sess.run(init)

# works
print(sess.run(entropy))
print(sess.run(tf.gradients(entropy, [logits])))

# apparently loses gradient information
print(sess.run(categorical_distribution_entropy))
print(sess.run(tf.gradients(categorical_distribution_entropy, [logits])))
In the outputs we see that the entropy calculation works but the gradients are somehow lost. This obviously also doesn't work when I try to maximize this entropy using any optimizer.
[ 0.83239555  0.27431309]
[array([[ 0.14181709,  0.14077036, -0.28258738],
       [ 0.13012242, -0.19513965,  0.06501719]], dtype=float32)]
[ 0.83239555  0.27431309]
[array([[ 0.,  0.,  0.],
       [ 0.,  0.,  0.]], dtype=float32)]