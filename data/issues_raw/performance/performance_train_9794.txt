how to get image shape after decode in C++

System information

OS Platform and Distribution: Debian
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.0.1
Bazel version (if compiling from source): 0.4.5
CUDA/cuDNN version: cuda-8.0, cudnn5.1.5
GPU model and memory: 12GB

I follow the tutorial of inception label_image,
source codes ,
README.md , I can compile and run the demo c++ code successfully.
I want to adapt this demo to my own project, the input images to my own Network is height fixed, while width varies accordingly, for example, the original image is size of 64x100, and I want to resize it to 32x50, as I said 32 is the new_height, and I want to know original image size after reading from the file, how can I get width=100 and height=64? then I can get new_width = new_height/height x width=32/64x100=50
the following is a small piece of the image_recognition tutorial C++ codes, resize is hard coded to a pre-define size, I try float_caster.shape(), tensor(), float_caster.dimension(0), etc, all failed(float_caster, file_reader are all not Tensor, I don't know why Google design like this, really slow down the development, and I find no documentation about this), is there any easy way to get the image size? or cast the tensorflow::Ouput type to Tensor?
one possible way is first use opencv to load the image, and resize it, then copy the elements to tensor like this example pixel by pixel, but the performance is the main problem and it seems hard to compile tensorflow along with opencv.  Any one knows some methods using tensorflow's API?
Thanks in advance!

// Given an image file name, read in the data, try to decode it as an image,
// resize it to the requested size, and then scale the values as desired.
Status ReadTensorFromImageFile(string file_name, const int input_height,
                               const int input_width, const float input_mean,
                               const float input_std,
                               std::vector<Tensor>* out_tensors) {
  auto root = tensorflow::Scope::NewRootScope();
  using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)

  string input_name = "file_reader";
  string output_name = "normalized";
  auto file_reader =
      tensorflow::ops::ReadFile(root.WithOpName(input_name), file_name);
  // Now try to figure out what kind of file it is and decode it.
  const int wanted_channels = 3;
  tensorflow::Output image_reader;
  if (tensorflow::StringPiece(file_name).ends_with(".png")) {
    image_reader = DecodePng(root.WithOpName("png_reader"), file_reader,
                             DecodePng::Channels(wanted_channels));
  } else if (tensorflow::StringPiece(file_name).ends_with(".gif")) {
    image_reader = DecodeGif(root.WithOpName("gif_reader"), file_reader);
  } else {
    // Assume if it's neither a PNG nor a GIF then it must be a JPEG.
    image_reader = DecodeJpeg(root.WithOpName("jpeg_reader"), file_reader,
                              DecodeJpeg::Channels(wanted_channels));
  }
  // Now cast the image data to float so we can do normal math on it.
  auto float_caster =
      Cast(root.WithOpName("float_caster"), image_reader, tensorflow::DT_FLOAT);
  // The convention for image ops in TensorFlow is that all images are expected
  // to be in batches, so that they're four-dimensional arrays with indices of
  // [batch, height, width, channel]. Because we only have a single image, we
  // have to add a batch dimension of 1 to the start with ExpandDims().
  auto dims_expander = ExpandDims(root, float_caster, 0);
  // Bilinearly resize the image to fit the required dimensions.
  auto resized = ResizeBilinear(
      root, dims_expander,
      Const(root.WithOpName("size"), {input_height, input_width}));
  // Subtract the mean and divide by the scale.
  Div(root.WithOpName(output_name), Sub(root, resized, {input_mean}),
      {input_std});

  // This runs the GraphDef network definition that we've just constructed, and
  // returns the results in the output tensor.
  tensorflow::GraphDef graph;
  TF_RETURN_IF_ERROR(root.ToGraphDef(&graph));

  std::unique_ptr<tensorflow::Session> session(
      tensorflow::NewSession(tensorflow::SessionOptions()));
  TF_RETURN_IF_ERROR(session->Create(graph));
  TF_RETURN_IF_ERROR(session->Run({}, {output_name}, {}, out_tensors));
  return Status::OK();
}