Estimator numpy_input_fn doesn't work when reading input with pytables

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Relatively straightforward attempt at using estimator flow with input_fn
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Gentoo Linux
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): b'v1.0.0-2171-gbaa85cb' 1.0.1
Bazel version (if compiling from source): 0.4.4-
CUDA/cuDNN version: 8.0.61
GPU model and memory: GTX 970 4GB
Exact command to reproduce:

Other stuff: Python 3.4, pytables 3.3.0, numpy 1.12.1, hdf5-1.8.18
Describe the problem
I have an issue when reading multidimensional arrays from hdf5 file using pytables. I can fix the issue for myself locally by changing _OrderedDictNumpyFeedFn class (line 173 in my version) from
 column[integer_indexes]
to
np.take(column, integer_indexes, axis=0)
Source code / logs
Relevant bit of code:
def make_input_fn(data, batch_size):
    input_features = {node.name: node for node in data.get_node('/x')}
    ys = data.get_node('/y')
    return numpy_input_fn(input_features, ys, batch_size=batch_size, num_epochs=5, shuffle=False, num_threads=1)

def main(unused_argv):
    model_fn = make_train_model(feat)
    config = learn.RunConfig(save_checkpoints_secs=60)
    est = learn.Estimator(
        model_fn=model_fn, model_dir="data/tf/try1", config=config
    )
    training_data = tables.open_file('data/hdf5/training.h5')
    train_in = make_input_fn(training_data, 256)
    est.fit(
        input_fn=train_in,
        steps=100
    )
    training_data.close()
Error I get:
INFO:tensorflow:Using config: {'_is_chief': True, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 60, '_environment': 'local', '_num_ps_replicas': 0, '_master': '', '_task_type': None, '_tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1.0
}
, '_num_worker_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff377eaf550>, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_evaluation_master': '', '_model_dir': None, '_save_summary_steps': 100, '_tf_random_seed': None, '_task_id': 0}
INFO:tensorflow:Create CheckpointSaverHook.
2017-04-17 10:05:38.231511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-04-17 10:05:38.231863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: 
name: GeForce GTX 970
major: 5 minor: 2 memoryClockRate (GHz) 1.4305
pciBusID 0000:01:00.0
Total memory: 3.94GiB
Free memory: 3.45GiB
2017-04-17 10:05:38.232016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 
2017-04-17 10:05:38.232048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 
2017-04-17 10:05:38.232081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0)
INFO:tensorflow:Restoring parameters from data/tf/try1/model.ckpt-4
INFO:tensorflow:Error reported to Coordinator: <class 'ValueError'>, operands could not be broadcast together with shapes (256,) (4,) 
INFO:tensorflow:Saving checkpoints for 4 into data/tf/try1/model.ckpt.
Traceback (most recent call last):
  File ".../venv/lib/python3.4/site-packages/tables/array.py", line 651, in __getitem__
    startl, stopl, stepl, shape = self._interpret_indexing(key)
  File ".../venv/lib/python3.4/site-packages/tables/array.py", line 408, in _interpret_indexing
    raise TypeError("Non-valid index or slice: %s" % key)
TypeError: Non-valid index or slice: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/lib64/python3.4/runpy.py", line 170, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib64/python3.4/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/zfs_data/Sources/betahex/betahex/training/supervised.py", line 106, in <module>
    tf.app.run()
  File ".../venv/lib/python3.4/site-packages/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "/zfs_data/Sources/betahex/betahex/training/supervised.py", line 99, in main
    steps=50
  File ".../venv/lib/python3.4/site-packages/tensorflow/python/util/deprecation.py", line 281, in new_func
    return func(*args, **kwargs)
  File ".../venvs/default/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 429, in fit
    loss = self._train_model(input_fn=input_fn, hooks=hooks)
  File ".../venv/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 977, in _train_model
    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])
  File .../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 500, in __exit__
    self._close_internal(exception_type)
  File ".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 535, in _close_internal
    self._sess.close()
  File ".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 769, in close
    self._sess.close()
  File ".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 866, in close
    ignore_live_threads=True)
  File ".../venv/lib/python3.4/site-packages/tensorflow/python/training/coordinator.py", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File "/usr/lib/python3.4/site-packages/six.py", line 686, in reraise
    raise value
  File ".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py", line 93, in _run
    feed_dict = None if feed_fn is None else feed_fn()
  File ".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py", line 175, in __call__
    for column in self._ordered_dict_of_arrays.values()
  File ".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py", line 175, in <listcomp>
    for column in self._ordered_dict_of_arrays.values()
  File ".../venv/lib/python3.4/site-packages/tables/array.py", line 656, in __getitem__
    coords = self._point_selection(key)
  File ".../venv/lib/python3.4/site-packages/tables/leaf.py", line 561, in _point_selection
    coords[idx] = (coords + self.shape)[idx]
ValueError: operands could not be broadcast together with shapes (256,) (4,) 
Closing remaining open files:data/hdf5/training.h5...done