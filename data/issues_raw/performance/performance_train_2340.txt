Tensor.eval() Performance Decay

I used Tensorflow 0.6 (I pip installed TensorFlow: pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.6.0-cp34-none-linux_x86_64.whl) with Python 3 to train Neural Network on GPU (Nvidia GeForce GTX Titan X with Cuda 7.0 and Cudnn 6.5), and I noticed an interesting problem: The time consumption for running tensor.eval(session=..., feed_dict=...) at each iteration was continuously growing as iteration goes by, which indicated that performance of tensor.eval() decayed. Specifically, the code looks like this:
import tensorflow as tf
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)
session = tf.Session(config=tensorflow.ConfigProto(gpu_options=gpu_options))

"""Then build the neural network tensor graph, For example,"""
"""we define an neural network to compute output layer tensor a."""

# input tensor is an numpy array with dimension 32 * 336 * 84.
dict = {input_tensor: input_tensor}
for _ in 1000000:
     a.eval(session=session, feed_dict=dict)

In this code, the running time for each a.eval() gradually got larger and larger as iteration time goes by. So I used Profiling tooI (CProfile) to dig into the code to see at which part of code performance going wrong, and it indicated that time consumption for executing built-in method TF_Run for running a.eval() was very long and kept growing. I am pretty sure the input_tensor size keeps exactly same for each iteration, I wonder if anyone can help me figure out the problem, and how I can improve my current performance. Thanks!!!