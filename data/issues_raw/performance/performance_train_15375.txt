Performance  problem TF VS Keras

Hello ,
I just got huge difference in results using Keras (Back-end TensorFlow) and TensorFlow. I want to know if the difference in performances is normal .
The keras model produces a loss of 0.2
model = k.models.Sequential() model.add(k.layers.convolutional.Conv2D(64, kernel_size=(3,3), input_shape=(75,75,3))) model.add(Activation('relu')) model.add(BatchNormalization()) model.add(k.layers.convolutional.MaxPooling2D(pool_size=(3,3), strides=(2,2))) model.add(k.layers.Dropout(0.2)) model.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3))) model.add(Activation('relu')) model.add(BatchNormalization()) model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) model.add(k.layers.Dropout(0.2)) model.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3))) model.add(Activation('relu')) model.add(BatchNormalization()) model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) model.add(k.layers.Dropout(0.3)) model.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3))) model.add(Activation('relu')) model.add(BatchNormalization()) model.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2))) model.add(k.layers.Dropout(0.3)) model.add(k.layers.Flatten()) model.add(k.layers.Dense(512)) model.add(Activation('relu')) model.add(BatchNormalization()) model.add(k.layers.Dropout(0.2)) model.add(k.layers.Dense(256)) model.add(Activation('relu')) model.add(BatchNormalization()) model.add(k.layers.Dropout(0.2)) model.add(k.layers.Dense(1)) model.add(Activation('sigmoid')) mypotim=Adam(lr=0.01, decay=0.0) model.compile(loss='binary_crossentropy', optimizer = mypotim, metrics=['accuracy'])
The TensorFlow normal model produces 0.7 :
x = tf.placeholder(tf.float32, [None, 75,75,3], name="DNN_Input") learningRateIn= tf.placeholder(tf.float32) keep_prob = tf.placeholder(tf.float32) isTrainPlace=tf.placeholder(tf.bool) with tf.name_scope('conv_1'): conv_1=tf.layers.conv2d(x,64,[3,3],activation=tf.nn.relu) batch_n1 = tf.contrib.layers.batch_norm(conv_1,center=True, scale=True, is_training=isTrainPlace, scope='bn1') mpool_1=tf.layers.max_pooling2d(batch_n1,pool_size=(2,2),strides=(2,2)) dropout_1=tf.layers.dropout(mpool_1,rate=0.8,training=isTrainPlace) with tf.name_scope('conv_2'): conv_2=tf.layers.conv2d(dropout_1,128,[3,3],activation=tf.nn.relu) batch_n2 = tf.contrib.layers.batch_norm(conv_2, center=True, scale=True,is_training=isTrainPlace,scope='bn2') mpool_2=tf.layers.max_pooling2d(batch_n2,pool_size=(2,2),strides=(2,2)) dropout_2=tf.layers.dropout(mpool_2,rate=0.8,training=isTrainPlace) with tf.name_scope('conv_3'): conv_3=tf.layers.conv2d(dropout_2,128,[3,3],activation=tf.nn.relu) batch_n3 = tf.contrib.layers.batch_norm(conv_3, center=True, scale=True,is_training=isTrainPlace,scope='bn3') mpool_3=tf.layers.max_pooling2d(batch_n3,pool_size=(2,2),strides=(2,2)) dropout_3=tf.layers.dropout(mpool_3,rate=0.7,training=isTrainPlace) with tf.name_scope('conv_4'): conv_4=tf.layers.conv2d(dropout_3,64,[3,3],activation=tf.nn.relu) batch_n4 = tf.contrib.layers.batch_norm(conv_4,center=True, scale=True,is_training=isTrainPlace,scope='bn4') mpool_4=tf.layers.max_pooling2d(batch_n4,pool_size=(2,2),strides=(2,2)) dropout_4=tf.layers.dropout(mpool_4,rate=0.7,training=isTrainPlace) h4=tf.contrib.layers.flatten(dropout_4) with tf.name_scope('dense_1'): y_dense_1=tf.layers.dense(h4,512,activation=tf.nn.relu) batch_dense_1 = tf.contrib.layers.batch_norm(y_dense_1,center=True, scale=True,is_training=isTrainPlace, scope='bn5') dropout_dense_1=tf.layers.dropout(batch_dense_1,rate=0.8,training=isTrainPlace) with tf.name_scope('dense_2'): y_dense_2=tf.layers.dense(dropout_dense_1,256,activation=tf.nn.relu) batch_dense_2 = tf.contrib.layers.batch_norm(y_dense_2, center=True, scale=True, is_training=isTrainPlace,scope='bn6') dropout_dense_2=tf.layers.dropout(batch_dense_2 ,rate=0.8, training=isTrainPlace) y_estimated=tf.layers.dense(dropout_dense_2,2)
PS : the code above , is inspired from :  https://www.kaggle.com/devm2024/keras-model-for-beginners-0-210-on-lb-eda-r-d
Can anybody help me, please, to undersand , if it's normal or not ? does Keras, uses different tensorflow parameters than the default parameters of tensorflow ?
Thanks in advance.
Toetoe.