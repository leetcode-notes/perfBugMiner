Strange performance: sparse tensor matmul in kernel_test

Sorry for the previous issue
According to the document HERE

tensorflow/python/sparse_tensor_dense_matmul_op_test --benchmarks
A sparse [m, k] with % nonzero values between 1% and 80%
B dense [k, n]

When I run sparse_tensor_dense_matmul_op_test.py with large n,m,k
I get:
% nnz 	 n 	 gpu 	 m 	 k 	 dt(dense) 	 dt(sparse) 	 dt(sparse)/dt(dense)
0.5 	 512 	 True 	 1822 	 4608 	 0.0222946 	 0.0130646 	 0.585998
0.5 	 512 	 True 	 1821 	 4608 	 0.0224976 	 0.0130761 	 0.581222
0.5 	 512 	 True 	 1820 	 4608 	 0.022529 	 0.79513 	 35.2936
0.5 	 512 	 True 	 1819 	 4608 	 0.0217343 	 0.795709 	 36.6107

It is strange that dt(sparse)/dt(dense) are very different when m=1821 -> 1820
BTY, I set the iterations to 10 for time saving...
delta_dense = _timer(sess, ops_fn, 10)
delta_sparse = _timer(sess, ops_fn, 10)

Here's some information:
OS: Ubuntu 14.04
tf-version: 1.1.0  installed from source
GPU: NVIDIA K80, 4 kernels (only '/gpu:0' is used)
CUDA: 8.0
cudnn: 5.1.5
You can run sparse_tensor_dense_matmul_op_test.py with my settings
  for thresh in (0.5,):
    for n in (512,):
      for use_gpu in (True,):
        for m in (1822, 1821, 1820, 1819):
          for k in (9*512,):
            sparse_tensor_dense_vs_dense_matmul_benchmark(
                thresh, m, k, n, False, False, use_gpu=use_gpu)