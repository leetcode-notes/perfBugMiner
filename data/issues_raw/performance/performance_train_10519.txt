tf.contrib.data: tf-slim training pipeline gets stuck

System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux leto28 3.16.0-4-amd64 1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux
VERSION_ID="8"
VERSION="8 (jessie)"


TensorFlow installed from (source or binary):
Binary


TensorFlow version (use command below):
tf.VERSION = 1.2.0-rc2
tf.GIT_VERSION = v1.2.0-rc1-24-gce1d6ec
tf.COMPILER_VERSION = v1.2.0-rc1-24-gce1d6ec


Bazel version (if compiling from source):
None


CUDA/cuDNN version:
8.0/5.1


GPU model and memory:
TITAN X (Pascal), 12189MiB


Exact command to reproduce:
python ./mwe.py


Describe the problem
I recently ported my dataset handling to the new dataset API from tf.contrib.data. Now it seems that the tf-slim training pipeline stalls if I request just 1 or 2 CPUs for my job (it used to work just fine with the dataset API provided by tf-slim). I does work if I grab 4 CPUs. I tried to come up with a MWE (see below). The interesting thing is that it is not getting stuck if I remove one of the tf.summary.scalars or .map() at line 39. I suspect this issue is related to #10369.
Source code / logs
import os
import tensorflow as tf
import tensorflow.contrib.data as tcd
import tensorflow.contrib.slim as slim

from tensorflow.contrib.data.python.ops.dataset_ops import _get_file_names

DATASET_DIR = '/path_to_the_dataset'
FILE_PATTERN = 'shapes_{}_*.tfrecord'
IMAGE_SHAPE = [48, 48, 3]


def _parse_function(example_proto):
    features = {
        "image/encoded": tf.FixedLenFeature(
            (), tf.string, default_value=""),
        'image/annotation/color': tf.FixedLenFeature(
            (), tf.int64, default_value=0),
        'image/annotation/shape': tf.FixedLenFeature(
            (), tf.int64, default_value=0),
    }
    parsed_features = tf.parse_single_example(example_proto, features)
    image_decoded = tf.image.decode_image(parsed_features["image/encoded"])
    color = parsed_features['image/annotation/color']
    shape = parsed_features['image/annotation/shape']

    return image_decoded, color, shape


def get_batch(batch_size=32, group_size=3, split_name='train'):
    file_pattern = os.path.join(
        DATASET_DIR, FILE_PATTERN.format(split_name))

    file_names = _get_file_names(file_pattern, randomize_input=True)

    dataset = tcd.TFRecordDataset(file_names)
    dataset = dataset.map(_parse_function)

    dataset = dataset.map(lambda image, color, shape: image)
    dataset = dataset.shuffle(buffer_size=10000)
    dataset = dataset.repeat().batch(group_size * batch_size)

    iterator = dataset.make_one_shot_iterator()
    images = iterator.get_next()

    images = tf.split(images, group_size, axis=0)
    images = [tf.reshape(x, [batch_size] + IMAGE_SHAPE) for x in images]

    return images


if __name__ == "__main__":
    with tf.Graph().as_default():
        x_1, x_2, x_3 = get_batch(batch_size=32,
                                  group_size=3)

        val = tf.reduce_sum(tf.add_n([x_1, x_2, x_3]))
        val = tf.Print(val, [tf.constant(0)], "I'm alive! ")

        global_step = slim.get_or_create_global_step()
        with tf.control_dependencies([val]):
            update_global_step_op = tf.assign_add(global_step, 1)

        train_op = update_global_step_op

        tf.summary.scalar('Summary 1', val)
        tf.summary.scalar('Summary 2', train_op)

        logdir = 'mwe_logdir'
        slim.learning.train(
            train_op=train_op,
            logdir=logdir,
            number_of_steps=1000000)