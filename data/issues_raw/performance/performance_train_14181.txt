Tensorflow or python having memory cleanup issues when using multiple models in iterative loop

System information

Have I written custom code: yes
OS Platform and Distribution: Linux Ubuntu 17.04
TensorFlow installed from (source or binary): binary
TensorFlow version: v1.3.0-rc2-20-g0787eee 1.3.0
Python version: Python 3.6.1 :: Anaconda 4.4.0 (64-bit)
CUDA/cuDNN version: none
GPU model and memory: none

== cat /etc/issue ===============================================
Linux Bragi 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
VERSION="17.04 (Zesty Zapus)"
VERSION_ID="17.04"
VERSION_CODENAME=zesty
== are we in docker =============================================
No
== compiler =====================================================
c++ (Ubuntu 6.3.0-12ubuntu2) 6.3.0 20170406
Copyright (C) 2016 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
== uname -a =====================================================
Linux Bragi 4.10.0-37-generic #41-Ubuntu SMP Fri Oct 6 20:20:37 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
== check pips ===================================================
numpy (1.12.1)
numpydoc (0.6.0)
protobuf (3.4.0)
tensorflow (1.3.0)
tensorflow-tensorboard (0.1.8)
== check for virtualenv =========================================
False
== tensorflow import ============================================
tf.VERSION = 1.3.0
tf.GIT_VERSION = v1.3.0-rc2-20-g0787eee
tf.COMPILER_VERSION = v1.3.0-rc2-20-g0787eee
Sanity check: array([1], dtype=int32)
== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset
== nvidia-smi ===================================================
./tf_env_collect.sh: line 105: nvidia-smi: command not found
Describe the problem
I am working on a tensorflow model which takes pretty much RAM. It is executed iteratively to process given tasks.
However, with increasing time the whole process starts consuming more and more RAM although it should clean it up. This sounds like as if I'd keep data of one graph over the iterations, but I am almost sure that the graphs are cleanly separated.
Problem
I reduced the code to the following:
import tensorflow as tf
import numpy as np

reps = 30
for i in range(reps):
    with tf.Graph().as_default() as graph:
        with tf.Session(graph=graph) as sess:
            tf.constant(np.random.random((1000,1000,200,1)))

I have 32GB RAM available, working on a ubuntu 17.04 with CPU Tensorflow 1.3. This will give following error message after about the 25th or 27th iteration:

terminate called after throwing an instance of 'std::bad_alloc'
what():  std::bad_alloc

Giving the process some time after each iteration results in no improvement:
import tensorflow as tf
import numpy as np
import time

reps = 30
for i in range(reps):
    with tf.Graph().as_default() as graph:
        with tf.Session(graph=graph) as sess:
            tf.constant(np.random.random((1000,1000,200,1)))
    time.sleep(1)

However, it works if I force garbage collection invocation after each repetition:
import tensorflow as tf
import numpy as np
import gc

reps = 30
for i in range(reps):
    with tf.Graph().as_default() as graph:
        with tf.Session(graph=graph) as sess:
            tf.constant(np.random.random((1000,1000,200,1)))
    gc.collect()

Question
Now I wonder why I need to force garbage collection to run even though tensorflow should have closed the session and de-referenced the graph object.
Back to my original model I am not sure, yet, if the gc invocation actually helps. The memory usage grows pretty intense, especially when I am about to persist the model to disk.
Thanks for any insights.