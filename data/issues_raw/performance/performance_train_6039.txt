Precision of reduce_sum operation

There seems to be a numerical precision problem with the reduce_sum operation, see the example provided below. Even though everything is set to float32 as datatype tensorflow produces a much more imprecise result than numpy (whose result is numerically exact).
Is this intended? It seems strange that tensorflow makes such serious numerical errors. Am I doing something wrong?
What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
nothing there to my knowledge
Environment info
Operating System: Mac OSX 10.12.1
Tensorflow 0.11.0 CPU
https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0-py2-none-any.whl
could be reproduced in docker-container tensorflow/tensorflow:0.12.0-rc0 in a virtualbox linux vm
If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
import tensorflow as tf
import numpy as np

data = tf.constant(1.23456, shape=[250,250], dtype=tf.float32)
sum = tf.reduce_sum(data)
sess = tf.Session()
sess.run(sum) #77151.477

data2 = np.full([250, 250], np.float32(1.23456), dtype=np.float32)
np.sum(data2) #77160
https://gist.github.com/flash1293/84c2719dd646c0314ec0f4ea05df117a
What other attempted solutions have you tried?



Logs or other output that would be helpful