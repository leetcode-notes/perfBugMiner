Source Built r1.4 on GPUs with CPU optimized is always slower than 'no cpu optimization'

System information

Have I written custom code: Yes, the model named PSIque arXiv:1711.10644
OS Platform and Distribution: CentOS 7.1/CentOS 7.3
TensorFlow installed from: source build w/ Bazel
TensorFlow version: 1.4
Python version: Anaconda 3.6.2
Bazel version: 0.8.1
GCC/Compiler version (if compiling from source): gcc version 4.8.3 20140911 (Red Hat4.8.3-9) (GCC)
CUDA/cuDNN version: CUDA 8.0/r375.26/cuDNN 6.0.0 & CUDA 9.0/r384.81/cuDNN 7.0.5
GPU model and memory: E5-2660v3*2 Socket, K40m 12GB, P100-PCIE-16GB
Exact command to reproduce: python model.py

Describe the problem


I built tensorflow from source for boosting operation performance.


6 different distributions were built;

CPU only & No CPU optimization (NO EXTRA flags)
CPU only & CPU optimization (--config=opt)
GPU support & CUDA 8/9 & No CPU optimization (--config=cuda)
GPU support & CUDA 8/9 & CPU optimization (--config=opt --config=cuda)



Experiments were basically done by 5 phases; experiments on CPU only are still going on,
so please focus on GPU version results.


Results are quite frustrating me, because 'most of CPU optimized versions' gave me slow results.



Test were made on multiple machine with random order.

P100: 2 nodes
K40m: 7 nodes
CPU only: 8 nodes



I am curious why CPU optimized version is slow

on every experiment combinations
even different GPU environments
even Dual CPU socket (E5-2660v3)



(Extra) I believe my current model does not require high throughputs


tf_env_collect.sh
== cat /etc/issue ===============================================
Linux  3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
VERSION="7 (Core)"
VERSION_ID="7"
CENTOS_MANTISBT_PROJECT_VERSION="7"
REDHAT_SUPPORT_PRODUCT_VERSION="7"
== are we in docker =============================================
No
== compiler =====================================================
c++ (GCC) 4.8.3 20140911 (Red Hat 4.8.3-9)
Copyright (C) 2013 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
== uname -a =====================================================
Linux vis5 3.10.0-229.el7.x86_64 #1 SMP Fri Mar 6 11:36:42 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux
== check pips ===================================================
numpy (1.13.3)
protobuf (3.4.0)
tensorflow (1.4.0)
tensorflow-tensorboard (0.4.0rc3)
== check for virtualenv =========================================
False
== tensorflow import ============================================
tf.VERSION = 1.4.0
tf.GIT_VERSION = b'unknown'
tf.COMPILER_VERSION = b'unknown'
Sanity check: array([1], dtype=int32)
== env ==========================================================
LD_LIBRARY_PATH :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
DYLD_LIBRARY_PATH is unset
== nvidia-smi ===================================================
Sat Dec 30 12:39:08 2017
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla P100-PCIE...  On   | 00000000:04:00.0 Off |                    0 |
| N/A   28C    P0    35W / 250W |      0MiB / 16276MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla P100-PCIE...  On   | 00000000:82:00.0 Off |                    0 |
| N/A   35C    P0    38W / 250W |  15661MiB / 16276MiB |     19%      Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    1     68169      C   python                                     15643MiB |
+-----------------------------------------------------------------------------+
== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176
/usr/local/cuda-9.0/lib64/libcudart_static.a