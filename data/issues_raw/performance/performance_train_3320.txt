CPU vs GPU Performance

I am working on a reinforcement learning model problem.  I have been working to get the model creation running faster and bumped into a strange issue I cannot explain.  It runs much faster ~50% or so on the CPU vs the GPU.  This was unexpected and I have disabled the GPU using "export CUDA_VISIBLE_DEVICES=-1" so the learning runs faster.  I have been looking at upgrading my GTX 950, but not sure it makes sense if I don't get a speed improvement.
I ran a profile based upon #1824 and got the following trace files for a single ".run()" iteration. I am not sure how to read this, but the GPU iteration took over 10ms where the CPU alone is <10ms. I am running the HEAD of TensorFlow (reports 0.9.0) on Ubuntu 15.10 with CUDA 7.5 and cuDNN 4 & 5 (tried both). The CPU is a dual XEON 6 core, 2.66 GHz  processors (24 threads total) with 72 GB or RAM (DDR3).
I have a GTX 950 GPU.  I can't tell if this performance difference is related to the structure of the graph or simply the data set isn't big enough to get a benefit from the GPU given the IO overhead?  I have tested the GPU with TF on a basic "matmut()" of a 7000x7000 matrix and it beats the CPU hands down by orders of magnitude.  So I known it is installed correctly.
Then networks runs in this case a Batch of 200 x 189 into 5 layers with Dropout() between each layer. The layers are 140, 120, 100, 80, and 3 as the output.  Any advice or things to try would be much appreciated.
CPU Timeline:

GPU Timeline:

NOTE: This issue was posted to #2444 but may have got lost.  It might be related to RL performance but feel it is a separate issue.
I have enclosed the TIMELINE trace files for more detail.  If it is of value, I can create a "tensorboard" log file so you can review the model in detail.
GPU Slowdown.zip