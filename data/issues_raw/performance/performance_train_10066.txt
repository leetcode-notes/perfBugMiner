cifar10 example running slower with Windows 10

System information 1

Have I written custom code: No
OS Platform and Distribution: Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 0.12.1
CUDA/cuDNN version: 8.0.44 / 5.1
GPU model and memory: GTX 1080 8gb
Exact command to reproduce: 'python3 cifar10_train.py'

System information 2

Have I written custom code: No
OS Platform and Distribution: Windows 10 Pro
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 0.12.1
CUDA/cuDNN version: 8.0.44 / 5.1
GPU model and memory: GTX 1080 8gb
Exact command to reproduce: 'python cifar10_train.py'

System information 3

Have I written custom code: No
OS Platform and Distribution: Windows 7 Pro
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 0.12.1
CUDA/cuDNN version: 8.0.44 / 5.1
GPU model and memory: Titan X maxwell 12gb
Exact command to reproduce: 'python cifar10_train.py'

Describe the problem
When running the cifar 10 CNN example code (https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10/), I get very different performance on several OS while having same installations of CUDA, CuDNN & TF, and the same code of course.
With System 1 (described above): running at ~2600 images/sec, Python CPU usage at ~50%
With System 2 (described above): running at ~600 images/sec, Python CPU usage at 100% (!)
With System 3 (described above): running at ~2600 images/sec, Python CPU usage at ~50%
I'm experiencing the same problems with TF r1.0.1.
Seems like something in this code (pherhaps the queue threading?) doesn't go well with win10? CPU usage reaches 100% with win10, and significantly slower, that's very weird.
Thanks.