tf.train.import_meta_graph should be parallelized

Hey guys, I've been wondering whether it's possible the tf.train.import_meta_graph to be parallelized across multiple cores. When I load a complex model it takes too long and I only see one of my 24 cores being utilized to 100%.
Environment info
Operating System: CentOS
Installed version of CUDA and cuDNN:
Not applicable
Minimal example:
sess = tf.Session()
new_saver = tf.train.import_meta_graph('my-model.meta')
new_saver.restore(sess, tf.train.latest_checkpoint('./'))
all_vars = tf.get_collection('vars')
for v in all_vars:
    v_ = sess.run(v)
    print(v_)

Any plans on changing that in the near future?