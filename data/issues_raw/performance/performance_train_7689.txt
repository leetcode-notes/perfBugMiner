tf.nn.softmax errors out, when dim=<dim_size - 1> instead of -1

Environment info
Operating System:
MacOS 10.12.1
Installed version of CUDA and cuDNN:
lrwxr-xr-x  1 root  wheel     50 Sep 26 15:00 /usr/local/cuda/lib/libcudart.8.0.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib
lrwxr-xr-x  1 root  wheel     47 Oct 24 21:11 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-8.0/lib/libcudnn.5.dylib
Tensorflow version 0.12.1
If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
def test_softmax():
  with tf.variable_scope("test_coattention_layer"):
    doc1_placeholder = tf.placeholder(tf.float32, shape=(None, 4, 3))

  init = tf.global_variables_initializer()

  with tf.Session() as session:
    session.run(init)
    input = np.array(range(2 * 4 * 3), dtype=np.float32).reshape((2, 4, 3))

    softmax1 = tf.nn.softmax(doc1_placeholder, dim=-1) # <======== THIS WORKS
    softmax2 = tf.nn.softmax(doc1_placeholder, dim=2) # <======== THIS BREAKS

    print("doc1 = " + str(input))
    softmax1_out = session.run(softmax1, feed_dict={doc1_placeholder: input})
    softmax2_out = session.run(softmax2, feed_dict={doc1_placeholder: input})
    print("softmax1_out = " + str(softmax1_out))
    print("softmax2_out = " + str(softmax2_out))


Error message:
InvalidArgumentError (see above for traceback): Requires start <= limit when delta > 0: 3/2
[[Node: range_1 = Range[Tidx=DT_INT32, _device="/job:localhost/replica:0/task:0/cpu:0"](range_1/start, Sub, range_1/delta)]]