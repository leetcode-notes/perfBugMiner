Keras multi input and estimator

If I've interpreted it correctly seems that there is some strange behavior with Keras multi inputs and the estimator.

Why input layers are renamed with _1 suffix?
Why TB display a _2 suffixed parallel sub-graph?

I've attached a snippet runnable on colab and the TB rendered image.
from tensorflow import keras as ks
import numpy as np
from IPython.display import clear_output, Image, display, HTML

def strip_consts(graph_def, max_const_size=32):
    """Strip large constant values from graph_def."""
    strip_def = tf.GraphDef()
    for n0 in graph_def.node:
        n = strip_def.node.add() 
        n.MergeFrom(n0)
        if n.op == 'Const':
            tensor = n.attr['value'].tensor
            size = len(tensor.tensor_content)
            if size > max_const_size:
                tensor.tensor_content = "<stripped %d bytes>"%size
    return strip_def

def show_graph(graph_def, max_const_size=32):
    """Visualize TensorFlow graph."""
    if hasattr(graph_def, 'as_graph_def'):
        graph_def = graph_def.as_graph_def()
    strip_def = strip_consts(graph_def, max_const_size=max_const_size)
    code = """
        <script src="//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js"></script>
        <script>
          function load() {{
            document.getElementById("{id}").pbtxt = {data};
          }}
        </script>
        <link rel="import" href="https://tensorboard.appspot.com/tf-graph-basic.build.html" onload=load()>
        <div style="height:600px">
          <tf-graph-basic id="{id}"></tf-graph-basic>
        </div>
    """.format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))

    iframe = """
        <iframe seamless style="width:1200px;height:620px;border:0" srcdoc="{}"></iframe>
    """.format(code.replace('"', '&quot;'))
    display(HTML(iframe))

class ExampleHook(tf.train.SessionRunHook):
    def __init__(self):
        print('Starting the session.')
        return

    def begin(self):
        g = tf.get_default_graph()
        show_graph(g)
        print('Starting the session.')
        
        #for op in tf.get_default_graph().get_operations():
          #print(str(op.name) )
        
my_input_fn = tf.estimator.inputs.numpy_input_fn(
    x={"input_rgb": np.array(np.random.rand(5,5,3).astype(np.float32)), "input_gray": np.array(np.random.rand(5,5,1).astype(np.float32)), 
       "input_mix": np.array(np.random.rand(5,5,1).astype(np.float32))},
    y= np.array(np.random.rand(5,5,1)),
      batch_size=1,
      num_epochs=1,
      shuffle=False)

input_rgb = ks.layers.Input(shape=(1,5, 5, 3), name="input_rgb")
input_gray = ks.layers.Input(shape=(1,5, 5, 1), name="input_gray")
input_mix = ks.layers.Input(shape=(1,5, 5, 1), name="input_mix")
rgb_gray = ks.layers.concatenate([input_rgb, input_gray, input_mix], name="rbg_gray")
x = ks.layers.Dense(1, activation='relu',name="Dense_1")(rgb_gray)
x = ks.layers.Dense(1, activation='softmax',name="softmax")(x)
model = ks.models.Model(
        inputs=[input_rgb, input_gray, input_mix],
        outputs=[x])
model.compile(loss={ 'softmax': 'binary_crossentropy'},optimizer=tf.keras.optimizers.Adam())


est = ks.estimator.model_to_estimator(
            keras_model=model)

model.summary()
print(model.input_names)
pred = list(est.predict(
    input_fn=my_input_fn,
    predict_keys=None,
    hooks=[ExampleHook()],
))