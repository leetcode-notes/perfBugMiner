All the graph have an operation _Retval that makes the train loop slow

I have tried to train the model in tf_cnn_benchmarks.py and cifar10_multi_gpu_train.py.
All the timelines results like the image bellow. There is an operation named '_Retval' in the end of training loop. But as we see, long idle time was leaved in the timeline. How can I make the training faster by getting rid of the operation '_Retval' ? Is there other method to let the gpu be at full power?


The images above were got by the script:
python tf_cnn_benchmarks.py local_parameter_device=cpu --num_gpus=2 --batch_size=64 --model=vgg16 --variable_update=independent --optimizer=sgd --trace_file=/home/zhaoerchao/timeline_benchmark.json --distortions