[Java API] Tensor.create() slow for large arrays

The current Java API's Tensor.create(Object) is really slow - for a batch of 128 images of size 224x224x3 it's taking around 1.5seconds. To put this into perspective runner.run() with that data and an InceptionV3 graph took below 1second so data prep is x1.5 of the runtime here (for a batch of 32 images it's around 0.35-0.45sec).
Is this working as intended? When running the Python code (using simple sess.run(fetches, feed_dict=feed_dict)) with which the graph meta file was generated (TF 1.0.1) and feeding a Python array I don't see such hiccups, the speed is the same as the Java runner.run().
Might it be because of build flags used, maybe I'm missing some optimizations?
For now this small part is killing the whole performance, bringing it down from 130obs/sec (runner.run() time) to about ~45obs/sec (Tensor.create+run()).
A bit of a sidenote, the performance page states:

This will result in poor performance.
sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})

But currently there's no other way to feed data from the Java API, right? A queue (able to read from a file and from memory, i.e. from a Java structure) would be amazing.
Jar build command
export CC="/usr/bin/gcc"
export CXX="/usr/bin/g++"
export TF_NEED_CUDA=1
export GCC_HOST_COMPILER_PATH=$CC
export BUILDFLAGS="--config=cuda --copt=-m64 --linkopt=-m64 --copt=-march=native"

bazel build -c opt \
  //tensorflow/java:tensorflow \
  //tensorflow/java:libtensorflow_jni \
  $BUILDFLAGS --spawn_strategy=standalone --genrule_strategy=standalone

Environment info
OS: Ubuntu 16.04
GPU: GPU TITAN X (Pascal) 12GB
CPU: Intel® Xeon® Processor E5-2630 v4 10core
GPU Drivers:
NVidia CUDA Driver Version: 375.39
CUDNN 5.1.5
CUDA 8
Tensorflow version: JAR file built from current master (c25ecb5)
Example
public void test() {
  Random r = new Random();
  int imageSize = 224 * 224 * 3;
  int batch = 128;
  float[][] input = new float[batch][imageSize];
  for(int i = 0; i < batch; i++) {
    for(int j = 0; j < imageSize; j++) {
      input[i][j] = r.nextFloat();
    }
  }

  long start = System.nanoTime();
  Tensor.create(input);
  long end = System.nanoTime();
  // Around 1.5sec
  System.out.println("Took: " + (end - start));
}