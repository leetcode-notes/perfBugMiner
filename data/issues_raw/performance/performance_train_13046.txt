tf.reduce_max inconsistent with numpy.max when handling NaN values

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.3 LTS
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.3.0-rc2-20-g0787eee 1.3.0
Python version: 3.5.2
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: 8.0 / 6.0
GPU model and memory: P100 (16GB)
Exact command to reproduce: [see below]

Describe the problem
The documentation for tf.reduce_max states that it is "Equivalent to np.max". This is not true when the provided input_tensor includes NaN values.
TensorFlow ignores NaN values and returns inf (if present) or the largest finite value. Numpy will propagate NaN values in np.max / np.amax and has a special function np.nanmax for ignoring NaN values. (See the Notes section here: https://docs.scipy.org/doc/numpy/reference/generated/numpy.amax.html)
Expected behavior is that tf.reduce_max returns NaN when its input includes NaN values.
Source code / logs
import numpy as np
import tensorflow as tf

vals = [float('1'), float('nan')]

np_max = np.max(vals)
tf_max = tf.reduce_max(tf.constant(vals))

with tf.Session() as sess:
    print('TF max: {}'.format(sess.run(tf_max)))
print('numpy max: {}'.format(np_max))
When run, this code produces the following output:
TF max: 1.0
numpy max: nan