t.eval() built with slim outputs wrong predictions when input batch contains identical images

When evaluating a model built with slim on a batch that contains identical images, the output of the batch will be wrong (mostly the outputs will be the most frequent label). For example, if my evaluation set has 421 images and my batch size is 40, I filled the last batch with 19 identical images (the 421st one) to avoid tensor shape mismatch error. Then,  the output for the 21st to the 40th image of the last batch will be the most common label in training set. If I replace the 19 images with some randomly selected images, the outputs will be correct.
What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
None.
Environment info
Operating System: Ubuntu 14.04.5
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*):

If installed from binary pip package, provide:


A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl


The output from python -c "import tensorflow; print(tensorflow.__version__)".


I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0
If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
The problem can be reproduced with any model built purely with slim but evaluated with output.eval(feed_dict={batch_image:test_batch}) or sess.run(output, feed_dict={batch_image:test_batch})
when the test batch contains several identical images.
What other attempted solutions have you tried?
Avoid identical or similar images in evaluation batch.
Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).