tensorflow crash when training in distribution

I'am train my model in distribution, running 12 workers and 2 ps server.
But the worker crash and dumping core files continuously.
What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
nothing
Environment info
Operating System:
centos 6.3 with cpu
tensorflow version 0.12
If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
if __name__ == "__main__":
  ps_hosts = FLAGS.ps_hosts.split(",")
  worker_hosts = FLAGS.worker_hosts.split(",")
  cluster = tf.train.ClusterSpec({"ps": ps_hosts, "worker": worker_hosts})
  server = tf.train.Server(cluster,
                           job_name=FLAGS.job_name,
                           task_index=FLAGS.task_index)
  if FLAGS.job_name == "ps":
    server.join()
  elif FLAGS.job_name == "worker":
    with tf.device(tf.train.replica_device_setter(
            worker_device="/job:worker/task:%d" % FLAGS.task_index,
            cluster=cluster)):
        # Read TFRecords files for training
        filename_queue = tf.train.string_input_producer(
            tf.train.match_filenames_once(FLAGS.train),
            num_epochs=epoch_number)
        serialized_example = read_and_decode(filename_queue)
        batch_serialized_example = tf.train.shuffle_batch(
            [serialized_example],
            batch_size=batch_size,
            num_threads=thread_number,
            capacity=capacity,
            min_after_dequeue=min_after_dequeue)
        features = tf.parse_example(
            batch_serialized_example,
            features={
                "label": tf.FixedLenFeature([], tf.float32),
                "ids": tf.VarLenFeature(tf.int64),
                "values": tf.VarLenFeature(tf.float32),
            })
        batch_labels = features["label"]
        batch_ids = features["ids"]
        batch_values = features["values"]

        # Read TFRecords file for validatioin
        validate_filename_queue = tf.train.string_input_producer(
            tf.train.match_filenames_once(FLAGS.eval),
            num_epochs=epoch_number)
        validate_serialized_example = read_and_decode(validate_filename_queue)
        validate_batch_serialized_example = tf.train.shuffle_batch(
            [validate_serialized_example],
            batch_size=validate_batch_size,
            num_threads=thread_number,
            capacity=capacity,
            min_after_dequeue=min_after_dequeue)
        validate_features = tf.parse_example(
            validate_batch_serialized_example,
            features={
                "label": tf.FixedLenFeature([], tf.float32),
                "ids": tf.VarLenFeature(tf.int64),
                "values": tf.VarLenFeature(tf.float32),
            })
        validate_batch_labels = features["label"]
        validate_batch_ids = features["ids"]
        validate_batch_values = features["values"]
        logits = inference(batch_ids, batch_values)
        batch_labels = tf.to_int64(batch_labels)
        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,
                                                                       batch_labels)
        loss = tf.reduce_mean(cross_entropy, name='loss')

        print("Use the optimizer: {}".format(FLAGS.optimizer))
        if FLAGS.optimizer == "sgd":
            optimizer = tf.train.GradientDescentOptimizer(learning_rate)
        elif FLAGS.optimizer == "momentum":
            # optimizer = tf.train.MomentumOptimizer(learning_rate)
            print("Not support optimizer: {} yet, exit now".format(FLAGS.optimizer))
            exit(1)
        elif FLAGS.optimizer == "adadelta":
            optimizer = tf.train.AdadeltaOptimizer(learning_rate)
        elif FLAGS.optimizer == "adagrad":
            optimizer = tf.train.AdagradOptimizer(learning_rate)
        elif FLAGS.optimizer == "adam":
            optimizer = tf.train.AdamOptimizer(learning_rate)
        elif FLAGS.optimizer == "ftrl":
            optimizer = tf.train.FtrlOptimizer(learning_rate)
        elif FLAGS.optimizer == "rmsprop":
            optimizer = tf.train.RMSPropOptimizer(learning_rate)
        else:
            print("Unknow optimizer: {}, exit now".format(FLAGS.optimizer))
            exit(1)

        #with tf.device("/cpu:0"):
        global_step = tf.Variable(0, name='global_step', trainable=False)
        train_op = optimizer.minimize(loss, global_step=global_step)

        # Compute accuracy
        tf.get_variable_scope().reuse_variables()
        accuracy_logits = inference(validate_batch_ids, validate_batch_values)
        validate_softmax = tf.nn.softmax(accuracy_logits)
        validate_batch_labels = tf.to_int64(validate_batch_labels)
        correct_prediction = tf.equal(
            tf.argmax(validate_softmax, 1), validate_batch_labels)
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

        # Compute auc
        validate_batch_labels = tf.cast(validate_batch_labels, tf.int32)
        sparse_labels = tf.reshape(validate_batch_labels, [-1, 1])
        derived_size = tf.shape(validate_batch_labels)[0]
        indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])
        concated = tf.concat(1, [indices, sparse_labels])
        outshape = tf.pack([derived_size, LABEL_SIZE])
        new_validate_batch_labels = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)
        _, auc_op = tf.contrib.metrics.streaming_auc(validate_softmax,
                                                     new_validate_batch_labels)

        # Define inference op
        sparse_index = tf.placeholder(tf.int64)
        sparse_ids = tf.placeholder(tf.int64)
        sparse_values = tf.placeholder(tf.float32)
        sparse_shape = tf.placeholder(tf.int64)
        inference_ids = tf.SparseTensor(sparse_index, sparse_ids, sparse_shape)
        inference_values = tf.SparseTensor(sparse_index, sparse_values, sparse_shape)
        inference_logits = inference(inference_ids, inference_values)
        inference_softmax = tf.nn.softmax(inference_logits)
        inference_op = tf.argmax(inference_softmax, 1)

        # Initialize saver and summary
        #checkpoint_file = checkpoint_dir + "checkpoint.ckpt"
        steps_to_validate = FLAGS.steps_to_validate
        init_op = tf.initialize_all_variables()

        saver = tf.train.Saver(max_to_keep = 2)
        keys_placeholder = tf.placeholder("float")
        keys = tf.identity(keys_placeholder)
        tf.add_to_collection("inputs", json.dumps({'key': keys_placeholder.name}))
        tf.add_to_collection("outputs", json.dumps({'key': keys.name,
                                                    'softmax': inference_softmax.name,
                                                    'prediction': inference_op.name}))
        tf.scalar_summary('loss', loss)
        tf.scalar_summary('accuracy', accuracy)
        tf.scalar_summary('auc', auc_op)
        summary_op = tf.merge_all_summaries()


    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                             logdir="./train_process/",
                             init_op=init_op,
                             summary_op=summary_op,
                             saver=saver,
                             global_step=global_step,
                             save_model_secs=60)

    # Create session to run graph
    with sv.managed_session(server.target) as sess:
        if mode == "train" or mode == "train_from_scratch":
            while not sv.should_stop():
                # Get coordinator and run queues to read data
                coord = tf.train.Coordinator()
                threads = tf.train.start_queue_runners(coord=coord, sess=sess)

                start_time = datetime.datetime.now()

                try:
                    while not coord.should_stop():
                        _, loss_value, step = sess.run([train_op, loss, global_step])
                        if step % steps_to_validate == 0:
                            accuracy_value, auc_value, summary_value = sess.run(
                                [accuracy, auc_op, summary_op])
                            end_time = datetime.datetime.now()
                            print("[{}] Task: {}, Step: {}, loss: {}, accuracy: {}, auc: {}".format(
                                end_time - start_time,
                                FLAGS.task_index,
                                step, loss_value, accuracy_value,
                                auc_value))

                            start_time = end_time
                except tf.errors.OutOfRangeError:
                    print("Done training after reading all data")
                finally:
                    coord.request_stop()
                    print("coord stopped")

                # Wait for threads to exit
                coord.join(threads)

logs
gdb python core.xxxxx , and then 'bt', shows that

#0  0x00007f5943d3f166 in pthread_detach () from /opt/glibc-2.17/lib/libpthread.so.0
#1  0x00007f58fc8c8ab5 in std::thread::detach() ()
    at /opt/install/gcc-build/x86_64-redhat-linux/libstdc++-v3/include/x86_64-redhat-linux/bits/gthr-default.h:674
#2  0x00007f58fec7f0bf in tensorflow::(anonymous namespace)::PosixEnv::SchedClosure(std::function<void ()()>) ()
   from /home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#3  0x00007f58fea8e981 in tensorflow::SchedClosure(std::function<void ()()>) ()
   from /home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#4  0x00007f58fd5f72cd in tensorflow::Master::RunStep(tensorflow::CallOptions*, tensorflow::RunStepRequest const*, tensorflow::RunStepResponse*, std::function<void ()(tensorflow::Status const&)>) ()
   from /home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#5  0x00007f58fd5f10f9 in tensorflow::GrpcMasterService::RunStepHandler(tensorflow::Call<tensorflow::GrpcMasterService, tensorflow::grpc::MasterService::AsyncService, tensorflow::RunStepRequest, tensorflow::RunStepResponse>*) ()
   from /home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#6  0x00007f58fd5f2c4c in tensorflow::GrpcMasterService::HandleRPCsLoop() ()
   from /home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#7  0x00007f58fc8c8b80 in execute_native_thread_routine_compat ()
    at ../../../../../gcc-6.2.0/libstdc++-v3/src/c++11/thread.cc:110
#8  0x00007f5943d3df83 in start_thread () from /opt/glibc-2.17/lib/libpthread.so.0
#9  0x00007f59433668bd in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:113