failed to convert model with "FusedBatchNorm" to TFLITE format

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
14.04
TensorFlow installed from (source or binary):
both source and binary tried
TensorFlow version (use command below):
1.4
Python version:
2.7
Bazel version (if compiling from source):
7
GCC/Compiler version (if compiling from source):
4.8
CUDA/cuDNN version:
8.0-5.1
GPU model and memory:
gtx1080-8G
Exact command to reproduce:

###Problem###
My original model is with node "FusedBatchNorm", when I run the script  bazel build tensorflow/contrib/lite/toco:toco and bazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/home/wz/Desktop/rt-mobilenet.pb --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --output_file=/home/wz/Desktop/tflite-pose.lite --inference_type=FLOAT --input_type=FLOAT --input_arrays=image --output_arrays=Openpose/concat_stage7 --input_shapes=1,368,368,3
Everything seems fine, but the result file is empty. And I traced the code, founding that code returned at file 'resolve_constant_binary' 's function 'EvaluateBinaryOperatorOnConstantInputs'.
My model can be get here.
God help me! Thanks a lot!