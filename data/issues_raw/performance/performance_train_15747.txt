An easy problem about tensorflow GPU unilization

Today , I run an easy RNN model to deal with a  NLP task, which the traindata is just about 4000 short sentences and the iteration is 30. However, the time cost about 1 hour to finish the procedure. my computer GPU is nvidia 1080Ti and CPU is i7 8700K.
In the console, the information is:
Total memory: 10.91GiB
Free memory: 10.30GiB
but in the terminal, i use the command： nvidia-smi -l
it return another information:
10713MiB / 11171MiB
my question are : 1. Does the GPU really work ???
2. if work, why the time cost still large???
Thx！