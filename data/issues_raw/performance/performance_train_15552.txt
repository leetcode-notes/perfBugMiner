Tensorflow 1.4 C++ API considerably slower than Python

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): source with all optimizations
TensorFlow version (use command below): 1.4
Python version:  3.5.2
Bazel version (if compiling from source): 0.8.1
GCC/Compiler version (if compiling from source): 5.4.0
CUDA/cuDNN version: 8.0 / 6.0
GPU model and memory: GTX960M

Describe the problem
I was trying to run several models and evaluate the performance with different batch sizes in python and c++ and noticed that the c++ API version is considerably slower than the python one. Both were compiled with the same optimizations and with cuda support.
When I try to predict the output of a single 256x256 image in python it takes me 0.5 seconds, and when i do it in tensorflow c++ api it takes me 1.7 seconds. Notice that in python I was using a non deployed model (without freezing and transforming graph), whereas in C++ I did those transformations.
Does anyone knows why this is happening? Is it because of the frozen and transformed graph?
I always thought the C++ API would be at least as fast as the Python version.