tf Dataset / Iterator console flood when using CUDA builds

System information

**Have I written custom code **: Yes
**OS Platform and Distribution **: Manjaro linux, Arch Linux repo
TensorFlow installed from (source or binary): binary
**TensorFlow version **: 1.3.0
Python version: 3.6.2
**Bazel version **:
CUDA/cuDNN version: cuda 8.0.61, cudnn 7.0.1 & cudnn6 6.0.21
GPU model and memory: Nvidia 1080 GTX 8GB
Exact command to reproduce:

The problem
When using a tensorflow wheel built with cuda support, my app prints the following warning message at the end of a training epoch:
2017-08-19 14:01:18.214060: W tensorflow/core/framework/op_kernel.cc:1192] Out of range: End of sequence [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[?,?,132], [?], [?,?], [?]], output_types=[DT_FLOAT, DT_INT64, DT_INT64, DT_INT64], _device="/job:localhost/replica:0/task:0/cpu:0"](Iterator)]]
The code trains a seq2seq model, and I assume the message gets printed somewhere downstream of seq2seq.dynamic_decode. The message still gets printed even when the NN cells are not wrapped with a tf.contrib.rnn.DeviceWrapper with device field indicating a GPU, only works fine on non-cuda builds.
All of this happens while the code is protected with the try/except statements:
        for epoch in range(num_epochs):
            session.run(iterator.initializer)
            while True:
                try:
                    session.run([operation])
                except tf.errors.OutOfRangeError:
                    break

Now the only cheeky thing is that I am using the binaries from Arch Linux repositories, but these are far from being dodgy.
python-tensorflow
python-tensorflow-cuda
The build script
This problem was in tensorflow 1.2 and persists in tensorflow 1.3.
Also tested on a laptop without dedicated gpu, but same OS and packages, works fine.