Add GPU implementation for tf.segment_sum.

As per #11228, a GPU version of segment sum has been created.
Performance
On a Tesla K40c GPU, the following performance tests have been performed.

The test case sizes are represented using 3-tuples of integers. The first two integers correspond to the outer and inner dimension of the input data and the last integer corresponds to the outer dimension of the output data, which is also the total number of segments.
The first three rows of data are obtained by running reductions on float32 input type whereas the last three rows of data are obtained by running reductions on float64 input type.
We use the GPU version of unsorted segment reduction as the baseline.
During experiments, they share the same input data and outputs are compared for consistency.





(1024, 1024, 128)
(2048, 2048, 256)
(4096, 4096, 512)




t_unsorted
84.942us
332.12us
1.3170ms


t_sorted
71.047us
264.16us
1.0391ms


speedup
1.20
1.26
1.27








t_unsorted
160.69us
594.93us
2.2895ms


t_sorted
106.94us
395.19us
1.5662ms


speedup
1.50
1.51
1.46

Known Limitations:

We do not check segment_id to make sure that they are within [0, num_outputs-1].
We do not verify that segment_id is increasing.