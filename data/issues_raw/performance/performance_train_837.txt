reading_data/fully_connected_reader.py VERY slow relative to fully_connected_feed.py

I noticed that when using a data reader to provide minibatches of examples to a model that performance is greatly reduced relative to just supplying the examples via feed_dict. For instance, when running reading_data/fully_connected_reader.py with the following flags::
--hidden1 512 --hidden2 512 --batch_size 128

it takes 28.7 seconds to process 600 minibatches with a GPU utilization of 13%. If I edit the code so that num_threads=16 (instead of num_threads=2) when shuffle_batch is called, these numbers improve to 14.9 seconds and 23% GPU utilization. However, training the same model via fully_connected_feed.py takes only 2.63 seconds and achieves a GPU utilization of 55%. This is hardly rigorous, but it seems that the overhead involved in reading the Example protos from the TFRecords file, putting them into a queue, etc is much higher than I would expect.
These numbers were compiled using 039981f and running on a Titan X card with no other background processes running.