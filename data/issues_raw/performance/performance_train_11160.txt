High variance in training convergence between keras (with tf backend) and tf.contrib.keras

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
TensorFlow installed from (source or binary):
binary
TensorFlow version (use command below):
1.2
Python version:
3.6

Describe the problem
I started to move my keras (Keras 2.0.4) scripts to tf.contrib.keras  (tf version 1.2) but I am achieving worse performance though the porting was seamless. Not sure why there is such huge discrepancy. in training performance
Source code / logs
Original (Keras 2.0.4 code)
import tensorflow as tf
import keras

resnet = keras.applications.ResNet50(include_top=False,weights='imagenet', pooling='avg')
input_ = resnet.input
final_layer = resnet.layers[-1]
output_ = keras.layers.Dense(1,activation='sigmoid')(final_layer.output)
model = keras.models.Model(input_, output_)
num_layers=len(model.layers)
for i,layer in enumerate(model.layers):
    if i == num_layers -1 :
        layer.trainable=True
    else:
        layer.trainable = False

ig=keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=preprocess_function)
training_data =ig.flow_from_directory('../../../data/dogsvscats/train/', class_mode='binary',target_size=(224,224),batch_size=64)
validation_data = ig.flow_from_directory('../../../data/dogsvscats/validation/',class_mode='binary', target_size=(224,224), batch_size=64)

model.compile(keras.optimizers.Adam(lr=1e-4),keras.losses.binary_crossentropy,metrics=['accuracy'])
model.fit_generator(training_data,steps_per_epoch=4000, epochs=2, validation_data=validation_data, validation_steps=300)

This model achieved 96% accuracy in 1 epoch (which is expected)
Same code (tf.contrib.keras)
import tensorflow as tf
import tensorflow.contrib.keras as keras

resnet = keras.applications.ResNet50(include_top=False,weights='imagenet', pooling='avg')
input_ = resnet.input
final_layer = resnet.layers[-1]
output_ = keras.layers.Dense(1,activation='sigmoid')(final_layer.output)
model = keras.models.Model(input_, output_)
num_layers=len(model.layers)
for i,layer in enumerate(model.layers):
    if i == num_layers -1 :
        layer.trainable=True
    else:
        layer.trainable = False

ig=keras.preprocessing.image.ImageDataGenerator(
    preprocessing_function=preprocess_function)
training_data =ig.flow_from_directory('../../../data/dogsvscats/train/', class_mode='binary',target_size=(224,224),batch_size=64)
validation_data = ig.flow_from_directory('../../../data/dogsvscats/validation/',class_mode='binary', target_size=(224,224), batch_size=64)

model.compile(keras.optimizers.Adam(lr=1e-4),keras.losses.binary_crossentropy,metrics=['accuracy'])
model.fit_generator(training_data,steps_per_epoch=4000, epochs=2, validation_data=validation_data, validation_steps=300)


_This model struggles to achieve 58% accuracy after 1 epoch and 61% after 2 epochs
Is there something different in terms of hyper-parameter settings that is required when switching between the 2 versions.