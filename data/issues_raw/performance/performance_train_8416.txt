CPU resources of Tensorflow's docker containers could not be controlled by --cup-shares

Environment info
OS:Ubuntu14.04LTS
GPU:Nvidia Pascal TITUN X
CUDA8.0
cuDNN CUDA8.0 V5.1
Docker Verison:17.03.0-ce
Nvidia docker : 1.0.1
CPU Intel Core i7 6900K , Hyper-THreading off , Turbo boost off
####Docker file
I installed Tensorflow by Dockerfile as below;
================================
FROM nvidia/cuda:8.0-cudnn5-devel
ENV http_proxy http://mycompany.proxy:8080
ENV https_proxy http://mycompany.proxyp:8080
RUN     apt-get update  &&  apt-get install -y 
python-dev 
python-pip 
nano 
git
RUN    rm -rf /var/lib/apt/lists/* /var/cache/apt/archieves/*
RUN    pip install --upgrade --user https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.0-cp27-none-linux_x86_64.whl
WORKDIR /root/.local/lib/python2.7/site-packages/tensorflow
RUN git clone https://github.com/tensorflow/models.git
WORKDIR /root/.local/lib/python2.7/site-packages/tensorflow/models/tutorials/image/cifar10
####My Procedure[a]
(1) At first ,I build Dockerfile
$ nvidia-docker build -t cpu:tensorflow0.
 Tensorflow docker image was build with no-problem and no-erros.

(2)Next  I run two docker container and log in two container via Bash
$ nvidia-docker run --cpuset-cpus=0-5 --cpu-shares=2048 -it cpu:tensorflow0
$nvidia-docker run --cpuset-cpus=0-5 --cpu-shares=1024 -it cpu:tensorflow0
I used all CPU cores(6 cores).

(3) I did "python cifar10_train.py" on two containers ,and check cpu-resources by docker stats.
By the way, tow python examples"cifar10_train.py" were same code.
CPU Resource of one container was  339.86%
CPU Resources of another on another container was 230.19%
  CPU Resouce Rate 339.86 : 230.19 was not different from --cpu-shares Rate 2048:1024 

####My Procedure[b]
To make sure, I did same procedure by using CPU 5cores.
(1)Next  I run two docker container and log in two container via Bash
$ nvidia-docker run --cpuset-cpus=0-4 --cpu-shares=2048 -it cpu:tensorflow0
$nvidia-docker run --cpuset-cpus=0-4 --cpu-shares=1024 -it cpu:tensorflow0
I used only 5 CPU cores. because --cpuset-cpus=0-4

(2) I did "python cifar10_train.py" on two containers ,and check cpu-resources by docker stats.
By the way, tow python examples"cifar10_train.py" were same code.
CPU Resource of one container was  278.13%
CPU Resources of another on another container was 195.80%
  CPU Resources Rate 278.13 :195.80 was not different from --cpu-shares Rate 2048:1024 

####My Procedure[c]
I did same process by Chainer Containers :Chainer Version 1.21.0
(1)6cores :Two Chainer containers ,--cpusets-cpu=0-5,--cpu-shares=2048 and --cpu-shares=1024
 CPU resources   394.23 : 195.41 nealy 2:1 , It is as same as 2048:1024

(2) 5cores :Two Chainer containers ,--cpusets-cpu=0-4,--cpu-shares=2048 and --cpu-shares=1024
 CPU resources   330 .82: 166.13 nealy 2:1 , It is as same as 2048:1024

####My additional Procedure[d]
I run 4 docker container at --cpu-shares setting at 2048,1024,1024 ,and 512.
*Tensoflow 4 Container CPU resources : 205.21 : 135.68 : 142.71 : 97.94
They were not rates of --cpu-shares ; 2.09 : 1.39 : 1.46 : 1.0
*Chainer 4 Containers CPU resources : 267.44 : 133.93 :129.59 : 59.98
They ware nearly equal rate of --cpu-shares ; 4.45 : 2.23 : 2.26 : 1.0
####Result
Two Chainer's docker containers operated according with the setting of --cpu-shares.
But  Two Tensorflow's docker containers did not operate according with the setting of --cpu-shares.
####My Question
Do you know the reason why two Tensorflow's containers did not operate according with the setting of --cpu-shares?