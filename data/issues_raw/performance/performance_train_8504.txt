Cannot reuse variables by tf.layers.conv2d

I am trying to make two conv layers share the same weights, however, it seems the API does not work.
import tensorflow as tf

x = tf.random_normal(shape=[10, 32, 32, 3])

conv1 = tf.layers.conv2d(x, 3, [2, 2], padding='SAME', reuse=None, name='conv')
print(conv1.name)
conv2 = tf.layers.conv2d(x, 3, [2, 2], padding='SAME', reuse=True, name='conv')
print(conv2.name)

gives
conv/BiasAdd:0
conv_2/BiasAdd:0

--------------------------------Update-------------------------------
According to a post, the weights are already sharing, with different layer names, since the computation not sharing. However, is it feasible to consider a better naming strategy so that it is easier to see from names that different layers are sharing the same weights ?