Converting TensorFlow frozen and inference model to lite fails with "Check failed: array->has_shape"

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mac OS X High Sierra
TensorFlow installed from (source or binary):
Source
TensorFlow version (use command below):
'v1.7.0-rc1-1018-g7a0def60d4' 1.7.0-rc1
Python version:
3.5.5
Bazel version (if compiling from source):
0.10.1
GCC/Compiler version (if compiling from source):
Apple LLVM version 9.1.0 (clang-902.0.39.1)
CUDA/cuDNN version:
NA
GPU model and memory:
NA
Exact command to reproduce:
bazel-bin/tensorflow/contrib/lite/toco/toco 
--input_file=frozen.pb 
--input_format=TENSORFLOW_GRAPHDEF 
--output_format=TFLITE 
--output_file=frozen.lite 
--input_array=Inputs/Input 
--output_array=Outputs/Prediction 
--input_shape=1,28,28,1 
--inference_type=FLOAT
-Error Message
F tensorflow/contrib/lite/toco/tooling_util.cc:831] Check failed: array->has_shape()

I have created a TensorFlow model which classifies MNIST image data. The model is then frozen and optimized for inference. These models I can benchmark as well. But when converting to TensorFlow lite, the toco command fails with the above mentioned error message.
I have summarized the graph as well for both frozen and inference model.
The frozen model has the same size of (1,28,28,1) but the inference has a size of (None). I am using a placeholder when creating the model for the Input.