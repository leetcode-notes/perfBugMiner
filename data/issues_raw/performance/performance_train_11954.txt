Dilated convolution does not preserve tensor shape

System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 14.04.5 LTS


TensorFlow installed from (source or binary):
Source


TensorFlow version (use command below):
('unknown', '1.3.0-rc0')


Python version:
2.7.12


Exact command to reproduce:


input_tensor = tf.placeholder(tf.float32, (10, None, 256, 3))

dilated = tf.nn.convolution(input_tensor,
                            tf.zeros((3, 1, 3, 16)),
                            dilation_rate=[2, 1],
                            padding='SAME')

print(dilated.get_shape()) # Displays: [10, ?, ?, 16], expected [10, ?, 256, 16]

Describe the problem
The documentation for tf.nn.convolution has the spatial dimensions of the output given as:
If padding == "SAME": output_spatial_shape[i] = ceil(input_spatial_shape[i] / strides[i])

Which suggests that input_spatial_shape[0] should not affect output_spatial_shape[1], as is the case in the code block above.
This problem arises when using dilated convolutions as part of a larger model containing recurrent layers, in which one spatial dimension is left undefined to allow for unrolling the recurrent layers out during training along the undefined dimension.
This might be related to a previously fixed problem with undefined batch sizes.