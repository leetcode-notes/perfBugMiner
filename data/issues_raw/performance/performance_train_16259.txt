Fix two small issues of XLA

1.In Tensorflow, conventionally, INT32 ops are regarded as shape or control
ops, and are registered on CPU only. XLA should follow the same rule, to
avoid the potential data transfer between TF CPU ops and in GPU_XLA ops,
which result into performance degradation when XLA is turned-on.
2. Any OpKernel with more than 500 inputs is excluded. This is a temp
workaround to avoid an potential issue that, the cuda drive do not accept
a compiled PTX kernel with parameter space larger than 4352 bytes. The data type
of PTX kernel parameter is u64. An OpKernel with 500 inputs are more likely
to exceed the limit.