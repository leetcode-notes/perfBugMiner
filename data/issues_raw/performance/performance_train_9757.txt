Large page fault causes slow performance while using gpu

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04
TensorFlow installed from (source or binary):
binary, using pip install tensorflow-gpu==1.0.1
TensorFlow version (use command below):
1.0.1
Bazel version (if compiling from source):
CUDA/cuDNN version:
8.0/5.1
GPU model and memory:
nvidia gtx1080, 8g

Describe the problem
I have observed a large amount of page fault while running the provided sample code on gpu, and this causes a serious performance drawdown.
The key parts of the output of /usr/bin/time -v python sample.py are:
System time (seconds): 7.28  
Percent of CPU this job got: 85%  
Elapsed (wall clock) time (h:mm:ss or m:ss): 0:22.41 
Minor (reclaiming a frame) page faults: 684695  
Involuntary context switches: 164 
File system inputs: 0  
File system outputs: 8  

There are 684k page faults,  and the gpu-volatile usage is only about 30%.
I am very hesitating to ask for help here, because on another system with exact os, software and gpu, this issue does not appears, I have posted on stackoverflow to compare two systems here
Is that possible that tensorflow handles different hardwares differently? It looks to me that the gpu-cpu I/O may have caused this issue, and I suspect that I need to configure my hardware settings somewhere, but don't know how.
Things I have tried:

Upgrade BIOS to the latest version and reset default settings.
Call Asus(my motherboard and gpu vendor) customer service for help.
Inject LD_PRELOAD="/usr/lib/libtcmalloc.so" to .bashrc file.

Source code / logs
Here is the sample code I used to test
import tensorflow as tf
import numpy as np
from tqdm import trange

np.random.seed(111)
h,w = 3000, 2000
steps = 1000

x = tf.placeholder(dtype=tf.float32, shape=[h, w], name='x')
t = tf.constant(np.random.random(size=[w, w]), dtype=tf.float32)
m = tf.matmul(x,t)

x0 = np.random.random(size=[h, w])
sess = tf.Session()
for i in trange(steps):
    x0 = sess.run(m, feed_dict={x: x0})

The attachment contains: Nvidia-smi output, /usr/bin/time -v output, hardware specs in html format, chrome trace timeline.
sysB.zip