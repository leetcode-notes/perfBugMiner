Optimize FusedBatchNormGrad.

Reuse the output buffer and allocate only one temporary tensor, when data format is NHWC and
GPU is used. This is based on the observation that cudnn can perform the backward computation
in place. The same idea is used in PR #15601 .
This lowers GPU memory consumption and may improve performance, because fewer distinct memory addresses are accessed. It also permits a higher batch size.
I've also added a new test for the gradient computation.