Unexpected error at contrib.seq2seq's BeamSearchDecoder

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below):  v1.1.0-rc2-773-g7fa0cf39f
Bazel version (if compiling from source):  0.4.5
CUDA/cuDNN version:  None
GPU model and memory: CPU

Describe the problem
I encountered an unexpected error at tf.contrib.seq2seq's BeamSearchDecoder, when the beam width is smaller than number of vocabs.
This is a part of _beam_search_step operation in beam_search_decoder.py:
  scores = _get_scores(
      log_probs=total_probs,
      sequence_lengths=new_prediction_lengths,
      length_penalty_weight=length_penalty_weight)

  time = ops.convert_to_tensor(time, name="time")
  # During the first time step we only consider the initial beam
  scores_flat = control_flow_ops.cond(
      time > 0,
      lambda: array_ops.reshape(scores, [batch_size, -1]),
      lambda: scores[:, 0])

  # Pick the next beams according to the specified successors function
  next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=beam_width)
  next_beam_scores.set_shape([static_batch_size, beam_width])
  word_indices.set_shape([static_batch_size, beam_width])

Since the shape of scores is [batch_size, beam_width, vocab_size],  the shape of scores_flat is[batch_size, vocab_size] at time step 0. However, if k < shape[-1] in nn.top_k operation, it just throws InvalidArgumentError: input must have at least k columns. Thus the code just throws an error and dies.
I think code should be modified to handle cases where vocab_size ** n < beam_width, or at least throw an appropriate error message when the input is vocab_size < beam_width.