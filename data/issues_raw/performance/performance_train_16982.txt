dnnConversionCreate_F32 fails when running TF with optimized MKL

System information

Have I written custom code: Yes, (https://github.com/jakubkarczewski/AlexNetF/blob/master/alexnet.py)
OS Platform and Distribution: Linux Centos 7
TensorFlow installed from: compiled from source from https://github.com/tensorflow/tensorflow/releases
TensorFlow version: 1.6.0-rc0
Python version:  2.7
Bazel version: 0.10.0
GCC/Compiler version: stock Centos 7 gcc
Compilation command: bazel build --config=mkl --copt="-DINTEL_MKL_ML" --copt="-mfma" --copt="-mavx2" --copt="-march=broadwell" --copt="-O3" -s -c opt //tensorflow/tools/pip_package:build_pip_package;;
Exact command to reproduce: python alexnet.py --training_epoch=1 --model_version=1 output/
CUDA/cuDNN version: N/A
GPU model and memory: N/A

Describe the problem
Running following training with Tensorflow compiled with command specified above results in error: 2018-02-12 23:40:38.088756: F tensorflow/core/kernels/mkl_lrn_op.cc:595] Check failed: dnnConversionCreate_F32( &convert_input, static_cast<dnnLayout_t>(inimage_shape.GetCurLayout()), lt_internal_input) == E_SUCCESS (-1 vs. 0) as opossed to running without any error and training properly on Tensorflow version available under pip install tensorflow.
For training data I used Imagenet 60gb dataset (http://www.image-net.org/challenges/LSVRC/2012/) with 1000 classes.
What's more - following error can be found when running with Tensorflow from precompiled wheel files for both versions of python. This makes me think that the way I compile TF is not the problem here.