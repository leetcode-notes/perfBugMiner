tf.argmax appears to be functioning incorrectly on occasion

EDIT
Link to script and input/label data as pickle files to reproduce the error.
System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I have written my own code. My code base, data set and batch generating algorithm are quite large, so I am attempting to illustrate this as best as possible. If no mistake of mine can be seen in this post and the examples I have given, then I will provide further code/data. I have asked on StackOverflow, but have got not replies. If  I am missing something simple, then I'm sure it would have been pointed out on StackOverflow by now.


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Manjaro 17.1.3 Kernel 4.14


TensorFlow installed from (source or binary):
python pip


TensorFlow version (use command below):
tensorflow-gpu 1.5.0


Python version:
3.6.4


CUDA/cuDNN version:
CUDA 9.0
cuDNN 7.0


GPU model and memory:
Nvidia GeForce GTX 1050 8GB


Describe the problem
tf.argmax seems to be occasionally producing incorrect results when used on the last axis of a 3-dimensional tensor.
Source code / logs
To debug this, I have printed out the following operations:
print(self.session.run(
    tf.equal(tf.argmax(self.predictions, axis=-1),
             tf.argmax(self.labelsUnrolled, axis=-1)),
    self.batchDict))
print("")
print(self.session.run(self.predictions, self.batchDict))
print("")
print(self.session.run(self.labelsUnrolled, self.batchDict))
print("\n********\n")

Which on two consecutive iterations output the following:
[[ True  True  True]
 [ True  True  True]]

[array([[0.06275553, 0.44493628, 0.42474008, 0.06756803],
        [0.06320112, 0.49631155, 0.4021484 , 0.03833894],
        [0.04378054, 0.59403986, 0.3236889 , 0.03849069]], dtype=float32), 
array([[8.1677590e-06, 9.9997127e-01, 2.0200867e-05, 3.6184446e-07],
        [4.3686719e-06, 9.9992716e-01, 6.6905603e-05, 1.5286902e-06],
        [1.3270236e-05, 9.9986196e-01, 1.1622251e-04, 8.5579613e-06]], dtype=float32)]

[array([[0., 0., 1., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], dtype=float32),
 array([[0., 1., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], dtype=float32)]

********

[[False False  True]
 [ True  True  True]]

 [array([[0.0466171 , 0.53605616, 0.37778312, 0.03954368],
         [0.05007472, 0.4603508 , 0.44400516, 0.0455693 ],
         [0.06134444, 0.38073638, 0.504286  , 0.05363319]], dtype=float32),
 array([[9.6363285e-05, 9.9861979e-01, 1.2741127e-03, 9.7381862e-06],
         [1.6185455e-05, 9.9977034e-01, 2.0742408e-04, 6.0521238e-06],
         [2.9893983e-05, 9.9954152e-01, 4.2436572e-04, 4.2021661e-06]], dtype=float32)]

[array([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 0., 1., 0.]], dtype=float32), 
 array([[0., 1., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], dtype=float32)]

********

Isn't the very first True in the first iteration incorrect? There are many more examples being executed where these are wrong (although it is right the majority of the time). Am I going wrong somewhere with the tf.argmax function?
Printing out the same operations, but not inside the session gives the following shapes:
Tensor("Equal_175:0", shape=(2, ?), dtype=bool)

[<tf.Tensor 'unstack_2:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'unstack_2:1' shape=(?, 4) dtype=float32>]

[<tf.Tensor 'unstack_1:0' shape=(?, 4) dtype=float32>, <tf.Tensor 'unstack_1:1' shape=(?, 4) dtype=float32>]

Is it a problem that the number associated with the tensor name "Equal_XXX:0" is incrementing each iteration?
I have also tried changing the axis argument in both argmax functions to axis=2, giving the "Equal" tensor a shape of (2, 3) again, but there are still similar errors.
Here is an example:
[[False False  True]
 [ True  True False]]

[array([[0.09075877, 0.41096467, 0.4460272 , 0.05224944],
        [0.04962843, 0.43777955, 0.46654516, 0.04604685],
        [0.07901238, 0.40768984, 0.46641603, 0.04688181]], dtype=float32),
 array([[0.04444276, 0.49195835, 0.42141557, 0.04218334],
        [0.02372498, 0.47147286, 0.4679979 , 0.03680426],
        [0.03707527, 0.435518  , 0.48937747, 0.03802926]], dtype=float32)]

[array([[0., 0., 1., 0.],
        [1., 0., 0., 0.],
        [0., 0., 1., 0.]], dtype=float32),
 array([[0., 1., 0., 0.],
        [0., 0., 1., 0.],
        [0., 1., 0., 0.]], dtype=float32)]

I would expect this to be:
[[ True False  True]
 [ True False False]]

I thought this may have been a problem with parallel computations on the GPU, but I tried the same execution on just my CPU and got the following, similar miscalculation, too:
[[False  True False]
 [False False False]]

[array([[0.07774187, 0.40993363, 0.47022063, 0.04210386],
        [0.04910654, 0.44086066, 0.46013904, 0.04989377],
        [0.06700655, 0.37128285, 0.51324743, 0.04846317]], dtype=float32), 
array([[0.07584244, 0.3863555 , 0.5090046 , 0.02879751],
        [0.06959026, 0.3221606 , 0.5715027 , 0.03674646],
        [0.09042579, 0.32515866, 0.5385905 , 0.04582503]], dtype=float32)]

[array([[0., 0., 1., 0.],
        [0., 0., 1., 0.],
        [0., 1., 0., 0.]], dtype=float32),
array([[0., 1., 0., 0.],
        [0., 1., 0., 0.],
        [0., 1., 0., 0.]], dtype=float32)]