tfdbg error: Causality violated in timing relations of debug dumps

What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
Nothing found
Environment info
Operating System:
Ubuntu 14.04
Installed version of CUDA and cuDNN:
CUDA 8.0, cuDNN 5.1
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
-rw-r--r-- 1 root root   558720  9月 15 07:02 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16  9月 15 07:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19  9月 15 07:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root   415432  9月 15 07:02 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162  9月 15 07:02 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 79337624 11月 16 22:50 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 79337624 11月 16 22:50 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 79337624 11月 16 22:50 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 11月 16 22:50 /usr/local/cuda/lib64/libcudnn_static.a

If installed from source, provide

The commit hash (git rev-parse HEAD)
12a9872
The output of bazel version

Build label: 0.4.4
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Feb 1 18:54:21 2017 (1485975261)
Build timestamp: 1485975261
Build timestamp as int: 1485975261

If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I have a model that basically consists of several bidirectional rnns, the longest of which has hundreds of timesteps.
What other attempted solutions have you tried?
Logs or other output that would be helpful
When I try to launch the first Session.run() call in tfdbg using command r, I got the following error:
2017-03-13 10:54:06.173974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.7335
pciBusID 0000:81:00.0
Total memory: 7.92GiB
Free memory: 7.81GiB
2017-03-13 10:54:06.174082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0
2017-03-13 10:54:06.174106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y
2017-03-13 10:54:06.174138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:81:00.0)
Created model with fresh parameters.
Traceback (most recent call last):
  File "train.py", line 143, in <module>
    trainer.train()
  File "train.py", line 76, in train
    step_loss, summary = self.m.train_step(self.sess, batch_docs, batch_queries, batch_answers, batch_target)
  File "/home/zhangx/nn_tool_x33/MR_base/model.py", line 186, in train_step
    feed_dict=feed_dict, options=run_options, run_metadata=run_metadata)
  File "/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/framework.py", line 470, in run
    run_end_resp = self.on_run_end(run_end_req)
  File "/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/wrappers/local_cli_wrapper.py", line 267, in on_run_end
    self._dump_root, partition_graphs=partition_graphs)
  File "/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py", line 502, in __init__
    self._load_partition_graphs(partition_graphs, validate)
  File "/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py", line 760, in _load_partition_graphs
    self._validate_dump_with_graphs()
  File "/home/zhangx/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/debug/lib/debug_data.py", line 927, in _validate_dump_with_graphs
    (node, datum.timestamp, repr(pending_inputs[node])))
ValueError: Causality violated in timing relations of debug dumps: optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_2 (1489373660302841): these input(s) are not satisfied: [('optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/b_acc_1', 0), ('optimizer/gradients/inference/encode/docs/encode/bidirectional_rnn/fw/fw/while/TensorArrayReadV3/Enter_1_grad/NextIteration', 0)]

Is this a model related error or possibly a tfdbg bug?