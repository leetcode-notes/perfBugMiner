from_generator feedback and questions

@mrry, thank you for implementing the from_generator method in tf.data. I just wanted to provide some feedback and ask a few more questions.
Interface
In addition to having generator be a callable that returns an iterator, would it be possible to support iterators that aren't wrapped in a callable? E.g. instead of
pool = multiprocessing.Pool()
dataset = tf.contrib.data.Dataset.from_generator(
    lambda: pool.imap(some_function, some_data), dtypes, shapes
)
also support
pool = multiprocessing.Pool()
dataset = tf.contrib.data.Dataset.from_generator(
    pool.imap(some_function, some_data), dtypes, shapes
)
Return types
from_generator does not seem to support unpacking numpy arrays at the moment. I don't think it's essential but would be a nice-to-have. E.g. this fails
def generator():
    while True:
        yield np.zeros(2, np.float32)
        
dataset = tf.contrib.data.Dataset.from_generator(generator, (tf.float32, tf.float32))
x, y = dataset.make_one_shot_iterator().get_next()
session = tf.Session()
session.run([x, y])
but this runs smoothly
def generator():
    while True:
        yield tuple(np.zeros(2, np.float32))
        
dataset = tf.contrib.data.Dataset.from_generator(generator, (tf.float32, tf.float32))
x, y = dataset.make_one_shot_iterator().get_next()
session = tf.Session()
session.run([x, y])
Performance
I've played around with a very naive example using the generator API (in the hope to eventually leverage ipyparallel or some other distributed computing framework). Unfortunately, I can't achieve the same performance that I would get using feed_dicts. The setup is as follows
import tensorflow as tf
from tensorflow.contrib import data as tfdata
import numpy as np
from time import time

num_batches = 1000
batch_size = 100

class Generator:
    def __init__(self):
        self.times = []
    
    def __iter__(self):
        while True:
            x = np.random.normal()
            y = 3 + 5 * x
            x, y = np.asarray([x, y], np.float32)
            self.times.append(time())
            yield x, y

generator_state1 = Generator()

dataset = tfdata.Dataset.from_generator(
    lambda: generator_state1, 
    (tf.float32, tf.float32),
    (tf.TensorShape([]), tf.TensorShape([]))
)
prefetched = dataset.prefetch(3 * batch_size)
batches = prefetched.batch(batch_size)
iterator = batches.make_one_shot_iterator()

x, y = iterator.get_next()

w = tf.Variable([0, 0], dtype=tf.float32)
prediction = w[0] + w[1] * x
loss = tf.losses.mean_squared_error(y, prediction)
optimizer = tf.train.AdamOptimizer(0.1)
train_op = optimizer.minimize(loss)
init_op = tf.global_variables_initializer()

session = tf.Session()
session.run(init_op)
Running the optimisation gives me
losses = []

start = time()
for _ in range(num_batches):
    _, _loss = session.run([train_op, loss])
    losses.append(_loss)
time() - start  # about seven seconds
Doing the same using feed_dicts gives
losses = []

generator_state2 = Generator()
iterator = iter(generator_state2)

start = time()
for _ in range(num_batches):
    _x, _y = np.transpose([next(iterator) for _ in range(batch_size)])
    _, _loss = session.run([train_op, loss], {x: _x, y: _y})
    losses.append(_loss)
time() - start  # about one second
It seems that the dataset created using the from_generator method isn't fetching from the generator fast enough:
np.mean(np.diff(generator_state1.times))  # 7.1533812683949508e-05
np.mean(np.diff(generator_state2.times))  # 1.0633696558370612e-05
Thanks again for this, and looking forward to hearing your thoughts.