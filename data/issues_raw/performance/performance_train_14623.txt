[BUG] tf.while_loop creates a seg-fault when setting parallel_iterations to high values

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): both
TensorFlow version (use command below): 1.3 / 1.4
Python version: 3.6
Bazel version (if compiling from source): 0.5.4
GCC/Compiler version (if compiling from source): 5.4.0
CUDA/cuDNN version: 8
GPU model and memory: Tesla P100-PCIE-16GB
Exact command to reproduce:

Describe the problem
The following code crashes on all of my test systems, with tensorflow 1.3 or 1.4.
Doesn't matter if build with MKL or without or using the pip-version.
import numpy as np
import tensorflow as tf

num_dim = 20
FORMAT = tf.float64 #32 or 64 does not matter
n = 3500 #reducing the number results in normal execution

def simpeLoop(alpha):
      i = tf.constant(0)
      m0 = tf.zeros([num_dim, 1], dtype=FORMAT)
      cond = lambda i, m: i < n
      def body(ic, vec): 
            #a meaningless example, summing up the first num_dim elements of a vector 
            op = alpha[ic * num_dim:(ic + 1) * num_dim, :]
            # with tf.control_dependencies([op]): #if you uncomment this, it will not fault!
            return ic + 1, vec + op
      loop = tf.while_loop(cond, body, [i, m0], parallel_iterations=10**4, back_prop=False)
      return loop[1]

with tf.device('/cpu:0'):
      alpha = tf.placeholder(FORMAT, [None, 1], name="alpha")
      fdict = {
          alpha: np.random.rand(n * num_dim, 1),
      }
      op = simpeLoop(alpha)
      op = tf.reduce_sum(op) #not necessary for the seg fault
      init = tf.global_variables_initializer()

config = tf.ConfigProto()
threads = 1
config.intra_op_parallelism_threads = threads
config.inter_op_parallelism_threads = threads
sess = tf.Session(config=config)
sess.run(init, feed_dict=fdict)
print("init")
print(sess.run(op, feed_dict=fdict))

Adding the control_dependencies results in normal execution.
The documentation states

The maximum number of parallel iterations can be controlled by parallel_iterations, which gives users some control over memory consumption and execution order

so I would expect parallel_iterations to be some kind of upper bound.
Small tests like presented in  #12937 showed that increasing the parallel_iterations number results in higher performance. But setting it to high results in a seg fault.