TensorFlow on ARMv7 seems to be slower

I have installed tensorflow on our custom board which is based on i.mx6 (ARMv7) processor. I have compiled the C++ module alone without python support and was able to run the "tensorflow/pi_examples/label_image"
Command used:  make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI
The problem is that the application seems to be very slow compared to Laptop (Intel i5). The inference takes close to 60-70s while it takes only 0.6 - 0.7s in my Laptop.
After that, I figured out that I missed to use compiler optimization flag to use Neon. I compiled with Neon support and now it takes around 10-17s for same example.
Command used: make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI  OPTFLAGS="-Os -mfpu=neon -funsafe-math-optimizations -ftree-vectorize"
Is there anything I am missing?
System information

Have I written custom code: No
OS Platform and Distribution: Yocto debian flavour
TensorFlow installed from:  source (27a9808)
TensorFlow version: NA
Bazel version (if compiling from source): Not used
CUDA/cuDNN version: NA
GPU model and memory: NA
Exact command to reproduce: NA