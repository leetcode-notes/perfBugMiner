Android Failed To Run Inference

Have I written custom code: No
OS Platform and Distribution: Android
TensorFlow installed from: binary
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A
Describe the problem
With JNI libtensorflow_core.a etc. I can do inference with my model, which is frozen and stripped off unused op by transform_graph tool.
But it took so long, about 50 secs to run on a 1x300x400x3 sized input image. I guess maybe the libtensorflow_core.a that I download from TensorflowPrebuiltWebsite is built in debug mode. The reason why I download libtensorflow_core.a is because I have trouble building it myself.
So I want to use Java API to do inference and see how much time it takes.
This is done by adding dependencies in build.gradle:
dependencies { compile 'org.tensorflow:tensorflow-android:+' }
But with Java API it throws exceptions for parsing the .pb file. I guess my .pb is incompatible. So I took a step back, I only froze the graph but not stripping off unused op. This time Java API is able to parse the .pb file. But after feed inputs, it throws exception when I call run method on org.tensorflow.contrib.android.TensorFlowInferenceInterface.run().
I have also tried to download prebuilt libandroid_tensorflow_inference_java.jar and libtensorflow_inference.so from TensorflowPrebuiltWebsite, but not working.
Notice that I can do inference with C++ code, that means my neural network model *.pb is CORRECT. I think this is a bug with Java API or its corresponding native implementation.
logs
12-16 11:33:59.954 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/System.out: debugger has settled (1330)
12-16 11:33:59.998 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/HwCust: Constructor found for class android.app.HwCustHwWallpaperManagerImpl
12-16 11:34:00.026 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance W/art: Before Android 4.1, method android.graphics.PorterDuffColorFilter android.support.graphics.drawable.VectorDrawableCompat.updateTintFilter(android.graphics.PorterDuffColorFilter, android.content.res.ColorStateList, android.graphics.PorterDuff$Mode) would have incorrectly overridden the package-private method in android.graphics.drawable.Drawable
12-16 11:34:00.157 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: Checking to see if TensorFlow native methods are already loaded
12-16 11:34:00.157 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: TensorFlow native methods already loaded
12-16 11:34:00.231 23001-23012/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/art: humin current process: cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance
12-16 11:34:00.231 23001-23012/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/art: current process_level is : 0
12-16 11:34:00.437 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: Model load took 169ms, TensorFlow version: 1.4.0
12-16 11:34:00.437 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/TensorFlowInferenceInterface: Successfully loaded model from 'frozen_graph.pb'
12-16 11:34:14.460 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance E/TensorFlowInferenceInterface: Failed to run TensorFlow inference with inputs:[is_training, feed_input], outputs:[hdr_conv_out/LeakyRelu/Maximum]
12-16 11:34:14.789 23001-23001/cn.edu.zju.cad.rwang.rendering.testtensorflowjavaapiperformance I/Process: Sending signal. PID: 23001 SIG: 9

Source code
My project is on git here, please help me, thanks!