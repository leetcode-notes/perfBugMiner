Slow quantized graph

On Ubuntu 15.10 with CUDA 7.5, cuDNN 7.0, tensorflow-0.9.0rc0, ran "tensorflow/examples/label_image/" application by taking inception-v3 graph and roughly measure the elapsed time.


Then take "tensorflow/contrib/quantization/tools:quantize_graph" to quant inception-v3, rebuilt application by giving
"//tensorflow/contrib/quantization:cc_ops",
"//tensorflow/contrib/quantization/kernels:quantized_ops",



into "tensorflow/examples/label_image/BUILD" and redo the same classification and measure the time.
Before/After quantization, elapsed time were 6 seconds vs. 17 seconds, i.e. quantization doubled the inference time?
The results looks ok as below so I think I was running it correctly.
Before

military uniform (866): 0.647299
suit (794): 0.0477195
academic gown (896): 0.0232407
bow tie (817): 0.0157355
bolo tie (940): 0.0145023

After

military uniform (866): 0.703474
suit (794): 0.0248454
bow tie (817): 0.0171362
bolo tie (940): 0.0171362
academic gown (896): 0.0164432

My tensor flow was built as CPU only. Have also tried to enable GPU while the timing didn't change. Do we know what the expected performance would be?