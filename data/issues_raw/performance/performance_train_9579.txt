MNIST Tutorial Appears to Not Toggle XLA Compilation

I have been using the JIT compilation/XLA tutorial (https://www.tensorflow.org/performance/xla/jit#step_3_run_with_xla), and it seems that whether or not XLA compilation happens doesn't depend on the statement on line 63 in mnist_softmax_xla.py. The comment above it says that line will turn on XLA JIT compilation. When I run with the two options explained on the page (--xla='' for compiling without XLA, and TF_XLA_FLAGS=--xla_generate_hlo_graph=.* for compiling with XLA), the second executes line 63 and the first does not. But, both seem to compute in exactly the same way, going through compiler/xla/service. The output for both runs is:
Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gz
Extracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz
2017-05-01 12:50:25.203870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-01 12:50:25.203904: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-05-01 12:50:25.232661: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-05-01 12:50:25.232702: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Xpu present with 8 visible devices
2017-05-01 12:50:25.233155: I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:
2017-05-01 12:50:25.233165: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
2017-05-01 12:50:25.233894: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices
2017-05-01 12:50:25.233903: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Xpu present with 8 visible devices
2017-05-01 12:50:25.234360: I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Xpu. Devices:
2017-05-01 12:50:25.234369: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>
2017-05-01 12:50:25.234372: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (1): <undefined>, <undefined>
2017-05-01 12:50:25.234376: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (2): <undefined>, <undefined>
2017-05-01 12:50:25.234379: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (3): <undefined>, <undefined>
2017-05-01 12:50:25.234382: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (4): <undefined>, <undefined>
2017-05-01 12:50:25.234385: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (5): <undefined>, <undefined>
2017-05-01 12:50:25.234389: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (6): <undefined>, <undefined>
2017-05-01 12:50:25.234392: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (7): <undefined>, <undefined>
0.9206