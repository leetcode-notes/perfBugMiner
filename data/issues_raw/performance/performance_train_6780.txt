crash when run distributed training

When I run distributed training on tensorflow 0.12, everything ok at first, loss and global step was printed.
But after thoudsands of steps, following errors appear
tensorflow.python.framework.errors_impl.UnavailableError: {"created":"@1484093728.844289839","description":"EOF","file":"external/grpc/src/core/lib/iomgr/tcp_posix.c","file_line":235," grpc_status":14}
and
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'save/RestoreV2_26': Could not satisfy explicit device specification
and
E tensorflow/core/distributed_runtime/master_session.cc:1372] Cleanup partition error: Unavailable