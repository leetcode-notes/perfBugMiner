Feature Request: Support for configuring deterministic options of cudNN Conv routines

Please go to Stack Overflow for help and support:
https://stackoverflow.com/questions/tagged/tensorflow
If you open a GitHub issue, here is our policy:

It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
The form below must be filled out.
It shouldn't be a TensorBoard issue. Those go here.

Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.6
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 7.1
GPU model and memory: GPU
Exact command to reproduce: N/A

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
You can obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the problem
http://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#reproducibility
cudNN documentation indicates that there are several routine options for cudnnConvolutionBackwardFilter, cudnnConvolutionBackwardData, and cudnnPoolingBackward operations. They default to non-deterministic atomic operations, but have the option to run in a deterministic mode. To achieve determinism on TensorFlow GPU, I would like to be able to make this performance trade-off, but currently cannot find a way to enable these options in TensorFlow.
Can a user-facing option be added, perhaps in tf.ConfigProto, to configurate these cudNN routines? This could be configured in a similar way as inter_op_parallelism_threads and intra_op_parallelism_threads are set to 1 to achieve determinism on CPU (https://stackoverflow.com/questions/41233635/meaning-of-inter-op-parallelism-threads-and-intra-op-parallelism-threads)
Source code / logs
N/A