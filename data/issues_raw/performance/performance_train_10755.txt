Weird behavior of tf.train.Saver

System information

Linux Ubuntu 14.04
TensorFlow installed from binary:
TensorFlow version v1.0.0-rc2:
CUDA: 8.0, CuDNN: 5.1
Tesla K80, 12GB

Describe the problem
I have a problem with the tf.train.Saver, specifically with the 'max_to_keep' argument. If I create a Saver with 'max_to_keep' set to let's say 3 and use the saver.save function to save my model in the current directory it keeps all files and doesn't delete the old ones after 3 or more are created. If I set the path where to save the model to a different location it works just fine.
See also my stackoverflow question
Source code / logs
Creates for the numbers 1 to 10 each 3 files:

testfile-1.data-00000-of-00001
testfile-1.index
testfile-1.meta

import tensorflow as tf

a = tf.Variable(name='a', initial_value=0)
addops = a+1

saver = tf.train.Saver(max_to_keep=3)
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)
sess.run(tf.global_variables_initializer())
for i in range(10):
    sess.run(addops)
    save_path = saver.save(sess, 'testfile', global_step=i+1)

sess.close()

This code works as expected and deletes all the old files and I only end up with the numbers 8 to 10:
import tensorflow as tf

a = tf.Variable(name='a', initial_value=0)
addops = a+1

saver = tf.train.Saver(max_to_keep=3)
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)
sess.run(tf.global_variables_initializer())
for i in range(10):
    sess.run(addops)
    save_path = saver.save(sess, 'test/testfile', global_step=i+1)

sess.close()