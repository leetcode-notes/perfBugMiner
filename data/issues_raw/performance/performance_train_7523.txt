Tensorflow graph transform quantize_weights Compression method creates corrupted graph.

Hi,
I have retrained inception v3 model using retrain.py on classes (People, Animal, Plants, Buildings, Birds) and the size is 87.5 MB. At this stage, the model works fine when I try classification using label_image example.
But, model compressed using quantization methods is producing false or incorrect results. As mentioned below, I have tried two ways of model compression using quantized methods, however both of these are producing a corrupted compressed model that gives incorrect classification results.
Method 1: Shrinking file size method in graph_transform. GitHub link: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md#shrinking-file-size
Step 1: Tried compression with round_weights method - size of model was still same (87.5 MB) and classification on images works perfectly.
Step 2: Compression using quantize_weights method - (as suggested by Pete Warden, I ran the command after removing " and newlines ) quantized model got created with size (22 MB) but it is producing false or incorrect results, and giving the same class irrespective of which image is given as input (plant, bird, etc.). Below are sample results for three images none of which were animal images:
Image 1 (plant)

Animal (1): 0.999713
Plants (5): 0.00028519
Buildings (3): 1.18105e-06
People (2): 1.77942e-07
Birds (4): 5.95436e-08

Image 2 (bird)

Animal (1): 0.981817
Plants (5): 0.0170753
Buildings (3): 0.000743494
People (2): 0.000190974
Birds (4): 0.000148184

Image 3 (building)

Animal (1): 0.991817
Plants (5): 0.0070753
Buildings (3): 0.00143494
People (2): 0.00090974
Birds (4): 0.000148184

Method 2: Quantization method link : https://www.tensorflow.org/how_tos/quantization/
 bazel build tensorflow/contrib/quantization/tools:quantize_graph 
ERROR: no such package 'tensorflow/contrib/quantization/tools': BUILD       file not found on package path.
Used  bazel build tensorflow/tools/quantization:quantize_graph  command for running build.
On running following command after adding dependencies "//tensorflow/contrib/quantization:cc_ops",
"//tensorflow/contrib/quantization/kernels:quantized_ops", to BUILD file of label_image.

bazel-bin/tensorflow/tools/quantization/quantize_graph \
--input=Trained_Model/CompressedJunkRetrained_graph.pb \
--output_node_names="final_result" --output=/Trained_Model/quantized_graph.pb \
--mode=eightbit

Note: Used final_result in output_node_names instead of softmax.
This is giving the following error:
ERROR: /tensorflow-master/tensorflow/examples/label_image/BUILD:10:1: no such package 'tensorflow/tools/quantization/kernels': BUILD file not found on package path and referenced by '//tensorflow/examples/label_image:label_image'.
ERROR: /tensorflow-master/tensorflow/examples/label_image/BUILD:10:1: no such target '//tensorflow/tools/quantization:cc_ops': target 'cc_ops' not declared in package 'tensorflow/tools/quantization' defined by /tensorflow-master/tensorflow/tools/quantization/BUILD and referenced by '//tensorflow/examples/label_image:label_image'.
ERROR: Analysis of target '//tensorflow/examples/label_image:label_image' failed; build aborted.
If I run the same command without adding dependencies, it is compressing the model successfully.
But again in this quantized model images are getting wrongly classified.