Training bug in mobilenet v1 extractor for Faster r-cnn

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
custom kitti format dataset (good performance in Inception, Resnet extractor)
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04
TensorFlow installed from (source or binary):
Source
TensorFlow version (use command below): 1.6.0
Python version: 3.4
Bazel version (if compiling from source): No
GCC/Compiler version (if compiling from source): GCC 4.8.4
CUDA/cuDNN version: 9, 7
GPU model and memory: Tesla 40
Exact command to reproduce:

Describe the problem
It seems like training bug with Faster R-CNN Mobilenet.
I've been training Faster R-CNN with mobilenet feature extractor for 400k iteration, batch 8, learning rate 3e-03(mentioned in HuangMurphy_2017_Speed,accuracy trade-offs for modern convolutional object detectors). But it's mAP is "zero".  I'm using my own dataset and it's going well with InceptionV2, Resnet50, 101. mAP of InceptionV2, Resnet50, 101 is 0.7. So it's not about hyperparameter tuning problem.
Source code / logs
here is loss of inception v2, which has good mAP.

here is loss of mobilenet. Second stage loss is strangely low (loss is zero almost of time)

here is mAP of mobilenet. How can it be a zero?

here is my tensorboard distributions. Compared to Incepction V2, mobilenet has No change in second stage conv2d_12, conv2d_13 - moving_mean, moving_variance. I think it could be a clue of cause.