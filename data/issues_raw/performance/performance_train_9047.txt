beta2_power is applied incorrectly in Adam optimizer

In adam.py and in the ApplyAdam op, the denominator is effectively:
(tf.sqrt(v_t) + epsilon_t) / tf.sqrt(1 - beta2_power)

However, this appears incorrect â€“ per the paper, the correct EMA adjustment should give:
tf.sqrt(v_t / (1 - beta2_power)) + epsilon_t

Otherwise, when epsilon_t is large relative to tf.sqrt(v_t), the effective epsilon used in the denominator is also scaled up by the correction factor, which doesn't match what's in the paper.
Does this seem right, or am I missing something here?