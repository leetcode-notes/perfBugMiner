Feature Request: an op that returns bytes_in_use for its device

We are trying to optimize some models to fit into TitanX's 12GB of RAM, and it's hard because of lack of transparency in TF available memory.
What would help this situation is an op that returns amount of bytes on its device when executed. Something similar to what's done in stack_ops for memory-aware heuristics
DeviceContext* device_ctxt = ctx->op_device_context();
auto device = static_cast<tensorflow::Device*>(ctx->device());
Allocator* allocator = device->GetAllocator(alloc_attrs);
AllocatorStats stats;
allocator->GetStats(&stats)
//  output stats.bytes_in_use


This op can be wedged between other ops using control dependencies and used for memory debugging. This is complementary to request in #6716 because it would account for memory from parallel run calls, variables, persistent tensors.
I can take this issue if this op fits into TF framework