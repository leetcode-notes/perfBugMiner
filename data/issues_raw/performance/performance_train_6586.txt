Crash in  Jupyter Notebook with conv2d - stream->parent()->GetConvolveAlgorithms(&algorithms)

What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I have googled for the issue on several fronts and found nothing close since the Windows release.
Environment info
Operating System:
Windows 7-64bit.  Intel i3-6100 (64-bit), 8 gb DDR4, nVidia GTX 750 ti 2gb,
nVidia GPU driver: 369.30
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
CUDA v8.0
cuDNN 5.1
jupyter notebook messages when importing tensorflow:
successfully loaded:
cublas64_80.dll
cudnn64_5.dll
cufft64_80.dll
nvcuda.dll
curand64_80.dll
Found device 0 with properties:
name: GeForce GTX 750 Ti
major: 5 minor: 0 memoryClockRate (GHz) 1.1105
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.65GiB
DMA:0
0: Y
Creating TensorFlow device ...
If installed from binary pip package, provide:

A link to the pip package you installed:
I used the default: pip install tensorflow as described on their website.
The output from python -c "import tensorflow; print(tensorflow.__version__)".
0.12.0-rc0

If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I built and tested this jupyter notebook WITHOUT gpu support.  It already builds and runs correctly (as in, have trained and optimized a network).  Now I'm trying to get it to work with gpu to speed it up.
Here's the step in the notebook that causes the issue.  Prior to this, tensorFlow is imported successfully as tf.  This is the first session it's running.  the 'training_operation' uses conv2d.
`
##run Training
with tf.Session() as sess:
sess.run(tf.global_variables_initializer())
num_examples = len(X_train)
print("Training...")
print()
for i in range(EPOCHS):
    X_train, y_train = shuffle(X_train, y_train)
    for offset in range(0, num_examples, BATCH_SIZE):
        end = offset + BATCH_SIZE
        batch_x, batch_y = X_train[offset:end], y_train[offset:end]
        sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})
        
    validation_accuracy = evaluate(X_validation, y_validation)
    print("EPOCH {} ...".format(i+1))
    print("Validation Accuracy = {:.3f}".format(validation_accuracy))
    print()
    
saver.save(sess, './lenetTrafficSign')
print("Model saved")`

What other attempted solutions have you tried?
I saw a similar issue in a pre-windows version that suggested it had something to do with memory.
I tried adding the following before the tensorflow session:
config = tf.ConfigProto() config.gpu_options.per_process_gpu_memory_fraction = 0.4 with tf.Session() as sess: sess.run(tf.global_variables_initializer())
It did not resolve the issue.
Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
The error is as follows, when trying to run the session:

The plain text at the last three lines are:
cuda_event.cc:49]Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED
gpu_event_mgr.cc:190] Unexpected Event Status: 1
cuda_dnn.cc:305] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
conv_ops.cc:532] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms)
A few seconds after the script crashes, the screen goes black and the video driver resets.