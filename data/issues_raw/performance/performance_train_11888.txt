Can't import graph containing MutableHashTable

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 18
TensorFlow installed from (source or binary): Binary (pip)
TensorFlow version (use command below): v1.3.0.0rc0
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

Describe the problem
Import a meta graph containing MutableHashTable operations fails. The MutableHashTable in my use case is named and inside a scope. After some digging around I found that the error is a result of a collection saveable_objects containing names of MutableHashTables but without the proper scoping.
Source code / logs
graph = create_eval_graph()
tf.train.export_meta_graph('eval_model.meta', graph=graph, as_text=True)

# ...
s = tf.train.import_meta_graph('eval_model.meta') # Fails 

This throws the following
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-238-7de9a7b0d1f2> in <module>()
----> 1 s = tf.train.import_meta_graph('eval_model.meta')

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py in import_meta_graph(meta_graph_or_file, clear_devices, import_scope, **kwargs)
   1696                                       clear_devices=clear_devices,
   1697                                       import_scope=import_scope,
-> 1698                                       **kwargs)
   1699   if meta_graph_def.HasField("saver_def"):
   1700     return Saver(saver_def=meta_graph_def.saver_def, name=import_scope)

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py in import_scoped_meta_graph(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)
    690           for value in field.value:
    691             col_op = graph.as_graph_element(
--> 692                 ops.prepend_name_scope(value, scope_to_prepend_to_names))
    693             graph.add_to_collection(key, col_op)
    694         elif kind == "int64_list":

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in as_graph_element(self, obj, allow_tensor, allow_operation)
   2704 
   2705     with self._lock:
-> 2706       return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
   2707 
   2708   def _as_graph_element_locked(self, obj, allow_tensor, allow_operation):

/home/ruben/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _as_graph_element_locked(self, obj, allow_tensor, allow_operation)
   2764         if name not in self._nodes_by_name:
   2765           raise KeyError("The name %s refers to an Operation not in the "
-> 2766                          "graph." % repr(name))
   2767         return self._nodes_by_name[name]
   2768 

KeyError: "The name 'lstm_c_table' refers to an Operation not in the graph."

Where lstm_c_table is created as follows
tf.contrib.lookup.MutableHashTable(key_dtype=tf.string, value_dtype=tf.float32, default_value=value, name='lstm_c_table')

I looked at the generated proto and it contains the following node:
  node {
    name: "input/lstm_c_table"
    op: "MutableHashTableOfTensorsV2"
    attr {
      key: "_output_shapes"
      value {
        list {
          shape {
          }
        }
      }
    }
    attr {
      key: "container"
      value {
        s: ""
      }
    }
    attr {
      key: "key_dtype"
      value {
        type: DT_STRING
      }
    }
    attr {
      key: "shared_name"
      value {
        s: ""
      }
    }
    attr {
      key: "use_node_name_sharing"
      value {
        b: true
      }
    }
    attr {
      key: "value_dtype"
      value {
        type: DT_FLOAT
      }
    }
    attr {
      key: "value_shape"
      value {
        shape {
          dim {
            size: 512
          }
        }
      }
    }
  }

collection_def {
  key: "saveable_objects"
  value {
    node_list {
      value: "lstm_c_table"
      value: "lstm_h_table"
      value: "history_table"
      value: "first_table"
      value: "encode_lstm_c_table"
      value: "encode_lstm_h_table"
    }
  }
}

Either removing the above collection or prefixing all the values with input/ results in the following error:
TypeError: Can't convert Operation 'input/lstm_c_table' to Tensor (target dtype=None, name=None, as_ref=True)

This solution is part of an imitation of batch_sequences_with_states so a graph can be exported that does not rely on queues but instead uses placeholders and the feed_dict mechanism, for use in interactive model evaluation.