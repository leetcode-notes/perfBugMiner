XLA operation semantics documentation BatchNormTrain error

Hey! I think there are a few errors in the documentation for the XLA BatchNormTrain operation in https://www.tensorflow.org/performance/xla/operation_semantics#batchnormgrad.
The gradient of the scaling factor gamma should be

instead of

Moreover, the gradient for the input tensor is also not correct. It should instead read something like this:

Where the products and summations are done in a "broadcasted" manner when shapes don't match and  is the whitened input tensor. That is:

There also seem to be a typo in the table explaining the output of this XLA node. The second row should say grad_offset in the first column, ComputationalDataHandle in the second column, and the semantics column should say something like gradient with respect to input offset.
Finally, it may be good if it could be specified that the summation used for the gradients of the scaling and offset tensors is performed over all dimensions that were used to compute the different statistics during normalization.