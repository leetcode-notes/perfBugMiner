[bug?] tf.nn.embedding_lookup returns 0 when ids out of range

It seems tf.nn.embedding_lookup will simply return tensor of zeros when ids out of range (larger than the embedding table size):
import tensorflow as tf
embs = tf.ones([100, 100]) 
idx = tf.cast(tf.ones([1]) * 1000, tf.int32)
with tf.Session() as sess:
  emb = sess.run(tf.nn.embedding_lookup(embs, idx))

The emb will be tensor of zeros. I am not sure if this is a bug, or by design for efficiency concern? It would be nice if there is a runtime exception. That will do a big favor in avoiding hidden bugs that lead to performance degeneration.
(I am running tensorflow-gpu 1.3.0 in Ubuntu 16.04)