Occupies GPU even if it is not compatible

As the title states, even if a GPU is not CUDA compatible, Tensorflow will occupy the GPU and then proceed to ignore it.
Here's a use case :
CUDA_VISIBLE_DEVICES=3 python convolutional.py
....
I tensorflow/core/common_runtime/gpu/gpu_device.cc:669] Ignoring gpu device (device: 0, name: Tesla K10.G2.8GB, pci bus id: 0000:45:00.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5.
....
From nvidia-dmi
|   3  Tesla K10.G2.8GB    Off  | 0000:45:00.0     Off |                    0 |
| N/A   34C    P0    43W / 117W |     50MiB /  3583MiB |      0%    E. Thread |
.....
|    3     26078    C   python                                          37MiB |
+-----------------------------------------------------------------------------+