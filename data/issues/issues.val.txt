buildinstall	Tensorflow Error - no such package '@local_config_cuda//cuda'So I'm trying to run the image retraining official tensorflow tutorial from this link: https://www.tensorflow.org/tutorials/image_retrainingI need to get it working for my dissertation with my own images in less than a month so it's extremely urgent.Once I get to the line "bazel build tensorflow/examples/image_retraining:retrain"I get this output:"ERROR: error loading package 'tensorflow/examples/image_retraining': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': error loading package 'external': The repository named 'local_config_cuda' could not be resolved."This thread seems to be the same issue, but no solutions offered: #5805This thread has more activity but it's talking about '@local_config_cuda//crosstool' rather than '@local_config_cuda/cuda/' so may not be helpful for me: #4105I'm using Linux Mint.Here is my tf_env.txt file for details about my system: tf_env.txtLet me know if there's any other details I should add which could be useful.I used this page for installation: https://www.tensorflow.org/install/install_linuxSo CUDA® Toolkit 8.0.cuDNN v5.1virtualenv install of TensorflowTrying to run python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"says "Failed to load the native TensorFlow runtime."but I can get other simple Tensorflow stuff to work so not sure why that is.
buildinstall	Python Configuration Error: 'PYTHON_BIN_PATH' environment variable is not setSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N/AOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X SierraTensorFlow installed from (source or binary): N/A (compiling from HEAD)TensorFlow version (use command below): N/A (see above)Bazel version (if compiling from source): 0.4.5-homebrewCUDA/cuDNN version: none (AMD GPU)GPU model and memory: Radeon Pro 460Exact command to reproduce:sudo bazel build --config opt --copt=-msse4.1 --copt=-msse4.1 --copt=-mavx --copt=-mavx2 --copt=-mfma //tensorflow/tools/pip_package:build_pip_packageDescribe the problemTrying to build tensorflow from source (version installed via pip does not use some optimised CPU instructions), get the following error: ~/workspace/tensorflow   master  sudo bazel build --config opt --copt=-msse4.1 --copt=-msse4.1 --copt=-mavx --copt=-mavx2 --copt=-mfma //tensorflow/tools/pip_package:build_pip_packageWARNING: Config values are not defined in any .rc file: optERROR: /Users/kachkach/workspace/tensorflow/third_party/py/numpy/BUILD:11:1: no such package '@local_config_python//': Traceback (most recent call last):File "/Users/kachkach/workspace/tensorflow/third_party/py/python_configure.bzl", line 180_create_python_repository(repository_ctx)File "/Users/kachkach/workspace/tensorflow/third_party/py/python_configure.bzl", line 157, in _create_python_repository_get_env_var(repository_ctx, _PYTHON_BIN_PATH)File "/Users/kachkach/workspace/tensorflow/third_party/py/python_configure.bzl", line 48, in _get_env_var_python_configure_fail("'%s' environment variable is no...)File "/Users/kachkach/workspace/tensorflow/third_party/py/python_configure.bzl", line 36, in _python_configure_failfail("%sPython Configuration Error:%...))Python Configuration Error: 'PYTHON_BIN_PATH' environment variable is not set and referenced by '//third_party/py/numpy:headers'.ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted.Note that I used which python3 to find where my Python binary is located, and exported that as PYTHON_BIN_PATH, but it does not seem to help.
buildinstall	Issue with running Tensorflow with OpenCL - Ubuntu 14.04.3 (Trusty) - AMD R5 Radeon M335 GPUHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution (e.g., Linux Ubuntu 16.04):14.04.3-->TrustyTensorFlow installed from (source or binary):SourceTensorFlow version (use command below):1.0 (Steps-> Downloaded tensorflow from https://github.com/benoitsteiner/tensorflow-opencl, ./configure - to configure project)Bazel version (if compiling from source):0.4.5CUDA/cuDNN version:NAOPENCL Version:Number of platforms:1Platform Profile:FULL_PROFILEPlatform Version:OpenCL 2.0 AMD-APP (1800.11)Platform Name:AMD Accelerated Parallel ProcessingPlatform Vendor:Advanced Micro Devices, Inc.Platform Extensions:cl_khr_icd cl_amd_event_callback cl_amd_offline_devicesGPU model and memory:Platform Name:AMD Accelerated Parallel ProcessingNumber of devices:2Device Type:CL_DEVICE_TYPE_GPUBoard name:AMD Radeon (TM) R5 M335Memory:4096MExact command to reproduce:run the python script -- ipython keras_code.py** G++/GCC version**:g++-4.9 (Ubuntu 4.9.4-2ubuntu1~14.04.1) 4.9.4I have compiled CPP programs, they work fine.ComputeCPP: 0.1.4-- ** Python**: I am using Anaconda distribution Python for 2.7.2. (Anaconda - 2.4.3)Describe the problemI have compile tensorflow, and deployed the same -> No issues here. when I try to run the code I run into the following error:2017-04-23 14:01:15.180795: W ./tensorflow/core/common_runtime/sycl/sycl_util.h:44] No OpenCL GPU found that is supported by ComputeCpp, trying OpenCL CPU2017-04-23 14:01:15.180843: F ./tensorflow/core/common_runtime/sycl/sycl_util.h:53] No OpenCL GPU nor CPU found that is supported by ComputeCppAborted (core dumped)I have attached the code file. Please note this is a simplified version of the file. The logic is:Read data from files,Pass it through a NNI am using Keras as the Functional programming API on top of Tensorflow.More details: Output of Computecpp_info:ComputeCpp Info (CE 0.1.4)Toolchain information:GLIBCXX: 20150426This version of libstdc++ is supported.Device Info:Discovered 2 devices matching:platform    : device type : Device 0:Device is supported                     : UNTESTED - Device not tested on this OSCL_DEVICE_NAME                          : HainanCL_DEVICE_VENDOR                        : Advanced Micro Devices, Inc.CL_DRIVER_VERSION                       : 1800.11 (VM)CL_DEVICE_TYPE                          : CL_DEVICE_TYPE_GPUDevice 1:Device is supported                     : UNTESTED - Device running untested driverCL_DEVICE_NAME                          : Intel(R) Core(TM) i7-6500U CPU @ 2.50GHzCL_DEVICE_VENDOR                        : GenuineIntelCL_DRIVER_VERSION                       : 1800.11 (sse2,avx)CL_DEVICE_TYPE                          : CL_DEVICE_TYPE_CPUIf you encounter problems when using any of these OpenCL devices, please consultthis website for known issues:https://computecpp.codeplay.com/releases/v0.1.4/platform-support-notesPlease let me know if there are any fixes or if I can do something to get round this issue.Thanks and regardsSayantantensorflow-code-throwing-error.txt
buildinstall	Unable to install v0.11 - missing distributionSystem informationOS Platform and Distribution: Ubuntu 16.04TensorFlow installed from (source or binary): Not installedTensorFlow version (use command below): 0.11CUDA/cuDNN version: 5.0GPU model and memory: Titan X 12 GBExact command to reproduce:root@system76-server:/# export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp35-cp35m-linux_x86_64.whlroot@system76-server:/# sudo -H pip3 install --upgrade TF_BINARY_URLDescribe the problemThe distribution for v0.11 is missing. I am building from binary. Here is the error message:"Collecting TF_BINARY_URLCould not find a version that satisfies the requirement TF_BINARY_URL (from versions: )No matching distribution found for TF_BINARY_URL"There is some URGENCY here. At our startup, we have just started a pilot with our very first client. Due to privacy concerns, the app is being shipped to client on a desktop, which is being set up right now. Our current stable app version uses TF 0.11 and we dont wish to move to 1.0 unless absolutely unavoidable.Would really appreciate it if you would help asap!PS: This might help just me, but given this is a distribution issue, others may also benefit from this. Either ways, many apologies if this is the wrong request for GitHub!
buildinstall	iOS Example error: Create kernel failedI'm trying to run the iOS example 'simple' provided. Script build_all_ios.sh runs fine, I'M able to deploy the application, but when I click on the 'Run Model' button, I get the following error:2017-04-26 00:16:30.272956: I /Users/robertofalk/Development/git/tensorflow/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:149] Session created.2017-04-26 00:16:30.273190: I /Users/robertofalk/Development/git/tensorflow/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:152] Graph created.2017-04-26 00:16:30.508996: I /Users/robertofalk/Development/git/tensorflow/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:157] Creating session.2017-04-26 00:16:30.772992: E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]().  Registered:  <no registered kernels>2017-04-26 00:16:30.773030: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]().  Registered:  <no registered kernels> [[Node: _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]2017-04-26 00:16:30.773723: E /Users/robertofalk/Development/git/tensorflow/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:221] Running model failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]().  Registered:  <no registered kernels> [[Node: _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]The error happens both on the simulator and on the device (iPhone 7).Please let me know if you need any additional information about this issue from my side.Thanks and regards,Roberto Falk
buildinstall	Tensorflow in Raspberry Pi -- Create kernel failed: Not found: No registered '_Arg' OpKernelSystem information-I have followed steps to install Tensorflow on Raspberry Pi 3 from the pagehttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefileAfter installation I tried to run the example from this pagehttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/pi_examplesDescribe the problemWhile executing the command label_image, I got a number of errors which I am unable to find anywhere on stack overflow or google. The error that I get I have pasted below.Source code / logspi@raspberrypi:~/tensorflow $ tensorflow/contrib/pi_examples/label_image/gen/bin/label_image2017-04-26 02:42:45.526198: I tensorflow/contrib/pi_examples/label_image/label_image.cc:145] Loaded JPEG: 512x600x32017-04-26 02:42:46.861870: E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_Mul_0_0 = _ArgT=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0".  Registered:  2017-04-26 02:42:46.862015: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_Mul_0_0 = _ArgT=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0".  Registered:   [[Node: _arg_Mul_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]2017-04-26 02:42:46.872857: E tensorflow/contrib/pi_examples/label_image/label_image.cc:376] Running model failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_Mul_0_0 = _ArgT=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0".  Registered:   [[Node: _arg_Mul_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]
buildinstall	python tensorflow ImportErrorThe following is my code:#matplotlib inlineimport matplotlib.pyplot as pltimport tensorflow as tfimport numpy as npfrom sklearn.metrics import confusion_matrixtf.versionfrom tensorflow.examples.tutorials.mnist import input_datadata = input_data.read_data_sets("data/MNIST/", one_hot=True)print("Size of:")print("- Training-set:\t\t{}".format(len(data.train.labels)))print("- Test-set:\t\t{}".format(len(data.test.labels)))print("- Validation-set:\t\t".format(len(data.validation.labels)))data.test.labels[0:5, :]data.test.cls = np.array([label.argmax() for label in data.test.labels])data.test.cls[0:5]The error in above code is:Traceback (most recent call last):File "C:/Users/KumarRaja/Desktop/skywalker.py", line 5, in from sklearn.metrics import confusion_matrixFile "C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn_init_.py", line 57, in from .base import cloneFile "C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\sklearn\base.py", line 10, in from scipy import sparseFile "C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\scipy\sparse_init_.py", line 221, in from .csr import *File "C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\scipy\sparse\csr.py", line 15, in from ._sparsetools import csr_tocsc, csr_tobsr, csr_count_blocks, File "C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\scipy\sparse_sparsetools.py", line 7, in bootstrap()File "C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\site-packages\scipy\sparse_sparsetools.py", line 6, in bootstrapimp.load_dynamic(name,file)File "C:\Users\KumarRaja\AppData\Local\Programs\Python\Python35\lib\imp.py", line 342, in load_dynamicreturn _load(spec)ImportError: DLL load failed: The specified module could not be found.I hv installed the missing dll files in their respective location but the code isn't working after that also.Please help me with the above problem.
buildinstall	ImportError: No module named '_pywrap_tensorflow_internal'Hi all,Using windows 7 and have made tensorflow work in the cpu version. But keep getting this error in the gpu version.Installed it using pip install tensorflow-gpu. Have cuda 8.0 and cudnn 5.1. Have the dll file and cudnn files copied over. GPU model is K610M.Thanks in advance for the assistance.Capture of the screen:(C:\Users\KiraYamato\Anaconda3) C:\Users\KiraYamato>activate tensorflow-gpu(tensorflow-gpu) C:\Users\KiraYamato>pythonPython 3.5.3 |Continuum Analytics, Inc.| (default, Feb 22 2017, 21:28:42) [MSC v.1900 64 bit (AMD64)] on win32Type "help", "copyright", "credits" or "license" for more information.import tensorflow as tfTraceback (most recent call last):File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 18, in swig_import_helperreturn importlib.import_module(mname)File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\importlib_init_.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)File "", line 986, in _gcd_importFile "", line 969, in _find_and_loadFile "", line 958, in _find_and_load_unlockedFile "", line 666, in _load_unlockedFile "", line 577, in module_from_specFile "", line 914, in create_moduleFile "", line 222, in _call_with_frames_removedImportError: DLL load failed: The specified procedure could not be found.During handling of the above exception, another exception occurred:Traceback (most recent call last):File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 41, in from tensorflow.python.pywrap_tensorflow_internal import *File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 21, in _pywrap_tensorflow_internal = swig_import_helper()File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 20, in swig_import_helperreturn importlib.import_module('pywrap_tensorflow_internal')File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\importlib_init.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)ImportError: No module named '_pywrap_tensorflow_internal'During handling of the above exception, another exception occurred:Traceback (most recent call last):File "", line 1, in File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow_init_.py", line 24, in from tensorflow.python import *File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python_init_.py", line 51, in from tensorflow.python import pywrap_tensorflowFile "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 52, in raise ImportError(msg)ImportError: Traceback (most recent call last):File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 18, in swig_import_helperreturn importlib.import_module(mname)File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\importlib_init_.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)File "", line 986, in _gcd_importFile "", line 969, in _find_and_loadFile "", line 958, in _find_and_load_unlockedFile "", line 666, in _load_unlockedFile "", line 577, in module_from_specFile "", line 914, in create_moduleFile "", line 222, in _call_with_frames_removedImportError: DLL load failed: The specified procedure could not be found.During handling of the above exception, another exception occurred:Traceback (most recent call last):File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 41, in from tensorflow.python.pywrap_tensorflow_internal import *File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 21, in _pywrap_tensorflow_internal = swig_import_helper()File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 20, in swig_import_helperreturn importlib.import_module('pywrap_tensorflow_internal')File "C:\Users\KiraYamato\Anaconda3\envs\tensorflow-gpu\lib\importlib_init.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)ImportError: No module named '_pywrap_tensorflow_internal'Failed to load the native TensorFlow runtime.See https://www.tensorflow.org/install/install_sources#common_installation_problemsfor some common reasons and solutions.  Include the entire stack traceabove this error message when asking for help.
buildinstall	Cmake build error on windows 10 (fatal error C1001)System informationHave I written custom code: NoOS Platform and Distribution: Windows 10TensorFlow installed from:sourceTensorFlow version:masterBazel version:NACUDA/cuDNN version:8.0/5.1GPU model and memory:GTX 1080Exact command to reproduce:MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxprojDescribe the problemI was following cmake build instructionhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmaketo build python package with GPU support using visual studio 2015 Update 3. It took a few hours until I hit fatal error C1001.logsc:\work\libraries_local\tensorflow\tensorflow\core\kernels\reduction_ops_gpu.cu.cc(64): fatal error C1001: An internal error has occurred in the compiler. [C:\work\libraries_local\tensorflow\tensorflow\contrib\cmake\build\tf_core_gpu_kernels.vcxproj]    (compiler file 'f:\dd\vctools\compiler\utc\src\p2\main.c', line 255)     To work around this problem, try simplifying or changing the program near the locations listed above.
buildinstall	Time cost for each training step increases with the training procedureWhen I try to run a SRGAN network by 32 images with 96 * 96 size, each training step the time cost increases. At the beginning, each step cost 35 seconds, but when 160 steps later, the time cost increases to more than 200 seconds. By checking the time log, I can see it do increase with the training step. If I save the model and restart training process, the time cost reduces to about 35 seconds and start increasing again.
buildinstall	ModuleNotFoundError: No module named 'tensorflow'ProblemI have problem running tensorflow, I am quite new in using tensorflow and Python, hence pardon me if this is stupid question to ask. The problem is when I tried running tensorflow in windows command prompt, it worked just fine but then it give me ModuleNotFoundError when I tried running it through .py file. Is there something wrong? Please help me, thank youSystem informationTensorflow version 1.1 (installed using instruction given in Here in conda environment named tensorflow-gpuOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10TensorFlow installed from (source or binary): pre-built binaryCUDA/cuDNN version: 8.0/5.1Source code / logs(tensorflow-gpu) C:\Users\USER\Anaconda3\envs>pythonPython 3.5.3 |Continuum Analytics, Inc.| (default, Feb 22 2017, 21:28:42) [MSC v.1900 64 bit (AMD64)] on win32Type "help", "copyright", "credits" or "license" for more information.>>> import tensorflow as tf>>> hello = tf.constant('Hello, TensorFlow!')>>> sess = tf.Session()2017-04-27 12:01:30.461948: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.2017-04-27 12:01:30.462096: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.2017-04-27 12:01:30.462199: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.2017-04-27 12:01:30.462298: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.2017-04-27 12:01:30.462375: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.2017-04-27 12:01:30.462448: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.2017-04-27 12:01:31.657721: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:887] Found device 0 with properties:name: GeForce GT 740Mmajor: 3 minor: 5 memoryClockRate (GHz) 1.0325pciBusID 0000:07:00.0Total memory: 2.00GiBFree memory: 1.67GiB2017-04-27 12:01:31.657920: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:908] DMA: 02017-04-27 12:01:31.659743: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:918] 0:   Y2017-04-27 12:01:31.660988: I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 740M, pci bus id: 0000:07:00.0)>>> print(sess.run(hello))b'Hello, TensorFlow!'>>> ^Z(tensorflow-gpu) C:\Users\USER\Anaconda3\envs>hello_tf.pyTraceback (most recent call last):  File "C:\Users\USER\Anaconda3\envs\hello_tf.py", line 1, in <module>    import tensorflow as tfModuleNotFoundError: No module named 'tensorflow'Here is my hello_tf.py:import tensorflow as tfhello = tf.constant('Hello, TensorFlow!')sess = tf.Session()print(sess.run(hello))
buildinstall	ImportError (in import tensorflw-gpu as tf) : Tensorflow windows10, CUDA8.0/cuDNN5.1 and python 3.5.2Hi, i am facing an issue if importError on a setup !Windows10, Microsoft visual studio (2017)CUDA 8.0/cuDNN5.1Python 3.5.2PATH for CUDA, cuDNN5.1 Libraries/bin/include set properly !!Setup is created with Docker & tensorflow-gpu environmentWhile i am trying to verify my installation with "import tensorflow-gpu as tf", encountering with  ImportError: python library specific errors. pl do suggest some remedies !!Here is complete log of error:$ pythonPython 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)] on win32Type "help", "copyright", "credits" or "license" for more information.import tensorflow-gpu as tfFile "", line 1import tensorflow-gpu as tf^SyntaxError: invalid syntaximport tensorflow as tfTraceback (most recent call last):File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 18, in swig_import_helperreturn importlib.import_module(mname)File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib_init_.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)File "", line 986, in _gcd_importFile "", line 969, in _find_and_loadFile "", line 958, in _find_and_load_unlockedFile "", line 666, in _load_unlockedFile "", line 577, in module_from_specFile "", line 906, in create_moduleFile "", line 222, in _call_with_frames_removedImportError: DLL load failed: The specified module could not be found.During handling of the above exception, another exception occurred:Traceback (most recent call last):File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 41, in from tensorflow.python.pywrap_tensorflow_internal import *File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 21, in _pywrap_tensorflow_internal = swig_import_helper()File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 20, in swig_import_helperreturn importlib.import_module('pywrap_tensorflow_internal')File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib_init.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)ImportError: No module named '_pywrap_tensorflow_internal'During handling of the above exception, another exception occurred:Traceback (most recent call last):File "", line 1, in File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow_init_.py", line 24, in from tensorflow.python import *File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python_init_.py", line 51, in from tensorflow.python import pywrap_tensorflowFile "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 52, in raise ImportError(msg)ImportError: Traceback (most recent call last):File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 18, in swig_import_helperreturn importlib.import_module(mname)File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib_init_.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)File "", line 986, in _gcd_importFile "", line 969, in _find_and_loadFile "", line 958, in _find_and_load_unlockedFile "", line 666, in _load_unlockedFile "", line 577, in module_from_specFile "", line 906, in create_moduleFile "", line 222, in _call_with_frames_removedImportError: DLL load failed: The specified module could not be found.During handling of the above exception, another exception occurred:Traceback (most recent call last):File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 41, in from tensorflow.python.pywrap_tensorflow_internal import *File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 21, in _pywrap_tensorflow_internal = swig_import_helper()File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 20, in swig_import_helperreturn importlib.import_module('pywrap_tensorflow_internal')File "C:\Users\Rajeev\Anaconda3\envs\tensorflow-gpu\lib\importlib_init.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)ImportError: No module named '_pywrap_tensorflow_internal'Failed to load the native TensorFlow runtime.See https://www.tensorflow.org/install/install_sources#common_installation_problemsfor some common reasons and solutions.  Include the entire stack traceabove this error message when asking for help.Please go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):OS Platform and Distribution (e.g., Linux Ubuntu 16.04):TensorFlow installed from (source or binary):TensorFlow version (use command below):Bazel version (if compiling from source):CUDA/cuDNN version:GPU model and memory:Exact command to reproduce:You can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.Source code / logsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
buildinstall	failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZEDSystem informationOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux 4.4.0-75-generic #96-Ubuntu SMP Thu Apr 20 09:56:33 UTC 2017 x86_64 x86_64 x86_64 GNU/LinuxTensorFlow version (use command below):I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locallyv1.0.0-65-g4763edf-dirty 1.0.1CUDA/cuDNN version:  8.0GPU model and memory:name: GeForce GTX 980major: 5 minor: 2 memoryClockRate (GHz) 1.2785pciBusID 0000:01:00.0Total memory: 3.94GiBFree memory: 145.50MiBDescribe the problemIf I change the order of device usage, it would report errorSource code / logsIf I use GPU first then CPU, it would be finewith tf.device('/gpu:0'):    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')    c = tf.matmul(a, b)with tf.device('/cpu:0'):    e = tf.constant([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], shape=[2, 9],dtype=tf.float32, name='e')    f = tf.matmul(c,e)sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))print(sess.run(f))But if I use CPU first then GPU, it return errorwith tf.device('/cpu:0'):    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')    c = tf.matmul(a, b)with tf.device('/gpu:0'):    e = tf.constant([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18], shape=[2, 9],dtype=tf.float32, name='e')    f = tf.matmul(c,e)sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))print(sess.run(f))the error dump below    print(sess.run(f))  File "/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 767, in run    run_metadata_ptr)  File "/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 965, in _run    feed_dict_string, options, run_metadata)  File "/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1015, in _do_run    target_list, options, run_metadata)  File "/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1035, in _do_call    raise type(e)(node_def, op, message)tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : a.shape=(2, 2), b.shape=(2, 9), m=2, n=9, k=2         [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](MatMul/_1, e)]]Caused by op 'MatMul_1', defined at:  File "m1_n0teb00k/tensorflow_palyground.py", line 13, in <module>    f = tf.matmul(c,e)  File "/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py", line 1765, in matmul    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)  File "/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py", line 1454, in _mat_mul    transpose_b=transpose_b, name=name)  File "/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py", line 763, in apply_op    op_def=op_def)  File "/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 2327, in create_op    original_op=self._default_original_op, op_def=op_def)  File "/home/pika/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 1226, in __init__    self._traceback = _extract_stack()InternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(2, 2), b.shape=(2, 9), m=2, n=9, k=2         [[Node: MatMul_1 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](MatMul/_1, e)]]
buildinstall	icc Compilation Errors in tf1.0: usage of "typename" on TTypesHave I written custom code (as opposed to using a stock example script provided in TensorFlow):OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04TensorFlow installed from (source or binary): sourceTensorFlow version (use command below): 1.0Bazel version (if compiling from source): 0.4.5CUDA/cuDNN version: not configuredGPU model and memory: not configuredExact command to reproduce: CC=icc bazel build -c opt //tensorflow/tools/pip_package:build_pip_packageWhen compiling tensorflow using icc (version 17.0.3 20170404) using the command above, errors appear concerning the usage of typename associated with TTypes. For instance:tensorflow/core/kernels/depthtospace_op.cc(88): error: type name is not allowedtypename TTypes<T, 4>::ConstTensor Tinput = input.tensor<T, 4>();A more constrained example, however, makes the problem more apparent. Command:CC=icc bazel build -c opt //tensorflow/core/kernels:resize_nearest_neighbor_opOutput (partial):tensorflow/core/kernels/resize_nearest_neighbor_op.cc(57): error: type name is not allowedtypename TTypes<T, 4>::ConstTensor input_data = input.tensor<T, 4>();I can change line resize_nearest_neighbor_op.cc(57) to:TTypes<T, 4>::ConstTensor input_data = input.tensor<T, 4>();and repeat the command to get Output (partial):tensorflow/core/kernels/resize_nearest_neighbor_op.cc(57): error: use the "typename" keyword to treat nontype "tensorflow::TTypes<T, NDIMS, IndexType>::ConstTensor [with T=T, NDIMS=4, IndexType=Eigen::DenseIndex={std::ptrdiff_t={long}}]" as a type in a dependent contextTTypes<T, 4>::ConstTensor input_data = input.tensor<T, 4>();I do not know if Intel Compiler compatibility is an intended feature of tensorflow, but I hoped this issue would still be of interest to the developers.Thank you!
buildinstall	No name 'debug' in module 'tensorflow'System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YesOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 ProTensorFlow installed from (source or binary): pip install tensorflow-gpu --upgradeTensorFlow version (use command below): 1.0.1Bazel version (if compiling from source): N/ACUDA/cuDNN version: Cuda:8, CuDnn:5.1GPU model and memory: Pascal TitanX (x2)Exact command to reproduce:from tensorflow.python import debug as tf_debugYou can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.Won't import.  This is the exact import from the docs; I have done nothing fancy; just normal install of everything.Source code / logsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.you can replicate this really easy.python -c "from tensorflow.python import debug as tf_debug;"
buildinstall	Cannot import tensorflow in IPython3 (while in normal python3 IDLE works fine) after pip installationI have installed tensorflow-gpu via pip installation and I am experiencing this issue. I cannot import it in IPython3 but it works fine with the regular python3.petrux@orion:~$ ipython -c "import tensorflow; print(tensorflow.__version__)"1.1.0petrux@orion:~$ python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')petrux@orion:~$ python3 -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"v1.1.0-rc0-61-g1ec6ed5 1.1.0petrux@orion:~$ ipython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')petrux@orion:~$ ipython3 -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"---------------------------------------------------------------------------ImportError                               Traceback (most recent call last)<ipython-input-1-5730349aae22> in <module>()----> 1 import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)/usr/local/lib/python3.5/dist-packages/tensorflow/__init__.py in <module>()     22      23 # pylint: disable=wildcard-import---> 24 from tensorflow.python import *     25 # pylint: enable=wildcard-import     26 /usr/local/lib/python3.5/dist-packages/tensorflow/python/__init__.py in <module>()     52      53 # Protocol buffers---> 54 from tensorflow.core.framework.graph_pb2 import *     55 from tensorflow.core.framework.node_def_pb2 import *     56 from tensorflow.core.framework.summary_pb2 import */usr/local/lib/python3.5/dist-packages/tensorflow/core/framework/graph_pb2.py in <module>()      4 import sys      5 _b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))----> 6 from google.protobuf import descriptor as _descriptor      7 from google.protobuf import message as _message      8 from google.protobuf import reflection as _reflectionImportError: No module named 'google.protobuf'; 'google' is not a packageSystem informationOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04TensorFlow installed from (source or binary): pipTensorFlow version (use command below): ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')
buildinstall	Tensor flow cannot be imported properly in windowsI have installed CPU version of Tensor flow in my laptop using the command line using pip install.OS: Windows 8.1 64 bit Python 3.5.1But, when I tried importing it in the python 3.5.1 it throws the following error message.import _pywrap_tensorflow ImportError: No module named '_pywrap_tensorflow' Error importing tensorflow. Unless you are using bazel, you should not try to import tensorflow from its source directory; please exit the tensorflow source tree, and relaunch your python interpreter from there.I have tried getting answers in Stackoverflow, but no hope. I have even tried changing the directories but nothing works.I am new to python. Please help me to solve this issue !!
buildinstall	Tensorflow Failed to create SessionHiI tried basic program in python shell. It fails to create session. Please assist.ThanksPython 2.7.6 (default, Oct 26 2016, 20:30:19)[GCC 4.8.4] on linux2Type "help", "copyright", "credits" or "license" for more information.>>> import tensorflow as tfI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.7.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.7.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.7.5 locally>>> hello = tf.constant('hi,tensorflow')>>> sess = tf.Session()I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node                                                                                                              read from SysFS had negative value (-1), but there must be at least one NUMA no                                                                                                             de, so returning NUMA node zeroI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with prop                                                                                                             erties:name: Tesla K40cmajor: 3 minor: 5 memoryClockRate (GHz) 0.745pciBusID 0000:02:00.0Total memory: 11.17GiBFree memory: 11.10GiBW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one                                                                                                              is currently active; existing: 0x2e0fe90E tensorflow/core/common_runtime/direct_session.cc:137] Internal: failed initial                                                                                                             izing StreamExecutor for CUDA device ordinal 1: Internal: failed call to cuDevic                                                                                                             ePrimaryCtxRetain: CUDA_ERROR_INVALID_DEVICETraceback (most recent call last):  File "<stdin>", line 1, in <module>  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.                                                                                                             py", line 1187, in __init__    super(Session, self).__init__(target, graph, config=config)  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.                                                                                                             py", line 552, in __init__    self._session = tf_session.TF_NewDeprecatedSession(opts, status)  File "/usr/lib/python2.7/contextlib.py", line 24, in __exit__    self.gen.next()  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/error                                                                                                             s_impl.py", line 469, in raise_exception_on_not_ok_status    pywrap_tensorflow.TF_GetCode(status))tensorflow.python.framework.errors_impl.InternalError: Failed to create session.
buildinstall	configure does not work on macOS if sed is GNU sedSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): noOS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.12.4TensorFlow installed from (source or binary): sourceTensorFlow version (use command below): Current head: 3ce228eDescribe the problemIf sed is GNU sed on macOS, configure fails with sed: can't read : No such file or directory.
buildinstall	no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path.Describe the problemI use ubuntu, and install anaconda3 and tensorflow followed the instruction. After it, I am trying to learn how to retrain a model that follows the inception tutorial. It seems that I got the following errorsERROR: no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path.Is there a way to solve this issue?Source code / logsparallels@ubuntu:~/anaconda3/lib/python3.6/site-packages$ bazel build tensorflow/examples/image_retraining:retrainERROR: no such package 'tensorflow/examples/image_retraining': BUILD file not found on package path.INFO: Elapsed time: 0.073s
buildinstall	No module named tensorflow (problem with python 2)Hi,I'm trying to install tensorflow on this machine:Ubuntu 16.04cuda 8.0cudnn 5.1python 2.7 (no Anaconda)I installed tensorflow on both python 3 and python 2. It works with python 3 but with python 2 always gives the import error: No module named tensorflow.What can I do to solve this?Thanks
buildinstall	Bazel error: building tensorflow 1.1 from source (CPU only)Problem descriptionThe Docker build script below fails to build TensorFlow 1.1 from source with the following error messages:ERROR: /tensorflow/WORKSPACE:3:1: //external:io_bazel_rules_closure: no such attribute 'urls' in 'http_archive' rule.ERROR: /tensorflow/WORKSPACE:3:1: //external:io_bazel_rules_closure: missing value for mandatory attribute 'url' in 'http_archive' rule.ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': error loading package 'external': Could not load //external package.Complete build log:$ docker start tensorflow-builder$ docker attach tensorflow-builderroot@8eef137e3404:/tensorflow# git fetch -fapvFrom https://github.com/tensorflow/tensorflow = [up to date]      0.6.0      -> origin/0.6.0 = [up to date]      docs-republishing -> origin/docs-republishing = [up to date]      estimator_windows -> origin/estimator_windows = [up to date]      fix-makefile-build -> origin/fix-makefile-build = [up to date]      master     -> origin/master = [up to date]      r0.10      -> origin/r0.10 = [up to date]      r0.11      -> origin/r0.11 = [up to date]      r0.12      -> origin/r0.12 = [up to date]      r0.7       -> origin/r0.7 = [up to date]      r0.8       -> origin/r0.8 = [up to date]      r0.9       -> origin/r0.9 = [up to date]      r1.0       -> origin/r1.0 = [up to date]      r1.1       -> origin/r1.1 = [up to date]      rn_delete  -> origin/rn_deleteroot@8eef137e3404:/tensorflow# git checkout -b r1.1 origin/r1.1Switched to a new branch 'r1.1'root@8eef137e3404:/tensorflow# git pullAlready up-to-date.root@8eef137e3404:/tensorflow# ./configurePlease specify the location of python. [Default is /usr/local/bin/python]: Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]: Do you wish to use jemalloc as the malloc implementation? [Y/n] jemalloc enabledDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] No Google Cloud Platform support will be enabled for TensorFlowDo you wish to build TensorFlow with Hadoop File System support? [y/N] No Hadoop File System support will be enabled for TensorFlowDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] No XLA support will be enabled for TensorFlowFound possible Python library paths:  /usr/lib/python3/dist-packages  /usr/local/lib/python3.5/dist-packagesPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]Using python library path: /usr/lib/python3/dist-packagesDo you wish to build TensorFlow with OpenCL support? [y/N] No OpenCL support will be enabled for TensorFlowDo you wish to build TensorFlow with CUDA support? [y/N] No CUDA support will be enabled for TensorFlowConfiguration finished.INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes...........ERROR: /tensorflow/WORKSPACE:3:1: //external:io_bazel_rules_closure: no such attribute 'urls' in 'http_archive' rule.ERROR: /tensorflow/WORKSPACE:3:1: //external:io_bazel_rules_closure: missing value for mandatory attribute 'url' in 'http_archive' rule.ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': error loading package 'external': Could not load //external package.DockerfileFROM ubuntu:16.04# https://github.com/kubernetes/test-infra/blob/master/images/pull-kubernetes-bazel/DockerfileRUN apt-get update && apt-get install -y --no-install-recommends \    build-essential \    openjdk-8-jdk \    pkg-config \    zip \    unzip \    zlib1g-dev \    bash-completion \    git \    wget \    python && \    apt-get cleanENV BAZEL_VERSION 0.3.2RUN wget "https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel_${BAZEL_VERSION}-linux-x86_64.deb" && \    dpkg -i "bazel_${BAZEL_VERSION}-linux-x86_64.deb" && \    rm "bazel_${BAZEL_VERSION}-linux-x86_64.deb"# Fetch TensorFlow source code and build dependenciesRUN apt-get install -y --no-install-recommends git python3-numpy swig python3-dev python3-wheel && \    apt-get install -y --no-install-recommends python3-setuptools rsync && \    apt-get clean && \    ln -s /usr/bin/python3 /usr/local/bin/python && \    git clone --quiet --recurse-submodules https://github.com/tensorflow/tensorflow.git /tensorflowWORKDIR /tensorflow# Steps to build:## host$ docker build -t bazel .# host$ docker run -it --name bazel-builder bazel## bazel-builder$ ./configure (press enter repeatedly)# bazel-builder$ bazel build -c opt --copt=-mavx2 //tensorflow/tools/pip_package:build_pip_package# bazel-builder$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg# bazel-builder$ exit## host$ docker cp bazel-build:/tmp/tensorflow_pkg/tensorflow-0.11.0-py3-none-any.whl /tmp
buildinstall	I updated tensorflow gpu version and jupyter notebook and I can not import tensorflow after updates. here is the error I got:Please go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):OS Platform and Distribution (e.g., Linux Ubuntu 16.04):TensorFlow installed from (source or binary):TensorFlow version (use command below):Bazel version (if compiling from source):CUDA/cuDNN version:GPU model and memory:Exact command to reproduce:You can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.Source code / logsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
buildinstall	cuda_error_out_of_memory when trying to run tensorflow/tensorflow/examples/tutorials/layers/cnn_mnist.pyWhen I run tensorflow/tensorflow/examples/tutorials/layers/cnn_mnist.py on GPU I get the cuda_error_out_of_memory.I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   YI c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970M, pci bus id: 0000:01:00.0)E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_driver.cc:1002] failed to allocate 3.00G (3221225472 bytes) from device: CUDA_ERROR_OUT_OF_MEMORYE c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_driver.cc:1002] failed to allocate 2.70G (2899102720 bytes) from device: CUDA_ERROR_OUT_OF_MEMORYE c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:397] could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZEDE c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:404] error retrieving driver version: Permission denied: could not open driver version path for reading: /proc/driver/nvidia/versionE c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:364] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAMF c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\kernels\conv_ops.cc:605] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms)To circumvent it, I thought of using config.gpu_options.per_process_gpu_memory_fraction or config.gpu_options.allow_growth, but I don't know where to set the session configuration as I don't see any sessions in the code. Also, is there any way I can set session configuration globally for one file?
buildinstall	Building TensorFlow with CPU SIMD OPTIONS enabled on Windows 10 FAILEDPlease go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10TensorFlow installed from (source or binary): SourceTensorFlow version (use command below): masterBazel version (if compiling from source): NoCUDA/cuDNN version: NoGPU model and memory: NoExact command to reproduce:MSBuild /p:Configuration=Release /filelogger tf_python_build_pip_package.vcxprojYou can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.I was following the instructions to build tensorflow on Windowshttps://github.com/tensorflow/tensorflow/tree/r0.12/tensorflow/contrib/cmakeThe error came when I tried to build the PIP package. I have VS2015.The error is related to zlib atCMake Error at C:/Projects/tensorflow/tensorflow/contrib/cmake/build/zlib/tmp/zlib-gitclone.cmake:84 (message):Failed to init submodules in:'C:/Projects/tensorflow/tensorflow/contrib/cmake/build/zlib/src/zlib'There are more errors with the same issue (git failed to init submodules) for: highwayhash, and jasoncpp.Source code / logsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12\swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:\Users\sergio.murillo\AppData\Local\Programs\Python\Python35/PYTHON.EXE -DPYTHON_LIBRARIES=C:\Users\sergio.murillo\AppData\Local\Programs\Python\Python35\libs\python35.lib  -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX-- Configuring done-- Generating done-- Build files have been written to: C:/Projects/tensorflow/tensorflow/contrib/cmake/buildMSBuild /p:Configuration=Release /filelogger tf_python_build_pip_package.vcxproj...."C:\Projects\tensorflow\tensorflow\contrib\cmake\build\zlib.vcxproj" (default target) (11) ->(CustomBuild target) ->C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\Microsoft.CppCommon.targets(171,5): error MSB6006: "cmd.exe" exited with code 1 [C:\Projects\tensorflow\tensorflow\contrib\cmake\build\zlib.vcxproj]...msbuild.logCreating directories for 'zlib'Performing download step (git clone) for 'zlib'Cloning into 'zlib'...Note: checking out '50893291621658f355bc5b4d450a8d06a563053d'.You are in 'detached HEAD' state. You can look around, make experimentalchanges and commit them, and you can discard any commits you make in thisstate without impacting any branches by performing another checkout.If you want to create a new branch to retain commits you create, you maymsbuild.txtdo so (now or later) by using -b with the checkout command again. Example:git checkout -b <new-branch-name>HEAD is now at 5089329... zlib 1.2.8fatal: 'submodule' appears to be a git command, but we were notable to execute it. Maybe git-submodule is broken?CMake Error at zlib-gitclone.cmake:84 (message):Failed to init submodules in:'C:/Projects/tensorflow/tensorflow/contrib/cmake/build/zlib/src/zlib'C:\Program Files (x86)\MSBuild\Microsoft.Cpp\v4.0\V140\Microsoft.CppCommon.targets(171,5): error MSB6006: "cmd.exe" exited with code 1. [C:\Projects\tensorflow\tensorflow\contrib\cmake\build\zlib.vcxproj]Done executing task "CustomBuild" -- FAILED.Done building target "CustomBuild" in project "zlib.vcxproj" -- FAILED.Done Building Project "C:\Projects\tensorflow\tensorflow\contrib\cmake\build\zlib.vcxproj" (default targets) -- FAILED.
buildinstall	Broken link Mac/GPU/py3 whl fileOn page:https://www.tensorflow.org/install/install_mac#the_url_of_the_tensorflow_python_packageThis link is broken:https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl
buildinstall	NameError: name' core' is not defined !When I try to : import tensorflow as tfthis error appears:NameError: name' core' is not defined !What should I do?
buildinstall	inception/imagenet_distributed_train running is faildSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Not - Use last TF master and last ModelsOS Platform and Distribution (e.g., Linux Ubuntu 16.04):   Ubuntu 16.04TensorFlow installed from (source or binary): from source ( dramatically less compilation number of files, less in 100 files.)TensorFlow version (use command below): 'v1.1.0-rc2-607-g550df41', '1.1.0-rc2'Bazel version (if compiling from source): 0.4.5CUDA/cuDNN version: 8.0, 6GPU model and memory: Nvidia P100 PCI - 16 GBExact command to reproduce:On ps - bazel-bin/inception/imagenet_distributed_train --job_name='ps' --task_id=0 --ps_hosts='11.11.11.31:2222' --worker_hosts='11.11.11.41:2222,11.11.11.41:2223'All goodINFO:tensorflow:PS hosts are: ['11.11.11.31:2222']INFO:tensorflow:Worker hosts are: ['11.11.11.41:2222', '11.11.11.41:2223']2017-05-03 11:12:54.447399: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}2017-05-03 11:12:54.447459: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> 11.11.11.41:2222, 1 -> 11.11.11.41:2223}2017-05-03 11:12:54.456646: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:296] Started server with target: grpc://localhost:2222Describe the problemOn WorkerCUDA_VISIBLE_DEVICES='1' bazel-bin/inception/imagenet_distributed_train --batch_size=128 --job_name='worker' --ps_hosts='11.11.11.31:2222' --worker_hosts='11.11.11.41:2222,11.11.11.41:2223' --data_dir=/data/imagenet_data/ --train_dir=/data/imagenet_train/ --task_id=1It's failed withINFO:tensorflow:PS hosts are: ['11.11.11.31:2222']INFO:tensorflow:Worker hosts are: ['11.11.11.41:2222', '11.11.11.41:2223']2017-05-03 11:24:17.640127: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> 11.11.11.31:2222}2017-05-03 11:24:17.640169: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> 11.11.11.41:2222, 1 -> localhost:2223}2017-05-03 11:24:17.648767: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:296] Started server with target: grpc://localhost:2223Traceback (most recent call last):File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py", line 66, in tf.app.run()File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 48, in run_sys.exit(main(_sys.argv[:1] + flags_passthrough))File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/imagenet_distributed_train.py", line 62, in maininception_distributed_train.train(server.target, dataset, cluster_spec)File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/inception_distributed_train.py", line 157, in traininception.loss(logits, labels)File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/inception_model.py", line 128, in lossweight=1.0)File "/root/models/inception/bazel-bin/inception/imagenet_distributed_train.runfiles/inception/inception/slim/losses.py", line 166, in cross_entropy_losscross_entropy = tf.contrib.nn.deprecated_flipped_softmax_cross_entropy_with_logits(File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/lazy_loader.py", line 53, in getattrmodule = self._load()File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/lazy_loader.py", line 42, in _loadmodule = importlib.import_module(self.name)File "/usr/lib/python2.7/importlib/init.py", line 37, in import_moduleimport(name)File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/init.py", line 34, in from tensorflow.contrib import imageFile "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/image/init.py", line 39, in from tensorflow.contrib.image.python.ops.single_image_random_dot_stereograms import single_image_random_dot_stereogramsFile "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/image/python/ops/single_image_random_dot_stereograms.py", line 26, in "_single_image_random_dot_stereograms.so"))File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/util/loader.py", line 55, in load_op_libraryret = load_library.load_op_library(path)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/load_library.py", line 64, in load_op_libraryNone, None, error_msg, error_code)tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/image/python/ops/_single_image_random_dot_stereograms.so: undefined symbol: _ZN6google8protobuf8internal10LogMessageC1ENS0_8LogLevelEPKciThanks,Boris
buildinstall	cuda_configure.bzl makes bad symlink for: cuda/include/cudnn.h --> cuda/include/include/cudnn.hSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NOOS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS release 6.7 (Final) x86_64TensorFlow installed from (source or binary):  sourceTensorFlow version (use command below): master: git version 550df41 (checked out May 3rd 2017)Bazel version (if compiling from source): bazel-0.4.5CUDA/cuDNN version: 7.5/5.1.3GPU model and memory: Quadro K600 1GB DDR3Exact command to reproduce:setenv CC '/mnt/nfs/home/momeara/opt/bin/gcc'setenv CXX '/mnt/nfs/home/momeara/opt/bin/g++'setenv EXTRA_BAZEL_ARGS '--verbose_failures --jobs=1'setenv CPLUS_INCLUDE_PATH '/mnt/nfs/home/momeara/opt/include'setenv C_INCLUDE_PATH '/mnt/nfs/home/momeara/opt/include'setenv LIBRARY_PATH '/mnt/nfs/home/momeara/opt/lib:/mnt/nfs/home/momeara/opt/lib64'setenv LD_LIBRARY_PATH /mnt/nfs/work/momeara/sea/DeepSEA/cuda/lib64:/usr/local/cuda-7.5/lib64:/mnt/nfs/home/momeara/opt/lib:/mnt/nfs/home/momeara/opt/lib64:/usr/local/cuda-7.5/extras/CUPTI/lib64:$LD_LIBR\ARY_PATHsetenv PATH /usr/local/cuda-7.5/bin:/mnt/nfs/work/momeara/sea/DeepSEA/tensorflow/bazel-0.4.5/output:$PATH./configurePlease specify the location of python. [Default is /mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/bin/python]:Found possible Python library paths:  /mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/lib/python2.7/site-packagesPlease input the desired Python library path to use.  Default is [/mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/lib/python2.7/site-packages]Using python library path: /mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/lib/python2.7/site-packagesPlease specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]:Do you wish to use jemalloc as the malloc implementation? [Y/n] njemalloc disabledDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] nNo Google Cloud Platform support will be enabled for TensorFlowDo you wish to build TensorFlow with Hadoop File System support? [y/N] nNo Hadoop File System support will be enabled for TensorFlowDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] yXLA JIT support will be enabled for TensorFlowDo you wish to build TensorFlow with VERBS support? [y/N] yVERBS support will be enabled for TensorFlowDo you wish to build TensorFlow with OpenCL support? [y/N] nNo OpenCL support will be enabled for TensorFlowDo you wish to build TensorFlow with CUDA support? [y/N] yCUDA support will be enabled for TensorFlowDo you want to use clang as CUDA compiler? [y/N] nnvcc will be used as CUDA compilerPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:Please specify which gcc should be used by nvcc as the host compiler. [Default is /mnt/nfs/home/momeara/opt/bin/gcc]:Please specify the cuDNN version you want to use. [Leave empty to use system default]: 5.1.3Please specify the location where cuDNN 5.1.3 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /mnt/nfs/work/momeara/sea/DeepSEA/cudaPlease specify a list of comma-separated Cuda compute capabilities you want to build with.You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.Please note that each additional compute capability significantly increases your build time and binary size.[Default is: "3.5,5.2"]: 5.2WARNING: Output base '/mnt/nfs/home/momeara/.cache/bazel/_bazel_momeara/ef8339021629a8146b3e301bb7dc3099' is on NFS. This may lead to surprising failures and undetermined behavior.................................................................................____Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.Configuration finishedbazel --output_user_root=/scratch/momeara/.cache/baze build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures --jobs=1Describe the problemDuring configure, it tries to make a symlinkln -s /mnt/nfs/work/momeara/sea/DeepSEA/cuda/include/cudnn.h /scratch/momeara/.cache/baze/ef8339021629a8146b3e301bb7dc3099/execroot/tensorflow/bazel-out/host/genfiles/external/local_config_cuda/cuda/include/include/cudnn.hbut this fails because the directory /scratch/momeara/.cache/baze/ef8339021629a8146b3e301bb7dc3099/execroot/tensorflow/bazel-out/host/genfiles/external/local_config_cuda/cuda/include/include does not existnotice that it has include/include at the end.If I change this line: https://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/cuda_configure.bzl#L877genrules.append(_symlink_genrule_for_dir(repository_ctx, None, "",        "cudnn-include", [cudnn_header_dir + "/cudnn.h"], ["include/cudnn.h"]))togenrules.append(_symlink_genrule_for_dir(repository_ctx, None, "",        "cudnn-include", [cudnn_header_dir + "/cudnn.h"], ["cudnn.h"]))the build proceeds without errorSource code / logs____[107 / 393] Writing script external/local_config_cuda/cuda/cuda-include.genrule_script.sh [for host]ERROR: /scratch/momeara/.cache/baze/ef8339021629a8146b3e301bb7dc3099/external/local_config_cuda/cuda/BUILD:1309:1: Executing genrule @local_config_cuda//cuda:cudnn-include failed: bash failed: error executing command(cd /scratch/momeara/.cache/baze/ef8339021629a8146b3e301bb7dc3099/execroot/tensorflow && exec env - LD_LIBRARY_PATH=/mnt/nfs/work/momeara/sea/DeepSEA/cuda/lib64:/usr/local/cuda-7.5/lib64:/mnt/nfs/home/momeara/opt/lib:/mnt/nfs/home/momeara/opt/lib64:/usr/local/cuda-7.5/extras/CUPTI/lib64:/mnt/nfs/home/momeara/opt/lib:/mnt/nfs/home/momeara/opt/lib64 PATH=/usr/local/cuda-7.5/bin:/mnt/nfs/work/momeara/sea/DeepSEA/tensorflow/tensorflow/bazel-0.4.5/output:/mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/bin:/mnt/nfs/work/momeara/tools/anaconda2/bin:/mnt/nfs/home/momeara/.local/bin:/mnt/nfs/home/momeara/opt/node-v4.5.0-linux-x64/bin:/mnt/nfs/home/momeara/opt/bin:/mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/bin:/mnt/nfs/work/momeara/tools/anaconda2/bin:/mnt/nfs/home/momeara/.local/bin:/mnt/nfs/home/momeara/opt/node-v4.5.0-linux-x64/bin:/mnt/nfs/home/momeara/opt/bin:/mnt/nfs/work/momeara/tools/anaconda2/envs/sea16/bin:/mnt/nfs/work/momeara/tools/anaconda2/bin:/mnt/nfs/home/momeara/.local/bin:/mnt/nfs/home/momeara/opt/node-v4.5.0-linux-x64/bin:/mnt/nfs/home/momeara/opt/bin:/usr/lib64/qt-3.3/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/local/bin:/bin:/usr/bin /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh;ln -s /mnt/nfs/work/momeara/sea/DeepSEA/cuda/include/cudnn.h bazel-out/host/genfiles/external/local_config_cuda/cuda/include/include/cudnn.h    '): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.ln: creating symbolic link bazel-out/host/genfiles/external/local_config_cuda/cuda/include/include/cudnn.h': No such file or directory blaze: Leaving directory/scratch/momeara/.cache/baze/ef8339021629a8146b3e301bb7dc3099/execroot/tensorflow/'____Building complete.Target //tensorflow/tools/pip_package:build_pip_package failed to build____Elapsed time: 75.364s, Critical Path: 3.99s
buildinstall	bazel coverage build failureSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NOOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.12TensorFlow installed from (source or binary): sourceTensorFlow version (use command below):('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')Bazel version (if compiling from source): Build label:0.4.5Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jarBuild time: Thu Mar 16 12:50:12 2017 (1489668612)Build timestamp: 1489668612Build timestamp as int: 1489668612CUDA/cuDNN version: 7.0GPU model and memory: AMD Radeon R9 M370X 2048 MBExact command to reproduce:Describe the problemI'm trying to run bazel coverage on my Mac. But it fails to build.$ bazel coverage //tensorflow/tensorboard/backend/... --verbose_failuresor$ bazel build //tensorflow/tensorboard/backend/...   --verbose_failures  --collect_code_coverageIt returns error message like belowcom.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.ld: library not found for -lgcovclang: error: linker command failed with exit code 1 (use -v to see invocation)Is there any way to fix ld: library not found for -lgcov problem?Source code / logs$ bazel coverage //tensorflow/tensorboard/backend/... --verbose_failures..INFO: Using default value for --instrumentation_filter: "//tensorflow/tensorboard/backend".INFO: Override the above default with --instrumentation_filterINFO: Found 14 targets and 9 test targets...ERROR: /private/var/tmp/_bazel_Chris/b0f26c43826ae438107dcf403665fcf5/external/protobuf/BUILD:609:1: Linking of rule '@protobuf//:python/google/protobuf/internal/_api_implementation.so' failed: link_dynamic_library.sh failed: error executing command   (cd /private/var/tmp/_bazel_Chris/b0f26c43826ae438107dcf403665fcf5/execroot/tensorflow && \  exec env - \    CLANG_CUDA_COMPILER_PATH=/usr/bin/clang \    CUDA_TOOLKIT_PATH=/usr/local/cuda \    CUDNN_INSTALL_PATH=/usr/local/cuda \    PATH=/Users/Chris/.rvm/gems/ruby-2.0.0-p648/bin:/Users/Chris/.rvm/gems/ruby-2.0.0-p648@global/bin:/Users/Chris/.rvm/rubies/ruby-2.0.0-p648/bin:/Users/Chris/anaconda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/share/dotnet:/Library/TeX/texbin:/Users/Chris/.rvm/bin:/Users/Chris/.rvm/bin \    PYTHON_BIN_PATH=/Users/Chris/anaconda/bin/python \    PYTHON_LIB_PATH=/Users/Chris/anaconda/lib/python2.7/site-packages \    TF_CUDA_CLANG=1 \    TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2 \    TF_CUDA_VERSION='' \    TF_CUDNN_VERSION='' \    TF_NEED_CUDA=1 \    TF_NEED_OPENCL=0 \    TMPDIR=/var/folders/tr/tl261hjj2wl4662x8msxh6fm0000gn/T/ \  external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cc/cc_wrapper.sh -shared -o bazel-out/local-opt/bin/external/protobuf/python/google/protobuf/internal/_api_implementation.so -Wl,-force_load,bazel-out/local-opt/bin/external/protobuf/_objs/python/google/protobuf/internal/_api_implementation.so/external/protobuf/python/google/protobuf/internal/api_implementation.pic.o -lstdc++ -lm -undefined dynamic_lookup -headerpad_max_install_names -lgcov): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.ld: library not found for -lgcovclang: error: linker command failed with exit code 1 (use -v to see invocation)INFO: Elapsed time: 17.559s, Critical Path: 2.03s//tensorflow/tensorboard/backend/event_processing:directory_watcher_test NO STATUS//tensorflow/tensorboard/backend/event_processing:event_accumulator_test NO STATUS//tensorflow/tensorboard/backend/event_processing:event_file_inspector_test NO STATUS//tensorflow/tensorboard/backend/event_processing:event_file_loader_test NO STATUS//tensorflow/tensorboard/backend/event_processing:event_multiplexer_test NO STATUS//tensorflow/tensorboard/backend/event_processing:plugin_asset_util_test NO STATUS//tensorflow/tensorboard/backend/event_processing:reservoir_test      NO STATUS//tensorflow/tensorboard/backend:http_util_test                       NO STATUS//tensorflow/tensorboard/backend:json_util_test                       NO STATUSExecuted 0 out of 9 tests: 9 were skipped.$ bazel build //tensorflow/tensorboard/backend/...   --verbose_failures  --collect_code_coverageINFO: Found 23 targets...ERROR: /private/var/tmp/_bazel_Chris/b0f26c43826ae438107dcf403665fcf5/external/protobuf/BUILD:609:1: Linking of rule '@protobuf//:python/google/protobuf/internal/_api_implementation.so' failed: link_dynamic_library.sh failed: error executing command   (cd /private/var/tmp/_bazel_Chris/b0f26c43826ae438107dcf403665fcf5/execroot/tensorflow && \  exec env - \    CLANG_CUDA_COMPILER_PATH=/usr/bin/clang \    CUDA_TOOLKIT_PATH=/usr/local/cuda \    CUDNN_INSTALL_PATH=/usr/local/cuda \    PATH=/Users/Chris/.rvm/gems/ruby-2.0.0-p648/bin:/Users/Chris/.rvm/gems/ruby-2.0.0-p648@global/bin:/Users/Chris/.rvm/rubies/ruby-2.0.0-p648/bin:/Users/Chris/anaconda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/share/dotnet:/Library/TeX/texbin:/Users/Chris/.rvm/bin:/Users/Chris/.rvm/bin \    PYTHON_BIN_PATH=/Users/Chris/anaconda/bin/python \    PYTHON_LIB_PATH=/Users/Chris/anaconda/lib/python2.7/site-packages \    TF_CUDA_CLANG=1 \    TF_CUDA_COMPUTE_CAPABILITIES=3.5,5.2 \    TF_CUDA_VERSION='' \    TF_CUDNN_VERSION='' \    TF_NEED_CUDA=1 \    TF_NEED_OPENCL=0 \    TMPDIR=/var/folders/tr/tl261hjj2wl4662x8msxh6fm0000gn/T/ \  external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored external/local_config_cc/cc_wrapper.sh -shared -o bazel-out/local-opt/bin/external/protobuf/python/google/protobuf/internal/_api_implementation.so -Wl,-force_load,bazel-out/local-opt/bin/external/protobuf/_objs/python/google/protobuf/internal/_api_implementation.so/external/protobuf/python/google/protobuf/internal/api_implementation.pic.o -lstdc++ -lm -undefined dynamic_lookup -headerpad_max_install_names -lgcov): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.ld: library not found for -lgcovclang: error: linker command failed with exit code 1 (use -v to see invocation)
buildinstall	Fail to compile binary for AndroidIs there simple way to compile a native binary for inference on Android? Now I can successfully build the benchmark and run it on my Android device. But it does not contain any actions about ops. I want to do something similar to the benchmark_model_test but it fails to build. I think it now lacks a android version of //tensorflow/cc APIs. How can I tackle it?
buildinstall	Unsound GPU driver version scheme assumption in StringToDriverVersionTensorflow's cuda_diagnostics.cc here assumes that the GPU driver version will match %d.%d.%d but that doesn't seem to be a safe assumption.2017-05-04 09:48:39.543664: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: Invalid argument: expected %d.%d or %d.%d.%d form for driver version; got "378.05.05.05"In FindDsoVersion(), TF is parsing the name of the loaded libcuda library to get the version number, and the current Nvidia web driver library is:/Library/Frameworks/CUDA.framework/Versions/A/Libraries/libcuda_378.05.05.05_mercury.dylib
buildinstall	*tf_gen_op_libs* BUILD rule uses host toolchain even when crosstool wrappers are provided.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes. I have done the following changes.I pulled the tensorflow branch - v1.0.1An ugly hack to compile on Tegra X1 /w Jetpack 2.3.1 release. - Added this for trying to cross compile tensorflow on NVIDIA Jetson Tx1Modified BUILD.tpl and CROSSTOOL.tpl in third_party/gpus/crosstool/ for cross building for aarch64 as mentioned in Bazel build wiki for custom toolchainOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04.1 - x86_64TensorFlow installed from (source or binary):Trying to cross compile for NVIDIA Jetson TX1 from sourceTensorFlow version (use command below):v1.0.1 branchBazel version (if compiling from source):v 0.4.5CUDA/cuDNN version:CUDA - 8.0.34cuDNN - 5.1.5Exact command to reproduce:Problem descriptionI am trying to cross compile tensorflow with GPU support for NVIDIA Jetson TX1. I have setup the crosstool file for using the cross-build tools which I downloaded from the Linaro Website ( I followed the instructions from the bazel wiki on how to do so). My code compiles fine till it reaches the stage where the tf_gen_op_libs BUILD rule is reached (tensorflow/cc/BUILD:314). All of the ops mentioned in the rule fails to build. To be more precise, if fails in the linking stage with the following error /home/jetsontx1/Softwares/tensorflow/tensorflow/cc/BUILD:314:1: Couldn't build file tensorflow/cc/ops/no_op_gen_cc: Linking of rule '//tensorflow/cc:ops/no_op_gen_cc' failed: gcc failed: error executing command   (cd /home/jetsontx1/.cache/bazel/_bazel_jetsontx1/aebd32d6c3050c56aab9d4678f2e4fce/execroot/tensorflow && \  exec env - \    LD_LIBRARY_PATH=/usr/local/cuda-8.0/lib64: \    PATH=/usr/local/cuda-8.0/bin:/home/jetsontx1/bin:/home/jetsontx1/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \  /usr/bin/gcc -o bazel-out/host/bin/tensorflow/cc/ops/no_op_gen_cc -Lbazel-out/host/bin/_solib_k8/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib '-Wl,-rpath,$ORIGIN/../../../_solib_k8/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib' -pthread -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 '-fuse-ld=gold' -Wl,-no-as-needed -Wl,-z,relro,-z,now -B/usr/bin -B/usr/bin '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -pass-exit-codes -Wl,-S -Wl,--gc-sections -Wl,@bazel-out/host/bin/tensorflow/cc/ops/no_op_gen_cc-2.params): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1./usr/bin/ld.gold: fatal error: bazel-out/host/bin/_solib_k8/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib/libcudart.so.8.0: unsupported ELF machine number 183collect2: error: ld returned 1 exit statusSo what I don't understand is, I have specified my crosstool toolchain to build all the tensorflow libs. But it is using the host compiler (/usr/bin/gcc) for this particular stage alone. Shouldn't it use the wrapper I specified in the crosstool file?To put in another way - Why is the rule tf_gen_op_libs building the ops mentioned in the BUILD rule with the host compiler and not my crosstool? Is this a BUG?
buildinstall	ImportError: No module named tensorflowImportError                               Traceback (most recent call last) in ()1 import numpy----> 2 from keras.datasets import mnist3 from keras.models import Sequential4 from keras.layers import Dense5 from keras.layers import DropoutC:\Users\Dilip\Anaconda2\lib\site-packages\keras_init_.py in ()1 from future import absolute_import2----> 3 from . import activations4 from . import applications5 from . import backendC:\Users\Dilip\Anaconda2\lib\site-packages\keras\activations.py in ()2 import six3 import warnings----> 4 from . import backend as K5 from .utils.generic_utils import deserialize_keras_object6 from .engine import LayerC:\Users\Dilip\Anaconda2\lib\site-packages\keras\backend_init_.py in ()71 elif _BACKEND == 'tensorflow':72     sys.stderr.write('Using TensorFlow backend.\n')---> 73     from .tensorflow_backend import *74 else:75     raise ValueError('Unknown backend: ' + str(_BACKEND))C:\Users\Dilip\Anaconda2\lib\site-packages\keras\backend\tensorflow_backend.py in ()----> 1 import tensorflow as tf2 from tensorflow.python.training import moving_averages3 from tensorflow.python.ops import tensor_array_ops4 from tensorflow.python.ops import control_flow_ops5 from tensorflow.python.ops import functional_opsImportError: No module named tensorflow
buildinstall	Tensorflow build from sources failsSystem informationTensorflow build from TF 1.1 sources cloned from GIT fails.  This was working a couple of days ago on the same machine.OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04, kernel 4.4.0-75-genericHardware: Skylake server, nVidia P4TensorFlow installed from (source or binary):SourceTensorFlow version (use command below):I believe is 1.1-rc2 ... cannot get it from TF itself because unable to build in the first placeBazel version (if compiling from source):Build label: 0.4.5Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jarBuild time: Thu Mar 16 12:19:38 2017 (1489666778)Build timestamp: 1489666778Build timestamp as int: 1489666778CUDA/cuDNN version:CUDA 8.0cuDNN 5.1.10GPU model and memory:nVidia P4, 8GBExact command to reproduce:Followed exactly the steps to build from source from - https://www.tensorflow.org/versions/master/install/install_sourcesDid the following:./configure - used all defaults (see attached -configure_nocuda.txt)bazel build --verbose_failures --config=opt //tensorflow/tools/pip_package:build_pip_packageORbazel build --verbose_failures --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_packageBoth fail with the same issue (see below for the non cuda build)Output from the environment collection script is attached -tf_env.txtDescribe the problemBuild fails.  I have tried it with --config=cuda also - same issue.Source code / logsHere are the first couple of errorsSystem informationTensorflow build from TF 1.1 sources cloned from GIT fails.  This was working a couple of days ago on the same machine.OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04, kernel 4.4.0-75-genericHardware: Skylake server, nVidia P4TensorFlow installed from (source or binary):SourceTensorFlow version (use command below):I believe is 1.1-rc2 ... cannot get it from TF itself because unable to build in the first placeBazel version (if compiling from source):Build label: 0.4.5Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jarBuild time: Thu Mar 16 12:19:38 2017 (1489666778)Build timestamp: 1489666778Build timestamp as int: 1489666778CUDA/cuDNN version:CUDA 8.0cuDNN 5.1.10GPU model and memory:nVidia P4, 8GBExact command to reproduce:Followed exactly the steps to build from source from - https://www.tensorflow.org/versions/master/install/install_sourcesDid the following:./configure - used all defaults (see attached -configure_nocuda.txt)bazel build --verbose_failures --config=opt //tensorflow/tools/pip_package:build_pip_packageORbazel build --verbose_failures --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_packageBoth fail with the same issue (see below for the non cuda build)Output from the environment collection script is attached -tf_env.txtDescribe the problemBuild fails.  I have tried it with --config=cuda also - same issue.Source code / logsHere are the first couple of errors in bold from a non-cuda build (compete build log is attached -tf_build_nocuda.txt):ERROR: /home/rajka/tensorflow/tensorflow/core/kernels/BUILD:2093:1: C++ compilation of rule '//tensorflow/core/kernels:self_adjoint_eig_v2_op' failed: gcc failed: error executing command(cd /home/rajka/.cache/bazel/bazel_rajka/28f0a9835f793d5627ca9486394f31f2/execroot/tensorflow && exec env - PYTHON_BIN_PATH=/usr/bin/python PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages TF_NEED_CUDA=0 TF_NEED_OPENCL=0 /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-march=native' '-std=c++0x' '-march=native' '-march=native' -MD -MF bazel-out/local-opt/bin/tensorflow/core/kernels/objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.d '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/kernels/objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -DSNAPPY -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/jemalloc -iquote bazel-out/local-opt/genfiles/external/jemalloc -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/protobuf -iquote bazel-out/local-opt/genfiles/external/protobuf -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local-opt/genfiles/external/snappy -isystem external/jemalloc/include -isystem bazel-out/local-opt/genfiles/external/jemalloc/include -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/protobuf/src -isystem bazel-out/local-opt/genfiles/external/protobuf/src -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local-opt/genfiles/external/zlib_archive -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions -msse3 -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE="redacted"' '-D__TIMESTAMP_="redacted"' '-D__TIME__="redacted"' -c tensorflow/core/kernels/self_adjoint_eig_v2_op.cc -o bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.... snip snip ...tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from hereexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:63:74: error: no type named 'ReturnType' in 'struct Eigen::ScalarBinaryOpTraits<__vector(8) double, std::complex, Eigen::internal::scalar_product_op<__vector(8) double, std::complex > >'typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;^In file included from external/eigen_archive/Eigen/Jacobi:27:0,from external/eigen_archive/Eigen/Eigenvalues:16,from ./third_party/eigen3/Eigen/Eigenvalues:1,from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:19:external/eigen_archive/Eigen/src/Jacobi/Jacobi.h: In instantiation of 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase&, Eigen::DenseBase&, const Eigen::JacobiRotation&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = double]':external/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation&) [with OtherScalar = double; Derived = Eigen::Map<Eigen::Matrix<std::complex, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'external/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = double; Scalar = std::complex; Index = long int]'external/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex, -1, -1>; DiagType = Eigen::Matrix<double, -1, 1>; SubDiagType = Eigen::Matrix<double, -1, 1>; Eigen::Index = long int]'external/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>]'external/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>]'tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op::MatrixMaps*) [with Scalar = std::complex; tensorflow::SelfAdjointEigV2Op::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from hereexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex, false, false>' has no member named 'pmul'pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));^external/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex, false, false>' has no member named 'pmul'in bold from a non-cuda build (compete build log is attached -tf_build_nocuda.txt):ERROR: /home/rajka/tensorflow/tensorflow/core/kernels/BUILD:2093:1: C++ compilation of rule '//tensorflow/core/kernels:self_adjoint_eig_v2_op' failed: gcc failed: error executing command(cd /home/rajka/.cache/bazel/bazel_rajka/28f0a9835f793d5627ca9486394f31f2/execroot/tensorflow && exec env - PYTHON_BIN_PATH=/usr/bin/python PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages TF_NEED_CUDA=0 TF_NEED_OPENCL=0 /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-march=native' '-std=c++0x' '-march=native' '-march=native' -MD -MF bazel-out/local-opt/bin/tensorflow/core/kernels/objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.d '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/kernels/objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.o' -fPIC -DEIGEN_MPL2_ONLY -DTENSORFLOW_USE_JEMALLOC -DSNAPPY -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/jemalloc -iquote bazel-out/local-opt/genfiles/external/jemalloc -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/protobuf -iquote bazel-out/local-opt/genfiles/external/protobuf -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-opt/genfiles/external/local_config_sycl -iquote external/gif_archive -iquote bazel-out/local-opt/genfiles/external/gif_archive -iquote external/jpeg -iquote bazel-out/local-opt/genfiles/external/jpeg -iquote external/com_googlesource_code_re2 -iquote bazel-out/local-opt/genfiles/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/local-opt/genfiles/external/farmhash_archive -iquote external/fft2d -iquote bazel-out/local-opt/genfiles/external/fft2d -iquote external/highwayhash -iquote bazel-out/local-opt/genfiles/external/highwayhash -iquote external/png_archive -iquote bazel-out/local-opt/genfiles/external/png_archive -iquote external/zlib_archive -iquote bazel-out/local-opt/genfiles/external/zlib_archive -iquote external/snappy -iquote bazel-out/local-opt/genfiles/external/snappy -isystem external/jemalloc/include -isystem bazel-out/local-opt/genfiles/external/jemalloc/include -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/protobuf/src -isystem bazel-out/local-opt/genfiles/external/protobuf/src -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive -isystem external/gif_archive/lib -isystem bazel-out/local-opt/genfiles/external/gif_archive/lib -isystem external/farmhash_archive/src -isystem bazel-out/local-opt/genfiles/external/farmhash_archive/src -isystem external/png_archive -isystem bazel-out/local-opt/genfiles/external/png_archive -isystem external/zlib_archive -isystem bazel-out/local-opt/genfiles/external/zlib_archive -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions -msse3 -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE="redacted"' '-D__TIMESTAMP_="redacted"' '-D__TIME__="redacted"' -c tensorflow/core/kernels/self_adjoint_eig_v2_op.cc -o bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/self_adjoint_eig_v2_op/tensorflow/core/kernels/self_adjoint_eig_v2_op.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.... snip snip ...tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from hereexternal/eigen_archive/Eigen/src/Core/util/BlasUtil.h:63:74: error: no type named 'ReturnType' in 'struct Eigen::ScalarBinaryOpTraits<__vector(8) double, std::complex, Eigen::internal::scalar_product_op<__vector(8) double, std::complex > >'typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;^In file included from external/eigen_archive/Eigen/Jacobi:27:0,from external/eigen_archive/Eigen/Eigenvalues:16,from ./third_party/eigen3/Eigen/Eigenvalues:1,from tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:19:external/eigen_archive/Eigen/src/Jacobi/Jacobi.h: In instantiation of 'void Eigen::internal::apply_rotation_in_the_plane(Eigen::DenseBase&, Eigen::DenseBase&, const Eigen::JacobiRotation&) [with VectorX = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; VectorY = Eigen::Block<Eigen::Map<Eigen::Matrix<std::complex, -1, -1>, 0, Eigen::Stride<0, 0> >, -1, 1, true>; OtherScalar = double]':external/eigen_archive/Eigen/src/Jacobi/Jacobi.h:297:40:   required from 'void Eigen::MatrixBase::applyOnTheRight(Eigen::Index, Eigen::Index, const Eigen::JacobiRotation&) [with OtherScalar = double; Derived = Eigen::Map<Eigen::Matrix<std::complex, -1, -1>, 0, Eigen::Stride<0, 0> >; Eigen::Index = long int]'external/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:861:7:   required from 'void Eigen::internal::tridiagonal_qr_step(RealScalar*, RealScalar*, Index, Index, Scalar*, Index) [with int StorageOrder = 0; RealScalar = double; Scalar = std::complex; Index = long int]'external/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:520:87:   required from 'Eigen::ComputationInfo Eigen::internal::computeFromTridiagonal_impl(DiagType&, SubDiagType&, Eigen::Index, bool, MatrixType&) [with MatrixType = Eigen::Matrix<std::complex, -1, -1>; DiagType = Eigen::Matrix<double, -1, 1>; SubDiagType = Eigen::Matrix<double, -1, 1>; Eigen::Index = long int]'external/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:439:49:   required from 'Eigen::SelfAdjointEigenSolver& Eigen::SelfAdjointEigenSolver<_MatrixType>::compute(const Eigen::EigenBase&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>]'external/eigen_archive/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h:168:14:   required from 'Eigen::SelfAdjointEigenSolver<_MatrixType>::SelfAdjointEigenSolver(const Eigen::EigenBase&, int) [with InputType = Eigen::Map<const Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >; _MatrixType = Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>]'tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:66:73:   required from 'void tensorflow::SelfAdjointEigV2Op::ComputeMatrix(tensorflow::OpKernelContext*, const ConstMatrixMaps&, tensorflow::SelfAdjointEigV2Op::MatrixMaps*) [with Scalar = std::complex; tensorflow::SelfAdjointEigV2Op::ConstMatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<const Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>; tensorflow::SelfAdjointEigV2Op::MatrixMaps = tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<std::complex, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>]'tensorflow/core/kernels/self_adjoint_eig_v2_op.cc:95:1:   required from hereexternal/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex, false, false>' has no member named 'pmul'pstore(px, padd(pm.pmul(pc,xi),pcj.pmul(ps,yi)));^external/eigen_archive/Eigen/src/Jacobi/Jacobi.h:359:24: error: 'struct Eigen::internal::conj_helper<__vector(8) double, std::complex, false, false>' has no member named 'pmul'
buildinstall	Installation instructions for conda install tensorflow in the root environmentThe instructions say tocreate a new empty environmentactivate itinstall tensorflow via pip.But pip is not installed in the new environment, so the third command will call the first pip inside the PATH system variable, that usually is the pip installed in the root conda environment. The ultimate result is that tensorflow is installed in the root environment.To solve this issue, it's sufficient to install pip in the new environment:conda create --name tensorflow pip
buildinstall	pkg-config file generationHi! I was wondering if a pkg-config file for the tensorflow library (libtensorflow.so) could be added so that depending projects could use it more easily.For the current stable version (1.1.0), if we installed it into /usr (which should be configurable), the generated pkg-config file tensorflow.pc should look something like:prefix=/usrexec_prefix=${prefix}libdir=${exec_prefix}/libincludedir=${prefix}/includemodules=1Name: tensorflowVersion: 1.1.0Description: Library for computation using data flow graphs for scalable machine learningRequires:Libs: -L${libdir} -ltensorflow -lstdc++Cflags: -I${includedir}/tensorflowThanks in advance :)
buildinstall	compile error C2064 when I use cmake(vs2015) to make windows binaryI follows the instructions (https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake  ) to compile the tensorflow in windows ( compiler vs2015)I usecmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=D:/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE="D:/Program Files/Python 3.5/python.exe" -DPYTHON_LIBRARIES="D:/Program Files/Python 3.5/libs/python35.lib" -Dtensorflow_ENABLE_GPU=OFF -Dtensorflow_ENABLE_GRPC_SUPPORT=OFF  -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVXto generate project files.after: MSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxprojit complains following :[in Chinese , the cl output]h:\tensorflow_c\tensorflow-1.1.0\tensorflow\core\lib\gtl\array_slice_internal.h(89): error C2064: 项不会计算为接受 0 个参数的函数 (编译源文件 H:\tensorflow_c\tensorflow-1.1.0\tensorflow\core\lib\strings\str_util.cc) [H:\tensorflow_c\tensorflow-1.1.0\tensorflow\contrib\cmake\build_vc\tf_core_lib.vcxproj][in English ]h:\tensorflow_c\tensorflow-1.1.0\tensorflow\core\lib\gtl\array_slice_internal.h(89): error C2064: term does not evaluate to a function taking 0 arguments ( compiling  H:\tensorflow_c\tensorflow-1.1.0\tensorflow\core\lib\strings\str_util.cc) [H:\tensorflow_c\tensorflow-1.1.0\tensorflow\contrib\cmake\build_vc\tf_core_lib.vcxproj]
buildinstall	How to know which will be supported wheel for my platform? (Installing Tensorflow)C:\Users\Sudhit>pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.1.0-cp35-cp35m-win_amd64.whltensorflow-1.1.0-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.how will I know which will be supported wheel for my platform?
buildinstall	Import errorsSystem informationTrying to run tutorial codeWin8.1pip3 install --upgrade tensorflowcan't run programm to write version (can't run any code with import tensorflow)Traceback (most recent call last):File "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 18, in swig_import_helperfp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(file)])File "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\imp.py", line 296, in find_moduleraise ImportError(_ERR_MSG.format(name), name=name)ImportError: No module named '_pywrap_tensorflow'During handling of the above exception, another exception occurred:Traceback (most recent call last):File "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\site-packages\tensorflow\python_init_.py", line 54, in from tensorflow.python import pywrap_tensorflowFile "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 28, in _pywrap_tensorflow = swig_import_helper()File "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 20, in swig_import_helperimport _pywrap_tensorflowImportError: No module named '_pywrap_tensorflow'During handling of the above exception, another exception occurred:Traceback (most recent call last):File "C:/Users/home-pc/PycharmProjects/untitled6/b.py", line 1, in import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)File "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\site-packages\tensorflow_init_.py", line 24, in from tensorflow.python import *File "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\site-packages\tensorflow\python_init_.py", line 60, in raise ImportError(msg)ImportError: Traceback (most recent call last):File "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 18, in swig_import_helperfp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(file)])File "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\imp.py", line 296, in find_moduleraise ImportError(_ERR_MSG.format(name), name=name)ImportError: No module named '_pywrap_tensorflow'During handling of the above exception, another exception occurred:Traceback (most recent call last):File "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\site-packages\tensorflow\python_init_.py", line 54, in from tensorflow.python import pywrap_tensorflowFile "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 28, in _pywrap_tensorflow = swig_import_helper()File "C:\Users\home-pc\AppData\Local\Programs\Python\Python35-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 20, in swig_import_helperimport _pywrap_tensorflowImportError: No module named '_pywrap_tensorflow'Error importing tensorflow.  Unless you are using bazel,you should not try to import tensorflow from its source directory;please exit the tensorflow source tree, and relaunch your python interpreterfrom there.
buildinstall	Error code 1 : While installing TensorFlow on windows 10 with pipI was trying to install TensorFlow  on windows 10 with pipWhen I type :pip3 install tensorflowI get the following error :ImportError : cannot import name 'setup'Command "python setup.py egg_info" failed with error code 1 in C:\Users\Dell\AppData\Local\Temp\pip-build-qzzubrm_\protobuf\
buildinstall	404 Error When Installing 1.1.0 GPU Python 3.x versionHTTP error 404 while getting https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl  Could not install requirement tensorflow-gpu==1.1.0 from https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl because of error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whlCould not install requirement tensorflow-gpu==1.1.0 from https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl because of HTTP error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whl for URL https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow_gpu-1.1.0-py3-none-any.whlRan same command to successfully install version 1.0.0 GPU py3. I thought this would be the best place to bring it to the Google team's attention, but let me know if not!
buildinstall	building error, tensorflow r1.0, with bazel 0.4.5, Ubuntu 16.04.1 LTS armv7 boardUpdate from #9632, @andydavis1 suggest upgrading to 1.1, but it seems to be worse:odroid@odroid:~/local_DT_project/tensorflow_git$ git checkout r1.1Branch r1.1 set up to track remote branch r1.1 from origin.Switched to a new branch 'r1.1'odroid@odroid:~/local_DT_project/tensorflow_git$ ./configurePlease specify the location of python. [Default is /usr/bin/python]:Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]:Do you wish to use jemalloc as the malloc implementation? [Y/n]jemalloc enabledDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]No Google Cloud Platform support will be enabled for TensorFlowDo you wish to build TensorFlow with Hadoop File System support? [y/N]No Hadoop File System support will be enabled for TensorFlowDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]No XLA support will be enabled for TensorFlowFound possible Python library paths:  /usr/local/lib/python2.7/dist-packages  /usr/lib/python2.7/dist-packagesPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]Using python library path: /usr/local/lib/python2.7/dist-packagesDo you wish to build TensorFlow with OpenCL support? [y/N]No OpenCL support will be enabled for TensorFlow Do you wish to build TensorFlow with CUDA support? [y/N]No CUDA support will be enabled for TensorFlow   Configuration finished......................................................................................................INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes......................................................................................................ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_dialog//': Error downloading [https://github.com/polymerelements/paper-dialog/archive/v1.0.4.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_dialog/v1.0.4.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_form_element_behavior//': Error downloading [https://github.com/polymerelements/iron-form-element-behavior/archive/v1.0.6.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_form_element_behavior/v1.0.6.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_collapse//': Error downloading [https://github.com/polymerelements/iron-collapse/archive/v1.0.8.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_collapse/v1.0.8.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_fit_behavior//': Error downloading [https://github.com/polymerelements/iron-fit-behavior/archive/v1.2.5.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_fit_behavior/v1.2.5.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_flex_layout//': Error downloading [https://github.com/polymerelements/iron-flex-layout/archive/v1.3.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_flex_layout/v1.3.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_dropdown//': Error downloading [https://github.com/polymerelements/iron-dropdown/archive/v1.4.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_dropdown/v1.4.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_checked_element_behavior//': Error downloading [https://github.com/polymerelements/iron-checked-element-behavior/archive/v1.0.4.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_checked_element_behavior/v1.0.4.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_behaviors//': Error downloading [https://github.com/polymerelements/iron-behaviors/archive/v1.0.17.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_behaviors/v1.0.17.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_autogrow_textarea//': Error downloading [https://github.com/polymerelements/iron-autogrow-textarea/archive/v1.0.12.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_autogrow_textarea/v1.0.12.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.  ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_ajax//': Error downloading [https://github.com/polymerelements/iron-ajax/archive/v1.2.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_ajax/v1.2.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@dagre//': Error downloading [https://github.com/cpettitt/dagre/archive/v0.7.4.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/dagre/v0.7.4.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@font_roboto//': Error downloading [https://github.com/polymerelements/font-roboto/archive/v1.0.1.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/font_roboto/v1.0.1.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_a11y_keys_behavior//': Error downloading [https://github.com/polymerelements/iron-a11y-keys-behavior/archive/v1.1.8.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_a11y_keys_behavior/v1.1.8.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'. ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_a11y_announcer//': Error downloading [https://github.com/polymerelements/iron-a11y-announcer/archive/v1.0.5.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_a11y_announcer/v1.0.5.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@graphlib//': Error downloading [https://github.com/cpettitt/graphlib/archive/v1.0.7.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/graphlib/v1.0.7.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@es6_promise//': Error downloading [https://github.com/components/es6-promise/archive/v2.1.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/es6_promise/v2.1.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@d3//': Error downloading [https://github.com/mbostock-bower/d3-bower/archive/v3.5.15.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/d3/v3.5.15.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@three_js_orbitcontrols_js//file': Error downloading [https://raw.githubusercontent.com/mrdoob/three.js/r77/examples/js/controls/OrbitControls.js] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/three_js_orbitcontrols_js/OrbitControls.js: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@web_animations_js//': Error downloading [https://github.com/web-animations/web-animations-js/archive/2.2.1.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/web_animations_js/2.2.1.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@weblas_weblas_js//file': Error downloading [https://raw.githubusercontent.com/waylonflinn/weblas/v0.9.0/dist/weblas.js] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/weblas_weblas_js/weblas.js: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@webcomponentsjs//': Error downloading [https://github.com/webcomponents/webcomponentsjs/archive/v0.7.22.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/webcomponentsjs/v0.7.22.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@three_js_three_min_js//file': Error downloading [https://raw.githubusercontent.com/mrdoob/three.js/r77/build/three.min.js] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/three_js_three_min_js/three.min.js: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@promise_polyfill//': Error downloading [https://github.com/polymerlabs/promise-polyfill/archive/v1.0.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/promise_polyfill/v1.0.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@polymer//': Error downloading [https://github.com/polymer/polymer/archive/v1.7.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/polymer/v1.7.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@plottable//': Error downloading [https://github.com/palantir/plottable/archive/v1.16.1.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/plottable/v1.16.1.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_tooltip//': Error downloading [https://github.com/polymerelements/paper-tooltip/archive/v1.1.2.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_tooltip/v1.1.2.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_toolbar//': Error downloading [https://github.com/polymerelements/paper-toolbar/archive/v1.1.4.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_toolbar/v1.1.4.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_toggle_button//': Error downloading [https://github.com/polymerelements/paper-toggle-button/archive/v1.2.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_toggle_button/v1.2.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_toast//': Error downloading [https://github.com/polymerelements/paper-toast/archive/v1.3.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_toast/v1.3.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_tabs//': Error downloading [https://github.com/polymerelements/paper-tabs/archive/v1.7.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_tabs/v1.7.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_styles//': Error downloading [https://github.com/polymerelements/paper-styles/archive/v1.1.4.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_styles/v1.1.4.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_toggle_button//': Error downloading [https://github.com/polymerelements/paper-toggle-button/archive/v1.2.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_toggle_button/v1.2.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_toast//': Error downloading [https://github.com/polymerelements/paper-toast/archive/v1.3.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_toast/v1.3.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_tabs//': Error downloading [https://github.com/polymerelements/paper-tabs/archive/v1.7.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_tabs/v1.7.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_styles//': Error downloading [https://github.com/polymerelements/paper-styles/archive/v1.1.4.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_styles/v1.1.4.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_spinner//': Error downloading [https://github.com/polymerelements/paper-spinner/archive/v1.1.1.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_spinner/v1.1.1.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_slider//': Error downloading [https://github.com/polymerelements/paper-slider/archive/v1.0.10.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_slider/v1.0.10.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_ripple//': Error downloading [https://github.com/polymerelements/paper-ripple/archive/v1.0.5.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_ripple/v1.0.5.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_radio_group//': Error downloading [https://github.com/polymerelements/paper-radio-group/archive/v1.0.9.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_radio_group/v1.0.9.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_radio_button//': Error downloading [https://github.com/polymerelements/paper-radio-button/archive/v1.1.2.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_radio_button/v1.1.2.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_progress//': Error downloading [https://github.com/polymerelements/paper-progress/archive/v1.0.9.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_progress/v1.0.9.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_menu_button//': Error downloading [https://github.com/polymerelements/paper-menu-button/archive/v1.5.1.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_menu_button/v1.5.1.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_menu//': Error downloading [https://github.com/polymerelements/paper-menu/archive/v1.2.2.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_menu/v1.2.2.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_material//': Error downloading [https://github.com/polymerelements/paper-material/archive/v1.0.6.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_material/v1.0.6.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_listbox//': Error downloading [https://github.com/polymerelements/paper-listbox/archive/v1.1.2.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_listbox/v1.1.2.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_item//': Error downloading [https://github.com/polymerelements/paper-item/archive/v1.1.4.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_item/v1.1.4.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_input//': Error downloading [https://github.com/polymerelements/paper-input/archive/v1.1.18.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_input/v1.1.18.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_icon_button//': Error downloading [https://github.com/polymerelements/paper-icon-button/archive/v1.1.3.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_icon_button/v1.1.3.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_header_panel//': Error downloading [https://github.com/polymerelements/paper-header-panel/archive/v1.1.4.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_header_panel/v1.1.4.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_dropdown_menu//': Error downloading [https://github.com/polymerelements/paper-dropdown-menu/archive/v1.4.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_dropdown_menu/v1.4.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_dialog_behavior//': Error downloading [https://github.com/polymerelements/paper-dialog-behavior/archive/v1.2.5.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_dialog_behavior/v1.2.5.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_dialog//': Error downloading [https://github.com/polymerelements/paper-dialog/archive/v1.0.4.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_dialog/v1.0.4.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_checkbox//': Error downloading [https://github.com/polymerelements/paper-checkbox/archive/v1.4.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_checkbox/v1.4.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_button//': Error downloading [https://github.com/polymerelements/paper-button/archive/v1.0.11.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_button/v1.0.11.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@paper_behaviors//': Error downloading [https://github.com/polymerelements/paper-behaviors/archive/v1.0.12.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/paper_behaviors/v1.0.12.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@numericjs_numeric_min_js//file': Error downloading [https://cdnjs.cloudflare.com/ajax/libs/numeric/1.2.6/numeric.min.js] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/numericjs_numeric_min_js/numeric.min.js: sun.security.validator.ValidatorException: PKIX path validation failed: java.security.cert.CertPathValidatorException: signature check failed and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@neon_animation//': Error downloading [https://github.com/polymerelements/neon-animation/archive/v1.2.2.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/neon_animation/v1.2.2.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@lodash//': Error downloading [https://github.com/lodash/lodash/archive/3.8.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/lodash/3.8.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_validatable_behavior//': Error downloading [https://github.com/polymerelements/iron-validatable-behavior/archive/v1.1.1.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_validatable_behavior/v1.1.1.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_selector//': Error downloading [https://github.com/polymerelements/iron-selector/archive/v1.5.2.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_selector/v1.5.2.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_scroll_target_behavior//': Error downloading [https://github.com/polymerelements/iron-scroll-target-behavior/archive/v1.0.3.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_scroll_target_behavior/v1.0.3.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_resizable_behavior//': Error downloading [https://github.com/polymerelements/iron-resizable-behavior/archive/v1.0.3.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_resizable_behavior/v1.0.3.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'. ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_range_behavior//': Error downloading [https://github.com/polymerelements/iron-range-behavior/archive/v1.0.4.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_range_behavior/v1.0.4.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_overlay_behavior//': Error downloading [https://github.com/polymerelements/iron-overlay-behavior/archive/v1.10.1.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_overlay_behavior/v1.10.1.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_meta//': Error downloading [https://github.com/polymerelements/iron-meta/archive/v1.1.1.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_meta/v1.1.1.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_menu_behavior//': Error downloading [https://github.com/polymerelements/iron-menu-behavior/archive/v1.1.10.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_menu_behavior/v1.1.10.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_list//': Error downloading [https://github.com/polymerelements/iron-list/archive/v1.3.9.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_list/v1.3.9.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_input//': Error downloading [https://github.com/polymerelements/iron-input/archive/1.0.10.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_input/1.0.10.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_iconset_svg//': Error downloading [https://github.com/polymerelements/iron-iconset-svg/archive/v1.1.0.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_iconset_svg/v1.1.0.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_icons//': Error downloading [https://github.com/polymerelements/iron-icons/archive/v1.1.3.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_icons/v1.1.3.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: /home/odroid/local_DT_project/tensorflow_git/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_icon//': Error downloading [https://github.com/polymerelements/iron-icon/archive/v1.0.11.tar.gz] to /home/odroid/.cache/bazel/_bazel_odroid/d841288b9ad4d0fda5b62853b4d2dddc/external/iron_icon/v1.0.11.tar.gz: java.lang.IllegalStateException and referenced by '//tensorflow/tensorboard/bower:bower'.ERROR: Evaluation of query "deps(((//tensorflow/... - //tensorflow/contrib/nccl/...) - //tensorflow/examples/android/...))" failed: errors were encountered while computing transitive closure.Any help will be appreciated.
buildinstall	contrib/verbs causes compile error on masterRecently merged RDMA-supporting feature is based on r1.0, and incompatible with the latest master.ERROR: /data/chuangchen/workspace/tensorflow/tensorflow/contrib/verbs/BUILD:104:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma_rendezvous_mgr' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 151 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.tensorflow/contrib/verbs/rdma_rendezvous_mgr.cc: In constructor 'tensorflow::RdmaRemoteRendezvous::RdmaRemoteRendezvous(const tensorflow::WorkerEnv*, tensorflow::int64, tensorflow::RdmaMgr*)':tensorflow/contrib/verbs/rdma_rendezvous_mgr.cc:34:35: error: 'worker_name' was not declared in this scope: BaseRemoteRendezvous(env, worker_name, step_id, true),^tensorflow/contrib/verbs/rdma_rendezvous_mgr.cc: In constructor 'tensorflow::RdmaRendezvousMgr::RdmaRendezvousMgr(const tensorflow::WorkerEnv*, const string&, tensorflow::WorkerCacheInterface*)':tensorflow/contrib/verbs/rdma_rendezvous_mgr.cc:139:41: error: no matching function for call to 'tensorflow::BaseRendezvousMgr::BaseRendezvousMgr(const tensorflow::WorkerEnv*&, const string&)': BaseRendezvousMgr(env, worker_name) {}^tensorflow/contrib/verbs/rdma_rendezvous_mgr.cc:139:41: note: candidate is:In file included from ./tensorflow/contrib/verbs/rdma_rendezvous_mgr.h:22:0,from tensorflow/contrib/verbs/rdma_rendezvous_mgr.cc:18:./tensorflow/core/distributed_runtime/base_rendezvous_mgr.h:62:12: note: tensorflow::BaseRendezvousMgr::BaseRendezvousMgr(const tensorflow::WorkerEnv*)explicit BaseRendezvousMgr(const WorkerEnv* worker_env);^./tensorflow/core/distributed_runtime/base_rendezvous_mgr.h:62:12: note:   candidate expects 1 argument, 2 providedTarget //tensorflow/tools/pip_package:build_pip_package failed to buildUse --verbose_failures to see the command lines of failed build steps.
buildinstall	Bazel unable to build on Jetson TX1 with --config=cuda option?System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 LTSTensorFlow installed from (source or binary): sourceTensorFlow version (use command below): 1.1 (latest master)Bazel version (if compiling from source): 0.4.5CUDA/cuDNN version: 8.0/5.1GPU model and memory: Tegra X1Exact command to reproduce:bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_packageDescribe the problemUsing the bazel build command above, I am unable to find a valid toolchain to support the aarch64 architecture in the Jetson TX1. However, by removing the --config=cuda option, the error is gone, although I am still unable to finish building the pip file (probably due to the fact that I configured TF for GPU using ./configure).Note: I changed the bazel files as seen in this guide: http://zhiyisun.github.io/2017/02/15/Running-Google-Machine-Learning-Library-Tensorflow-On-ARM-64-bit-Platform.html , in order to get bazel to build for aarch64.Is there anything more that I have to change? using the suggested command of bazel build -c opt --copt="-funsafe-math-optimizations" --copt="-ftree-vectorize" --copt="-fomit-frame-pointer" --verbose_failures tensorflow/tools/pip_package:build_pip_package I get the same error too.I saw this issue over here: bazelbuild/bazel#1855and it says it has something related to the cuda crosstool. Is there a way to fix this to configure TensorFlow-GPU on the Jetson TX1?Thank you for your help. :DSource code / logsHere is the error I got:ubuntu@tegra-ubuntu:~/tensorflow$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_packageWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.ERROR: No toolchain found for cpu 'aarch64'. Valid cpus are: [  k8,  piii,  arm,  darwin,  ppc,].INFO: Elapsed time: 1.589s
buildinstall	how to call AttentionWrapper?I am trying to write a simple seq2seq model with attention. But  it gets the following error:attn_cell = tf.contrib.seq2seq.AttentionWrapper(AttributeError: 'module' object has no attribute 'AttentionWrapper'How should I call AttentionWrapper?Here is my code:    T=1000    N=100    input = tf.placeholder(tf.float32, shape=(N, T, 512), name="input_matrix")    seq_lengths = tf.placeholder(tf.int32, shape=(N), name="input_lengths")    cell= MultiRNNCell([DeviceWrapper(ResidualWrapper(LSTMCell(num_units=512)),device='/gpu:%d' %(i+1)) for i in range(2)])    encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(cell,input, parallel_iterations=32, swap_memory=True, dtype=tf.float32)    # Attention Mechanisms. Bahdanau is additive style attention    attn_mech = tf.contrib.seq2seq.BahdanauAttention(        num_units = 100, # depth of query mechanism        memory = encoder_outputs, # hidden states to attend (output of RNN)        #memory_sequence_length= T,#tf.sequence_mask(seq_lengths, T), # masks false memories        normalize=False, # normalize energy term        name='BahdanauAttention')    cell_out= MultiRNNCell([DeviceWrapper(ResidualWrapper(LSTMCell(num_units=512)),device='/gpu:%d' %(i+1)) for i in range(2)])        # Attention Wrapper: adds the attention mechanism to the cell    # Attention Wrapper: adds the attention mechanism to the cell    attn_cell = tf.contrib.seq2seq.AttentionWrapper(        cell = cell,# Instance of RNNCell        attention_mechanism = attn_mech, # Instance of AttentionMechanism        attention_size = 100, # Int, depth of attention (output) tensor        attention_history=False, # whether to store history in final output        name="attention_wrapper")     # TrainingHelper does no sampling, only uses inputs    helper = tf.contrib.seq2seq.TrainingHelper(        inputs = x, # decoder inputs        sequence_length = seq_len_dec, # decoder input length        name = "decoder_training_helper")     # Decoder setup    decoder = tf.contrib.seq2seq.BasicDecoder(              cell = attn_cell,              helper = helper, # A Helper instance              initial_state = encoder_final_state, # initial state of decoder              output_layer = None) # instance of tf.layers.Layer, like Dense     # Perform dynamic decoding with decoder object    outputs, final_state = tf.contrib.seq2seq.dynamic_decode(decoder)
buildinstall	Tensorflow worked and now suddenly giving errors ?Hello,I was able to run tensorflow (both CPU and GPU) without issues yesterday. Today, after restarting my laptop, I get the below error as I tried running Tensorflow.I have previously checked that my path variables were set properly and only then Tensorflow worked, but I'm not sure how it suddenly isn't working.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):YesOS Platform and Distribution (e.g., Linux Ubuntu 16.04):OS = Windows 10TensorFlow installed from (source or binary):*Installed from SourceTensorFlow version (use command below):*When I ran =>  python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"*I get only this result =>  b'unknown' 1.0.0Bazel version (if compiling from source):*I'm unsure about this as I don't remember installing thisCUDA/cuDNN version:*cuda_8.0.61_win10*cuDNN v5.1 (Jan 20, 2017), for CUDA 8.0GPU model and memory:*GeForce GTX 1050 graphics card*RAM 32GBExact command to reproduce:*import tensorflow as tfError code I got:ImportError                               Traceback (most recent call last)C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()17         try:---> 18             return importlib.import_module(mname)19         except ImportError:C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_init_.py in import_module(name, package)125             level += 1--> 126     return _bootstrap._gcd_import(name[level:], package, level)127C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_bootstrap.py in _gcd_import(name, package, level)C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_bootstrap.py in find_and_load(name, import)C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_bootstrap.py in find_and_load_unlocked(name, import)C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_bootstrap.py in _load_unlocked(spec)C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_bootstrap.py in module_from_spec(spec)C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_bootstrap_external.py in create_module(self, spec)C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)ImportError: DLL load failed: The specified module could not be found.During handling of the above exception, another exception occurred:ImportError                               Traceback (most recent call last)C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in ()40     sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)---> 41   from tensorflow.python.pywrap_tensorflow_internal import *42   from tensorflow.python.pywrap_tensorflow_internal import versionC:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in ()20             return importlib.import_module('_pywrap_tensorflow_internal')---> 21     _pywrap_tensorflow_internal = swig_import_helper()22     del swig_import_helperC:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()19         except ImportError:---> 20             return importlib.import_module('_pywrap_tensorflow_internal')21     _pywrap_tensorflow_internal = swig_import_helper()C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_init_.py in import_module(name, package)125             level += 1--> 126     return _bootstrap._gcd_import(name[level:], package, level)127ImportError: No module named '_pywrap_tensorflow_internal'During handling of the above exception, another exception occurred:ImportError                               Traceback (most recent call last) in ()----> 1 import tensorflow as tf2 import numpy as np34 IM_SIZE_PX = 505 SLICE_COUNT = 20C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow_init_.py in ()2223 # pylint: disable=wildcard-import---> 24 from tensorflow.python import *25 # pylint: enable=wildcard-import26C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python_init_.py in ()49 import numpy as np50---> 51 from tensorflow.python import pywrap_tensorflow5253 # Protocol buffersC:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in ()50 for some common reasons and solutions.  Include the entire stack trace51 above this error message when asking for help.""" % traceback.format_exc()---> 52   raise ImportError(msg)5354 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-longImportError: Traceback (most recent call last):File "C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 18, in swig_import_helperreturn importlib.import_module(mname)File "C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_init_.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)File "", line 986, in _gcd_importFile "", line 969, in _find_and_loadFile "", line 958, in _find_and_load_unlockedFile "", line 666, in _load_unlockedFile "", line 577, in module_from_specFile "", line 906, in create_moduleFile "", line 222, in _call_with_frames_removedImportError: DLL load failed: The specified module could not be found.During handling of the above exception, another exception occurred:Traceback (most recent call last):File "C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 41, in from tensorflow.python.pywrap_tensorflow_internal import *File "C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 21, in _pywrap_tensorflow_internal = swig_import_helper()File "C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 20, in swig_import_helperreturn importlib.import_module('pywrap_tensorflow_internal')File "C:\Users\dines\Anaconda3\envs\tensorflow-gpu\lib\importlib_init.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)ImportError: No module named '_pywrap_tensorflow_internal'Failed to load the native TensorFlow runtime.See https://www.tensorflow.org/install/install_sources#common_installation_problemsfor some common reasons and solutions.  Include the entire stack traceabove this error message when asking for help.`
buildinstall	tensorflow for Nvidia TX1System informationOS Platform and Distribution: Linux Ubuntu 16.4Bazel version (if compiling from source): 0.4.4CUDA/cuDNN version: cuda-8.0Describe the problemI want to install tensorflow 1.0.0 in Nvidia TX1. I am following this so as to install version 1.0.0. But while installing bazel-0.4.4... I am getting this errorLogsINFO: You can skip this first step by providing a path to the bazel binary as second argument:INFO:    ./compile.sh compile /path/to/bazel🍃  Building Bazel from scratch.......🍃  Building Bazel with Bazel..WARNING: /tmp/bazel_OpcCR2sk/out/external/bazel_tools/WORKSPACE:1: Workspace name in /tmp/bazel_OpcCR2sk/out/external/bazel_tools/WORKSPACE (@io_bazel) does not match the name given in the repository's definition (@bazel_tools); this will cause a build error in future versions.ERROR: No toolchain found for cpu 'unknown'. Valid cpus are: [  arm,  armeabi-v7a,  x64_windows_msvc,  s390x,].INFO: Elapsed time: 6.533sERROR: Could not build Bazelcp: cannot stat 'output/bazel': No such file or directoryAny suggestion on this, why this is happing, really helpful.Thanks,
buildinstall	Importing tensorflow fails.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 HomeTensorFlow installed from (source or binary): BinaryTensorFlow version (use command below): I can't import, but the wheel file is "tensorflow_gpu-1.1.0-cp35-cp35m-win_amd64.whl (48.5MB)"Bazel version (if compiling from source): -CUDA/cuDNN version: cuda_8.0.61_win10.exe / cudnn-8.0-windows10-x64-v5.1.zipGPU model and memory: NVIDIA GeForce GTX 1070Exact command to reproduce: import tensorflowDescribe the problemImporting tensorflow fails.Source code / logsInstalling tensorflow-gpu:λ pip3 install tensorflow-gpu --upgradeCollecting tensorflow-gpu  Downloading tensorflow_gpu-1.1.0-cp35-cp35m-win_amd64.whl (48.5MB)    100% |################################| 48.6MB 16.9MB/sRequirement already up-to-date: wheel>=0.26 in c:\users\arthu\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)Requirement already up-to-date: protobuf>=3.2.0 in c:\users\arthu\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)Requirement already up-to-date: werkzeug>=0.11.10 in c:\users\arthu\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)Requirement already up-to-date: numpy>=1.11.0 in c:\users\arthu\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)Requirement already up-to-date: six>=1.10.0 in c:\users\arthu\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)Requirement already up-to-date: setuptools in c:\users\arthu\appdata\local\programs\python\python35\lib\site-packages (from protobuf>=3.2.0->tensorflow-gpu)Requirement already up-to-date: packaging>=16.8 in c:\users\arthu\appdata\local\programs\python\python35\lib\site-packages (from setuptools->protobuf>=3.2.0->tensorflow-gpu)Requirement already up-to-date: appdirs>=1.4.0 in c:\users\arthu\appdata\local\programs\python\python35\lib\site-packages (from setuptools->protobuf>=3.2.0->tensorflow-gpu)Requirement already up-to-date: pyparsing in c:\users\arthu\appdata\local\programs\python\python35\lib\site-packages (from packaging>=16.8->setuptools->protobuf>=3.2.0->tensorflow-gpu)Installing collected packages: tensorflow-gpuSuccessfully installed tensorflow-gpu-1.1.0Importing tensorflow:λ pythonPython 3.5.3 (v3.5.3:1880cb95a742, Jan 16 2017, 16:02:32) [MSC v.1900 64 bit (AMD64)] on win32Type "help", "copyright", "credits" or "license" for more information.>>> import tensorflowTraceback (most recent call last):  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 18, in swig_import_helper    return importlib.import_module(mname)  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py", line 126, in import_module    return _bootstrap._gcd_import(name[level:], package, level)  File "<frozen importlib._bootstrap>", line 986, in _gcd_import  File "<frozen importlib._bootstrap>", line 969, in _find_and_load  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked  File "<frozen importlib._bootstrap>", line 666, in _load_unlocked  File "<frozen importlib._bootstrap>", line 577, in module_from_spec  File "<frozen importlib._bootstrap_external>", line 914, in create_module  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removedImportError: DLL load failed: The specified module could not be found.During handling of the above exception, another exception occurred:Traceback (most recent call last):  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 41, in <module>    from tensorflow.python.pywrap_tensorflow_internal import *  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 21, in <module>    _pywrap_tensorflow_internal = swig_import_helper()  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 20, in swig_import_helper    return importlib.import_module('_pywrap_tensorflow_internal')  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py", line 126, in import_module    return _bootstrap._gcd_import(name[level:], package, level)ImportError: No module named '_pywrap_tensorflow_internal'During handling of the above exception, another exception occurred:Traceback (most recent call last):  File "<stdin>", line 1, in <module>  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\__init__.py", line 24, in <module>    from tensorflow.python import *  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\__init__.py", line 51, in <module>    from tensorflow.python import pywrap_tensorflow  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 52, in <module>    raise ImportError(msg)ImportError: Traceback (most recent call last):  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 18, in swig_import_helper    return importlib.import_module(mname)  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py", line 126, in import_module    return _bootstrap._gcd_import(name[level:], package, level)  File "<frozen importlib._bootstrap>", line 986, in _gcd_import  File "<frozen importlib._bootstrap>", line 969, in _find_and_load  File "<frozen importlib._bootstrap>", line 958, in _find_and_load_unlocked  File "<frozen importlib._bootstrap>", line 666, in _load_unlocked  File "<frozen importlib._bootstrap>", line 577, in module_from_spec  File "<frozen importlib._bootstrap_external>", line 914, in create_module  File "<frozen importlib._bootstrap>", line 222, in _call_with_frames_removedImportError: DLL load failed: The specified module could not be found.During handling of the above exception, another exception occurred:Traceback (most recent call last):  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 41, in <module>    from tensorflow.python.pywrap_tensorflow_internal import *  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 21, in <module>    _pywrap_tensorflow_internal = swig_import_helper()  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py", line 20, in swig_import_helper    return importlib.import_module('_pywrap_tensorflow_internal')  File "C:\Users\arthu\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py", line 126, in import_module    return _bootstrap._gcd_import(name[level:], package, level)ImportError: No module named '_pywrap_tensorflow_internal'Failed to load the native TensorFlow runtime.See https://www.tensorflow.org/install/install_sources#common_installation_problemsfor some common reasons and solutions.  Include the entire stack traceabove this error message when asking for help.
buildinstall	Building failure on KNLBuild withCurrent master branch source code from github~/tensorflow$ ./configurePlease specify the location of python. [Default is /usr/bin/python]:Found possible Python library paths:/usr/local/lib/python2.7/dist-packages/usr/lib/python2.7/dist-packagesPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]Using python library path: /usr/local/lib/python2.7/dist-packagesDo you wish to build TensorFlow with MKL support? [y/N] yMKL support will be enabled for TensorFlowDo you wish to download MKL LIB from the web? [Y/n]Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]:Do you wish to use jemalloc as the malloc implementation? [Y/n]jemalloc enabledDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]No Google Cloud Platform support will be enabled for TensorFlowDo you wish to build TensorFlow with Hadoop File System support? [y/N]No Hadoop File System support will be enabled for TensorFlowDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]No XLA support will be enabled for TensorFlowDo you wish to build TensorFlow with VERBS support? [y/N]No VERBS support will be enabled for TensorFlowDo you wish to build TensorFlow with OpenCL support? [y/N]No OpenCL support will be enabled for TensorFlowDo you wish to build TensorFlow with CUDA support? [y/N]No CUDA support will be enabled for TensorFlowWarning: ignoring http_proxy in environment.INFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.Configuration finishedCommandbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failuresThe error only part of build logBuild Log.txtThe Env collected by tf_env_collect.shEnv.txtBazel$ bazel versionWarning: ignoring http_proxy in environment.Build label: 0.4.5Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jarBuild time: Thu Mar 16 12:19:38 2017 (1489666778)Build timestamp: 1489666778Build timestamp as int: 1489666778Xeon Phi Platform(KNL)No GPUOne thing to notice is that with my experiments,The changes inFix TensorFlow compilation errors with KNL optimization flagsfixed the building issue. Although I don't know whether it is functioning correctly.Then the code is rolled back inFIxed merge issues Could you please look into this.Thank you.
buildinstall	Bazel Clean hangsHi ,I am trying to build TensorFlow example for Android using Bazel but it hanged. So I tried to find the reasonand after a while tried to clean the previous build with "bazel clean" and it hangs again the same way as it happened while building TensorFlow examples:$ bazel clean.................................................................................................................................................................................{hangs here}It doesn't move beyond that and we get no other info. Is there any other way to debug this or log the "bazel clean" output which we can later use to debug the issue?We are using:tensorflow: 1.1.0Python: 2.7.6We tried to find bazel version using "bazel version" now this is also hanging:$ bazel version. {hangs here}Looks like its an issue with bazel. may be the installation is not correct. Can someone help?
buildinstall	Compiling tensorflow 1.1 under Centos 7I'm trying to compile tensorflow with cuda support under linux Centos 7 distribution.I followed the instructions provides at github: gentaiscool/tensorflow.md  with no success.In this page they ask for hacking the file tensorflow/third_party/gpus/crosstool/CROSSTOOL (adding the line "cxx_builtin_include_directory : "/usr/local/cuda/targets/x86_64-linux/include").In the current version of Tensorflow (1.1) there is no such a file; similar files, such as: CROSSTOOL.tpl, CROSSTOOL_nvcc.tpl, CROSSTOOL_clang.tpl, are found. I tried the proposed hacking on each of these files and didn't get successful compilation.Since I'm interested is tensorflow deployment, I'm compiling it using the instructions found in gitgub cjweeks/tensorflow-cmake (building a library to be linked with a C++ based program). My build command is:bazel build -c opt --config=cuda tensorflow:libtensorflow_all.soThe error I've got is:ERROR: /root/tensorflow/tensorflow/core/kernels/BUILD:3004:1: undeclared inclusion(s) in rule '//tensorflow/core/kernels:depth_space_ops_gpu': this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/spacetodepth_op_gpu.cu.cc': '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/limits.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/syslimits.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/stddef.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/stdarg.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/stdint.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/x86intrin.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/ia32intrin.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/mmintrin.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/xmmintrin.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/mm_malloc.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/emmintrin.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/immintrin.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/fxsrintrin.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/adxintrin.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/float.h' '/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/stdbool.h'.System information:Linux Centos 7.2Kernel: 3.10.0-327.36.1.el7.x86_64Compiler: gcc version 4.8.5 20150623 (Red Hat 4.8.5-4) (GCC)Tensorflow: 1.1, installed from source.nvcc: Cuda compilation tools, release 8.0, V8.0.44CUDA: 8.0cudaa: 5.1.5bazel: 0.4.5Any help please?Thanks in advance,Ron.
buildinstall	Would you please accomodate for building tensorflow with a custom clang (4.0.0) and libc++ instead of stdlibc++?I have a custom clang with additional optimization passes but I cant get TS compiled with it.$ bazel build --cxxopt=-std=c++11 --cxxopt=-stdlib=libc++ tensorflow:libtensorflow.soINFO: Found 1 target...INFO: From Compiling external/protobuf/src/google/protobuf/compiler/js/embed.cc [for host]:external/protobuf/src/google/protobuf/compiler/js/embed.cc:37:12: warning: unused variable 'output_file' [-Wunused-const-variable]const char output_file[] = "well_known_types_embed.cc";^1 warning generated.ERROR: /home/hbucher/.cache/bazel/_bazel_hbucher/ad427c7fddd5b68de5e1cfaa7cd8c8cc/external/com_googlesource_code_re2/BUILD:11:1: undeclared inclusion(s) in rule '@com_googlesource_code_re2//:re2':this rule is missing dependency declarations for the following files included by 'external/com_googlesource_code_re2/re2/bitstate.cc':'/home/hbucher/install/include/c++/v1/stddef.h''/home/hbucher/install/include/c++/v1/__config'
buildinstall	[CMAKE] Unresolved external symbol rdftSystem informationOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (Visual studio 2015)TensorFlow installed from (source or binary): via cmake and includes into c++ project as static lib.(tensorflor_static.lib file).Describe the problemAfter successful building Release version I tried to add tensorflow_static.lib and dependencies into c++ project. Then linker threw an error:SeverityCodeDescriptionProjectFileLineSuppression StateErrorLNK2001unresolved external symbol rdftMyLibC:\path\to\release\tensorflow_static.lib(spectrogram.obj)1
buildinstall	configure script overrides user's bazelrcThe ./configure script will write to a .bazelrc file in the cwd to save some of it's options (in particular, jemalloc). Unfortunately this has the effect of overriding ~/.bazelrc. This is undocumented, and probably should not happen. For now, the solution is copy your own bazelrc into the tensorflow root before configuring - fortunately ./configure will not overwrite it and only append to it.
buildinstall	Building with config MKL with current master (git version: v1.1.0-rc2-1163-gcbe5eb4) fails with a build rule errorBuilding with config MKL with the current master fails with build rule error.System information:(contents from tf_env.txt)== cat /etc/issue ===============================================Linux desktop 4.4.0-75-generic #96-Ubuntu SMP Thu Apr 20 09:56:33 UTC 2017 x86_64 x86_64 x86_64 GNU/LinuxVERSION="16.04.2 LTS (Xenial Xerus)"VERSION_ID="16.04"VERSION_CODENAME=xenial== are we in docker =============================================No== compiler =====================================================c++ (Ubuntu 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609Copyright (C) 2015 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.== uname -a =====================================================Linux desktop 4.4.0-75-generic #96-Ubuntu SMP Thu Apr 20 09:56:33 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux== check pips ===================================================numpy (1.12.1)protobuf (3.3.0)tensorflow (1.1.0)== check for virtualenv =========================================False== tensorflow import ============================================tf.VERSION = 1.1.0-rc2tf.GIT_VERSION = v1.1.0-rc2-1163-gcbe5eb4tf.COMPILER_VERSION = v1.1.0-rc2-1163-gcbe5eb4Sanity check: array([1], dtype=int32)== env ==========================================================LD_LIBRARY_PATH is unsetDYLD_LIBRARY_PATH is unset== nvidia-smi ===================================================== cuda libs  ===================================================Exact command to reproduce:bazel --output_user_root=/home/desktop/gtt/tfbuild_opt/ build --copt="-DEIGEN_USE_VML" --config=mkl -c opt //tensorflow/tools/pip_package:build_pip_packageDescribe the problem: Build with the above setup and following configure options fails with a build rule error.$ ./configurePlease specify the location of python. [Default is /usr/bin/python]:Found possible Python library paths:/usr/local/lib/python2.7/dist-packages/usr/lib/python2.7/dist-packagesPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]Using python library path: /usr/local/lib/python2.7/dist-packagesDo you wish to build TensorFlow with MKL support? [y/N] yMKL support will be enabled for TensorFlowDo you wish to download MKL LIB from the web? [Y/n]Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]:Do you wish to use jemalloc as the malloc implementation? [Y/n]jemalloc enabledDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]No Google Cloud Platform support will be enabled for TensorFlowDo you wish to build TensorFlow with Hadoop File System support? [y/N]No Hadoop File System support will be enabled for TensorFlowDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]No XLA support will be enabled for TensorFlowDo you wish to build TensorFlow with VERBS support? [y/N]No VERBS support will be enabled for TensorFlowDo you wish to build TensorFlow with OpenCL support? [y/N]No OpenCL support will be enabled for TensorFlowDo you wish to build TensorFlow with CUDA support? [y/N]No CUDA support will be enabled for TensorFlowWarning: ignoring http_proxy in environment.........................INFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.Configuration finishedBuild failed with following error:ERROR: /home/desktop/gtt/tensorflow/core/BUILD:1544:1: undeclared inclusion(s) in rule '//tensorflow/core:core_cpu_base': this rule is missing dependency declarations for the following files included by 'tensorflow/core/graph/mkl_tfconversion_pass.cc': '/home/desktop/gtt/tensorflow/core/common_runtime/function.h' '/home/desktop/gtt/tensorflow/core/common_runtime/device_mgr.h' '/home/desktop/gtt/tensorflow/core/common_runtime/optimization_registry.h' '/home/desktop/gtt/tensorflow/core/common_runtime/device_set.h'. ____Building complete. Target //tensorflow/tools/pip_package:build_pip_package failed to build Use --verbose_failures to see the command lines of failed build steps. ____Elapsed time: 615.488s, Critical Path: 227.18s
buildinstall	How to build tensorflow for mips64elThe recommended way to build TensorFlow from source is using the Bazel open-source build system.Howerver, bazel depends protobuf,grpc-java,osdetector etc.  protocbuf can build  successfully for mips64el. But i  build grpc-java  failed. details see #3012. i refer #2022. but osdetector-gradle-plugin occur error.Could anybody give me some help for building tensorflow for mips64el arch?
docs	problem with exemple in API documentation for tf.contrib.distributions.bijector.ScaleAndShiftHelloI am currently using tensorflow version 1.0.0 (from conda vanilla installation),and I am running a snippet code fromAPI documentation :https://www.tensorflow.org/api_docs/python/tf/contrib/distributions/TransformedDistribution?authuser=3I get an AttributeError which seems an accurate error since I can't seem to find ScaleAndShift on the github repo for tensorflow r1.0>>> ds.TransformedDistribution(...   distribution=ds.Normal(mu=0., sigma=1.),...   bijector=ds.bijector.ScaleAndShift(loc=mu, scale=sigma,   event_ndims=0),...   name="NormalTransformedDistribution")Traceback (most recent call last):  File "<stdin>", line 3, in <module>AttributeError: 'module' object has no attribute 'ScaleAndShift'
docs	Broken link in README.mdIn https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim/README.md...In addition to the types of scope mechanisms in TensorFlow (name_scope, variable_scope, TF-Slim adds a...Link of variable_scope ( https://www.tensorflow.org/api_docs/python/state_layers#variable_scope ) is broken.
docs	Documentation: broken links and image in documentationThe URL:  https://www.tensorflow.org/versions/master/api_docs/python/tf/segment_sum has a broken link labelled "the section on Segmentation".  Also, there is a broken image on that page as well.Same problems here too (except not all have an image to be broken):https://www.tensorflow.org/versions/master/api_docs/python/tf/segment_prodhttps://www.tensorflow.org/versions/master/api_docs/python/tf/segment_minhttps://www.tensorflow.org/versions/master/api_docs/python/tf/segment_maxhttps://www.tensorflow.org/versions/master/api_docs/python/tf/segment_meanhttps://www.tensorflow.org/versions/master/api_docs/python/tf/unsorted_segment_sumhttps://www.tensorflow.org/versions/master/api_docs/python/tf/sparse_segment_sumhttps://www.tensorflow.org/versions/master/api_docs/python/tf/sparse_segment_meanhttps://www.tensorflow.org/versions/master/api_docs/python/tf/sparse_segment_sqrt_nThe page I believe they should link back to is here: https://www.tensorflow.org/versions/master/api_guides/python/math_ops#SegmentationI came here because I haven't grokked just what segmented operations are yet.  So I would be much obliged if the explanation of segmentation were more thoroughly be explained there, perhaps with a couple of examples.I found [a few places] in the code where this could be address.  And I would have attempted a pull request to fix these, but I'm not up on how to generate the documentation to verify that it was fixed.
docs	cpp protobuf instructions out-of-date for MacOSInstructions to upgrade to cpp protobuf implementation on Mac from https://www.tensorflow.org/install/install_mac#protobuf_pip_package_31 don't work work, makes TF fails with following stacktraceTraceback (most recent call last):  File "kronecker_benchmark.py", line 3, in <module>    import tensorflow as tf  File "/Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/tensorflow/__init__.py", line 24, in <module>    from tensorflow.python import *  File "/Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/tensorflow/python/__init__.py", line 54, in <module>    from tensorflow.core.framework.graph_pb2 import *  File "/Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/tensorflow/core/framework/graph_pb2.py", line 6, in <module>    from google.protobuf import descriptor as _descriptor  File "/Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/google/protobuf/descriptor.py", line 46, in <module>    from google.protobuf.pyext import _messageImportError: dlopen(/Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-darwin.so, 2): Library not loaded: /usr/local/lib/libprotobuf.10.dylib  Referenced from: /Users/yaroslav/anaconda/envs/mar1/lib/python3.5/site-packages/google/protobuf/pyext/_message.cpython-35m-darwin.so  Reason: image not foundWork-around is to use older link:pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/protobuf-3.1.0-cp35-none-macosx_10_11_x86_64.whlCheck that it workspython -c "from google.protobuf.internal import api_implementation; print(api_implementation._default_implementation_type)"MacOS: 10.12.4 (16E195), TensorFlow, latest nightly from today installed as:pip install --upgrade https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-cpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=mac-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-1.1.0rc1-py3-none-any.whl
docs	problem with wide_n_deep_tutorial.py on Tensorflow 1.0Using Python 3.6.0 (Anaconda x64), Tensorflow 1.0, macOS Sierra version 10.12.4, I get the following error:python wide_deep.pyTraining data is downloaded to /var/folders/h2/727s56vx40s_6n2z9ldl6kx00000gs/T/tmp76m50o3hTest data is downloaded to /var/folders/h2/727s56vx40s_6n2z9ldl6kx00000gs/T/tmpwzhof_zbmodel directory = /var/folders/h2/727s56vx40s_6n2z9ldl6kx00000gs/T/tmpclbsc2wmTraceback (most recent call last):File "wide_deep.py", line 234, in tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)File "/Users/CBrauer/anaconda/lib/python3.6/site-packages/tensorflow/python/platform/app.py", line 44, in run_sys.exit(main(_sys.argv[:1] + flags_passthrough))File "wide_deep.py", line 197, in mainFLAGS.train_data, FLAGS.test_data)File "wide_deep.py", line 185, in train_and_evalm = build_estimator(model_dir, model_type)File "wide_deep.py", line 132, in build_estimatorfix_global_step_increment_bug=True)TypeError: init() got an unexpected keyword argument 'fix_global_step_increment_bug'Charles
docs	Documentation link issueNOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.under this linkhttps://www.tensorflow.org/api_docs/python/tf/contrib/deprecated/scalar_summarythe webpage is not foundhttps://www.tensorflow.org/code/tensorflow/contrib/deprecated/__init__.pyYou must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:TensorFlow installed from (source or binary)?:TensorFlow version:Bazel version (if compiling from source):CUDA/cuDNN version:GPU Model and Memory:Exact command to reproduce:Describe the problem clearlySource Code / LogsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
docs	Hi, I am unable to access the documentationNOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.You must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:TensorFlow installed from (source or binary)?:TensorFlow version:Bazel version (if compiling from source):CUDA/cuDNN version:GPU Model and Memory:Exact command to reproduce:Describe the problem clearlySource Code / LogsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
docs	possible doc inconsistency `tf.contrib.framework.load_variable`NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.You must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:TensorFlow installed from (source or binary)?:TensorFlow version:Bazel version (if compiling from source):CUDA/cuDNN version:GPU Model and Memory:Exact command to reproduce:Describe the problem clearlyIn my experience, this function tf.contrib.framework.load_variable returns a numpy.ndarray instead of a Tensor as the doc suggests. Furthermore according to the unit test, it is expected to return the value of a tensor instead of a Tensor object itself. I think the behavior of returning tensor values is desired (to load select variables from arbitrary checkpoints without a session), so this should be a minor doc issue.Source Code / LogsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
docs	README.md has a deprecated API callSystem InformationTensorflow ('v1.0.0-65-g4763edf-dirty', '1.0.1')Describe the problem clearlyIn README.md line predictions = vgg.vgg16(images, is_training=True) should be predictions = vgg.vgg_16(images, is_training=True) (see source code for vgg).
docs	stack_bidirectional_dynamic_rnn input incorrect documentationHi, this is really a documentation problem rather than problem with the actual code.The doc states that inputs should be of shape number of numSequences x batchSize x inputSize, but in reality it's batchSize x numSequences x inputSize.
docs	Tutorial has error: Recurrent Neural NetworksTutorial URL: https://www.tensorflow.org/tutorials/recurrentI'm going through the tutorial listed above and I think there is a mistake in the very first code example:lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)# Initial state of the LSTM memory.state = tf.zeros([batch_size, lstm.state_size])An error is reported for the third line:ValueError: setting an array element with a sequence.If one prints the lstm.state_size object (where say, lstm_size = 50) one finds:LSTMStateTuple(c=50, h=50)I'm guessing this should be:lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)# Initial state of the LSTM memory.state = tf.zeros([batch_size, lstm_size])But frankly there are numerous other errors in this tutorial as well, so I'm not sure.  I will continue to report them as I find them.Version: tensorflow_gpu-1.0.1-cp27-none-linux_x86_64.whlRunning on Ubuntu 14.04
docs	`Evaluable` docs: name, checkpoint_path, and hooks should be new bullets.See https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Evaluable - final params for evaluate() are not bullets, making reading the documentation less readable. I've seen this in other docs too (can comment if I come across more of them).I wonder if the parser has some bug that causes it to not bullet-ify some params for functions.
docs	tf.get_collection documentation: argument description is confusingFrom https://www.tensorflow.org/api_docs/python/tf/get_collection:"Items without a name attribute are never returned if a scope is supplied and the choice or re.match means that a scope without special tokens filters by prefix."What does this mean? Is there a typo here?
docs	Explain what tf.nn.softplus does to integerstf.nn.softplus computes log(1 + exp(x)).  Naively, I wouldn't expect this to work for integers, but it does.  On integers, it seems to degenerate to a poorly named version of tf.relu: it computes max(0, x).We probably can't eliminate the integer versions for backward compatibility reasons, but we should at least explain what they do.
docs	tflearn Incorrect CommentIn the tflearn quick start guide here:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/tflearn.mdBelow the section "Describe the training input pipeline {#train-input}"The first snippet:# Define the test inputsdef get_train_inputs():  x = tf.constant(training_set.data)  y = tf.constant(training_set.target)  return x, yShould be# Define the training inputsdef get_train_inputs():  x = tf.constant(training_set.data)  y = tf.constant(training_set.target)  return x, ywhere# Define the test inputs -> # Define the training inputsIn the overall listing at the top of this file, it appears to have the correct comment. It's just here in this section where the comment is incorrect.
docs	Mac Gpu Link not working?Hello,I was trying to install Tensorflow for Mac GPU Python 3 one from github and I found that it is a broken URL Giving me an HTTP 404 Error.The URL is - https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-mac-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON3,label=gpu-mac/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-1.1.0rc2-py3-none-any.whlPlease Fix the Url.Best,Daksh
docs	Cifar10 Tutorial Link to Example Code 404'sFollowing any of the links to the code for the CIFAR10 tutorial 404's.Example link: https://www.tensorflow.org/versions/master/tutorials/deep_cnn#code_organizationAny from above.
docs	Non deterministic behaviour of tf.train.batch in case the number of threads is higher than 1.This is related to the StackOverflow question: http://stackoverflow.com/questions/43612366/tf-train-batch-output-is-not-deterministic/43613376#43613376The thread owner creates a batch with the following code:BatchedInputs = tf.train.batch(  Inputs,  batch_size=64,  num_threads=8,  capacity=500 + 3 * 64)And he noticed that created batches are not in every run the same. They are quite similar, but sometimes the inputs are mixed or some are missing.According to the answer on StackOverflow reducing the number of pre-fetch threads to 1 is solving this issue.Since this could be an issue for test-set evaluation (where everyone would expect the exact same outcome for every run), I wonder if this is the intended behaviour?It should at least be added to the documentation for tf.train.batch that the generated batches can be non-deterministic.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):YesOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10TensorFlow installed from (source or binary):Binary (pip3)TensorFlow version (use command below):1.1.0Bazel version (if compiling from source):nonCUDA/cuDNN version:CUDA 8.0, cuDNN 5.1GPU model and memory:GTX680Exact command to reproduce:See above.Describe the problemsee aboveSource code / logs
docs	Improved documentation for TensorArrayThe current documentation for TensorArray could use an expanded introduction explaining its utility and main motivation, examples of actual usage, and further explanation of some of its methods. The docs here do not have a single usage example. The overall description of the section is just:"This class is meant to be used with dynamic iteration primitives such as while_loop and map_fn. It supports gradient back-propagation via special "flow" control flow dependencies."How is meant to be used with dynamic iteration primitives? What does that entail and why do we need a special construct for dynamic iteration? And what is "flow"? It's very cryptic as it stands. Furthermore, some methods are very poorly described, like close. It's unclear if it needs to be invoked at the end, or what? Comments on stack overflow only add to the confusion. With the increasing importance of dynamic graphs, a basic construct like TensorArray should really be well documented, like Variable.
docs	Link Error for the deprecated/__init__.pyIt seems that the link "look 'here'" can not point to the right page in the doc of histogram_summary, should we just change it to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/deprecated/__init__.py?Please go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):OS Platform and Distribution (e.g., Linux Ubuntu 16.04):TensorFlow installed from (source or binary):TensorFlow version (use command below):Bazel version (if compiling from source):CUDA/cuDNN version:GPU model and memory:Exact command to reproduce:You can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.Source code / logsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
docs	iOS: No OpKernel was registered to support Op 'Less' with these attrs.hi , all! I have tried to load the model inside iOS that I generated from python.and right now, I have the following problem:Error adding graph to session:No OpKernel was registered to support Op 'Less' with these attrs.  Registered devices: [CPU],     Registered kernels: device='CPU'; T in [DT_FLOAT]  [[Node: rnn/while/Less = Less[T=DT_INT32](rnn/while/Merge, rnn/while/Less/Enter)]]Here is the python script generating the model:def add_dynamic_rnn_layer(inputs, out_size, batch_size, Xt_size, time_step, num_layer=1, keep_prob=0.5):    # Reshaping to (batch_size, time_step, Xt_size)    inputs = tf.reshape(inputs, [-1, time_step, Xt_size])    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.LSTMCell(out_size, state_is_tuple=True,forget_bias=1.0),                                                input_keep_prob=keep_prob)                             for _ in range(num_layer)])    cell =  tf.contrib.rnn.DropoutWrapper(cell,  input_keep_prob=keep_prob)    sequence_length = np.zeros([batch_size], dtype=int)    sequence_length += time_step    init_state = cell.zero_state(batch_size, tf.float32)    rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, inputs, initial_state=init_state, dtype=tf.float32, time_major=False,sequence_length=sequence_length)    return tf.transpose(rnn_outputs, [1, 0, 2])[-1]with tf.Session() as sess:  # ...... other model code....   add_dynamic_rnn_layer()   output_graph_def = convert_variables_to_constants(sess, sess.graph_def,                                                          output_node_names=['predictions', 'prediction_labels'])   with tf.gfile.FastGFile('inference'+str(time.time())+'.pb', mode='wb') as f:            f.write(output_graph_def.SerializeToString())Here is the objective-C++ code loading the model and creating the session:{    NSString *path = [[NSBundle mainBundle] pathForResource:pbname ofType:@"pb"];    if (!path) return false;    auto status = ReadBinaryProto(tensorflow::Env::Default(), path.fileSystemRepresentation, &graph);    if (!status.ok()) {        NSLog(@"Error reading graph: %s", status.error_message().c_str());        return NO;    }        // This prints out the names of the nodes in the graph.    auto nodeCount = graph.node_size();    NSLog(@"Node count: %d", nodeCount);    for (auto i = 0; i < nodeCount; ++i) {        auto node = graph.node(i);        NSLog(@"Node %d: %s '%s'", i, node.op().c_str(), node.name().c_str());    }        tensorflow::SessionOptions options;    auto status = tensorflow::NewSession(options, &session);    if (!status.ok()) {        NSLog(@"Error creating session: %s", status.error_message().c_str());        return NO;    }        status = session->Create(graph);    if (!status.ok()) {        NSLog(@"Error adding graph to session: %s", status.error_message().c_str());    }  }the environment as follows:python 3.5 / xcode 8.3.2the iOS based on mac os x 10.12  / the tensorflow version: r1.1the model generated based on Ubuntu / tensorflow is r1.1 gpu versionI have done things as follow:build_all_ios.shsuccess,don't have any warning and error.set the xcode build settingsheader search path/Users/jw/Desktop/tensorflow  non-recursive/Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/downloads non-recursive/Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/downloads/protobuf/src non-recursive/Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/downloads/eigen non-recursive/Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/gen/proto non-recursiveother linker flags:/Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/libprotobuf.a/Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib/libprotobuf-lite.a/Users/jw/Desktop/tensorflow/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a-force_loadcheck the tf_op_files.txthave the line tensorflow/core/kernels/cwise_op_less.ccusing the tensorflow version v1.0have the same errorI would be gratefull if anyone has an idea on why iOS seems to not be able to find the less Op ?Or the solution to the question : No OpKernel was registered to support Op 'Less' with these attrs.
docs	How do you generate tensorflow docs so you can confirm documentation fixes you make?Example: Suppose I see a formatting error in a Tensorflow function's arguments on the web. I then make a change in the "Args: ..." section of the function's python comments.How can I generate these html docs after making this fix?
docs	Documentation for tf.nn.ctc_* `label` argument is unclearThe documentation for the connectionist temporal classifiers is unclear for label argument.  Here is what exists currently:labels: An int32 SparseTensor. labels.indices[i, :] == [b, t] means labels.values[i] stores the id for (batch b, time t). labels.values[i] must take on values in [0, num_labels). See core/ops/ctc_ops.cc for more details.The only way I was able to figure it out is from Jerod's comment on this SO:http://stackoverflow.com/questions/42488070/how-to-design-the-label-for-tensorflows-ctc-loss-layer
docs	[Tutorial Update] Logging and Monitoring BasicsPlease go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationTensorFlow 1.1n/a as purely documentation relatedDescribe the problemThe currently published tutorial for Logging and Monitoring is based on functionality that has been identified as deprecated (see i.p. the discussion in #7669 .)I truly appreciate all the hard work 💯  put into moving the functionality of TF itself forward.It would be most appreciated, if this tutorial could be updated to reflect suggested best practices when using sessionRunHook et al. to ease adoptabilty of TF.Source code / logsn/a
docs	TensorFlow processes and core engine documentationsHi all,I am interesting to understand more details about TF core engine. My focus interest on how a process create and launch when session is being created. Also, how the threads work and how python api translate these threads to C++ TF engine. Is there any documentation about that ?Sincerely
docs	Documentation pages are unnecessarily largecurl https://www.tensorflow.org/api_docs/python/tf/abs | wc -c  # 1841844 (1.8MB)Each page in the documentation now contains a HUGE left navbar contributing over 99% of the size.This would waste a lot of network traffic on loading identical navbar over and over again.It creates a big trouble when I tried to build an offline version of the doc. The whole html documents used to be <100MB, now they are 2.5GB.
docs	Several links error in README.md.System informationOS: Windows 10 Enterprise x64:Browser: Chrome 58 x64:Location: China:IssueThe Installing TensorFlow link from README.md fails with error:Error: Not FoundThe requested URL /versions/r0.12/install/index.html was not found on this server.The Community link fails with error:Error: Not FoundThe requested URL /versions/r0.12/community/index.html was not found on this server.
docs	Invalid link in https://www.tensorflow.org/deploy/distributedSeems that the CIFAR-10 multi-GPU trainer link in https://www.tensorflow.org/deploy/distributed is broken. Actually this code only exists <= r0.12. There is three ways to fix it:Use an old version such as  CIFAR-10 multi-GPU trainerRemove this link in the doc pageCreate a new cifar10_multi_gpu_train.py file for r1.1I can work on this issue, is there any suggestions on which way to go?Please go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):OS Platform and Distribution (e.g., Linux Ubuntu 16.04):TensorFlow installed from (source or binary):TensorFlow version (use command below):Bazel version (if compiling from source):CUDA/cuDNN version:GPU model and memory:Exact command to reproduce:You can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.Source code / logsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
docs	Is batch_norm_param argument missing in the depthwise convolution 2d layer implementation?This is with reference to: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L1850The line says "if batch_norm_params is None" but there is no batch_norm_params argument included in the function, and it doesn't seem that batch_norm is implemented within the function as an option. Is the batch_norm function included in the regularizer function or has it not been implemented by default within the function?Thanks for your help.
docs	Convolutional Neural Networks Tutorial problemI am learning about Convolutional Neural Networks from the tutorial:https://www.tensorflow.org/tutorials/deep_cnnInside it there is a link for getting the code but it is not working:https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/image/cifar10/how can I get the code?
docs	Missing image in https://www.tensorflow.org/api_docs/python/tf/gatherSystem informationn/aDescribe the problemhttps://www.tensorflow.org/api_docs/python/tf/gather includes an image, https://www.tensorflow.org/api_docs/images/Gather.png, but this does not exist.  Gather.png doesn't seem to exist anywhere in the TF repository.
docs	More description for optimizers Adagrad, Adadelta, FTRL...Is it necessary to add more description for optimizers such as Adagrad, Adadelta, FTRL and so on just as what Adam does? Since these are several quite new optimizers and I think it's better to show users more details about these optimizers so that they can understand why do these optimizers work better than SGD in some situations.If more descriptions are welcomed, I'm glad to make new PRs to do this.Please go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):OS Platform and Distribution (e.g., Linux Ubuntu 16.04):TensorFlow installed from (source or binary):TensorFlow version (use command below):Bazel version (if compiling from source):CUDA/cuDNN version:GPU model and memory:Exact command to reproduce:You can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.Source code / logsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
docs	Not a JPEG issuebazel-bin/tensorflow/examples/image_retraining/retrain --image_dir /Training_imageLooking for images in 'non-human'Looking for images in 'human'Creating bottleneck at /tmp/bottleneck/non-human/Data__negatives_jpeg_cr_night_512x384_cr_night_512x384_rCR_m26_a10_d2005-04-07_t22-38_wN.jpg.txt2017-05-09 01:56:48.890091: W tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().Not a JPEG file: starts with 0x89 0x50Traceback (most recent call last):File "/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py", line 1105, in tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)File "/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/platform/app.py", line 48, in run_sys.exit(main(_sys.argv[:1] + flags_passthrough))File "bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py", line 844, in mainbottleneck_tensor)File "bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py", line 469, in cache_bottlenecksjpeg_data_tensor, bottleneck_tensor)File "bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py", line 417, in get_or_create_bottleneckbottleneck_tensor)File "bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py", line 376, in create_bottleneck_fileraise RuntimeError('Error during processing file %s' % image_path)RuntimeError: Error during processing file /Training_images/non-human/Data__negatives_jpeg_cr_night_512x384How to fix this?
docs	tf.abs() isn't documented to handle complex, but it does appear to work as tf.complex_abs() used to.Issue #7405 was a bug filed that tf.complex_abs() was removed in 1.0.  At the bottom it says that tf.abs() now does that work, but the docs for tf.abs() only mention float.  I confirmed that tf.abs() does in fact do as the comment on the issue describes (https://github.com/tensorflow/tensorflow/blob/r1.1/tensorflow/python/ops/math_ops.py#L225)Please incorporate the info from https://www.tensorflow.org/versions/r0.11/api_docs/python/math_ops/complex_number_functions#complex_absintohttps://www.tensorflow.org/api_docs/python/tf/abs... specifically the parts about it computing sqrt(a^2 + b^2) for complex numbers.
docs	www.tensorflow.org/versions/ incorrectly lists 0.12 as the most recent stable branchhttps://www.tensorflow.org/versions/ says that 0.12 is most recent stable branch, which is causing new users to install the older version --#9590 (comment)
docs	Wrong hyperlink in web page tutorialThere is a wrong html link in text in the tutorial "Vector Representations of Words" at address https://www.tensorflow.org/tutorials/word2vecThe text is in the first paragraph after the bullet points in the Highlights section at the top of the page.The link for:tensorflow_models/tutorials/embedding/word2vec.pyhttps://www.github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/embedding/word2vec.pyis wrong, it should point to the following address:https://github.com/tensorflow/models/blob/master/tutorials/embedding/word2vec.pyI hope that this is helpful.
docs	ValueError: Refusing to perform an overparameterized separable convolutionPlease go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YesOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04TensorFlow installed from (source or binary): binaryTensorFlow version (use command below): 1.1rcBazel version (if compiling from source):CUDA/cuDNN version: No CUDAGPU model and memory:Exact command to reproduce:You can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemI am using tensorflow function tf.nn.separable_conv2d. I want to understand why  channel_multiplier * in_channels > out_channels is not allowed. It was not clear anywhere from the documentation.Source code / logsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
docs	#issue: broken or outdated link link for NLP tutorialThe second link, in the highlights session of the webpageVector Representationsis broken or outdated.This is the link that's not working (404 from github)https://www.github.com/tensorflow/tensorflow/blob/r1.1/tensorflow_models/tutorials/embedding/word2vec.py
docs	tf.Estimator vs contrib. Very unclear differences and lots of deprecations.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows/UbuntuTensorFlow installed from (source or binary): BinaryTensorFlow version (use command below): 1.1.0Bazel version (if compiling from source): /CUDA/cuDNN version: 5GPU model and memory: K40Exact command to reproduce: N/ADescribe the problemIs it just me or is there quite a large disconnect between the two versions of Estimator. The tutorial in the docs guides you through the contrib version but I understand that it has also been moved to tf.Estimator? However in the docs it appears that almost all functionality, e.g. canned estimators or .fit() appears to be missing or altered and there is little documentation to explain this new API.Have I misunderstood something here? I imagine that we are preferred to use tf.estimator because using the contrib version kicks up all sorts of warning about how it will be deprecated last year! Although the estimator tutorial still uses it and also .fit() which I can't clearly see the replacement for in the new API. Is there going to be any example code or tutorial for the new tf.Estimator API as I feel it desperately needs it. The contrib version was difficult enough to understand that I gave up but want to try again! Thanks
feature	Conditionally trainable variables and stochastic depth neural networksI came across with a task where I would like to apply stochastic depth regularization technique using Tensorflow (https://arxiv.org/pdf/1603.09382.pdf). Tensorflow doesn't provide enough settings to implement this one. I found closed issue  #1784 which is similar to this request, where guys finished the discussion with claim that [ tf.cond | tf.select ] primitives are enough for this task. But if you carefully read the paper it says that during training the depth changes for both directions: forward and backward propagation steps. Therefore number of tranable W parameters of the network changes too. The core conception of the Tensorflow is building computation graph before session of training is run. Currently, I can not create dynamic computation graph, so that depending on a boolean value W parameters of a layer were not engaged in optimisation process.If tf.Variable accepted trainable parameter as a boolean tensor apart from built-in boolean value it would solve the problem. In this case, it would mean that Tensorflow operates natively with dynamic computational graphs, which in fact very powerful tool.I would appreciate any suggestions and ideas, so that this question was closed for good and all.@vrv, @martinwicke, @aselle
feature	Gradient of reduce_prod not available on GPUThe following example fails to colocate the values:with tf.device('/gpu:2'):    x = tf.placeholder(tf.float32, shape=[None, 100])    weight_dense_1 = tf.Variable(tf.zeros([100, 10]))    dense_1_out = tf.matmul(x, weight_dense_1)    y = tf.reduce_prod(tf.cast(tf.shape(dense_1_out), tf.float32))    grad = tf.gradients(y, [weight_dense_1], colocate_gradients_with_ops=True)A bunch of warnings like this is displayed:WARNING:tensorflow:Tried to colocate gradients_1/Prod_1_grad/Rank with an op Prod_1 that had a different device: /device:CPU:0 vs /device:GPU:2. Ignoring colocation property.The symptom is similar to #3397. Using CPU or specifying all input dimensions solves the problem. But the cause seems different.Gradient of Prod operation is defined in python/ops/math_grad.py. There, the operation is forced to run on CPU (see 182fef1), mentioning the listdiff() operation is CPU-only.I tried remove the forcing line and run this. It yields a kind explanation:InvalidArgumentError: Cannot assign a device to node 'gradients/Prod_grad/range_1': Could not satisfy explicit device specification '/device:GPU:2' because no supported kernel for GPU devices is available.Colocation Debug Info:Colocation group had the following types and devices: InvertPermutation: GPU CPU Transpose: GPU CPU ConcatV2: GPU CPU Pack: GPU CPU Cumprod: GPU CPU ListDiff: CPU Shape: GPU CPU     ...(many GPU CPU ops)Reshape: GPU CPU Gather: CPU Two operations used here, namely Gather and ListDiff, are defined on CPU-only. As some of the operations needed in calculating the gradient are CPU-only, by the colocation rule, they get grouped into CPU-only.This also occurs when using moments() or sufficient_statistics() (the former calls the latter). There, when some of the axes of the tensor are unknown (like batch size), the total number of values (which is needed for the mean and variance) is calculated by reduce_prod() on shape().When the value of mean or variance is differentiated in some way (which is the case in batch normalization), a colocation between tensors named like gradients/moments/sufficient_statistics/count_grad/Rank and moments/sufficient_statistics/count fails.Though listdiff() is renamed later on Python interface to setdiff1d(), it's still named ListDiff internally.gather() operation is defined on GPU too, but only on float types.It seems there hasn't been any issue on this. Would it mean that Prod() op is not differentiated in most of the cases?How this can be solved? I'm not sure if the setdiff1d() operation is needed.For me, this occured when using moments(), where the reciprocal of number of values is multiplicated to the sum of values. I think this is unnecessary, as it can be done with reduce_mean(). Is it right?Environment infoOperating System: Ubuntu 16.04.Installed version of CUDA and cuDNN: CUDA 8.0.61 / cuDNN 5.1.10.pip3-installed tensorflow-gpu==1.0.1; all links here pointed to r1.0, but the problematic parts are the same as master.python -c "import tensorflow; print(tensorflow.__version__)" yields: 1.0.1.
feature	Allow SavedModelBuilder to overwrite existing directoryCurrently, SavedModelBuilder throws an exception when called with a directory that already exists. It will be helpful to add a flag overwrite when initializing SavedModelBuilder, which allows it to overwrite the contents of the directory when .save() is called.When training a model every couple of hours on fresh data, it will be easier to overwrite existing models than having to implement housekeeping code around cleaning old models or writing code to move around new model after training.
feature	Utility for repeatedly running tensors on queued input and accumulating the resultsI've written a utility function in TensorFlow that I've found quite helpful for loading Tensors with queue based inputs into memory, e.g., for looking at input data stored in the form of TF-records files or for looking at inference results. I've found it especially useful for interactively exploring the results of saved models from IPython notebooks, i.e., doing inference on small datasets or small portions of big datasets.Here's what the API looks like:from typing import Mapping, Optional, Dictdef run_repeatedly(    batched_tensors: Mapping[object, tf.Tensor],    checkpoint_dir: Optional[str] = None,    max_num_batches: Optional[int] = None) -> Dict[object, np.ndarray]:  """Repeatedly run tensors until they are exhausted.  Args:    batched_tensors: dict of tensors to evaluate, each of which should have a      first axis corresponding to a batch of examples.    checkpoint_dir: optional path to checkpoint to load.    max_num_batches: optional maximum number of batches to run.  Returns:    A dict of numpy.ndarray objects containing the result of evaluating    batched_tensors and concatenated across batches along the first axis.  Raises:    ValueError: if checkpoint_dir has no valid checkpoint  """  # the implementation makes use of tf.contrib.metrics.streaming_concat  # and a tf.train.Supervisor: it handles all the boilerplate around starting  # up a session.And a few usage example:Previewing features loaded from files:tensors = tf.contrib.learn.read_batch_features(....)arrays = run_repeatedly(tensors, max_num_batches=10)For running inference on a full dataset while also accumulating input tensors (useful for debugging):tensors = tf.contrib.learn.read_batch_features(....)predictions = make_predictions(tensor_inputs, ...)tensors.update(predictions)arrays = run_repeatedly(tensors, checkpoint_dir=path_to_saved_model)Does something like this belong somewhere in core TensorFlow, or maybe one of the contrib libraries?This is somewhat similar to Estimator.predict from tf.contrib.learn, but with a few key differences:It's more flexible, not expecting inputs in the form of a tf.learn model.It automatically concatenates across batches. In practice, I find this highly useful, because I can often store the results of a model in memory even though I don't have enough memory to run inference on everything at once.
feature	Arbitrary dimension support for tf.tile and binary operatorstf.transpose uses template specialization for dimensions <= 5, then falls back to a slightly slower generic implementation which works for any dimension:            tensorflow/tensorflow/core/kernels/transpose_functor_cpu.cc                 Line 23      in      504b91d                                             template <typename Device, typename T>               It would be nice to use the same mechanism for tf.tile and the various binary operators.
feature	8-bit quantized atrous conv2d op not supportedIt looks like that 8-bit quantized atrous conv2d op is not supported. As per the latest API,  there are only 4 quantized ops supported namely quantized_conv2d, quantized_relu_x, quantized_max_pool and quantized_avg_pool.  Any target date by which 8-bit atrous conv2d op will be available?
feature	Embedding visualizations for hi-res images training (feature request)Hi Tensorflow people, thank you all.I wonder if I could train my image classification model on my normal sized images (1080px X 1920px) but still use Tensorboard's cool embedding visualizations. I prefer to keep the images with the highest resolution possible since it proved to be important for the classification.In the tutorial (https://www.tensorflow.org/get_started/embedding_viz) the developers specify tensorflow currently supports sprites up to 8192px X 8192px, meaning you can either use a lot of low-res images (fine for MNIST 28X28 and CIFAR-10 32X32) or a few high-res images (a too small training set size). So, I was wondering if there could be a way around it.What if, we could use full-res photos for training, but downsize them for the thumbnails needed to make up the sprite?That way we could still get a sense of which picture is which in the visualization, but let the model train on higher quality data.Can I do it myself, by creating a low-res (down-sized) copy of my entire database beforehand, and use it to create the sprite etc., will the embedding event still correlate to the same source image (and the right label in the metadata)?Instead, should I put inside the training code itself, a small procedure for resizing of the full-res image after each bottleneck calculation, and then store that thumbnail in a separate folder - making sure the embedding log in the metadata actually corresponds to the right thumbnail?Environment info:Ubuntu 16.04.02 (64 bit)tensorflow 0.12.1 CPU only (64 bit). I have a NVIDIA GTX 1050ti waiting to be used if crucial for this task.I'm am a kind of a coding noob so forgive my inaccuracies and ignorance. I'm relatively new (6 months) to tensorflow and CNNs in general. I've been transfer-training inception V3 on classification of large (1080px X 1920px) images, divided to 10 labels (folders).The reason I'm asking and not just diving deep into it is that I'll have to spend a lot of time to resize my images and create the perfect sprite image and metadata file, but won't have the confidence that the trained data corresponds to the sprite image. So I want to see if it's even possible to begin with - to get full certainty of visualized thumbnail corresponding to actual full-res image used for training.Thank you for this great platform!! Tensorboard is a very powerful tool and I'm very excited to unlock the embedding visualizations' potential. @dandelionmane
feature	Support Kernels for SVMKernels in support vector machines are really usefull. I would like to test some object detection algorithms in tensorflow using svm and a radial basis kernel.I am willing to help implementing kernels for support vector machines, though I am not familiar with the sdca optimization.Is there any design doc, or plan how to add more features to the svm estimator api?
feature	Feature Request : PathNorm and PathSGDPathSGD was introduced in this paper. Is there existing support for this? If not, this is a feature request for:PathNorm computation (Equation 5 in the paper)PathSGD using the PathNormFor the first part, the interface can be to provide a function path_norm(a, b, p=2) where a and b are tensors, p is a scalar. The function returns the p-PathNorm for the "path" between the tensors a and b (assuming that b depends on a and some weights. If not, there can be an exception or simply return 0).
feature	Image Distortions should be able to be applied to batches. [Feature Request?]The tf.image distortion functions only accept a single image as an input whereas it would be much more useful to be able to place the distortion within your graph flow so any batches of images that pass through it get distorted too. I believe a current solution is as suggeested by @mrry here on Stack Overflow however it feels like, much like the other ops for images work, being able to take batches would be much more useful.Is the solution proposed by @mrry the accepted method or should the distortion functions be taking batches?
feature	Has complex MVN been implemented?I have below error for my code , where muC and SigmaC are complex vector and matrixdist = tf.contrib.distributions.MultivariateNormalFull(muC, SigmaC)TypeError: Value passed to parameter 'input' has DataType complex64 not in list of allowed values: float64, float32
feature	Log Selected Convolution AlgorithmReposting from #8928 (comment):It might make sense for the selected algorithm to be logged either to the logging system or maybe in the RunMetadata protocol buffer./CC @asimshankar
feature	Using output of `tf.argmax` as index raises TypeErrorMinimal examplea = tf.constant([1, 2, 3], dtype=tf.float32)b = tf.argmax(a)tf.Session().run(a[b])This raises a TypeErrorTypeError: Input 'strides' of 'StridedSlice' Op has type int32 that does not match type int64 of argument 'begin'.The solution is to tf.cast b into a tf.int32 before using it as an index. The output of tf.argmax should be usable as an index immediately. I feel that the current state is not consistent, is there some hidden reason for this?
feature	Graph Collections in the C APIHi,In Python we have graph collections (e.g., TRAINABLE_VARIABLES) which are stored in the Graph class. I assume that these are somehow serialized in the graph protobuf so that when a GraphDef is imported, the relevant collections are imported too. However, I do not see any option in the C API for defining such collections? Is there something that I am missing? If not, why not include that functionality in the C API?Thank you,Anthony
feature	conv2d_transpose output shape more undefined than input shapeI have posted this on StackOverflow already but haven't gotten an answer yet, plus it feels like a bug very similar to #5807 which is why I'm posting it here as well.Basically the problem is that the output shape of tf.nn.conv2d_transpose is entirely undefined, even if e.g. only one dimension in the input is unknown. So in the following code snippet, the shape of out is [3, 10, 5, 5] as expected if using the static shape to get the size of the first dimension. However if you use the dynamic shape (commented line in the snippet below), then the shape of out is [?, ?, ?, ?] instead of [?, 10, 5, 5].This is a problem for me because I am using out in a batch-normalization layer with tf.contrib.layers.python.layers.batch_norm for which certain dimensions must be defined.import tensorflow as tfinput_ = tf.Variable(tf.random_normal([3, 10, 5, 1]))w = tf.get_variable('w', initializer=tf.truncated_normal([3, 3, 5, 1], mean=0.0, stddev=0.01, dtype=tf.float32))# output_shape = [tf.shape(input_)[0], 10, 5, 5]output_shape = [input_.get_shape()[0].value, 10, 5, 5]out = tf.nn.conv2d_transpose(input_,                             filter=w,                             output_shape=tf.pack(output_shape),                             strides=[1, 1, 1, 1],                             padding='SAME')I am using TF v0.12 on Ubuntu 14.04, Python 3.5.2, installed in Anaconda environment through pip.
feature	Feature Request : Stochastic DepthStochastic Depth (aka layer dropout) has been shown to speed up and improve training in ResNets, as well as overall accuracy on testing sets. Essentially, every training step a random subset of residual layers are entirely removed from the network, and training proceeds on the remaining layers. Direct connections are made between the missing layers.It is described in this paper: https://arxiv.org/pdf/1603.09382.pdf. (Deep Networks with Stochastic Depth by Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, Kilian Q. Weinberger)I can't think of a way to implement this with the python API without reconstructing the model every training iteration, and I'm not familiar the with the C++ API / Cudnn to try to write the op myself.Of course I'm willing to try any python-only suggestions.Thanks in advance,Alex
feature	tf.image.crop_and_resize not working with uint8 imagesInstallationCustom codePip installTensorFlow version: 1.0.1Python 2.7.9CPU basedDebian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/LinuxProblemWhen reading images with opencv and then trying to use crop_and_resize on a tensor of uint8 data type, i get the following error :InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CropAndResize' with these attrs.  Registered devices: [CPU], Registered kernels:  device='CPU'; T in [DT_FLOAT] [[Node: generate_resized_crop = CropAndResize[T=DT_UINT8, extrapolation_value=0, method="bilinear"](ExpandDims, stack, zeros_like, generate_resized_crop/crop_size)]]However, when casting my tensor in float32, the program works perfectly.But the documentation specifies that it should work with uint8 datatype.Source Codeimport cv2import tensorflow as tfframe=cv2.imread('path to img.jpg',-1)raw_image=tf.placeholder(dtype=tf.uint8, shape=frame.shape, name='input_image')def img2batch(input_image):    raw_sample_tensor_4d=tf.expand_dims(input_image, 0)    patches_top=[0,0.5]    patches_bottom =[0.25,0.75]    boxes=tf.stack([patches_top, patches_top, patches_bottom, patches_bottom], axis=1)    crops=tf.image.crop_and_resize(raw_sample_tensor_4d, boxes, box_ind=tf.zeros_like(patches_top, dtype=tf.int32), crop_size=[200,200], method="bilinear", extrapolation_value=None, name="generate_resized_crop")    return cropswith tf.Session() as sess:    myBatchedImage=sess.run(img2batch(raw_image), feed_dict={raw_image:frame})Problem solved with :crops=tf.image.crop_and_resize(tf.cast(raw_sample_tensor_4d, dtype=tf.float32), boxes, box_ind=tf.zeros_like(patches_top, dtype=tf.int32), crop_size=[200,200], method="bilinear", extrapolation_value=None, name="generate_resized_crop")
feature	Tensorboard to LatexIt would be nice if there was an export option in tensorboard that would export a latex-ready version of the visible graph - perhaps using SVG, Pgfplots or something similar. It's possible now to export CSV, and create the graphic by hand... but having it baked into tensorboard would be nice.
feature	[FeatureRequest ] Add sparse_column_with_cat_prob to tensorflow.contrib.layers.python.layers.feature_column_ops.pyHi there,working on deep learning for recommender systems I came across the Google Wide and Deep model (see [1] and [2]).ProblemIn my application context there are users and items as well as the interactions between those entities. Furthermore there are item and user features, that are both, continuous and categorical. Here, we have item_features = user_features (user_features derived from user interactions).A big problem is the representation of categorical user features as a result from their interaction with different items with respectively different item features. (Some intuition to be found below)tf.contrib.layers.python.layers.sparse_column_with_keystf.contrib.layers.python.layers.sparse_column_with_hash_bucketallow to define or induce keys for categorical features that are then one-hot encoded behind the scenes - as far as I understoodThis works for items that can just have one feature value, but users can have a multivalent preference that should be reflected by a categorcial probability distribution (cpd).To capture this result we need TF to capture this cpd and compare it with the one-hot-encoded movie features. The latter is provided internally, but for realizing user profiles I couldn't find proper means meaning that within tensorflow.contrib.layers.python.layers there are no sparse columns providing this possibility which in fact is petty relevant.Proposed SolutionAdd following method feature column:sparse_column_with_cat_prob(column_name, value_prob_dict, counterpart)column_name: see sparse_column_with_keys for examplevalue_prob_dict: dictionary containing feature values (value) and associated probabilities (prob)counterpart:  eventually, name of the one-hot-encoded sparse column this one is refering toThis would allow for building user features for categorcial user interaction data, especially within recommendation contexts.IntuitionTo give some intuition see the following example from a movie recommendation context:user 1 interacts with movies A, B, C, D, and Emovie_features: genre {Romance, Action},   movie_id movie_genre  movie_length0         0     Romance           1201         1      Action            952         2      Action           1303         3     Romance           1504         4     Romance           110   user_id user_genre user_length0        0    unknown      unknown1        1    unknown      unknownObserved interactions:   user_id  movie_id0        0         01        0         12        1         13        1         24        1         35        1         4Merge, group by size and calculation the shares produces:user_id  movie_genre0        Action         0.333333         Romance        0.6666671        Action         0.500000         Romance        0.500000So, as we can observe user 0 rather prefers Romance movies whereas user 1 is indifferent between genres. As a learning outcome user 0 should be recommended more Romance than Action movies, analogously for user 1.These should be handed over to sparse_column_with_cat_prob to solve this problem.Resources[1] https://arxiv.org/abs/1606.07792[2] https://www.tensorflow.org/tutorials/wide_and_deep
feature	Split on / Has Unexpected BehaviorRepost from: #8993 (comment) /CC @dandelionmaneSo it looks like using /only works if the keys on the left does not already exist.For example this works (both on 1.1rc1):but this does not:
feature	tf.matmul should be extended for rank 1 tensorsThis:import numpy as npa = np.array([1, 2, 1])w = np.array([[.5, .6], [.7, .8], [.7, .8]])print(np.dot(a, w))# [ 2.6  3. ] # plain nice old matrix multiplication n x (n, m) -> mimport tensorflow as tfa = tf.constant(a, dtype=tf.float64)w = tf.constant(w)with tf.Session() as sess:    print(tf.matmul(a, w).eval())results in:ValueError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [3], [3,2].That's surprising and keeps tripping people up (see: http://stackoverflow.com/q/34908033/281545,  http://stackoverflow.com/q/43284897/281545, for instance), which is natural as matrix multiplication should not have any constraints apart from dimension alignment. Workarounds are verbose and complicated:  print(tf.matmul(tf.expand_dims(a,0), w).eval())  print((tf.reduce_sum(tf.multiply(tf.expand_dims(a,-1), w), axis=0)).eval())  print((tf.reduce_sum(tf.multiply(a, tf.transpose(w)), axis=1)).eval())You must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?: yesTensorFlow installed from (source or binary)?: pipTensorFlow version: tf.__version__ gives '1.0.1' - windows and python 3.5.2Bazel version (if compiling from source): -CUDA/cuDNN version: -GPU Model and Memory: -Exact command to reproduce: see aboveSource Code / LogsFull traceback (why printing the same error twice ?)C:\_\Python35\python.exe C:/Users/MrD/.PyCharm2017.1/config/scratches/scratch_31.py[ 2.6  3. ]E c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "BestSplits" device_type: "CPU"') for unknown op: BestSplitsE c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "CountExtremelyRandomStats" device_type: "CPU"') for unknown op: CountExtremelyRandomStatsE c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "FinishedNodes" device_type: "CPU"') for unknown op: FinishedNodesE c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "GrowTree" device_type: "CPU"') for unknown op: GrowTreeE c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "ReinterpretStringToFloat" device_type: "CPU"') for unknown op: ReinterpretStringToFloatE c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "SampleInputs" device_type: "CPU"') for unknown op: SampleInputsE c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "ScatterAddNdim" device_type: "CPU"') for unknown op: ScatterAddNdimE c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "TopNInsert" device_type: "CPU"') for unknown op: TopNInsertE c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "TopNRemove" device_type: "CPU"') for unknown op: TopNRemoveE c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "TreePredictions" device_type: "CPU"') for unknown op: TreePredictionsE c:\tf_jenkins\home\workspace\release-win\device\cpu\os\windows\tensorflow\core\framework\op_kernel.cc:943] OpKernel ('op: "UpdateFertileSlots" device_type: "CPU"') for unknown op: UpdateFertileSlotsTraceback (most recent call last):  File "C:\_\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py", line 671, in _call_cpp_shape_fn_impl    input_tensors_as_shapes, status)  File "C:\_\Python35\lib\contextlib.py", line 66, in __exit__    next(self.gen)  File "C:\_\Python35\lib\site-packages\tensorflow\python\framework\errors_impl.py", line 466, in raise_exception_on_not_ok_status    pywrap_tensorflow.TF_GetCode(status))tensorflow.python.framework.errors_impl.InvalidArgumentError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [3], [3,2].During handling of the above exception, another exception occurred:Traceback (most recent call last):  File "C:/Users/MrD/.PyCharm2017.1/config/scratches/scratch_31.py", line 14, in <module>    print(tf.matmul(a, w).eval())  File "C:\_\Python35\lib\site-packages\tensorflow\python\ops\math_ops.py", line 1765, in matmul    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)  File "C:\_\Python35\lib\site-packages\tensorflow\python\ops\gen_math_ops.py", line 1454, in _mat_mul    transpose_b=transpose_b, name=name)  File "C:\_\Python35\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 763, in apply_op    op_def=op_def)  File "C:\_\Python35\lib\site-packages\tensorflow\python\framework\ops.py", line 2329, in create_op    set_shapes_for_outputs(ret)  File "C:\_\Python35\lib\site-packages\tensorflow\python\framework\ops.py", line 1717, in set_shapes_for_outputs    shapes = shape_func(op)  File "C:\_\Python35\lib\site-packages\tensorflow\python\framework\ops.py", line 1667, in call_with_requiring    return call_cpp_shape_fn(op, require_shape_fn=True)  File "C:\_\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py", line 610, in call_cpp_shape_fn    debug_python_shape_fn, require_shape_fn)  File "C:\_\Python35\lib\site-packages\tensorflow\python\framework\common_shapes.py", line 676, in _call_cpp_shape_fn_impl    raise ValueError(err.message)ValueError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [3], [3,2].Process finished with exit code 1
feature	Support for nvidia-cuda-mps-serverI'm experimenting with multiple Tensorflow GPU processes and the NVIDIA Multi-Process Server.https://docs.nvidia.com/deploy/pdf/CUDA_Multi_Process_Service_Overview.pdfI have the following MNIST example as a benchmark (neural.py)import tensorflow as tfimport osfrom tensorflow.examples.tutorials.mnist import input_datadata = input_data.read_data_sets('MNIST_data_%d' % os.getpid(), one_hot=True)# construction phasex = tf.placeholder(tf.float32, shape=[None, 784])y = tf.placeholder(tf.float32, shape=[None, 10])with tf.name_scope('fc_1'):  W1 = tf.Variable(tf.truncated_normal([784, 200], stddev=0.1))  b1 = tf.Variable(tf.truncated_normal([200], stddev=0.1))  h = tf.sigmoid(tf.matmul(x, W1) + b1)with tf.name_scope('fc_2'):  W2 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))  b2 = tf.Variable(tf.truncated_normal([10], stddev=0.1))  y_predict = tf.nn.softmax(tf.matmul(h, W2) + b2)with tf.name_scope('eval'):  with tf.name_scope('loss'):    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_predict), reduction_indices=[1]))learning_rate = 0.5backprop = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)correct = tf.equal(tf.argmax(y, 1), tf.argmax(y_predict, 1))accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))#executionsess = tf.Session()sess.run(tf.initialize_all_variables())train_steps = 2000batch_size = 50for i in range(train_steps):  batch_x, batch_y = data.train.next_batch(batch_size)  sess.run(backprop, feed_dict={x: batch_x, y: batch_y})print(sess.run(accuracy, feed_dict={x: data.test.images, y: data.test.labels}))And I'm running two processes like this:$ time python neural.py & time python neural.pyWithout nvidia-cuda-mps-control running as a daemon, this is the output:0.94830.947real    0m15.602suser    0m6.172ssys     0m5.092sreal    0m15.861suser    0m6.288ssys     0m1.964sWith nvidia-cuda-mps-control running as a daemon, I'm getting an internal error:F tensorflow/core/common_runtime/gpu/gpu_device.cc:121] Check failed: err == cudaSuccess (71 vs. 0)F tensorflow/core/common_runtime/gpu/gpu_device.cc:121] Check failed: err == cudaSuccess (71 vs. 0)-bash: line 76: 47018 Aborted                 (core dumped) python neural.pyI can verify from the nvidia-mps logs in /var/log/nvidia-mps that the tensorflow Cuda context successfully started an nvidia-cuda-mps-server and connected to it./var/log/nvidia-mps/control.log[2017-04-09 10:05:09.539 Control 46322] Start[2017-04-09 10:05:21.023 Control 46322] Accepting connection...[2017-04-09 10:05:21.024 Control 46322] NEW CLIENT 46325 from user 1000: Server is not ready, push client to pending list[2017-04-09 10:05:21.024 Control 46322] Starting new server 46348 for user 1000The MPS server should be compatible with the Cuda API which Tensorflow uses, so I'm uncertain about why I'm getting this error.Tensorflow version: 1.01Ubuntu 16.04Cuda 8.0, CuDNN+-----------------------------------------------------------------------------+| NVIDIA-SMI 375.39                 Driver Version: 375.39                    ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  Tesla K80           Off  | 8915:00:00.0     Off |                  Off || N/A   51C    P8    28W / 149W |     82MiB / 12205MiB |      0%      Default |+-------------------------------+----------------------+----------------------+
feature	Feature request: In tensorboard, move "Image" and "Audio" columnsA very minor feature request: it would make sense to move the Image and Audio columns to the right, and let the first columns be: Scalar, Histogram and Distribution. Those two columns are arguably not as frequently used, and switching between looking at scalars and histograms get tiring sometimes.(but if there's plans to allow for visualising different types of variables together, that might be even better)
feature	Nearest neighbor interpolation method for tf.image.crop_and_resize ?At the moment, only bilinear interpolation is supported by crop_and_resize.However, when working with little images (and with labeled images), it sometimes makes more sense to use a nearest neighbor interpolation.Any plans of adding a nearest neighbor interpolation for the method in the near future ?
feature	Tensorflow tests failing on s390x (Farmhash related)Below tests are failing on big endian s390x platform.The tests are failing due to farmhash doesn't support s390x platform.We have already raised an issue  with farmhash. Test are passing after applying patch provided there.However, we would like to know if the testcases are used  for some complex functionality of TensorFlow?Tests: //tensorflow/contrib/layers:sparse_feature_cross_op_test  //tensorflow/contrib/learn:tensorflow_dataframe_test  //tensorflow/contrib/linear_optimizer:sdca_ops_test  //tensorflow/core:platform_fingerprint_testTensorflow version: v0.10.0
feature	Fused batch renormalizationRecently introduced batch renormalization could be very useful, but without support for a fused batch norm, it has limited use (XLA JIT still has too many problems to be used instead of a fused version)
feature	`model_checkpoint_dir` in `ProjectorConfig` is not implementedNOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.You must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:TensorFlow installed from (source or binary)?:TensorFlow version:Bazel version (if compiling from source):CUDA/cuDNN version:GPU Model and Memory:Exact command to reproduce:Describe the problem clearlymodel_checkpoint_dir is defined in the projector_config.proto definition but currently, it is not functional. I believe there is missing logic in tensorboard/plugins/projector/projector_plugin.py: in fact, a quick search reveals that model_checkpoint_dir does not appear in source. There is good reason to support this (seemingly planned) feature as checkpoint files and summary event files are often saved under different directories.I would love to contribute a solution.Source Code / LogsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
feature	C API TensorsI am currently using the C API and building a Scala API on top of it. It seems that what is done in the Python API and the Java API is that the tensors fed into sessions are being copied to buffers internal to the native library. I am also currently doing that in the Scala library but I was wondering if we can do the following:Let's assume we can share a pointer to the underlying data structure between C and Scala (through a Java NIO DirectMemoryBuffer for example). Then, is there any functionality to obtain a tensor "view" that is a slice of that tensor, directly using that buffer? I imagine that since the TF op kernels are implemented in C++, it should be possible to use the StridedSlice op directly on a tensor data structure (without needing to use a session). The same idea can be extended to other ops. So, first of all, is that true?Secondly, if it is, where is that functionality available in the C API (or exposed elsewhere) so that I can use it from within my Scala library? I currently do the indexing on the byte buffer myself, but that can be painful for arbitrary slices.One main issue with sharing a pointer is how to deal with the Java garbage collector. I haven't figured that out yet, but even if I can't do that, the above comment still applies. How can I use op kernels directly in order to manipulate tensors outside of the symbolic graph? That is useful for languages other than Python, where a library as powerful as numpy is not available.Thank you!
feature	Make `py_func` accept `SparseTensor`Describe the problem clearlyAccording to the doc, py_func accepts inp as a list of tensors (or convertible to tensor). However SparseTensor is not one of them. Could we support SparseTensor as well? Semantically there is no reason to treat SparseTensor differently.Source Code / Logsmy_sparse_tensor = tf.SparseTensor(...)tf.py_func(my_py_func, [my_sparse_tensor, ...], [tf.float32])What I got:TypeError: Tensors in list passed to 'input' of 'PyFunc' Op have types [<NOT CONVERTIBLE TO TENSOR>, ...] that are invalid.
feature	Tensorflow Still Trying to use CUDA even when Session Created with device_count={'GPU': 0}System InformationUsing the tensorflow/tensorflow:1.0.1-devel-gpu Docker image.('v1.0.0-65-g4763edf-dirty', '1.0.1')Host: Driver Version: 367.57, 3.13.0-57-genericIssueIf I Set compute mode to EXCLUSIVE_PROCESS on the Nvidia device (sudo nvidia-smi -c 1), then even though I tell the Session not to use GPUs (config=tf.ConfigProto(device_count={'GPU': 0})), Tensorflow attempts to use the GPU resulting in an inability to create session:InternalErrorTraceback (most recent call last)<ipython-input-1-cabf26c1451a> in <module>()      1 import tensorflow as tf      2 from tensorflow.python.framework import ops----> 3 with tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:      4     pass/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)   1174    1175     """-> 1176     super(Session, self).__init__(target, graph, config=config)   1177     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.   1178     self._default_graph_context_manager = None/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, target, graph, config)    550     try:    551       with errors.raise_exception_on_not_ok_status() as status:--> 552         self._session = tf_session.TF_NewDeprecatedSession(opts, status)    553     finally:    554       tf_session.TF_DeleteSessionOptions(opts)/usr/lib/python2.7/contextlib.pyc in __exit__(self, type, value, traceback)     22         if type is None:     23             try:---> 24                 self.gen.next()     25             except StopIteration:     26                 return/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc in raise_exception_on_not_ok_status()    464           None, None,    465           compat.as_text(pywrap_tensorflow.TF_Message(status)),--> 466           pywrap_tensorflow.TF_GetCode(status))    467   finally:    468     pywrap_tensorflow.TF_DeleteStatus(status)InternalError: Failed to create session.This can be demonstrated by running:import tensorflow as tffrom tensorflow.python.framework import opswith tf.Session(config=tf.ConfigProto(device_count={'GPU': 0})) as sess:    passwhen another process is using CUDA and the exclusive process mode is set.If exclusive process mode is not set, then the session is created but using nvidia-smi, I see that the process is using GPU ram (and CUDA):+-----------------------------------------------------------------------------+| Processes:                                                       GPU Memory ||  GPU       PID  Type  Process name                               Usage      ||=============================================================================||    0      2237    C   /usr/bin/python                                 61MiB |The issue seems limited to TF trying to lock the CUDA device (an allocate ~61MB memory). Subsequent computations do happen correctly on the CPU.
feature	Add support for matrix square rootPlease consider adding a matrix square root operation, with gradients.It will make it possible to implement stable whitening, which could be broadly useful, in addition to being useful for my particular problem :)Note, Cholesky whitening is currently supported in TensorFlow, but I'm not aware of any guarantees it provides regarding the correspondences between whitened and non-whitened data.It appears Eigen already has a matrix square root function, so this might not be too hard to implement.
feature	Feature: Sparse matrix multiplications for Tensors with rank > 2System Information:Windows 10, x64, Tensorflow 1.1.0.rc1Description:The 3-D sparse tensor (placeholder) multiply with 3-D dense tensor has bug, the operation will failed.x = tf.sparse_placeholder(tf.float32, shape=[None, 2, 2])y = tf.constant(np.ones([3, 2, 1]), dtype=tf.float32)z = tf.matmul(x, y, a_is_sparse=True)indices = [[1, 1, 1], [2, 0, 0], [3, 0, 1]]values = [1.0, 2.0, 3.0]dense_shape = [3, 2, 2]x_val = tf.SparseTensorValue(indices, values, dense_shape)with tf.Session() as sess:  res = sess.run(z, feed_dict={x: x_val})  print(res)expected result(3x2x1):[[[ 0.][ 1.]] [[ 1.][ 0.]] [[ 1.][ 0.]]]but output some errors actually :Traceback (most recent call last):  File "D:/Learning/master_project/clinicalText/SourceCode/Python/DNN_CWS/seg_dnn.py", line 369, in <module>    cws = SegDNN(constant.VOCAB_SIZE, embed_size, constant.DNN_SKIP_WINDOW)  File "D:/Learning/master_project/clinicalText/SourceCode/Python/DNN_CWS/seg_dnn.py", line 76, in __init__    self.loss = tf.reduce_sum(tf.matmul(self.slim_map_matrix,tf.expand_dims(tf.transpose(self.word_score),2),a_is_sparse=True))  File "E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\ops\math_ops.py", line 1755, in matmul    a = ops.convert_to_tensor(a, name="a")  File "E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\ops.py", line 639, in convert_to_tensor    as_ref=False)  File "E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\ops.py", line 704, in internal_convert_to_tensor    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)  File "E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\constant_op.py", line 113, in _constant_tensor_conversion_function    return constant(v, dtype=dtype, name=name)  File "E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\constant_op.py", line 102, in constant    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))  File "E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\tensor_util.py", line 444, in make_tensor_proto    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])  File "E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\framework\tensor_util.py", line 444, in <listcomp>    tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])  File "E:\IntelPython35\envs\tensorflow-intel\lib\site-packages\tensorflow\python\util\compat.py", line 65, in as_bytes    (bytes_or_text,))TypeError: Expected binary or unicode string, got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x00000195FA86B1D0>change the z toz = tf.sparse_tensor_dense_matmul(x,y)also failed because the shape of sparse must 2-D,but xandbhas 3-D
feature	spectral ops make freeze_graph tool trigger "No OpKernel was registered ..." errorSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yesOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.2 LTSTensorFlow installed from (source or binary): sourceTensorFlow version (use command below): v1.1.0-rc1-253-gd5a9356 1.1.0-rc1Bazel version (if compiling from source): 0.4.5CUDA/cuDNN version: 8.0/5.1GPU model and memory: NVIDIA Geforce GTX 750 TiExact command to reproduce: bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=model.pb --input_checkpoint=model.ckpt --output_graph=frozen_model.pb --output_node_names=y_convDescribe the problemThe freeze_graph tool malfunctions when processing a graph containing spectral ops.Without spectral ops, everything works just fine, all the way to inference.Might this have something to do with the fact that spectral ops don't have a CPU implementation yet?And if so, why would this lead to this error?Source code / logsTraceback (most recent call last):  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py", line 1136, in _do_call    return fn(*args)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py", line 1114, in _run_fn    self._extend_graph()  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py", line 1163, in _extend_graph    self._session, graph_def.SerializeToString(), status)  File "/usr/lib/python3.5/contextlib.py", line 66, in __exit__    next(self.gen)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/errors_impl.py", line 466, in raise_exception_on_not_ok_status    pywrap_tensorflow.TF_GetCode(status))tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'RFFT' with these attrs.  Registered devices: [CPU], Registered kernels:  <no registered kernels> [[Node: rfft = RFFT[](framesig, Const_1)]]During handling of the above exception, another exception occurred:Traceback (most recent call last):  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py", line 218, in <module>    app.run(main=main, argv=[sys.argv[0]] + unparsed)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py", line 48, in run    _sys.exit(main(_sys.argv[:1] + flags_passthrough))  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py", line 150, in main    FLAGS.variable_names_blacklist)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py", line 128, in freeze_graph    saver.restore(sess, input_checkpoint)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/training/saver.py", line 1545, in restore    {self.saver_def.filename_tensor_name: save_path})  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py", line 786, in run    run_metadata_ptr)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py", line 994, in _run    feed_dict_string, options, run_metadata)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py", line 1129, in _do_run    target_list, options, run_metadata)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py", line 1149, in _do_call    raise type(e)(node_def, op, message)tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'RFFT' with these attrs.  Registered devices: [CPU], Registered kernels:  <no registered kernels> [[Node: rfft = RFFT[](framesig, Const_1)]]Caused by op 'rfft', defined at:  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py", line 218, in <module>    app.run(main=main, argv=[sys.argv[0]] + unparsed)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py", line 48, in run    _sys.exit(main(_sys.argv[:1] + flags_passthrough))  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py", line 150, in main    FLAGS.variable_names_blacklist)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py", line 103, in freeze_graph    _ = importer.import_graph_def(input_graph_def, name="")  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/importer.py", line 308, in import_graph_def    op_def=op_def)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/ops.py", line 2336, in create_op    original_op=self._default_original_op, op_def=op_def)  File "bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/ops.py", line 1228, in __init__    self._traceback = _extract_stack()InvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'RFFT' with these attrs.  Registered devices: [CPU], Registered kernels:  <no registered kernels> [[Node: rfft = RFFT[](framesig, Const_1)]]
feature	Why are there not dbn and rbm in tensorflow model zoo?Can anyone add them to tensorflow to make it better?
feature	Create support for a score threshold in NonMaxSuppression to skip over boxes with low scoreRight now tensorflow::ops::NonMaxSuppression only prunes away boxes that have a high IOU overlap with previously selected boxes. It would be nice to also support a threshold on score so that the algorithm can skip over boxes that have a score below that threshold. We strongly believe this feature will speed up nms. Is there a plan to add this score threshold as a parameter?
feature	Sampling from a categorical distribution without replacementBoth tf.multinomial() and tf.contrib.distributions.Categorical.sample() allow to sample from a multinomial distribution. However, they only allow sampling with replacement.In constrast, Numpy's numpy.random.choice() has a replace parameter that allows sampling without replacement. Would it be possible to add a similar functionality to TensorFlow?One use case is sampling examples from the dataset proportional to the model's last loss on them. When an example generates a very large loss, the next batch will mainly consist of that example. Using sampling without replacement, we can avoid this problem.I see that sampling with replacement can be parallelized and implemented in a vectorized way, but I don't think sampling speed is a bottleneck in most people's programs.
feature	SVM output layer in tensor flowThe SVM output layer has been shown to accelerate model training in https://arxiv.org/pdf/1306.0239.pdf.  Is the SVM output layer available as an alternative for tf.nn.softmax in tensorflow at this moment?
feature	[idea] new Op: Conv2DWithBiasActivation for Backends that Support Higher Level OpThis is a repost of the comment here:Along the lines of MklConv2DWithBias, I suggest defining a new primitive Op, Conv2DWithBiasActivation that can be used to define kernels on platforms that support a higher level primitive conv-bias-acitivation unit.As far as the (new) fused Conv2D Op that I am using for my BNNS implementation, I used the MKL Conv2D Op as a predicate. In that case Intel has defined a new Op that includes both the convolution Op and the BiasAdd Op. My Conv Op actually isn't pulling in just the activation function, rather, my Op and the MKL both have the bias add has been fused as well.I understand that the primitive Conv2D op in TF does not currently handle activations or bias addition, but this op may be "too primitive". In fact cuDNN is now moving in the direction of fusing these three into one kernel (see: #8828). Perhaps, a different FusedConv2D Op should be added that can be used by not just BNNS but also cuDNN v6 and any other underlying platform implementations that can take advantage of doing all three ops together. This would be  along the lines of batch norm, which now offers a fused version of the Op to reduce the number of primitive Ops used.AddendumThere are even more implementations that can benefit from fusing Conv-Bias-Activation. Others include:Metal Performance Shaders (#7958). Here it might be extra extra important because of 1. avoiding extra copies back and forth from GPU memory (ie using the tuned MPSTemporary​Image and 2. because MPS uses a very weird memory layout and ideally transposing to this only needs to be done once.MKL (as linked above, perhaps the MKL specific Op (MklConv2DWithBias) can be unified with this new Op.cuDNN v6/CC @drpngx @petewarden @flx42 @gunan
feature	Ability to Create New Device Context (GPU)If I destroyed GPU context for any reason and tried to start new tensorflow session I got this error CUDA_ERROR_CONTEXT_IS_DESTROYED and notebook kernel crashes. So, it will be a nice feature for python users if they can create a new context for tensorflow if one is destroyed.
feature	Broadcasting support in `tf.where`tf.where does not support broadcasting like its numpy equivalent at the moment. How easy would it be to add broadcasting?Here are some examples.condition = np.random.normal(0, 1, (3, 5, 1, 1)) < 0x = np.zeros((7, 11))y = np.ones((7, 11))np.where(condition, x, y).shape  # (3, 5, 7, 11)tf.where(condition, x, y)>>> InvalidArgumentError: Shapes must be equal rank, but are 2 and 4 for 'Select_2' >>> (op: 'Select')  with input shapes: [3,5,1,1], [7,11], [7,11].condition = np.random.normal(0, 1, (3, 5, 1, 1)) < 0x = np.zeros((1, 1, 7, 11))y = np.ones((1, 1, 7, 11))np.where(condition, x, y).shape  # (3, 5, 7, 11)tf.where(condition, x, y)>>> InvalidArgumentError: Dimension 0 in both shapes must be equal, but are 1 and 3 >>> for 'Select_3' (op: 'Select') with input shapes: [3,5,1,1], [1,1,7,11], [1,1,7,11].
feature	xorshift128+ version of (stateless) random opsCurrently, TensorFlow's random numbers use the Philox counter mode generator, which is extremely easy to parallelize on both CPU and GPU.  This applies to both the normal stateful ops and the new tf.contrib.stateless versions with custom seeding.xorshift128+ is a simpler generator that could conceivably speed up random number generation.  Unfortunately, it is not a counter mode generator, and is thus difficult to parallelize or use safely in a random access setting.Until now!  Commit girving/tensorflow@60abb26 on branch https://github.com/girving/tensorflow/tree/xorshift implements random access into the xorshift128+ generator in a reasonably efficient manner, using some finite field machinery.  Specifically, jumps in xorshift128+ are represented as elements of the finite field GF(2^128), composed to produce other jumps, then mapped through linear maps to produce xorshift128+ values.However, the code is a proof of concept.  A decent amount of further work would have to be done to get committed to TensorFlow.  In particular, the parallelism code on both CPU and GPU would have to be written, by computing one jump per thread of execution (many jumps can be computed more cheaply vs. one at a time).  The current code is also nonportable: it assumes special  instructions for carryless multiplication of polynomials over GF(2).  These instructions are available on recent Intel and AMD CPUs, but a slow path would need to be written to handle everything else.Also, whether the result would actually be faster is an open question.I don't have time to do the remaining work, so I am leaving this here as a project in case someone wants to take it on with my help.
feature	Import additional RNNCells in tf.contrib.rnn.__init__.pySome RNNCells, like IntersectionRNNCell, NASCell, are implemented in tf.contrb.rnn.python.ops.rnn_cell. I would like to try these cells but found that these can't be used as the same way as LSTMCell, which I can import by from tf.contrib.rnn import LSTMCell. I checked the code found that these cells are not imported by tf.contrib.rnn.__init__.py.Is there any way to try these cells? Or is it possible to import these cells in tf.contrib.rnn.__init__.py.Thanks.
feature	Not all image ops accept image tensors with batch dimensionIt appears that only some of the image ops (e.g. tf.image.random_saturation()) only accept single images (rank-3 tensors), while others allow batches of images (rank-4 tensors). Should this be made more consistent so that all image ops allow for higher-rank tensors? There doesn't seem to be much about this in the API documentation (some ops just say that the last dimension needs to be 3).System InformationHave I written custom code?: YesOS Platform and Distribution: Ubuntu 16TensorFlow installed from (source or binary)?: binaryTensorFlow version: 1.0.1Bazel version (if compiling from source): N/ACUDA/cuDNN version: N/AGPU Model and Memory: N/AExact command to reproduce:import tensorflow as tfimages = tf.placeholder(tf.float32, shape=(None, None, None, 3), name='images')# This is OKx = tf.image.random_contrast(images, lower=0.5, upper=1.0)# Throws an exception because `images` is rank-4x = tf.image.random_saturation(images, lower=0.5, upper=1.0)
feature	decode_image return tensor without shape in pythonSystem InformationOS Platform and Distribution (i.e. Linux Ubuntu 16.0): CentOS Linux release 7.0.1406 (Core)TensorFlow installed from (source or binary)?: python3 pipTensorFlow version : v1.0.0-65-g4763edf-dirty 1.0.1Python version : Python 3.5.2 :: Anaconda custom (64-bit)Describe the problem clearlyWhen I decode a jpeg file to a tensor with decode_jpeg, the code ran normally.but if I use decode_image instead of decode_jpeg for more compatibilities, It raised a ValueError as follow.Is It a bug?ThanksSource Code / Logsdef preprocess_image(image_path):    file_content = tf.read_file(image_path)        #image = tf.image.decode_jpeg(file_content)    image = tf.image.decode_image(file_content)    image = tf.image.per_image_standardization(image)    image = tf.image.resize_images(image, [480, 640])output :Traceback (most recent call last):  File "/data/home/zhangbowen/is_vehicle/classify.py", line 29, in <module>    main()  File "/data/home/zhangbowen/is_vehicle/classify.py", line 26, in main    image = preprocess_image(image_file)  File "/data/home/zhangbowen/is_vehicle/classify.py", line 15, in preprocess_image    image = tf.image.resize_images(image, [480, 640])  File "/data/home/zhangbowen/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/image_ops_impl.py", line 643, in resize_images    raise ValueError('\'images\' contains no shape.')ValueError: 'images' contains no shape.
feature	Equality operator not overloadedIt's unexpected and a gotcha that some comparison operators (>, <, <=, =>) are overloaded but not all (==, !=). Is there a particular reason for this? I think either all standard operators should be overloaded, or none at all.In [1]: import tensorflow as tfIn [2]: tensor = tf.zeros((3,5))In [3]: tensor > 0Out[3]: <tf.Tensor 'Greater:0' shape=(3, 5) dtype=bool>In [4]: tensor == 0Out[4]: FalseThis is on TensorFlow 1.1.0rc2.
feature	Check in tensorboard_bower_dependency_sync.py fileHi TF Developers,Could you kindly check in the tensorboard_bower_dependency_sync.py file to the repo? We need to customize the build process and having that file would be really helpful. Thanks a lot in advance!Ying
feature	PreventGradients in SoftmaxCrossEntropyWithLogit opsSparseSoftmaxCrossEntropyWithLogits cannot take second order gradients (It's not a beautiful hack, and I am not sure how much computational speed up it will bring).Adding PreventGradient node in the gradient graph seems to contaminate the computation graph structure, e.g. I am doing custom forward-mode automatic differentiation.Reference: https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/python/ops/nn_grad.py#L334
feature	Max_pool with dynamic ksizeI have the following code for a convolutional layer. This layer is part a larger computational graph.# Define the shape of the filterfilter_shape = [1,                config.char_filter_size,                config.dim_char,                config.dim_char]# Define the convolutional layer weights and biasesW_conv = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1),                     name="W_conv")b_conv = tf.Variable(tf.constant(0.1, shape=[config.dim_char]),                     name="b_conv")# Do 2d convolutionconv = tf.nn.conv2d(char_embeddings,                    W_conv,                    strides=[1, 1, 1, 1],                    padding="VALID",                    name="conv")# Apply nonlinearity# h_conv has the same shape as convh_conv = tf.nn.relu(tf.nn.bias_add(conv, b_conv),                    name="conv_relu")# Maxpooling h_conv over dim 2 (char dim)# ERROR HEREconv_pooled = tf.nn.max_pool(h_conv,                             ksize=[1, 1, tf.shape(h_conv)[-2], 1],                             strides=[1, 1, 1, 1],                             padding='VALID',                             name="conv_max_pool")When trying to run, I get the error:TypeError: Expected int for argument 'ksize' not tf.Tensor shape=() dtype=int32.is tf.nn.max_pool unable to handle dynamic ksize?
feature	Abandon gerrit and use github for everythingGerrit review workflow is very hard to maintain and follow. A lot of project abandoned it and turns to github finally.Really hope tensorflow will use github for all the cooperation workflow. Google Kubernetes and Docker are all excellent examples  for how to use github maintain a huge and global scale open source project successfully.github + travis CI + slack is awesome.  Just make everything be a PR :)
feature	[Java] Distributed mode supportDescribe the problemIs there any plan to add distributed mode to the Java API? I checked the code and it seems to be doable (unless I missed something) so I was wondering if anyone is already working on it? I went through the issue tracker and PRs but couldn't find anything related.
feature	Enable use of cuDNN RNNs with optimizers other than GradientDescentOptimizerCurrently cuDNN-based RNNs in TF are limited to GradientDescentOptimizer (#6620). This is a serious limitation given the widespread use of other optimizers. The claim that this cannot be supported in TF because cuDNN RNN don't have known shapes at static time seems overly pessimistic. Just like RNNParamsSaver provides a mechanism to convert between canonical shaped variables and the parameter buffer, a simple wrapper can be provided that does this automatically for cuDNN RNNs, so that the size of the parameter buffer is statically calculated and then used to define the variable, especially since the shape of the parameter buffer is just a 1D vector anyway.
feature	Feature Request : Gradients for tf.contrib.image.rotate()I wish to propagate gradients through image rotation. This is currently not supported:import tensorflow as tfimport numpy as npimages = tf.zeros(shape=[5, 10, 10, 1])angles = 2 * np.pi * np.random.random(5) - np.piout = tf.contrib.image.rotate(images, angles)out_sum = tf.reduce_sum(out)images_grad = tf.gradients(out_sum, [images])print images_gradgives[None]
feature	No 1-dimensional max pool?It seems that there is no 1-dimensional max pool.I'm using one for my own projects.  Should I submit a pull request?
feature	Ops added after calling start_queue_runners() are broken(Using the OSX CPU-only  v.0.6 wheel).I think this is a minimal example:image = tf.constant(0)images = tf.train.shuffle_batch([image], batch_size=1, capacity=100, min_after_dequeue=1)a = tf.constant(1)with tf.Session():    b = a+1    tf.train.start_queue_runners()    c = a+1    print(a.eval())    print(b.eval())    print(c.eval())It usually crashes on the c.eval() giving the following error:Traceback (most recent call last):  File "test.py", line 11, in <module>    print(c.eval())  File ".../python2.7/site-packages/tensorflow/python/framework/ops.py", line 460, in eval    return _eval_using_default_session(self, feed_dict, self.graph, session)  File ".../python2.7/site-packages/tensorflow/python/framework/ops.py", line 2910, in _eval_using_default_session    return session.run(tensors, feed_dict)  File ".../python2.7/site-packages/tensorflow/python/client/session.py", line 368, in run    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)  File ".../python2.7/site-packages/tensorflow/python/client/session.py", line 446, in _do_run    six.reraise(e_type, e_value, e_traceback)  File ".../python2.7/site-packages/tensorflow/python/client/session.py", line 428, in _do_run    target_list)tensorflow.python.pywrap_tensorflow.StatusNotOK: Not found: FetchOutputs node add_1:0: not foundEven just a clearer error message in this situation would be a big help.
feature	Misleading error message when running restore op with path to an .index fileUsing V2 checkpoint files, calling saver.restore() with path to the .index returns the following error:Error loading checkpoint from /home/peci1/tradr-git/tradr-ws/src/tradr-simulation/safe_exploration/scripts/ddpg/models/my-model.index: Not found: Tensor name "ActorFullyConnected1/b" not found in checkpoint files /home/peci1/tradr-git/tradr-ws/src/tradr-simulation/safe_exploration/scripts/ddpg/models/my-model.indexI think it'd be nicer to get an error saying "File ... is not a checkpoint. Please, remove the .index extension". This is roughly what you get if you pass any other file.
feature	Error on Windows when installed in a virtualenv that has a non-ASCII character in the pathSystem informationOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64TensorFlow installed from (source or binary): binary from PyPITensorFlow version (use command below): 1.1.0Exact command to reproduce:from tensorflow.contrib.rnn.python.ops.gru_ops import *Describe the problemI encountered this when importing keras but it's reproducible with the command above. My virtualenv is in a folder that has an accented character in its name (see the log below). If I install TensorFlow globally, it works.Source code / logsD:\Marci\Programozás\algorimp\test>venv\scripts\python -c "from tensorflow.contrib.rnn.python.ops.gru_ops import *"Traceback (most recent call last):  File "<string>", line 1, in <module>  File "D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\__init__.py", line 26, in <module>    from tensorflow.contrib import crf  File "D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\crf\__init__.py", line 32, in <module>    from tensorflow.contrib.crf.python.ops.crf import _lengths_to_masks  File "D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\crf\python\ops\crf.py", line 44, in <module>    from tensorflow.contrib.rnn.python.ops import core_rnn_cell  File "D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\rnn\__init__.py", line 80, in <module>    from tensorflow.contrib.rnn.python.ops.gru_ops import *  File "D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\rnn\python\ops\gru_ops.py", line 32, in <module>    resource_loader.get_path_to_datafile("_gru_ops.so"))  File "D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\util\loader.py", line 55, in load_op_library    ret = load_library.load_op_library(path)  File "D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\python\framework\load_library.py", line 64, in load_op_library    None, None, error_msg, error_code)tensorflow.python.framework.errors_impl.NotFoundError: D:\Marci\Programozás\algorimp\test\venv\lib\site-packages\tensorflow\contrib\rnn\python\ops\_gru_ops.dll not found
feature	BernoulliWithSigmoidProbs is obsoleteI think tf.contrib.distributions.BernoulliWithSigmoidProbs can be removed, because Bernoulli itself has a logits parameter that does the exact same thing, afaik. If you agree, I can make a pull-request if necessary.
feature	tf.metrics.accuracy maintains a running accuracy?I use the tf.metrics.accuracy, however it is a bit counter-intuitive in that it maintains a running accuracy (the doc agrees with this).  The following simple script illustrates the situationimport os# supress tensorflow logging other than errorsos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'import numpy as npimport tensorflow as tfprint(tf.__version__)# 1.1.0x = tf.placeholder(tf.int32, [5])y = tf.placeholder(tf.int32, [5])acc, acc_op = tf.metrics.accuracy(labels=x, predictions=y)sess = tf.InteractiveSession()sess.run(tf.global_variables_initializer())sess.run(tf.local_variables_initializer())v = sess.run([acc, acc_op], feed_dict={x: [1, 0, 0, 0, 0],                                       y: [1, 0, 0, 0, 1]})print(v)# [0.0, 0.8]v = sess.run(acc)print(v)# 0.8v = sess.run([acc, acc_op], feed_dict={x: [1, 0, 0, 0, 0],                                       y: [0, 1, 1, 1, 1]})print(v)# [0.8, 0.4]v = sess.run(acc)print(v)# 0.4My concerns arethe use of accuracy is bit surprising, are we supposed to manually construct the normal accuracy?IMHO, it is better toimplement the normal accuracy behavior orprovide a clean way to reset the local variables created by tf.metrics.accuracy, i.e., the count and total.
feature	Securing Tensorflow models on AndroidDescribe the problemI am using android to deploy my Tensorflow model. I am obfuscating names already but that wont stop people stealing and just plugging and playing graph file in their apps. Feature request for accepting encrypted graph files to prevent our graph files from leaking or any pointers on how to implement it.
feature	Ops for Reading from Cloud SpannerIs there any plan to make F1 public (be it a service in Google Cloud or just open source) and make it possible to store TensorFlow tensors in F1? I ask because as far as I can tell (might be wrong), there isn't a "native" database for TensorFlow (meaning a C++ reader with direct connection to the DB), and F1 supports Protobuf columns which would seem like a natural fit for Tensorflow data.From hereThe F1 data model is very similar to the Spanner datamodel. In fact, Spanner’s original data model was more likeBigtable, but Spanner later adopted F1’s data model. Atthe logical level, F1 has a relational schema similar to thatof a traditional RDBMS, with some extensions includingexplicit table hierarchy and columns with Protocol Bufferdata types.
feature	4D and higher dimensional convolutional layersAre there any plans to implement 4D or higher convolutional layers?
feature	Placing Variables on the cpu using `tf.contrib.layers` functionsDear tensorflow team,After constructing my model using the functionality provided by tf.contrib.layers I now want to extend my model over several GPUs. I learned that it might be beneficary to place Variables on the CPU when doing that, to reduce data transfer overhead. After not seeing an easy way to do this I found a workaround I described on stackoverflow. My solution is to generate Variable-nodes in the graph where the Variable-getter of the fully_connected layer for example would expect the variables to be.As this is not a very nice solution, I messed with the fully_connected layer and the _build_variable_getter function to basically allow me to specify, where I want to place the variabels. Thus afteradding the kwarg variable_device to tf.contrib.layer.fully_connectedadding the kwarg variable_device to tf.contrib.layer._build_variable_getteradding the kwarg device to tf.contrib.layer._model_variable_getterand passing this as kwarg to model_variable defined in tensorflow.contrib.framework.python.ops.variablesI get the desired functionality when using the fully_connected layer.Below you find the modified version of layers.pyIn my eyes this would be a very useful feature for all layers that contain trainable variables, which is why I would like to make a request for this feature.If you think the supplied modification is good enough, I can also try to make a pull request, after updating the other layers.Best, JohannesSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): As described above, I didOS Platform and Distribution: Linux Ubuntu 16.04TensorFlow installed from (source or binary): binaryTensorFlow version: ('v1.0.0-65-g4763edf-dirty', '1.0.1')CUDA/cuDNN version: 8, 5.1GPU model and memory: Titan X Pascal, 12GBSource code / logsSeestackoverflowmodified layers.py
feature	GPU version of self_adjoint_eigSystem informationOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux RBSylaptop 4.9.0-1-amd64 #1 SMP Debian 4.9.6-3 (2017-01-28) x86_64 GNU/LinuxTensorFlow installed from (source or binary):$ pip3 install tensorflow-gpuTensorFlow version (use command below):tf.VERSION = 1.1.0tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5GPU model and memory:Found device 0 with properties:name: GeForce GTX 1070major: 6 minor: 1 memoryClockRate (GHz) 1.645pciBusID 0000:01:00.0Total memory: 7.92GiBFree memory: 7.31GiBDescribe the problemIt looks like there is no eigen vector kernel that would run on GPU. Even the CPU version seems to be serial as it uses only one core for a single matrix.Source code / logsThis code just create a random 10*10 matrix and try to compute its eigen values and vectors on the GPU.mat = np.random.random((10, 10))sess = tf.Session()with tf.device('/gpu:0'):    eigen = tf.self_adjoint_eig(mat)sess.run(eigen)Which fails with the error:InvalidArgumentError (see above for traceback): Cannot assign a device to node 'SelfAdjointEigV2': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.     [[Node: SelfAdjointEigV2 = SelfAdjointEigV2[T=DT_DOUBLE, compute_v=true, _device="/device:GPU:0"](SelfAdjointEigV2/input)]]And for a large enough matrix, it can be seen that the CPU kernel only uses one core.
feature	Feature request: other types of padding besides zero-padding.I would like to have other options of padding for tf.pad and convolution ops.Some types that come to my mind right now:reflectconstant value (other than zero)maybe implement other options of numpy.pad: http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.pad.html
feature	model_dir deletion while running python scriptSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yesOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win10TensorFlow installed from (source or binary):  binary, installed via pipTensorFlow version (use command below): 1.1.0Bazel version (if compiling from source):naCUDA/cuDNN version: naGPU model and memory: naExact command to reproduce:?Describe the problemFeature request: As part of an hyperparameter optimization routine, I use tensorflow's high level api tf.contrib.learn.DNNRegressor() (should apply to the others as well). The problem is that it creates for each instance an own new model_dir, which I can't delete during running the python script (even after the model instance is overwritten and no longer in RAM). It is a problem because it consumes rather fast large amounts of disk storage. As far as I can see there is no way to delete the temp dir while running the program, only once it terminates the dir is released and removable.Source code / logshere is a pseudo code example:https://stackoverflow.com/questions/43639516/model-dir-deletion-in-tensorflow
feature	How can I load data from a data file just like http://projector.tensorflow.org/ does when using Tensorboard embedding projectorAt http://projector.tensorflow.org/  we can choose a data file from our own computer by the Load data button(see the red rectangle below) and visualize the high-dimensional dataBut when I tried to using Tensorboard embedding on my own computer (follow the instruction at https://www.tensorflow.org/get_started/embedding_viz and start a server on localhost:6006 by command tensorboard --logdir=LOG_DIR )I just find the Load data button doesn't exist (see below)So I want to ask when I run Tensorboard on localhost, how can I enable the load data button like http://projector.tensorflow.org/ does, thus I can visualize the high-dimensional data by uploading my file rather than writing code ?thanks a lot :)
feature	Gather/Slice/StridedSlice Gradients Support in the C++ APIHi,I noticed that there is currently no gradient support in the C++ API for the gather, slice, and strided slice ops. Would it be too difficult to add support for those gradient ops? I am asking because they are ops very frequently used in the context of machine learning models and without them building ML models can be unnecessarily complicated.Thank you!P.S. I have noticed that the Python API implementation of the gather op gradient uses indexed slices, but I am not sure if that is entirely necessary and can thus probably also be supported in the C++ API.
feature	Estimator's argument checking overzealous : model_fn has following not expected args: ['self']I'm using TensorFlow (1.1) high-level API Estimators to create my neural net. But I'm using it into a class and I have to call an instance of my class to generate the model of the neural network. (Here self.a)class NeuralNetwork(object):  def __init__(self):    """ Create neural net """    regressor = tf.estimator.Estimator(model_fn=self.my_model_fn,                                       model_dir="/tmp/data")    // ...  def my_model_fn(self, features, labels, mode):  """ Generate neural net model """    self.a = a    predictions = ...    loss = ...    train_op = ...    return tf.estimator.EstimatorSpec(      mode=mode,      predictions=predictions,      loss=loss,      train_op=train_op)But I get the error : ValueError: model_fn [...] has following not expected args: ['self']. I tried to remove the self for the args of my model but got another error TypeError: … got multiple values for keyword argument.Solution for now (as it was suggested on StackOverflow) is to use a lambda function to wrap my function my_model_fn (see below) but it will be nicer without it.class NeuralNetwork(object):  def __init__(self):    """ Create neural net """    regressor = tf.estimator.Estimator(        model_fn=lambda features, labels, mode: self.my_model_fn(features, labels, mode),        model_dir="/tmp/data")    // ...
feature	[feature] Support Cross Compiling with tfcompileTensorflow (using XLA) is able to AOT compile a graph using tfcompile. There does not seem to be a way to, or it it not documented, cross compile the graph (ie compile on OS X for deployment on iOS). (Related SO question).I suggest adding a means of performing this cross compilation.
feature	Run half-precision models on AndroidIs it possible to run half-precision (float16) graphs on Android (arm64-v8a/AArch64 supports half-precision)? If so, what would be the approach to do that? Trying to run a float16 graph gives an exception saying that only INT32 and Float32 ops are supported.Thank you in advance,
feature	Android Inference AAR Release BuildsAndroid Release requestYou currently have nightly Android builds.  Is it possible to also have a Jenkins job that publishes stable release (and maybe RC) builds for Android?Or alternatively, can you publish release and RC builds of your Android Inference AAR out somewhere they can be pulled as dependencies by Gradle (Maven Central or wherever other Android dependencies are stored)?
feature	[Java][Suggestion] Add Enum with all OperationsCurrently it is hard for beginners to start with the Java API of TF. Mostly because the function names staed in the python tutorial do not apply to the Operation names used in Java. It would be nice if we had an Enum Containing all standart possible Operations.grapth.opBuilder(type, name)I am currently struggling to find out what the correct name of "Multiply" is.I have digged my way thorgh the code and most of the operations are registered trought REGISTER_OP and I could trace down the java methods to TF_OperationDescription(TF_Graph* g, const char* op_type, const char* node_name) in c_api_internal.h. But I absolutly dont know were the operations are storred.Also nice would be a table "python function name" to "internal operation name"
feature	Expose TensorFlow build detailsRequesting addition of API method(s) to enable programmatic checking of TensorFlow version and other build capabilities (such as if TF was compiled with GPU support, for eg.). I would find this useful in deployment scripts that operate in foreign TensorFlow environments.
feature	Error restoring checkpoints using tf.estimator.Estimator or tf.contrib.learn.Estimator, If moved since trainingSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04TensorFlow installed from (source or binary): binaryTensorFlow version (use command below): 1.1Bazel version (if compiling from source):CUDA/cuDNN version: 8.0/5.1GPU model and memory: Titan XExact command to reproduce:output_dir = /location1estimator = learn.Estimator(model_fn=model_fn, model_dir=output_dir,                                params=params, config = config)estimator.fit(input_fn=train_input_fn, steps = 1000)$ cp -r /location1 /location2$ rm -rf /location1output_dir = /location2estimator = learn.Estimator(model_fn=model_fn, model_dir=output_dir,                                params=params, config = config)estimator.fit(input_fn=train_input_fn, steps = 1000)InvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on /location1Describe the problemI had a need to copy my checkpoints to continue training on another machine, without access to the original location.The root cause seems to be in tensorflow/python/training/session_manager.py  at line 177 whereckpt = saver_mode.get_checkpoint_state(checkpoint_dir) is used to find the checkpoint path used at training, and then line 188saver.restore(sess, ckpt.model_checkpoint_path) is used to restore, instead of using, for example, the latest checkpoint available provided by the model_dir argument to estimator.fit, which is the behavior I expected.In any case, it would be nice to be able to point an estimator.fit() or .train() (v1.1) call to continue at a specific checkpoint file.
feature	Resize image for ndIs there a functionality of resize image for n-d where n > 2? It seems currently tensorflow only support resize images for 2d images (4D tensor). Could you add the functionality?
feature	[inputs] instead of inputs for rnn_cell?In current rnn_cell implementation, It gets inputs as 2-d tensor for cell inputs,Hence embedding layer before the actual rnn_cell gets a little bit annoying for making 'decoder'.I really like the "wrapper" concept in current implementation that expand by each layer with embedding, residual net, or dropouts.If rnn_cell gets list of '2-d' tensor like [inputs1, inputs2, ...], then the concept of wrapper can be fully used in decoder as well as simple rnn or encoder;for a little more concretely,if "embedding wrapped cell" gets input list [inputs, context_inputs_from_attention],then the "embedding wrapped cell" can just pass [embedded_inputs, context_inputs_from_attention] to the real "LSTM_cell" and "LSTM_cell" can weight sum those inputs in inputs list.what do you think about this idea?
feature	feature request: support placeholder for parameter k in tf.nn.in_top_kCurrently tf.nn.in_top_k requires an int as k, while tf.nn.top_k does support a 0-D int32 Tensor as parameter k. This is kind of inconsistent and inconvenient.Is it possible to allow k to be a 0-D int32 Tensor in tf.nn.in_top_k?
feature	Feature request: Add 'axis' option for 'tf.boolean_mask()'tf.boolean_mask() is extremely useful when it comes to training.However, the present tf.boolean_mask() does not have an axis option, thus masking some specific dimension of an array could be troublesome.Appreciate your consideration.
feature	Tensorflow searching for outdated version of cudnn64_6.dll (Import Error)So I tried my first install of tensorflow-gpu on Window 7x64 with a GTX1080 and was met with a DLL import error python exception that wasn't very helpful at all (that message needs to be updated to indicate what DLL it can't find!).Anyways, I decided to attempt the import tensorflow function with proc_mon watching all the file I/O from python... Turns out, Tensorflow is searching for 'cudnn64_5.dll' ... The latest 'cudnn-8.0-windows7-x64-v6.0' installs the following dll: 'cudnn64_6.dll' ... By copying the newer DLL to the DLL name that tensorflow expects, I was able to get past this issue and run tensorflow.Tensorflow needs to be updated to support the latest cudnn64_6 dll that NVidia provides by default.
feature	Adding a random seed parameter for tensorflow.layer.denseHi,I noticed that the tensorflow.layer.dense wrapper does not have a seed parameter, and I was wondering what you think about adding one. E.g., this seed would be used to initialize the random weights and bias units (if they are not initialized to zero).Related to the points above,  it is currently also not clear how the weights are initialized. I.e., what distribution the random numbers are drawn from (if not zero). Does someone have some info on this? -- maybe this could be added to the API docs.What do you think? (I am happy to contribute a random seed implementation and a doc update if that's desirable.)
feature	Feature Request: "training" argument for contrib.rnn.DropoutWrapper like the one in tf.layers.dropoutSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.0.4TensorFlow installed from (source or binary): BinaryTensorFlow version (use command below): 1.1.0Feature Request: "training" argument for contrib.rnn.DropoutWrapper for applying dropout depending on train/inference phase.In tf.layers.dropout, the training parameter is a handy setting that lets you apply dropout depending on whether the model is training or doing inference. It's very convenient to be able to pass a boolean to the model placeholder and have it automatically do the right thing when it comes to dropout.Unfortunately, tf.contrib.rnn.DropoutWrapper does not have this same parameter, and I think it would greatly benefit from it. This is a feature request for it.I tried implementing it myself with tf.cond and either returning the dropped-out outputs/states or the untouched ones, but I couldn't figure out how to share the variables between them in the cond.
feature	Custom configuration of tf.estimator.Estimator - unfavorable change on tf1.1This is a feature request, following a change in behavior from TF1.0 to TF1.1.Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes.OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 8 (jessie) 64-bitTensorFlow installed from (source or binary): installed using pipTensorFlow version (use command below): v1.1.0-rc0-61-g1ec6ed5Bazel version (if compiling from source):CUDA/cuDNN version: N/AGPU model and memory: N/AExact command to reproduce:my_estimator = tf.estimator.Estimator(model_fn = my_model_fn,model_dir = my_model_dir,config=tf.contrib.learn.RunConfig(save_checkpoints_steps=20,save_checkpoints_secs=None,save_summary_steps=40,))Describe the problemon tf version 1.0 we could easily configure the checkpoint dump (and more) of tf.contrib.learn.Estimator, as stated above: by sending as an input to the estimator tf.contrib.learn.RunConfig with the desired configuration.on tf version 1.1 this became more complex: the above (and more) configurations in RunConfig are static, and changing them requires either changing the original tf code, or maybe creating a class inheriting from tf.estimator.RunConfig to serve as the config for the estimator.Source code / logsin tf.estimator.RunConfig (v1.1), e.g.:@propertydef save_checkpoints_secs(self):return 600in tf.contrib.learn.RunConfig (v1.0, yet supported on tf1.1):@propertydef save_checkpoints_secs(self):return self._save_checkpoints_secs
feature	Optimizers in the C++ APIThere is currently no Optimizer in the C++ API compared as the ones that we can find in the Python API.It means, when using only the C++ API that we have to manually collect the gradients and apply them.Don't you think it should be a convenient add? Retrieving the gradients and applying them is kind of hard and error prone. If yes, I could work on it and create an Optimizer + GradientDescentOptimizer in the C++ API.I maybe missed something.
feature	Where is tf.layers.flatten?I hope this question is considered suitable for asking here on GitHub rather than StackOverflow as it relates to a possibly missing feature of the TensorFlow API. I apologize beforehand if I am wasting your time.This concerns TensorFlow 1.1.0 and tf.layersThe tutorial on tf.layers uses manual reshaping to get from 4-rank to 2-rank tensors (search for the word flatten):https://www.tensorflow.org/tutorials/layersThis is not very elegant and I would prefer to use a flatten() function.The documentation for tf.layers.dense() says something about flattening the input, but it apparently does something else, as discussed in other threads #8175 and #9043There does not seem to be any tf.layers.flatten() function, see e.g. the API docs:https://www.tensorflow.org/api_docs/python/tf/layersAlthough there is one for tf.contrib.layers.flatten() as shown here:https://www.tensorflow.org/api_docs/python/tf/contrib/layers/flattenI wonder if flatten() has been omitted for some reason when moving layers to TF core (why?) or perhaps it has been moved somewhere else, but I have searched and I cannot find it anywhere?Furthermore, I would like to ask if I can expect that tf.layers is going to be the standard builder API going forward? Or will you focus on Keras instead? I have previously used PrettyTensor. There is also tf.slim and other builder APIs. I don't want to change builder API every 6 months, so I'd like to know what the TF developers are betting on this time?
feature	Chrome timeline for Keras?I've been looking at the chrome timeline to profile my Keras models, but have been unable to find any documentation on how I could use it with my Keras models.I am running keras with a tf backend, and my sequential models are all built in keras. For instance, this is how my model is being built:'model.fit_generator( \generator= data_gen(args, 1), \ steps_per_epoch=tr_steps, \ epochs=args.epochs, \ validation_data=data_gen(args, 2), \ validation_steps=val_steps, \ verbose=1, \ callbacks=[checkpointer])`I am at a loss for how I would try to generate a timeline trace for this model, and wanted to know if there is any related documentation for how I can do this?
feature	errors in ipython sessions cause core dump or segfaultSystem informationPython 2.7.13 :: Anaconda custom (64-bit)ipython :: 5.3.0linux :: 3.16.0-4-amd64https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh gives:== cat /etc/issue ===============================================Linux leto26 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2 (2017-04-30) x86_64 GNU/LinuxVERSION_ID="8"VERSION="8 (jessie)"== are we in docker =============================================No== compiler =====================================================c++ (Debian 4.9.2-10) 4.9.2Copyright (C) 2014 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.== uname -a =====================================================Linux leto26 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2 (2017-04-30) x86_64 GNU/Linux== check pips ===================================================msgpack-numpy (0.3.9)numpy (1.12.1)numpydoc (0.6.0)protobuf (3.2.0)tensorflow-gpu (1.0.1)== check for virtualenv =========================================False== tensorflow import ============================================tf.VERSION = 1.0.1tf.GIT_VERSION = v1.0.0-65-g4763edf-dirtytf.COMPILER_VERSION = v1.0.0-65-g4763edf-dirtySanity check: array([1], dtype=int32)I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally== env ==========================================================LD_LIBRARY_PATH /Tmp/lisa/os_v5/cudnn_v5.1:/Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/lib:/Tmp/lisa/os_v5/lib64:/usr/local/lib:/usr/lib64/atlas:/Tmp/lisa/os_v5/lib32:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/libDYLD_LIBRARY_PATH is unset== nvidia-smi ===================================================Fri May 12 19:38:18 2017+-----------------------------------------------------------------------------+| NVIDIA-SMI 375.39                 Driver Version: 375.39                    ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  GeForce GTX 1050    Off  | 0000:05:00.0      On |                  N/A || 61%   67C    P0    36W /  75W |    145MiB /  1998MiB |      0%      Default |+-------------------------------+----------------------+----------------------+|   1  TITAN X (Pascal)    Off  | 0000:06:00.0     Off |                  N/A || 54%   84C    P2    68W / 250W |  11530MiB / 12189MiB |      0%      Default |+-------------------------------+----------------------+----------------------+|   2  TITAN X (Pascal)    Off  | 0000:09:00.0     Off |                  N/A || 45%   78C    P2    85W / 250W |  11820MiB / 12189MiB |     35%      Default |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes:                                                       GPU Memory ||  GPU       PID  Type  Process name                               Usage      ||=============================================================================||    0      1518    G   /usr/bin/X                                     141MiB ||    1     20850    C   python                                       11527MiB ||    2     18363    C   python                                       11817MiB |+-----------------------------------------------------------------------------+== cuda libs  ===================================================/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7/usr/local/cuda-7.5/doc/man/man7/libcudart.7/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18/usr/local/cuda-7.5/lib64/libcudart_static.a/usr/local/cuda-7.5/lib/libcudart.so.7.5.18/usr/local/cuda-7.5/lib/libcudart_static.a/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7/usr/local/cuda-8.0/doc/man/man7/libcudart.7/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44/usr/local/cuda-8.0/lib64/libcudart_static.a== cat /etc/issue ===============================================Linux leto26 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2 (2017-04-30) x86_64 GNU/LinuxVERSION_ID="8"VERSION="8 (jessie)"== are we in docker =============================================No== compiler =====================================================c++ (Debian 4.9.2-10) 4.9.2Copyright (C) 2014 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.== uname -a =====================================================Linux leto26 3.16.0-4-amd64 #1 SMP Debian 3.16.43-2 (2017-04-30) x86_64 GNU/Linux== check pips ===================================================msgpack-numpy (0.3.9)numpy (1.12.1)numpydoc (0.6.0)protobuf (3.2.0)tensorflow-gpu (1.0.1)== check for virtualenv =========================================False== tensorflow import ============================================tf.VERSION = 1.0.1tf.GIT_VERSION = v1.0.0-65-g4763edf-dirtytf.COMPILER_VERSION = v1.0.0-65-g4763edf-dirtySanity check: array([1], dtype=int32)I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally== env ==========================================================LD_LIBRARY_PATH /Tmp/lisa/os_v5/cudnn_v5.1:/Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/lib:/Tmp/lisa/os_v5/lib64:/usr/local/lib:/usr/lib64/atlas:/Tmp/lisa/os_v5/lib32:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/libDYLD_LIBRARY_PATH is unset== nvidia-smi ===================================================Fri May 12 19:38:27 2017+-----------------------------------------------------------------------------+| NVIDIA-SMI 375.39                 Driver Version: 375.39                    ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  GeForce GTX 1050    Off  | 0000:05:00.0      On |                  N/A || 61%   67C    P0    36W /  75W |    145MiB /  1998MiB |      0%      Default |+-------------------------------+----------------------+----------------------+|   1  TITAN X (Pascal)    Off  | 0000:06:00.0     Off |                  N/A || 54%   84C    P2    68W / 250W |  11530MiB / 12189MiB |      0%      Default |+-------------------------------+----------------------+----------------------+|   2  TITAN X (Pascal)    Off  | 0000:09:00.0     Off |                  N/A || 46%   78C    P2   155W / 250W |  11820MiB / 12189MiB |     38%      Default |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes:                                                       GPU Memory ||  GPU       PID  Type  Process name                               Usage      ||=============================================================================||    0      1518    G   /usr/bin/X                                     141MiB ||    1     20850    C   python                                       11527MiB ||    2     18363    C   python                                       11817MiB |+-----------------------------------------------------------------------------+== cuda libs  ===================================================/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7/usr/local/cuda-7.5/doc/man/man7/libcudart.7/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18/usr/local/cuda-7.5/lib64/libcudart_static.a/usr/local/cuda-7.5/lib/libcudart.so.7.5.18/usr/local/cuda-7.5/lib/libcudart_static.a/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7/usr/local/cuda-8.0/doc/man/man7/libcudart.7/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44/usr/local/cuda-8.0/lib64/libcudart_static.a== cat /etc/issue ===============================================Linux leto06 3.16.0-4-amd64 #1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/LinuxVERSION_ID="8"VERSION="8 (jessie)"== are we in docker =============================================No== compiler =====================================================c++ (Debian 4.9.2-10) 4.9.2Copyright (C) 2014 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.== uname -a =====================================================Linux leto06 3.16.0-4-amd64 #1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux== check pips ===================================================msgpack-numpy (0.3.9)numpy (1.12.1)numpydoc (0.6.0)protobuf (3.2.0)tensorflow-gpu (1.0.1)== check for virtualenv =========================================False== tensorflow import ============================================tf.VERSION = 1.0.1tf.GIT_VERSION = v1.0.0-65-g4763edf-dirtytf.COMPILER_VERSION = v1.0.0-65-g4763edf-dirtySanity check: array([1], dtype=int32)I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally== env ==========================================================LD_LIBRARY_PATH /Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/cudnn_v5.1:/Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/lib:/Tmp/lisa/os_v5/lib64:/usr/local/lib:/usr/lib64/atlas:/Tmp/lisa/os_v5/lib32:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/libDYLD_LIBRARY_PATH is unset== nvidia-smi ===================================================Fri May 12 19:40:02 2017+-----------------------------------------------------------------------------+| NVIDIA-SMI 367.44                 Driver Version: 367.44                    ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  GeForce GTX TIT...  Off  | 0000:02:00.0     Off |                  N/A || 22%   46C    P8    18W / 250W |      1MiB / 12206MiB |      0%   E. Process |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes:                                                       GPU Memory ||  GPU       PID  Type  Process name                               Usage      ||=============================================================================||  No running processes found                                                 |+-----------------------------------------------------------------------------+== cuda libs  ===================================================/usr/local/cuda-7.5/lib/libcudart.so.7.5.18/usr/local/cuda-7.5/lib/libcudart_static.a/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18/usr/local/cuda-7.5/lib64/libcudart_static.a/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7/usr/local/cuda-7.5/doc/man/man7/libcudart.7/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44/usr/local/cuda-8.0/lib64/libcudart_static.a/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7/usr/local/cuda-8.0/doc/man/man7/libcudart.7== cat /etc/issue ===============================================Linux leto06 3.16.0-4-amd64 #1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/LinuxVERSION_ID="8"VERSION="8 (jessie)"== are we in docker =============================================No== compiler =====================================================c++ (Debian 4.9.2-10) 4.9.2Copyright (C) 2014 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.== uname -a =====================================================Linux leto06 3.16.0-4-amd64 #1 SMP Debian 3.16.39-1+deb8u2 (2017-03-07) x86_64 GNU/Linux== check pips ===================================================msgpack-numpy (0.3.9)numpy (1.12.1)numpydoc (0.6.0)protobuf (3.2.0)tensorflow-gpu (1.0.1)== check for virtualenv =========================================False== tensorflow import ============================================tf.VERSION = 1.0.1tf.GIT_VERSION = v1.0.0-65-g4763edf-dirtytf.COMPILER_VERSION = v1.0.0-65-g4763edf-dirtySanity check: array([1], dtype=int32)I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally== env ==========================================================LD_LIBRARY_PATH /Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/cudnn_v5.1:/Tmp/lisa/os_v5/nccl_8/lib:/Tmp/lisa/os_v5/lib:/Tmp/lisa/os_v5/lib64:/usr/local/lib:/usr/lib64/atlas:/Tmp/lisa/os_v5/lib32:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/lib:/u/kruegerd/.local/lib64/:/u/kruegerd/.local/libDYLD_LIBRARY_PATH is unset== nvidia-smi ===================================================Fri May 12 19:40:54 2017+-----------------------------------------------------------------------------+| NVIDIA-SMI 367.44                 Driver Version: 367.44                    ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  GeForce GTX TIT...  Off  | 0000:02:00.0     Off |                  N/A || 22%   47C    P8    18W / 250W |      1MiB / 12206MiB |      0%   E. Process |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes:                                                       GPU Memory ||  GPU       PID  Type  Process name                               Usage      ||=============================================================================||  No running processes found                                                 |+-----------------------------------------------------------------------------+== cuda libs  ===================================================/usr/local/cuda-7.5/lib/libcudart.so.7.5.18/usr/local/cuda-7.5/lib/libcudart_static.a/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18/usr/local/cuda-7.5/lib64/libcudart_static.a/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7/usr/local/cuda-7.5/doc/man/man7/libcudart.7/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44/usr/local/cuda-8.0/lib64/libcudart_static.a/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7/usr/local/cuda-8.0/doc/man/man7/libcudart.7python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)" gives('v1.0.0-65-g4763edf-dirty', '1.0.1')Describe the problemWhen I run tensorflow code (e.g. keras's mnist_cnn.py) in ipython, errors and Ctrl+C often crashes the interactive ipython session with a core dump or segfault, e.g....Source code / logsIn [1]: run mnist_cnn.pyUsing TensorFlow backend.I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locallyx_train shape: (60000, 1, 28, 28)60000 train samples10000 test samples/u/kruegerd/python_modules/keras/keras/backend/tensorflow_backend.py:2252: UserWarning: Expected no kwargs, you passed 1kwargs passed to function are ignored with Tensorflow backendwarnings.warn('\n'.join(msg))Train on 60000 samples, validate on 10000 samplesEpoch 1/12W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:name: GeForce GTX TITAN Xmajor: 5 minor: 2 memoryClockRate (GHz) 1.076pciBusID 0000:02:00.0Total memory: 11.92GiBFree memory: 11.81GiBI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   YI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:02:00.0)23680/60000 [==========>...................] - ETA: 10s - loss: 0.5787 - acc: 0.8213^C---------------------------------------------------------------------------KeyboardInterrupt                         Traceback (most recent call last)/u/kruegerd/python_modules/keras/examples/mnist_cnn.py in ()65           epochs=epochs,66           verbose=1,---> 67           validation_data=(x_test, y_test))68 score = model.evaluate(x_test, y_test, verbose=0)69 print('Test loss:', score[0])/u/kruegerd/python_modules/keras/keras/models.pyc in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)863                               class_weight=class_weight,864                               sample_weight=sample_weight,--> 865                               initial_epoch=initial_epoch)866867     def evaluate(self, x, y, batch_size=32, verbose=1,/u/kruegerd/python_modules/keras/keras/engine/training.pyc in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)1499                               val_f=val_f, val_ins=val_ins, shuffle=shuffle,1500                               callback_metrics=callback_metrics,-> 1501                               initial_epoch=initial_epoch)15021503     def evaluate(self, x, y, batch_size=32, verbose=1, sample_weight=None):/u/kruegerd/python_modules/keras/keras/engine/training.pyc in _fit_loop(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)1153                 batch_logs['size'] = len(batch_ids)1154                 callbacks.on_batch_begin(batch_index, batch_logs)-> 1155                 outs = f(ins_batch)1156                 if not isinstance(outs, list):1157                     outs = [outs]/u/kruegerd/python_modules/keras/keras/backend/tensorflow_backend.pyc in call(self, inputs)2229         session = get_session()2230         updated = session.run(self.outputs + [self.updates_op],-> 2231                               feed_dict=feed_dict)2232         return updated[:len(self.outputs)]2233/u/kruegerd/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)765     try:766       result = self._run(None, fetches, feed_dict, options_ptr,--> 767                          run_metadata_ptr)768       if run_metadata:769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)/u/kruegerd/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)963     if final_fetches or final_targets:964       results = self._do_run(handle, final_targets, final_fetches,--> 965                              feed_dict_string, options, run_metadata)966     else:967       results = []/u/kruegerd/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)1013     if handle is None:1014       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,-> 1015                            target_list, options, run_metadata)1016     else:1017       return self._do_call(_prun_fn, self._session, handle, feed_dict,/u/kruegerd/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)1020   def _do_call(self, fn, *args):1021     try:-> 1022       return fn(*args)1023     except errors.OpError as e:1024       message = compat.as_text(e.message)/u/kruegerd/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)1002         return tf_session.TF_Run(session, options,1003                                  feed_dict, fetch_list, target_list,-> 1004                                  status, run_metadata)10051006     def _prun_fn(session, handle, feed_dict, fetch_list):KeyboardInterrupt:Fatal Python error: GC object already trackedAborted (core dumped)
feature	Support for float16 in tf.layersIt seems like tf.layers.* do not support tf.float16, because they rely on the default value handed to the _Layer superclass here. It would be great if tf.float16 could be supported there.
feature	Estimator predict() fails after fit() or evaluate()System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I did write an input_fn based code based on the Abalone example. Specifically, I replaced the x and y parameters with custom input_fn implementations loading images and applying map_fn to them before batching. This resulted in a batch of unknown tensor shape (None).OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04TensorFlow installed from (source or binary): sourceTensorFlow version (use command below): v1.1.0-1-g10ec24aBazel version (if compiling from source): 0.4.5CUDA/cuDNN version: 8.0, 5.1GPU model and memory: GeForce 1080 TiExact command to reproduce:  running the codeDescribe the problemWhen calling predict() after calling fit() or evaluate() on an Estimator instance (an unlikely scenario, but shown in the example), the call crashes withTraceback (most recent call last):  File "/home/mmayer/dev/everybag/orientation_network/orientation.py", line 169, in <module>    main()  File "/home/mmayer/dev/everybag/orientation_network/orientation.py", line 35, in main    as_iterable=False)  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 281, in new_func    return func(*args, **kwargs)  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 565, in predict    as_iterable=as_iterable)  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 857, in _infer_model    infer_ops = self._get_predict_ops(features)  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 1187, in _get_predict_ops    self._labels_info)  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/tensor_signature.py", line 164, in create_placeholders_from_signatures    return signatures.get_placeholder()  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/tensor_signature.py", line 89, in get_placeholder    shape=[None] + list(self.shape[1:]))  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py", line 478, in __iter__    raise ValueError("Cannot iterate over a shape with unknown rank.")ValueError: Cannot iterate over a shape with unknown rank.if self._labels_info of the Estimator has unknown shape (e.g. as an effect of using map_fn on images to obtain both feature and target from them. This is due to  def get_placeholder(self):    if self.is_sparse:      return array_ops.sparse_placeholder(dtype=self.dtype)    return array_ops.placeholder(dtype=self.dtype,                                 shape=[None] + list(self.shape[1:]))in tensor_signature.py, since self.shape[1:] is None.The call comes through  def _get_predict_ops(self, features):    labels = tensor_signature.create_placeholders_from_signatures(        self._labels_info)    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.INFER)which uses the labels to construct the inference graph, when it probably shouldn't.The predict() operation succeeds if it is called without prior calls to fit() or evaluate() as in this case the methoddef create_placeholders_from_signatures(signatures):  if signatures is None:    return None  if not isinstance(signatures, dict):    return signatures.get_placeholder()  return {      key: signatures[key].get_placeholder()      for key in signatures}early exits.Source code / logsExample code that triggers the problem; requires images in img directory. The problem can be resolved by explicitly setting the indices Tensor's shape in input_fn using a tf.reshape to [-1], but given that it works for training and evaluation and that inference probably shouldn't use the targets at all (especially not from previous runs), I consider this a bug.import osimport timefrom typing import Dict, Optional, Anyimport tensorflow as tfimport tensorflow.contrib.learn as tflimport tensorflow.contrib.slim as slimfrom tensorflow.contrib.slim.python.slim.nets import inception_v3 as inceptiondef main():    model_params = {'learning_rate': 0.001,                    'batch_size': 16,                    'num_epochs': None}    nn = tfl.Estimator(model_fn=model_fn, params=model_params)    nn.fit(input_fn=lambda: input_fn('img', params=model_params), steps=10)    ev = nn.evaluate(input_fn=lambda: input_fn('img', params=model_params), steps=1)    predictions = nn.predict(input_fn=lambda: input_fn('img', params=model_params), as_iterable=False)def model_fn(features, targets, mode, params):    training = (mode == tfl.ModeKeys.TRAIN)    num_classes = 5    image = features['image']    image.set_shape((None, 299, 299, 3))    targets.set_shape((None, num_classes))    with tf.contrib.slim.arg_scope(inception.inception_v3_arg_scope()):        _, end_points = inception.inception_v3(image, is_training=training, num_classes=num_classes)        logits = end_points['Logits']        predictions = end_points['Predictions']    predictions_dict = {'predictions': predictions}    loss = tf.losses.softmax_cross_entropy(targets, logits)    eval_metric_ops = {        'rmse': tf.metrics.root_mean_squared_error(targets, predictions)    }    train_op = tf.contrib.layers.optimize_loss(        loss=loss,        global_step=tf.contrib.framework.get_global_step(),        learning_rate=params['learning_rate'],        optimizer='Adam')    return tfl.ModelFnOps(        mode=mode,        predictions=predictions_dict,        loss=loss,        train_op=train_op,        eval_metric_ops=eval_metric_ops)def input_fn(dataset_dir, params):    pattern = os.path.join(dataset_dir, '*.jpg')    filename_queue = tf.train.string_input_producer(        tf.train.match_filenames_once(pattern),        num_epochs=params['num_epochs'])    image_reader = tf.WholeFileReader()    _, image_file = image_reader.read_up_to(filename_queue, 10)    image_batch = tf.train.shuffle_batch([image_file], params['batch_size'], 1000, 100,                                         num_threads=2,                                         enqueue_many=True,                                         allow_smaller_final_batch=True)    images, indices = tf.map_fn(image_fn, image_batch,                                dtype=(tf.float32, tf.int32),                                infer_shape=False)    images = tf.reshape(images, [-1, 299, 299, 3])    features = {'image': images}    targets = tf.one_hot(indices=indices, depth=5, dtype=tf.float32)    return features, targetsdef image_fn(image_file):    image = tf.image.decode_jpeg(image_file, channels=3)    image = tf.expand_dims(image, 0)    image = tf.image.resize_bilinear(image, [299, 299])    image = tf.squeeze(image, [0])    k = 2    image = tf.image.rot90(image, k=k, name='rotate')    image = tf.cast(image, tf.float32)    image = tf.subtract(tf.divide(image, 128.), 1.)    return image, kif __name__ == '__main__':    main()Full output:WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpv1o9e6jk2017-05-15 11:55:54.834870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2017-05-15 11:55:54.835292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: name: GeForce GTX 1080 Timajor: 6 minor: 1 memoryClockRate (GHz) 1.6325pciBusID 0000:01:00.0Total memory: 10.91GiBFree memory: 9.24GiB2017-05-15 11:55:54.835305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 2017-05-15 11:55:54.835309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 2017-05-15 11:55:54.835315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)2017-05-15 11:56:03.923926: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 1546 get requests, put_count=1200 evicted_count=1000 eviction_rate=0.833333 and unsatisfied allocation rate=0.9353172017-05-15 11:56:03.923951: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 1102017-05-15 11:57:49.153141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0)WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.WARNING:tensorflow:From untitled.py:18: calling BaseEstimator.predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable is deprecated and will be removed after 2016-12-01.Instructions for updating:Estimator is decoupled from Scikit Learn interface by moving intoseparate class SKCompat. Arguments x, y and batch_size are onlyavailable in the SKCompat class, Estimator will only accept input_fn.Example conversion:  est = Estimator(...) -> est = SKCompat(Estimator(...))Traceback (most recent call last):  File "untitled.py", line 97, in <module>  File "untitled.py", line 18, in main    predictions = nn.predict(input_fn=lambda: input_fn('img', params=model_params), as_iterable=False)  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py", line 281, in new_func    return func(*args, **kwargs)  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 565, in predict    as_iterable=as_iterable)  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 857, in _infer_model    infer_ops = self._get_predict_ops(features)  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 1187, in _get_predict_ops    self._labels_info)  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/tensor_signature.py", line 164, in create_placeholders_from_signatures    return signatures.get_placeholder()  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/estimators/tensor_signature.py", line 89, in get_placeholder    shape=[None] + list(self.shape[1:]))  File "/home/mmayer/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py", line 478, in __iter__    raise ValueError("Cannot iterate over a shape with unknown rank.")ValueError: Cannot iterate over a shape with unknown rank.
feature	problem importing tensorflow with tensorflow-gpu pip package and Nvidia PRIMESystem informationOS Platform and Distribution: Linux Ubuntu 16.10TensorFlow installed from: binaryTensorFlow version: tensorflow-gpu-1.1.0CUDA/cuDNN version:GPU model and memory: GeForce 940MX 982MiBExact command to reproduce: import tensorflow== cat /etc/issue ===============================================Linux Lyn 4.8.0-51-generic #54-Ubuntu SMP Tue Apr 25 16:32:21 UTC 2017 x86_64 x86_64 x86_64 GNU/LinuxVERSION="16.10 (Yakkety Yak)"VERSION_ID="16.10"VERSION_CODENAME=yakkety== are we in docker =============================================No== compiler =====================================================c++ (Ubuntu 6.2.0-5ubuntu12) 6.2.0 20161005Copyright (C) 2016 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.== uname -a =====================================================Linux Lyn 4.8.0-51-generic #54-Ubuntu SMP Tue Apr 25 16:32:21 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux== check pips ===================================================numpy (1.12.1)numpydoc (0.6.0)protobuf (3.3.0)tensorflow-gpu (1.1.0)== check for virtualenv =========================================False== tensorflow import ============================================2017-05-15 16:22:31.009080: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.2017-05-15 16:22:31.009102: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.2017-05-15 16:22:31.009124: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.2017-05-15 16:22:31.009131: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.2017-05-15 16:22:31.009139: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.2017-05-15 16:22:31.119107: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2017-05-15 16:22:31.119494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:name: GeForce 940MXmajor: 5 minor: 0 memoryClockRate (GHz) 0.993pciBusID 0000:01:00.0Total memory: 982.12MiBFree memory: 675.25MiB2017-05-15 16:22:31.119518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 02017-05-15 16:22:31.119526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y2017-05-15 16:22:31.119542: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0)tf.VERSION = 1.1.0tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5Sanity check: array([1], dtype=int32)== env ==========================================================LD_LIBRARY_PATH is unsetDYLD_LIBRARY_PATH is unset== nvidia-smi ===================================================Mon May 15 16:21:29 2017+-----------------------------------------------------------------------------+| NVIDIA-SMI 375.39                 Driver Version: 375.39                    ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  GeForce 940MX       Off  | 0000:01:00.0     Off |                  N/A || N/A   43C    P0    N/A /  N/A |    262MiB /   982MiB |      0%      Default |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes:                                                       GPU Memory ||  GPU       PID  Type  Process name                               Usage      ||=============================================================================||    0      1017    G   /usr/lib/xorg/Xorg                             168MiB ||    0      1860    G   /usr/bin/compiz                                 41MiB ||    0      2324    G   ...el-token=2DD3BDBDD08C58317A0131100BC13BC1    52MiB |+-----------------------------------------------------------------------------+== cuda libs  ===================================================tf.GIT_VERSIONv1.1.0-rc0-61-g1ec6ed5tf.VERSION1.1.0Describe the problemI have a laptop with a dedicated Nvidia GPU. I use it only for prototyping my tensorflow code.But dedicated GPUs drain a lot of energy and reduce the laptop's battery life.So when I'm outside on battery (eg: in the library at university) I always set Nvidia PRIME to use the integrated card only (type nvidia-settings in a console to reach this setting).With the previous versions of tensorflow-gpu (installedi via pip3 on Ubuntu) everything worked well.Now with the current release I can no longer use tensorflow-gpu while I have the Nvidia card disabled with PRIME.Now, to be able to work with tensorflow AND have enough battery to conclude my day, I have to install the pip package "tensorflow" (and not "tensorflow-gpu"). but that turns useless if, for some reason, need to test my code with GPU acceleration, turning back on the dedicated graphic card via Nvidia PRIME.If I really want GPU acceleration I have to re-enable the dedicated card in PRIME, uninstall tensorflow and reinstall tensorflow-gpu. every time. that's a mess!To me, there are two way to resolve this bug:make tensorflow-gpu again able to handle situation with all the Nvidia GPU are temporarily disabled.unify the tensorflow and tensorflow-gpu packages, including a smart logic inside them that enable the software to handle theese ibrid situations, which I think will be very common in the laptops in the near futureSource code / logsimport tensorflowImportError                               Traceback (most recent call last)/home/federico/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py in ()40     sys.setdlopenflags(_default_dlopen_flags | ctypes.RTLD_GLOBAL)---> 41   from tensorflow.python.pywrap_tensorflow_internal import *42   from tensorflow.python.pywrap_tensorflow_internal import version/home/federico/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in ()27             return _mod---> 28     _pywrap_tensorflow_internal = swig_import_helper()29     del swig_import_helper/home/federico/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py in swig_import_helper()23             try:---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)25             finally:/usr/lib/python3.5/imp.py in load_module(name, file, filename, details)241         else:--> 242             return load_dynamic(name, filename, file)243     elif type_ == PKG_DIRECTORY:/usr/lib/python3.5/imp.py in load_dynamic(name, path, file)341             name=name, loader=loader, origin=path)--> 342         return _load(spec)343ImportError: libnvidia-fatbinaryloader.so.375.39: cannot open shared object file: No such file or directoryDuring handling of the above exception, another exception occurred:ImportError                               Traceback (most recent call last) in ()----> 1 import tensorflow/home/federico/.local/lib/python3.5/site-packages/tensorflow/init.py in ()2223 # pylint: disable=wildcard-import---> 24 from tensorflow.python import *25 # pylint: enable=wildcard-import26/home/federico/.local/lib/python3.5/site-packages/tensorflow/python/init.py in ()49 import numpy as np50---> 51 from tensorflow.python import pywrap_tensorflow5253 # Protocol buffers/home/federico/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py in ()50 for some common reasons and solutions.  Include the entire stack trace51 above this error message when asking for help.""" % traceback.format_exc()---> 52   raise ImportError(msg)5354 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-longImportError: Traceback (most recent call last):File "/home/federico/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py", line 41, in from tensorflow.python.pywrap_tensorflow_internal import *File "/home/federico/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 28, in _pywrap_tensorflow_internal = swig_import_helper()File "/home/federico/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py", line 24, in swig_import_helper_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)File "/usr/lib/python3.5/imp.py", line 242, in load_modulereturn load_dynamic(name, filename, file)File "/usr/lib/python3.5/imp.py", line 342, in load_dynamicreturn _load(spec)ImportError: libnvidia-fatbinaryloader.so.375.39: cannot open shared object file: No such file or directoryFailed to load the native TensorFlow runtime.See https://www.tensorflow.org/install/install_sources#common_installation_problemsfor some common reasons and solutions.  Include the entire stack traceabove this error message when asking for help.
feature	tf.self_adjoint_eig doesn't behave the same way with float32 and float64Here is an example to reproduce the probleml = tf.constant([[10., -4., -4., -2.],                  [-4., 10., -2., -4.],                  [-4., -2., 6., 0.],                  [-2., -4., 0., 6.]], dtype=tf.float64)e, v = tf.self_adjoint_eig(tf.expand_dims(l, 0))When I set dtype=tf.float64 the output is// Eigen values[[ -2.31986627e-15   5.52786405e+00   1.20000000e+01   1.44721360e+01]]// Eigen vectors[[-0.5        -0.16245985  0.5        -0.68819096] [-0.5         0.16245985  0.5         0.68819096] [-0.5        -0.68819096 -0.5         0.16245985] [-0.5         0.68819096 -0.5        -0.16245985]]When dtype=tf.float32 the output is// Eigen values[[ -1.02379988e-06   5.52786446e+00   1.20000019e+01   1.44721375e+01]]// Eigen vectors[[ 0.49999985  0.16245979  0.49999985 -0.68819106] [ 0.5        -0.16246006  0.50000018  0.68819082] [ 0.5         0.68819106 -0.49999988  0.16246004] [ 0.49999991 -0.68819088 -0.50000012 -0.16245979]]In this case the sign of the second eigen vector changed.The numpy equivalent of this code always give the same result (in float or float32) and is similar to the result I got with the tf.float64 versionL = np.array([[10., -4., -4., -2.],                  [-4., 10., -2., -4.],                  [-4., -2., 6., 0.],                  [-2., -4., 0., 6.]])D, V =np.linalg.eigh(L)// numpy eigen values[  1.11716192e-15   5.52786405e+00   1.20000000e+01   1.44721360e+01]// numpy eigen vectors[[ 0.5        -0.16245985  0.5        -0.68819096] [ 0.5         0.16245985  0.5         0.68819096] [ 0.5        -0.68819096 -0.5         0.16245985] [ 0.5         0.68819096 -0.5        -0.16245985]]
feature	Feature request: tf.nn.depthwise_conv2d_transposeSystem informationTensorFlow installed from (source or binary): sourceTensorFlow version (use command below): ('v1.1.0-0-g1ec6ed5', '1.1.0')Bazel version (if compiling from source): 0.4.5- (@non-git)CUDA/cuDNN version: 7.5/5.1GPU model and memory: NVIDIA M40, 12GBDescribe the problemI would like to apply a tf.nn.conv2d_transpose operation to each channel of a feature image independently. There is no tf.nn.depthwise_conv2d_transpose operation.I tried using tf.nn.depthwise_conv2d_native_backprop_input however, when I try to optimize a function that involves one of these operations, it results in an error because there is no gradient operation defined:LookupError: No gradient defined for operation 'DepthwiseConv2dNativeBackpropInput_1' (op type: DepthwiseConv2dNativeBackpropInput)This is related to #7934It is possible to achieve this functionality using conv2d_transpose by constructing a large filter with many coefficients set to zero. However, it is relatively inefficient, especially for a large number of channels.
feature	preserving specific checkpointsSavers automatically clean up checkpoints and that's lovely.  But there are special points during training that I want to be sure to save (e.g. transitioning from a pre-training phrase to full training), which I can't ensure with the current options (unless I just keep everything, by making max_to_keep & keep_checkpoint_every_n_hours huge).Two possible approaches:saver.save(..., preserve=True)Never clean up this checkpoint.max_to_keep is defined per save_pathi.e. Whenever I change the save_path argument to save() in the middle of the session, don't clean up the checkpoints with the previous save_path.This is related to #8658 (with a little book-keeping on the client, you could do #8658 yourself).
feature	Freezing graphs with custom opsSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YesOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 and MacOS SierraTensorFlow installed from (source or binary): sourceTensorFlow version (use command below): master (quite recent)Bazel version (if compiling from source): 0.4.5Exact command to reproduce: freeze_graphDescribe the problemI've asked my question on StackOverflow here:http://stackoverflow.com/questions/43880729/using-new-op-while-importing-graph-in-tensorflowI'm trying to freeze a model which contains a custom op. But freeze_graph gives the following error:Traceback (most recent call last):  File "<local path>/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py", line 202, in <module>    app.run(main=main, argv=[sys.argv[0]] + unparsed)  File "<local path>/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py", line 44, in run    _sys.exit(main(_sys.argv[:1] + flags_passthrough))  File "<local path>/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py", line 134, in main    FLAGS.variable_names_blacklist)  File "<local path>/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py", line 99, in freeze_graph    _ = importer.import_graph_def(input_graph_def, name="")  File "<local path>/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/importer.py", line 260, in import_graph_def    raise ValueError('No op named %s in defined operations.' % node.op)ValueError: No op named RoiPool in defined operations.I was suggested on StackOverflow to build freeze_graph with my custom op as a dependency. I did that, but freeze_graph still gives the same error.It was also suggested for me to open a feature request to make an easier-to-use interface for using freeze_graph with custom ops.Source code / logsHere is the freeze_graph command I'm using:bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=<local path>/data/graph_vgg.pb --input_checkpoint=<local path>/data/VGGnet_fast_rcnn_iter_70000.ckpt --output_node_names="cls_prob,bbox_pred" --output_graph=<local path>/graph_frozen.pb
feature	Some small problems with the RNN and seq2seq implementationsIn the class AttentionCellWrapper , https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/rnn_cell.py#L1116  , maybe the lstm_output should be replaced by some other token, since the wrapper is not specified for LSTM.In the class Decoder, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/decoder.py#L90 , I think the step() method should not return an output as an instance of BasicDecoderOutput. From an object-oriented-programming view, the BasicDecoder is an inheritance of Decoder, the basic class should not have access to something designed for the inherited class, the same problem exists in the dynamic_decode method.
feature	reimplement core/util/cuda_kernel_helper.h?Hi,I'm trying to implement a GetCuda3DLaunchConfig into cuda_kernel_helper.h, but while reading the code, I feel it's a bit confusing and there might be a better way to implement it.Here is the pointer:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/cuda_kernel_helper.hIn line 55-57, there is something like block_count = physical_thread_count / thread_per_block. Why use thread_per_block instead of virtual_thread_count?  The number of blocks can be higher than physical maximum and cuda will automatically put these blocks into queue. On the other hand, limiting the number of blocks to physical limit would make the computation incomplete when the number of threads is large.See: http://docs.nvidia.com/cuda/cuda-c-programming-guide/graphics/automatic-scalability.pngThe the kernel launch config computed is not optimal. I would suggest using the API provided by cuda >=6.5See: https://devblogs.nvidia.com/parallelforall/cuda-pro-tip-occupancy-api-simplifies-launch-configuration/Can anyone confirm what I said? If my suggestion make sense, I would like to reimplement these functions using cuda's occupancy api while writing my GetCuda3DLaunchConfig.
feature	[feature] Support Lanczos method in tf.image.resize_imagesAdd support for a Lanczos (a truncated sinc) mode in tf.image.resize_images. Currently this mode is not offered.Pillow supports LANCZOS (aka ANTIALIAS) as a resampling method and stipulates this method has the highest quality for down sampling (default for thumbnail for example).
performance	Tensorboard broken on latest sourceNOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.For general support from the community, see StackOverflow.To make bugs and feature requests more easy to find and organize, we close issues that are deemedout of scope for GitHub Issues and point people to StackOverflow.For bugs or installation issues, please provide the following information.The more information you provide, the more easily we will be able to offerhelp and advice.What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?Environment infoOperating System: Ubuntu 16.04Installed version of CUDA and cuDNN:(please attach the output of ls -l /path/to/cuda/lib/libcud*):-rw-r--r-- 1 root root   556000 Mar  4 15:04 libcudadevrt.alrwxrwxrwx 1 root root       16 Mar  4 15:04 libcudart.so -> libcudart.so.8.0lrwxrwxrwx 1 root root       19 Mar  4 15:04 libcudart.so.8.0 -> libcudart.so.8.0.61-rwxr-xr-x 1 root root   415432 Mar  4 15:04 libcudart.so.8.0.61-rw-r--r-- 1 root root   775162 Mar  4 15:04 libcudart_static.a-rwxr-xr-x 1 root root 84163560 Mar  4 15:06 libcudnn.so-rwxr-xr-x 1 root root 84163560 Mar  4 15:06 libcudnn.so.5-rwxr-xr-x 1 root root 84163560 Mar  4 15:06 libcudnn.so.5.1.10-rw-r--r-- 1 root root 70364814 Mar  4 15:06 libcudnn_static.aIf installed from binary pip package, provide:A link to the pip package you installed:The output from python -c "import tensorflow; print(tensorflow.__version__)".If installed from source, provideThe commit hash (git rev-parse HEAD)9738902The output of bazel versionBuild label: 0.4.5Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jarBuild time: Thu Mar 16 12:19:38 2017 (1489666778)Build timestamp: 1489666778Build timestamp as int: 1489666778If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)What other attempted solutions have you tried?Logs or other output that would be helpful(If logs are large, please upload as attachment or provide link).Fails with the following error.Traceback (most recent call last):  File "/usr/local/bin/tensorboard", line 7, in <module>    from tensorflow.tensorboard.tensorboard import main  File "/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/tensorboard.py", line 33, in <module>    from tensorflow.tensorboard.backend import application  File "/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/backend/application.py", line 47, in <module>    from tensorflow.tensorboard.plugins.projector import projector_plugin  File "/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/plugins/projector/projector_plugin.py", line 30, in <module>    from tensorflow.contrib.tensorboard.plugins.projector import projector_config_pb2  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/__init__.py", line 59, in <module>    from tensorflow.contrib import tensorboard  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorboard/__init__.py", line 22, in <module>ragha@ragha-gpu:~/dsb-2017$ tensorboardTraceback (most recent call last):  File "/usr/local/bin/tensorboard", line 7, in <module>    from tensorflow.tensorboard.tensorboard import main  File "/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/tensorboard.py", line 33, in <module>    from tensorflow.tensorboard.backend import application  File "/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/backend/application.py", line 47, in <module>    from tensorflow.tensorboard.plugins.projector import projector_plugin  File "/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/plugins/projector/projector_plugin.py", line 30, in <module>    from tensorflow.contrib.tensorboard.plugins.projector import projector_config_pb2  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/__init__.py", line 59, in <module>    from tensorflow.contrib import tensorboard  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorboard/__init__.py", line 22, in <module>    from tensorflow.contrib.tensorboard import plugins  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorboard/plugins/__init__.py", line 22, in <module>    from tensorflow.contrib.tensorboard.plugins import projector  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tensorboard/plugins/projector/__init__.py", line 34, in <module>    from tensorflow.tensorboard.plugins.projector import projector_pluginImportError: cannot import name projector_plugin
performance	Large Strides for 1x1 ConvolutionsWhen a conv2d operator has a stride greater than the kernel size, the following error is thrown:ValueError: ('stride must be less than or equal to filter size', 'stride: [2x2] filter: [Dimension(1)xDimension(1)]')This makes implementing the 1x1 convolutions used to reduce spatial resolution in several papers (MSRA 2015 among others) awkward. Also, a convolution with stride greater than kernel size may be unusual but is it still well defined. Fixing this may be as simple as removing this assertion.Thanks to everyone who developed TensorFlow, it's a fascinating tool.
performance	outputs indifferent to input when applying `merge_duplicate_nodes`I think I might have located the root of #8698It seems that merge_duplicate_nodes is the reason that quantize_nodes malfunctions.Whatever I do, whenever I apply a merge_duplicate_nodes somewhere during a graph transformation, the output becomes completely indifferent to the input.(Unfortunately) I don't get any error messages concerning this...
performance	SVD float64 NaN bugI've encountered a tf.float64 matrix (of size 60 x 200) such that tf.svd of it returns NaNs, whilenp.linalg.svd works fine.Converting the matrix into tf.float32 and then converting back to tf.float64 makes everything works with TF too (while being a tiny perturbation).Here is an example Jupyter notebook: https://nbviewer.jupyter.org/urls/dl.dropbox.com/s/mf9e2eqg2isupce/Scary%20matrix.ipynb?dl=0You can download pickled matrix here: https://www.dropbox.com/s/b8wex6voladtgw1/scary_matrix.cPickle?dl=0I'm using Conda Python 2.7.13 (tried on Mac and Ubuntu) and a fresh version of tensorflow from pip (tried both cpu and gpu versions).
performance	Bijectors in contrib.distributions not availableIn 1.1.0rc0 and beyond, all bijectors are moved into a subdirectory in contrib.distributions. This seems to make it unavailable?ds = tf.contrib.distributionsds.bijectors## Traceback (most recent call last):##   File "<stdin>", line 1, in <module>## AttributeError: 'module' object has no attribute 'bijectors'ds.Bijector## Traceback (most recent call last):##   File "<stdin>", line 1, in <module>## AttributeError: 'module' object has no attribute 'Bijector'In my install location of /Users/dvt/Envs/tf1.1/lib/python2.7/site-packages/tensorflow/contrib/distributions, it seems like it would be imported, as the following line exists:from tensorflow.contrib.distributions.python.ops.bijectors import *However, inspecting the ds submodule, no bijectors are available.ds.__dict__.keys()## ['Deterministic', '__path__', 'QuantizedDistribution', 'softplus_inverse', 'Mixture', 'ExpRelaxedOneHotCategorical', 'ConditionalTransformedDistribution', 'Exponential', 'ConditionalDistribution', '__file__', 'StudentTWithAbsDfSoftplusScale', 'RelaxedOneHotCategorical', 'StudentT', 'ReparameterizationType', 'Categorical', 'MultivariateNormalTriL', 'VectorDeterministic', 'TransformedDistribution', 'Chi2', 'MultivariateNormalDiagPlusLowRank', '_allowed_symbols', 'Gamma', 'normal_conjugates_known_scale_predictive', '__builtins__', 'WishartFull', '__name__', 'Normal', 'ExponentialWithSoftplusRate', 'InverseGamma', 'WishartCholesky', 'Distribution', 'RelaxedBernoulli', 'Bernoulli', 'Beta', 'Binomial', '__doc__', 'BetaWithSoftplusConcentration', 'MultivariateNormalDiagWithSoftplusScale', 'NOT_REPARAMETERIZED', 'BernoulliWithSigmoidProbs', 'Laplace', 'GammaWithSoftplusConcentrationRate', 'Poisson', 'FULLY_REPARAMETERIZED', 'DirichletMultinomial', 'matrix_diag_transform', 'RegisterKL', 'InverseGammaWithSoftplusConcentrationRate', 'Uniform', 'NegativeBinomial', 'Geometric', 'LaplaceWithSoftplusScale', '__package__', 'Dirichlet', 'MultivariateNormalDiag', 'Logistic', 'Chi2WithAbsDf', 'NormalWithSoftplusScale', 'normal_conjugates_known_scale_posterior', 'kl', 'Multinomial', 'OneHotCategorical']
performance	cudnnFindConvolutionForwardAlgorithmEx vs cudnnGetConvolutionForwardAlgorithmFollowing up on #7187 (comment), why does Tensorflow use cudnnGetConvolutionForwardAlgorithm rather than cudnnFindConvolutionForwardAlgorithmEx?  It looks like Tensorflow tries to do the more complete profiling itself.For reference, cudnnGetConvolutionForwardAlgorithm serves as a heuristic for obtaining the best suited algorithm for cudnnConvolutionForward for the given layer specifications. Based on the input preference, this function will either return the fastest algorithm or the fastest algorithm within a given memory limit. For an exhaustive search for the fastest algorithm, please use cudnnFindConvolutionForwardAlgorithm.Whereas:cudnnFindConvolutionForwardAlgorithmEx function attempts all available cuDNN algorithms for cudnnConvolutionForward, using user-allocated GPU memory, and outputs performance metrics to a user-allocated array of cudnnConvolutionFwdAlgoPerf_t. These metrics are written in sorted fashion where the first element has the lowest compute time.Looking at a number of other DNN, they seem to use cudnnFindConvolutionForwardAlgorithmEx / cudnnFindConvolutionForwardAlgorithm:pytorch (when benchmark is on):Theano (if time_once or time_on_shape_change)cntk (non-static finder)/CC @Yangqing @zheng-xq
performance	Execution Stuck after few steps in sess.run()What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?Execution is stuck in between steps. For few steps, it seems to run fine but after that the execution just halts without throwing any exception or the error.Environment infoOperating System: Ubuntu 14.04GPU: NVIDIA TITAN X (Pascal)GPU Memory: 12GBInstalled version of CUDA and cuDNN:-rw-r--r-- 1 root root   556000 Mar 29 05:10 /usr/local/cuda/lib64/libcudadevrt.alrwxrwxrwx 1 root root       16 Mar 29 05:10 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0lrwxrwxrwx 1 root root       19 Mar 29 05:10 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61-rwxr-xr-x 1 root root   415432 Mar 29 05:10 /usr/local/cuda/lib64/libcudart.so.8.0.61-rw-r--r-- 1 root root   775162 Mar 29 05:10 /usr/local/cuda/lib64/libcudart_static.alrwxrwxrwx 1 root root       13 Apr  4 13:18 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5lrwxrwxrwx 1 root root       18 Apr  4 13:18 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.10-rwxr-xr-x 1 root root 84163560 Apr  4 13:18 /usr/local/cuda/lib64/libcudnn.so.5.1.10lrwxrwxrwx 1 root root       18 Apr  4 12:55 /usr/local/cuda/lib64/libcudnn.so.6 -> libcudnn.so.6.0.20-rwxrwxrwx 1 root root 84163560 Apr  4 13:17 /usr/local/cuda/lib64/libcudnn.so.6.0.20-rwxrwxrwx 1 root root 70364814 Apr  4 13:18 /usr/local/cuda/lib64/libcudnn_static.aIf installed from binary pip package, provide:A link to the pip package you installed:https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp34-cp34m-linux_x86_64.whlThe output from python -c "import tensorflow; print(tensorflow.__version__)".I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally1.0.1If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)I ran the mnist_deep.py script provided in tutorials.What other attempted solutions have you tried?Previously, the display used to get hang showing error CUDA_LAUNCH_ERROR_TIMEOUT. On nvidia forum, someone suggested to switch off the X-server. I switched it off, but the problem still persisted.I noticed that the script was hogging full memory of GPU, I tried to limit the allocation by using "allow_growth" flag. But the problem still persists.Logs or other output that would be helpfulstep 47, training accuracy 0.64step 48, training accuracy 0.72step 49, training accuracy 0.7step 50, training accuracy 0.68step 51, training accuracy 0.76step 52, training accuracy 0.66step 53, training accuracy 0.82step 54, training accuracy 0.82step 55, training accuracy 0.64step 56, training accuracy 0.64step 57, training accuracy 0.74step 58, training accuracy 0.76step 59, training accuracy 0.8step 60, training accuracy 0.68step 61, training accuracy 0.88step 62, training accuracy 0.62step 63, training accuracy 0.84step 64, training accuracy 0.72step 65, training accuracy 0.76step 66, training accuracy 0.74step 67, training accuracy 0.86step 68, training accuracy 0.76step 69, training accuracy 0.9step 70, training accuracy 0.84step 71, training accuracy 0.82step 72, training accuracy 0.7Attached is the screenshot of "nvidia-smi"
performance	gradient of tf.floorimport numpy as npimport tensorflow as tff = np.array([3.8], dtype='float32')vif = tf.placeholder(tf.float32, shape=[1])#out = vif + tf.cast(tf.cast(vif, tf.int32), tf.float32)out = vif + tf.floor(vif)grad = tf.gradients(tf.reduce_sum(out), vif)sess = tf.Session()sess.run(tf.initialize_all_variables())print sess.run(grad, feed_dict={vif: f})  # print 2import theanoimport theano.tensor as Tvif = T.fvector()out = vif + T.floor(vif)grad = T.grad(out.sum(), vif)func = theano.function([vif], grad)print func(f) # print 1It looks like the gradient of tf.floor(x) w.r.t x is 1. But I'm expecting it to be 0, as in theano.Right now I could use a double casting as a work around, but why is it different?
performance	log_device_placement not working in some casesHey guys, thank you for working on TensorFlow so hard!I think I found a small bug, but it might be so that I just don't understand ConfigProto correctly.So:config = tf.ConfigProto(log_device_placement=True)server = tf.train.Server.create_local_server()with tf.Session(server.target, config=config):outputs the device placement correctly, butconfig = tf.ConfigProto(log_device_placement=True)server = tf.train.Server.create_local_server(config=config)with tf.Session(server.target):doesn't (at all).While this is not groundbreaking, just wanted to let you know.Cheers, Kris
performance	Reload Button in Tensorboard 1.1rc1 Resets Chart ScalesIn tensorboard 1.1rc1, hitting the "reload button",  , causes the scaling on the charts to reset. That was not the case in 1.0.1.For example if I zoom in here:to:this zoom is lost.
performance	BiasGradOp mistakenly put on CPUNOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.You must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:custom codeTensorFlow installed from (source or binary)?: from binaryTensorFlow version: 1.0.1Bazel version (if compiling from source): N/ACUDA/cuDNN version: CUDA 8.0, cuDNN v5.1GPU Model and Memory: GTX 1080, 8GBExact command to reproduce:Here is a sample script in Python that can reproduce the problem:import tensorflow as tfimport numpy as nply = tf.layersdef lrelu(x, leak=0.2, name="lrelu"):    with tf.variable_scope(name):        f1 = 0.5 * (1 + leak)        f2 = 0.5 * (1 - leak)        return f1 * x + f2 * tf.abs(x)        # return tf.maximum(leak*x, x)x = np.ones([16, 3, 32, 32], dtype=np.float32)with tf.device('/gpu:0'):    input = tf.placeholder(tf.float32, shape=[16, 3, 32, 32])    output = ly.conv2d(input, 3, kernel_size=1, data_format='channels_first',                       strides=1, activation=lrelu)    loss = tf.gradients(input - output, input)[0]    optimizer = tf.train.AdamOptimizer()    gradients = optimizer.compute_gradients(loss)    grad_op = optimizer.apply_gradients(gradients)with tf.Session() as sess:    sess.run(tf.global_variables_initializer())    out = sess.run(grad_op, feed_dict={input: x})Describe the problem clearlyI am on Ubuntu 16.04. While running the above script, despite the device has been specified to be GPU, tensorflow still try to do the BiasGradOp on CPU and will cause an error because of the data format. If I change the implementation of lrelu() to return tf.maximum(leak*x, x) then the problem goes away.Source Code / LogsHere is the output from console:I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locallyI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zeroI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: name: GeForce GTX 1080major: 6 minor: 1 memoryClockRate (GHz) 1.797pciBusID 0000:01:00.0Total memory: 7.92GiBFree memory: 7.21GiBI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: CPU BiasGradOp only supports NHWC. [[Node: gradients_1/conv2d/BiasAdd_grad/BiasAddGrad = BiasAddGrad[T=DT_FLOAT, data_format="NCHW", _device="/job:localhost/replica:0/task:0/gpu:0"](gradients_1/gradients/conv2d/lrelu/Abs_grad/Sign_grad/zeros)]]E tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Invalid argument: CPU BiasGradOp only supports NHWC. [[Node: gradients_1/conv2d/BiasAdd_grad/BiasAddGrad = BiasAddGrad[T=DT_FLOAT, data_format="NCHW", _device="/job:localhost/replica:0/task:0/gpu:0"](gradients_1/gradients/conv2d/lrelu/Abs_grad/Sign_grad/zeros)]]
performance	Freshly built tfcompile core dumpsNOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.You must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?: NoTensorFlow installed from (source or binary)?: SourceTensorFlow version: docker image: "tensorflow/tensorflow:nightly-devel" - git describe = 0.6.0-16017-ga9b7946 (aka: docker-pullable://tensorflow/tensorflow@sha256:5b568f7dd9890bb0b86101bb27779c539f608724c7d4ecf4fdfbbab289bc29de)Bazel version (if compiling from source): Build label: 0.4.5CUDA/cuDNN version: -GPU Model and Memory: -Exact command to reproduce: cd /tensorflow; bazel build tensorflow/compiler/aot:tfcompile ; bazel-bin/tensorflow/compiler/aot/tfcompileDescribe the problem clearlyI'm trying to use tfcompile, when I build it in a Pod on my kubernetes cluster, the resulting binary exits with Aborted (core dumped) after displaying the help message.Source Code / LogsI create a pod like this:apiVersion: v1kind: Podmetadata:  labels:    name: tfcompile  name: tfcompilespec:  containers:  - args:    - sh    - -c    - cd /tensorflow; bazel build tensorflow/compiler/aot:tfcompile ; sleep 864000    image: tensorflow/tensorflow:nightly-devel    name: tfcompile    resources:      limits:        cpu: "1"        memory: 16Gi      requests:        cpu: "1"        memory: 16Giand then when the build is finished, I execute into the pod and try the resulting binary: bazel-bin/tensorflow/compiler/aot/tfcompilefull output:root@tfcompile-1266760932-s2dht:/tensorflow# bazel-bin/tensorflow/compiler/aot/tfcompile                                         2017-04-06 08:08:02.798285: F tensorflow/compiler/aot/tfcompile_main.cc:136] Check failed: argc == 1 && !flags.config.empty() && (flags.dump_fetch_nodes || (!flags.graph.empty() && !flags.entry_point.empty())) tfcompile performs ahead-of-time compilation of a TensorFlow graph,resulting in an object file compiled for your target architecture, and aheader file that gives access to the functionality in the object file.A typical invocation looks like this:   $ tfcompile --graph=mygraph.pb --config=myfile.pbtxtusage: bazel-bin/tensorflow/compiler/aot/tfcompileFlags:--graph=""                       stringInput GraphDef file.  If the file ends in '.pbtxt' it is expected to be in the human-readable proto text format, otherwise it is expected to be in the proto binary format.--config=""                      stringInput file containing Config proto.  If the file ends in '.pbtxt' it is expected to be in the human-readable proto text format, otherwise it is expected to be in the proto binary format.--dump_fetch_nodes=false         boolIf set, only flags related to fetches are processed, and the resulting fetch nodes will be dumped to stdout in a comma-separated list.  Typically used to format arguments for other tools, e.g. freeze_graph.--debug_dir=""                   stringSpecifies a directory to dump debugging information, including rewritten graphs and the XLA HLO module.--target_triple="x86_64-pc-linux"stringTarget platform, similar to the clang -target flag.  The general format is <arch><sub>-<vendor>-<sys>-<abi>.  http://clang.llvm.org/docs/CrossCompilation.html#target-triple.--target_cpu=""                  stringTarget cpu, similar to the clang -mcpu flag.  http://clang.llvm.org/docs/CrossCompilation.html#cpu-fpu-abi--target_features=""             stringTarget features, e.g. +avx2, +neon, etc.--entry_point=""                 stringName of the generated function.  If multiple generated object files will be linked into the same binary, each will need a unique entry point.--cpp_class=""                   stringName of the generated C++ class, wrapping the generated function.  The syntax of this flag is [[<optional_namespace>::],...]<class_name>.  This mirrors the C++ syntax for referring to a class, where multiple namespaces may precede the class name, separated by double-colons.  The class will be generated in the given namespace(s), or if no namespaces are given, within the global namespace.--out_object="out.o"             stringOutput object file name.--out_header="out.h"             stringOutput header file name.--xla_debug_cpu_dump_ir=""       stringDump IR, before optimizations to a path--xla_cpu_llvm_opt_level=2       int32The LLVM optimization level for the CPU XLA backend. Valid range is from 0 to 3 where 0 means no optimizations.--xla_cpu_llvm_cl_opts=""        stringComma-separated list of command line options to pass to LLVM.--xla_cpu_embed_ir=false         boolEmbed the LLVM IR module string in the resultant CpuExecutable.--xla_cpu_parallel=false         boolUse the multi-threaded CPU backend.--xla_cpu_use_eigen=true         boolUse Eigen for matrix multiply on the CPU platform. This is a useful hack for performance comparisons against XLA's implementation.--xla_cpu_multi_thread_eigen=trueboolWhen generating calls to Eigen for matmul and conv, should single or multi-threaded eigen be used? Only used when --xla_cpu_use_eigen is true.Aborted (core dumped)root@tfcompile-1266760932-s2dht:/tensorflow#I've actually been trying this sporadically with different nightly/release builds for the past few weeks, hoping that this would be resolved, but it still does not work, so here is my GH issue ;)
performance	Windows: tf.gfile methods (tf.gfile.Exists, tf.gfile.IsDirectory) are not Windows friendly(Windows 10) in saver.py  train.save() takes a sess_path but on windows it returns an empty result.I had to modify to the following (around line 1354)if not gfile.IsDirectory(os.path.dirname(os.path.abspath(save_path))):similar issue found here:http://stackoverflow.com/questions/7783308/os-path-dirname-file-returns-emptythis is via pip install --upgrade tensorflow-gpu
performance	XLA with tower parallelizationYou must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?: yesTensorFlow installed from (source or binary)?: sourceTensorFlow version: 1.1rc1Bazel version (if compiling from source): 0.4.5CUDA/cuDNN version: 8.0/5.1GPU Model and Memory: Titan X (12 GB)Exact command to reproduce: NADescribe the problem clearlyUsing the automatic XLA optionsess_config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1 causes an 8x performance improvement for my model (while training) when running with 1 GPU, amazing! I would like to parallelize this with a standard tower setup, without XLA this scales linearly (using 4 GPUs) but with XLA I see no difference. The timeline profiler (chrome://tracing) indicates that it just executes each tower one at the time on each GPU.The example in tensorflow/models/neural_gpu/neural_gpu.py indicates that one can use the manual tf.contrib.compiler.jit.experimental_jit_scope context creator, using this causes a x6 times performance peanality compared to not using XLA, but does scale with multiple GPUs.I would like a feature where experimental_jit_scope works similarly to the automatic sess_config XLA option or the sess_config works with multiple GPUs.Source Code / LogsMy model is almost identical to the one in https://github.com/buriburisuri/ByteNet.
performance	Computing 2nd-order tf.gradients of tensors throws Exception when used with batch_normDescribe the problem clearlyIf the updates_collections of a batch_norm layer is set other than tf.GraphKeys.UPDATE_OPS, it is no longer possible to compute 2nd-order tf.gradients with respect to the weights of a fully_connected layer.p.s. It is okay when updates_collections is set as tf.GraphKeys.UPDATE_OPS. I think updates_collections should not affect the ability to compute gradients?EnvironmentsUbuntu 16.04 64bitPython 3.6.0 |Anaconda 4.3.1 (64-bit)| (default, Dec 23 2016, 12:22:00)[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linuxtensorflow-gpu 1.0.1 installed from piplibcublas.so.8.0, libcudnn.so.5, libcufft.so.8.0,  libcuda.so.1, libcurand.so.8.0Source Codeimport tensorflow as tfwith tf.Session() as sess:    X = tf.placeholder(tf.float32, [None, 2])    is_training = tf.placeholder(tf.bool, [], name='is_training')    outputs = tf.contrib.layers.fully_connected(inputs=X, num_outputs=1)    outputs = tf.contrib.layers.batch_norm(        inputs=outputs,        is_training=is_training,        updates_collections='bad_collections')    # get gradients of X with respect to outputs values    grads = tf.gradients(outputs, [        X,    ])[0]    bad_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)    # get gradients of weights with respect to gradients of X    bad_grads = tf.gradients(grads, bad_vars) # this lineLogsTraceback (most recent call last):  File "test.py", line 18, in <module>    bad_grads = tf.gradients(grads, bad_vars)  File "$HOME/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py", line 474, in gradients    out_grads[i] = control_flow_ops.ZerosLikeOutsideLoop(op, i)  File "$HOME/anaconda2/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py", line 1303, in ZerosLikeOutsideLoop    pred = op_ctxt.predAttributeError: 'NoneType' object has no attribute 'pred'
performance	beta2_power is applied incorrectly in Adam optimizerIn adam.py and in the ApplyAdam op, the denominator is effectively:(tf.sqrt(v_t) + epsilon_t) / tf.sqrt(1 - beta2_power)However, this appears incorrect – per the paper, the correct EMA adjustment should give:tf.sqrt(v_t / (1 - beta2_power)) + epsilon_tOtherwise, when epsilon_t is large relative to tf.sqrt(v_t), the effective epsilon used in the denominator is also scaled up by the correction factor, which doesn't match what's in the paper.Does this seem right, or am I missing something here?
performance	tensorboard doesnt display y-axis correctly.This plot makes it look like AUC is greater than 1.0 when it is not.c:\Python35\Scripts>pip show tensorflow-gpuName: tensorflow-gpuVersion: 1.1.0rc1Summary: TensorFlow helps the tensors flowHome-page: http://tensorflow.org/Author: Google Inc.Author-email: opensource@google.comLicense: Apache 2.0Location: c:\python35\lib\site-packagesRequires: numpy, wheel, protobuf, six, werkzeug
performance	Any idea why "failed to create cublas handle"?When I run a demo of Faster R-CNN,I meet an error,I have spend a whole week on it,but not work:Env:OS:Ubuntu16.04TensorFlow version:1.0.1TensorFlow installed from (source or binary)?:binaryCUDA/cuDNN version:CUDA8.0 cuDNN5.1GPU Model and Memory: GTX 950 2GExact command to reproduce:python ./tools/demo.py --model model_pathSee https://github.com/smallcorgi/Faster-RCNN_TFThe error as follows:W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 791.02MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 1.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.E tensorflow/stream_executor/cuda/cuda_blas.cc:372] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZEDW tensorflow/stream_executor/stream.cc:1390] attempting to perform BLAS operation using StreamExecutor without BLAS supportTraceback (most recent call last):File "./tools/demo.py", line 126, in _, _= im_detect(sess, net, im)File "/home/tangshouquan/Faster-RCNN_TF/tools/../lib/fast_rcnn/test.py", line 179, in im_detectrun_metadata=run_metadata)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 767, in runrun_metadata_ptr)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 965, in _runfeed_dict_string, options, run_metadata)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1015, in _do_runtarget_list, options, run_metadata)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1035, in _do_callraise type(e)(node_def, op, message)tensorflow.python.framework.errors_impl.InternalError: Blas SGEMM launch failed : m=1369, n=18, k=512[[Node: rpn_cls_score/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="VALID", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](rpn_conv/3x3/rpn_conv/3x3, rpn_cls_score/weights/read)]][[Node: cls_score/cls_score/_109 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_357_cls_score/cls_score", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]]Caused by op u'rpn_cls_score/Conv2D', defined at:File "./tools/demo.py", line 114, in net = get_network(args.demo_net)File "/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/factory.py", line 28, in get_networkreturn networks.VGGnet_test()File "/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/VGGnet_test.py", line 16, in initself.setup()File "/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/VGGnet_test.py", line 40, in setup.conv(1,1,len(anchor_scales)32,1,1,padding='VALID',relu = False,name='rpn_cls_score'))File "/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py", line 25, in layer_decoratedlayer_output = op(self, layer_input, *args, **kwargs)File "/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py", line 109, in convconv = convolve(input, kernel)File "/home/tangshouquan/Faster-RCNN_TF/tools/../lib/networks/network.py", line 100, in convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py", line 396, in conv2ddata_format=data_format, name=name)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 763, in apply_opop_def=op_def)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2327, in create_oporiginal_op=self._default_original_op, op_def=op_def)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1226, in initself._traceback = _extract_stack()InternalError (see above for traceback): Blas SGEMM launch failed : m=1369, n=18, k=512[[Node: rpn_cls_score/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="VALID", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](rpn_conv/3x3/rpn_conv/3x3, rpn_cls_score/weights/read)]][[Node: cls_score/cls_score/_109 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_357_cls_score/cls_score", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]]
performance	Uncaught TypeError: Cannot read property 'toString' of undefined when use TensorBoard projectorHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?: Yes. I was training a tree based network using Tensorflow Fold to train word embeddings for SQL parse tree. But this shouldn't be a problem because the TensorBoard can correctly read the checkpoint file.TensorFlow installed from (source or binary)?: binary (installed using pip)TensorFlow version: 1.0.0Bazel version (if compiling from source): N/ACUDA/cuDNN version: N/AGPU Model and Memory: CPU onlyExact command to reproduce:Open the log folder tflogs.zip using TensorBoard (Seems the absolute path is hardcoded in the checkpoint file, the absolute path should be /tmp/workspace/tflogs):tensorboard --logdir=tflogsSwitch to embedding tabEnable 3D label on the top left corner of the projectorDescribe the problem clearlyBefore enabling 3D labelAfter enabling 3D labelExpected result: label shownActual result: the projector becomes blank, while the following error shown in the js console:Uncaught TypeError: Cannot read property 'toString' of undefined    at ProjectorScatterPlotAdapter.getLabelText (tf-tensorboard.html:20587)    at ProjectorScatterPlotAdapter.generate3DLabelsArray (tf-tensorboard.html:20582)    at ProjectorScatterPlotAdapter.createVisualizers (tf-tensorboard.html:20613)    at ProjectorScatterPlotAdapter.set3DLabelMode (tf-tensorboard.html:20245)    at HTMLElement.<anonymous> (tf-tensorboard.html:24813)ProjectorScatterPlotAdapter.getLabelText @ tf-tensorboard.html:20587ProjectorScatterPlotAdapter.generate3DLabelsArray @ tf-tensorboard.html:20582ProjectorScatterPlotAdapter.createVisualizers @ tf-tensorboard.html:20613ProjectorScatterPlotAdapter.set3DLabelMode @ tf-tensorboard.html:20245(anonymous) @ tf-tensorboard.html:24813
performance	BUG: tensorflow.placeholder shape does not serialize with protobufProfobuf serialization(json){"attr": {"dtype": {"type": "DT_FLOAT"},"shape": {"shape": {}}},"name": "x","op": "Placeholder"},Tensorflow codex = tf.placeholder(tf.float32, shape=None, name="x")
performance	KeyError in tf.contrib.graph_editor.graph_replaceWhen applying graph_replace to graphs containing ops with the _original_op attribute, it can fail with a KeyError. The error occurs in Transformer._copy_ops when trying to copy an op whose _original_op has not yet been copied. The ordering of ops that are copied is not deterministic so this error pops up somewhat randomly.The _original_op attributes appear to be created by tf.gradients to point back to the op from the forward pass.Example code snippet (note: you may need to run this multiple times to get a failure):import tensorflow as tfgraph_replace = tf.contrib.graph_editor.graph_replacew = tf.Variable(0.0, name="w")y = tf.multiply(tf.multiply(w, w, name="mul1"), w, name="mul2")g = tf.gradients(y, w)[0]g_new = graph_replace(g, {w.value(): g})Error:/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/graph_editor/transform.py in transform_op_if_inside_handler(info, op, keep_if_possible)    122   """    123   if op in info.sgv.ops:--> 124     return info.transformed_ops[op]    125   else:    126     if keep_if_possible and info.graph is info.graph_:KeyError: <tf.Operation 'mul1' type=Mul>I see three possible fixes:Remove _original_op attributes in the copied graph (I don't see anywhere in the TF codebase where it is used)Move the creation of the _original_op attribute from the copy_op_handler function to the end of Transformer._copy_ops after all ops have been copied.Topologically sort the ops being copied so that ops that are _original_op attributes are created before their children.My implementation of option 2 seems to fix this problem, but I might be missing something about the usage of _original_op.
performance	YoloDetector example needs java_test() ruleHi:when I use android studio to compile TensorflowYoloDetector, the following error occurs:E/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate()(tried Java_org_tensorflow_contrib_android_RunStats_allocate and  Java_org_tensorflow_contrib_android_RunStats_allocate__)TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inferenceTensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)TensorFlowInferenceInterface: Failed to load model from 'file:///android_asset/graph-tiny-yolo-voc.pb': java.io.IOException: Not a valid TensorFlow Graph serialization: Invalid GraphDeftensorflow: TensorFlowYoloDetector: TF init status: 1. Look forward to your reply.
performance	Issues when using Queues + tf.train.ServerNOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.You must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?: YesTensorFlow installed from (source or binary)?: binaryTensorFlow version: 1.0.0 CPU / 1.0.1 (CPU and GPU enabled) / 1.1.0rc1 (CPU)Bazel version (if compiling from source):CUDA/cuDNN version: N/AGPU Model and Memory: N/AExact command to reproduce: cf below.This problem has been reproduced on both Linux and various Mac OS machines.Describe the problem clearlyWe seem to experience issues when using both queues + tf.train.Server. When executed in a simple python 3.5.3 console, the following script hangs:import tensorflow as tfimport timecluster = tf.train.ClusterSpec({"cpu1" : ['localhost:2222']})server = tf.train.Server(cluster, job_name="cpu1", task_index=0)with tf.Graph().as_default() as graph:    # Queue    input_queue = tf.train.input_producer(tf.constant([0.], dtype=tf.float32))    # Useless variable    variable = tf.Variable(1., dtype=tf.float32, trainable=False, name="variable")    # Session and queue runners    session = tf.Session(target=server.target)    session.run(tf.global_variables_initializer())    tf.train.start_queue_runners(session)print(session.run(variable))  # this worksprint(session.run(tf.assign(variable, 2)))  # this also works, but only if called directly# any pause between creating and running the session breaks ittime.sleep(1)print(session.run(variable))  # retrieving a variable still works, but...print(session.run(tf.assign(variable, 3)))  # ... assigning a variable will make the program hang.It outputs:122and then hangs forever. The problem vanishes when either commenting the input_queue=... line, or when writing session = tf.Session() instead of passing the server.target.The problems seems to happen not only with variable assignments, but also saving the model using tf.train.Saver().save(session, 'my_model') for instance (and possibly other operations). Note that reading a variable works fine.In the example script, the time.sleepcommand simulates a pause between creating the session and running it to set a variable. The same effect is achieved, for example, when splitting session creation and running code across two Jupyter notebook cells. When executing the whole code in one cell, it works fine.Source Code / LogsThe source code to reproduce the problem is displayed above. I have attached a traceback using gdb, which shows that the program is hanging while trying to acquire a lock.tf-issue-gdb-bt.txttf-issue-gdb-stack-threads.txt
performance	Incorrect results when graph is split across several GPUs.Background info:Custom codeTensorflow r1.0 installed from binaries on WindowsCUDA 8.0, cuDNN 5.1.52 GPUs: GTX Titan X and Titan X PascalProblem:I have a model that is small enough to be trained on a single GPU with 12GB memory. Training works fine and converges.However, when I evaluate the model with a validation set that is too large to fit on one of my GPUs, TensorFlow seems to use both of my GPUs (one GTX Titan X and one Titan X Pascal). When this happens, a large fraction of the results returned by TensorFlow are incorrect. The returned values are not completely missing, i.e. not all zero or something like that, but so inaccurate that the validation performance is terrible.More specifically, my model consists of a shared initial stage, followed by a list of ~50 sub-networks that all receive input from the shared stage, but are otherwise independent. Data is split using tf.dynamic_partition(). From the results that I get, it appears that TensorFlow moves some of the 50 sub-networks to the second GPU if the memory on the first one isn't sufficient. The moved sub-models then return incorrect results (the others are unchanged).If I instead force evaluation to be performed on the CPU, all results are as expected. All I need to do is add with tf.device('/cpu:0') to the very top of my script. The results also look good if I reduce the size of the validation set so that it fits onto one GPU.I am sorry for not providing a working example. I will try to create one, but it might take a while since, by nature of the problem, it needs to be a fairly large/complex model.
performance	Make bounding box operators consistentRight now, the bounding box operators (tf.image.draw_bounding_boxes, tf.image.non_max_suppression and tf.image.sample_distorted_bounding_box) expect bounding boxes in the form of [ymin, xmin, ymax, xmax], with the origin (0,0) being the lower left corner of the image. But images themselves are tensors, and the pixel with index [0,0] in the tensor is in the top left, so bounding box coordinates are the opposite in the y direction to tensor indices.Additionally, the operations tf.image.pad_to_bounding_box and tf.image.crop_to_bounding_box take coordinates in the form of [ymin, xmin, height, width], with the origin being the top-left corner, so the coordinates are inconsistent even within the image ops themselves (plus the parametrization of the bounding boxes is different, too).And the tf.image.crop_and_resize op doesn't specify what origin it uses (though I think it's bottom left too)I feel like this sort of inconsistency is unnecessarily confusing and a high risk for introducing errors.It's especially bad since, if you supply bounding boxes the wrong way around to draw_bounding_boxes, it'll still draw them correctly (All bounding box operators should use the same coordinate system and preferably the same parametrization, and preferably the coordinates should be consistent with image tensor indexing.
performance	consecutive calls of saver.restore(sess,path) slows downYou must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?: noTensorFlow installed from (source or binary)?: binaryTensorFlow version: 0.12.1Bazel version (if compiling from source):CUDA/cuDNN version: cpuDescribe the problem clearlyHi I was building and evaluating ensemble models about 45 very simple neural networks.when evaluating, I noticed that consecutive calls to saver.restore(sess, path) slows downat first it spent about 0.08 seconds but after 45 calls to  saver.restore(), time spent on restore increased to 0.5 seconds. It kept increasing to 1 second and beyond.Is anyone having the same problem? In the source code, I called test_model() consecutively. Other part didn't slow down but only the part with saver.restore() didSource Code / Logsdef test_model(model, batch_gen, batch_num, batch_size, num_class, model_id):    saver = tf.train.Saver()    start_time = time.time()    print('## Testing model : {}'.format(model_id))    with tf.Session() as sess:        ot = time.time()        sess.run(tf.global_variables_initializer())        # Load latest model to evaluate        checkpoint_dir = CHECKPOINTS_DIR+str(model_id)+'/'        ckpt = tf.train.get_checkpoint_state(os.path.dirname(checkpoint_dir))                if ckpt and ckpt.model_checkpoint_path:            saver.restore(sess, ckpt.model_checkpoint_path)        else:            print('# No trained weight found')            return        nt = time.time()        print('1 : {}'.format(nt-ot))        vote_list = []        for i in xrange(batch_num):            X_batch, Y_batch = batch_gen.next()            _, loss_batch, softmax_batch = sess.run([model.optimizer, model.loss, model.softmax], feed_dict={model.input: X_batch, model.output:Y_batch})                         vote_batch = dense_to_one_hot(np.argmax(softmax_batch,1), num_class)            vote_list.append(vote_batch)        total_vote_list = np.concatenate(vote_list, 0)           print('# time elapsed :{:.1f} seconds'.format(time.time() - start_time ))    return total_vote_list------------------EDIT------------------Problem was not saver.restore() but consecutive calling ofsess.run(tf.global_variables_initializer())session is suppose to free all the memories right?so I think there has to be no performance slow down but there is when making multiple sessionsimport timeimport tensorflow as tfa = tf.Variable([1,2,3,4,5])def test():    for i in range(1000):        with tf.Session() as sess:            ot = time.time()            sess.run(tf.global_variables_initializer())            nt = time.time()            print('test : {:.3f}'.format(nt-ot))running time of tf.global_varaiables_initializer() op slowly increases
performance	[Windows] `import tensorflow` error messages are uninformative.When a user runs import tensorflow, we attempt to dynamically load the DLL _pywrap_tensorflow.pyd. If this fails, the user gets an uninformative (perhaps downright misleading) message:Traceback (most recent call last): File "C:\...\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 18, in swig_import_helper    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(file)])File "C:\...\lib\imp.py", line 296, in find_module    raise ImportError(_ERR_MSG.format(name), name=name)ImportError: No module named '_pywrap_tensorflow'This error can happen for several reasons:(Rare) The package has not been installed correctly, and the file _pywrap_tensorflow.pyd is not present in the expected location.The package has been installed for an incompatible version of Python (e.g. installed on Python 3.6, but built for 3.5, as in #9167). I suspect this is because it fails to load python35.dll.The library has been installed correctly, but one or more of its native dependencies is missing. Common examples include:MSVCP140.dll (the Microsoft Visual C++ redistributable library). The compiled C++ code depends on this library being present, but it is not installed as standard, unless you use Anaconda. (See this Stack Overflow question, for example.)CUDA libraries. The user's %PATH% may not include the directory that contains the CUDA DLLs.cudnn64_5.dll. This is typically installed in a different directory from the CUDA libraries, and must be added to the user's %PATH% explicitly.It would be helpful if we could provide more information about the cause of an ImportError, and in particular we would like to show the name of the missing DLL to aid the user in diagnosing the problem. It's less clear to me how we achieve this, since the error is reported by LoadLibrary() of our compiled code before we have the chance to execute anything.A couple of thoughts spring to mind:Can we use /DELAYLOAD during the build process so that (at least) we have the chance to probe the CUDA-related libraries before using them? Are there any performance consequences to doing this?Alternatively, can we implement a sanity check in Python before we import _pywrap_tensorflow.pyd to ensure that the relevant files will be found?/cc @guschmue @vit-stepanovs in case they have any smart ideas!
performance	The running speed of Windows is lower than that in LinuxPlease go to Stack Overflow for help and support. http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g. fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.System InformationHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:OS Platform and Distribution (i.e. Linux Ubuntu 16.0):TensorFlow installed from (source or binary)?:TensorFlow version (use command below):Bazel version (if compiling from source):CUDA/cuDNN version:GPU Model and Memory:Exact command to reproduce:You can collect some of this information using our environment capture script https://github.com/tensorflow/tensorflow/blob/master/tools/You can collect the TensorFlow version withpython -c "import tensorflow as tf; print (tf.GIT_VERSION, tf.VERSION)"Describe the problem clearlySource Code / LogsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
performance	AssertionError: Items are not equal: ACTUAL: 2147483647 DESIRED: -2147483648System informationOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04 (ppc64le)TensorFlow installed from (source or binary):Installed from source (v1.0.1)TensorFlow version (use command below):('v1.0.1-0-ge895d5c-dirty', '1.0.1')Bazel version (if compiling from source):bazel release 0.4.4-2017-04-10 (@80a07b5)CUDA/cuDNN version:In disable modeExact command to reproduce:bazel test //tensorflow/python/kernel_tests:cast_op_testDescribe the problemBuilt TF successfully , however I am getting Items are not equal error while running the cast_op_testTo cross verify the test results , I ran this test on X86 vm and that passed successfully. This test is failing only on ppc64le platform . Here I would like to know your suggestions and comments.Source code / logs$ bazel test //tensorflow/python/kernel_tests:cast_op_testexec ${PAGER:-/usr/bin/less} "$0" || exit 1-----------------------------------------------------------------------------I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 16 visible devicesI tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/cast_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/cast_op_test.py:62: ComplexWarning: Casting complex values to real discards the imaginary part  np_ans = x.astype(dtype)....F.W tensorflow/core/framework/op_kernel.cc:983] Unimplemented: Cast int64 to string is not supportedE tensorflow/core/common_runtime/executor.cc:594] Executor failed to create kernel. Unimplemented: Cast int64 to string is not supported         [[Node: Cast = Cast[DstT=DT_STRING, SrcT=DT_INT64, _device="/job:localhost/replica:0/task:0/cpu:0"](Cast/x)]]........======================================================================FAIL: testInfNan (__main__.CastOpTest)----------------------------------------------------------------------Traceback (most recent call last):  File "/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/cast_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/cast_op_test.py", line 150, in testInfNan    self._compare(np.inf, np.int32, i4.min, False)  File "/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/python/kernel_tests/cast_op_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/cast_op_test.py", line 124, in _compare    x, dst_dtype, use_gpu=use_gpu), dst_dtype(expected))  File "/usr/lib64/python2.7/site-packages/numpy/testing/utils.py", line 425, in assert_equal    raise AssertionError(msg)AssertionError:Items are not equal: ACTUAL: 2147483647 DESIRED: -2147483648----------------------------------------------------------------------Ran 14 tests in 2.485sFAILED (failures=1)````
performance	One set of GPUs on same machine and same model work well, another gets OOM errorI am using multiple GPUs (num_gpus = 4) for training one model with multiple towers. The model is training well on one set of GPUs: CUDA_VISIBLE_DEVICES = 0,1,2,3 while it gets OOM problem during the first graph evaluation with CUDA_VISIBLE_DEVICES = 0,1,4,5Following options are used for creating a sessionsession_config=tf.ConfigProto(      allow_soft_placement=True,      log_device_placement=False)session_config.gpu_options.per_process_gpu_memory_fraction = 0.94session_config.gpu_options.allow_growth=FalseBatch size, is already super small, = 3System informationTensorflow 1.0Cuda 8.0Ubuntu 14.04.5 LTSAll GPUs : GeForce GTX 1080Source code / logsname: GeForce GTX 1080major: 6 minor: 1 memoryClockRate (GHz) 1.7335pciBusID 0000:07:00.0Total memory: 7.92GiBFree memory: 7.81GiBW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0xcc4593a0I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: name: GeForce GTX 1080major: 6 minor: 1 memoryClockRate (GHz) 1.7335pciBusID 0000:08:00.0Total memory: 7.92GiBFree memory: 7.81GiBW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0xd2404670I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 2 with properties: name: GeForce GTX 1080major: 6 minor: 1 memoryClockRate (GHz) 1.7335pciBusID 0000:18:00.0Total memory: 7.92GiBFree memory: 7.81GiBW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0xd25591b0I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 3 with properties: name: GeForce GTX 1080major: 6 minor: 1 memoryClockRate (GHz) 1.7335pciBusID 0000:1c:00.0Total memory: 7.92GiBFree memory: 7.81GiBI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 2 3 I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y Y Y Y I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   Y Y Y Y I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 2:   Y Y Y Y I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 3:   Y Y Y Y I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:07:00.0)I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 1080, pci bus id: 0000:08:00.0)I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:2) -> (device: 2, name: GeForce GTX 1080, pci bus id: 0000:18:00.0)I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:3) -> (device: 3, name: GeForce GTX 1080, pci bus id: 0000:1c:00.0)I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 47441 get requests, put_count=8461 evicted_count=1000 eviction_rate=0.118189 and unsatisfied allocation rate=0.844839I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.33GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.08GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.98GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.98GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.54GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.54GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.17GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.68GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 3.86GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2698 get requests, put_count=8709 evicted_c
performance	Segfaults/NaN's in SVDI'm getting failures trying to run SVD on a particular matrix. The result is either all NaN's for u matrix, or it's segfaults like below.To reproduce, run this script in Python3: https://github.com/yaroslavvb/stuff/blob/master/svd_test.pyI can't see anything special about this matrix beside the fact that it's badly conditioned. IE, I can perform SVD on this matrix in Mathematica fine@rmlarsen #0  0x00007fffe320e121 in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::perturbCol0(Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<long, 1, -1, 1, 1, -1>, 0, Eigen::InnerStride<1> > const&, Eigen::Matrix<float, -1, 1, 0, -1, 1> const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> > const&, Eigen::Ref<Eigen::Array<float, -1, 1, 0, -1, 1>, 0, Eigen::InnerStride<1> >) ()#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so# #1  0x00007fffe320fa81 in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::computeSVDofM(long, long, Eigen::Matrix<float, -1, -1, 0, -1, -1>&, Eigen::Matrix<float, -1, 1, 0, -1, 1>&, Eigen::Matrix<float, -1, -1, 0, -1, -1>&) ()#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so# #2  0x00007fffe321e21c in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::divide(long, long, long, long, long) ()#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so# #3  0x00007fffe321dbb8 in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::divide(long, long, long, long, long) ()#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so# #4  0x00007fffe32220bd in Eigen::BDCSVD<Eigen::Matrix<float, -1, -1, 1, -1, -1> >::compute(Eigen::Matrix<float, -1, -1, 1, -1, -1> const&, unsigned int) ()#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so# #5  0x00007fffe32227a1 in tensorflow::SvdOp<float>::ComputeMatrix(tensorflow::OpKernelContext*, tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<float, -1, -1, 1, -1, -1> const, 0, Eigen::Stride<0, 0> >, 4> const&, tensorflow::gtl::InlinedVector<Eigen::Map<Eigen::Matrix<float, -1, -1, 1, -1, -1>, 0, Eigen::Stride<0, 0> >, 4>*) ()                                                                 from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so                                       #6  0x00007fffe3228c75 in tensorflow::LinearAlgebraOp<float>::ComputeTensorSlice(tensorflow::OpKernelContext*, long long, tensorflow::gtl::InlinedVector<tensorflow::Tensor const*, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::TensorShape, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::Tensor*, 4> const&, tensorflow::gtl::InlinedVector<tensorflow::TensorShape, 4> const&) ()#    from /home/yaroslav/.conda/envs/whitening/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
performance	TensorFlow on ARMv7 seems to be slowerI have installed tensorflow on our custom board which is based on i.mx6 (ARMv7) processor. I have compiled the C++ module alone without python support and was able to run the "tensorflow/pi_examples/label_image"Command used:  make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PIThe problem is that the application seems to be very slow compared to Laptop (Intel i5). The inference takes close to 60-70s while it takes only 0.6 - 0.7s in my Laptop.After that, I figured out that I missed to use compiler optimization flag to use Neon. I compiled with Neon support and now it takes around 10-17s for same example.Command used: make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI  OPTFLAGS="-Os -mfpu=neon -funsafe-math-optimizations -ftree-vectorize"Is there anything I am missing?System informationHave I written custom code: NoOS Platform and Distribution: Yocto debian flavourTensorFlow installed from:  source (27a9808)TensorFlow version: NABazel version (if compiling from source): Not usedCUDA/cuDNN version: NAGPU model and memory: NAExact command to reproduce: NA
performance	Estimator numpy_input_fn doesn't work when reading input with pytablesSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Relatively straightforward attempt at using estimator flow with input_fnOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Gentoo LinuxTensorFlow installed from (source or binary): sourceTensorFlow version (use command below): b'v1.0.0-2171-gbaa85cb' 1.0.1Bazel version (if compiling from source): 0.4.4-CUDA/cuDNN version: 8.0.61GPU model and memory: GTX 970 4GBExact command to reproduce:Other stuff: Python 3.4, pytables 3.3.0, numpy 1.12.1, hdf5-1.8.18Describe the problemI have an issue when reading multidimensional arrays from hdf5 file using pytables. I can fix the issue for myself locally by changing _OrderedDictNumpyFeedFn class (line 173 in my version) from column[integer_indexes]tonp.take(column, integer_indexes, axis=0)Source code / logsRelevant bit of code:def make_input_fn(data, batch_size):    input_features = {node.name: node for node in data.get_node('/x')}    ys = data.get_node('/y')    return numpy_input_fn(input_features, ys, batch_size=batch_size, num_epochs=5, shuffle=False, num_threads=1)def main(unused_argv):    model_fn = make_train_model(feat)    config = learn.RunConfig(save_checkpoints_secs=60)    est = learn.Estimator(        model_fn=model_fn, model_dir="data/tf/try1", config=config    )    training_data = tables.open_file('data/hdf5/training.h5')    train_in = make_input_fn(training_data, 256)    est.fit(        input_fn=train_in,        steps=100    )    training_data.close()Error I get:INFO:tensorflow:Using config: {'_is_chief': True, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 60, '_environment': 'local', '_num_ps_replicas': 0, '_master': '', '_task_type': None, '_tf_config': gpu_options {  per_process_gpu_memory_fraction: 1.0}, '_num_worker_replicas': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff377eaf550>, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_evaluation_master': '', '_model_dir': None, '_save_summary_steps': 100, '_tf_random_seed': None, '_task_id': 0}INFO:tensorflow:Create CheckpointSaverHook.2017-04-17 10:05:38.231511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero2017-04-17 10:05:38.231863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: name: GeForce GTX 970major: 5 minor: 2 memoryClockRate (GHz) 1.4305pciBusID 0000:01:00.0Total memory: 3.94GiBFree memory: 3.45GiB2017-04-17 10:05:38.232016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 2017-04-17 10:05:38.232048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 2017-04-17 10:05:38.232081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0)INFO:tensorflow:Restoring parameters from data/tf/try1/model.ckpt-4INFO:tensorflow:Error reported to Coordinator: <class 'ValueError'>, operands could not be broadcast together with shapes (256,) (4,) INFO:tensorflow:Saving checkpoints for 4 into data/tf/try1/model.ckpt.Traceback (most recent call last):  File ".../venv/lib/python3.4/site-packages/tables/array.py", line 651, in __getitem__    startl, stopl, stepl, shape = self._interpret_indexing(key)  File ".../venv/lib/python3.4/site-packages/tables/array.py", line 408, in _interpret_indexing    raise TypeError("Non-valid index or slice: %s" % key)TypeError: Non-valid index or slice: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]During handling of the above exception, another exception occurred:Traceback (most recent call last):  File "/usr/lib64/python3.4/runpy.py", line 170, in _run_module_as_main    "__main__", mod_spec)  File "/usr/lib64/python3.4/runpy.py", line 85, in _run_code    exec(code, run_globals)  File "/zfs_data/Sources/betahex/betahex/training/supervised.py", line 106, in <module>    tf.app.run()  File ".../venv/lib/python3.4/site-packages/tensorflow/python/platform/app.py", line 48, in run    _sys.exit(main(_sys.argv[:1] + flags_passthrough))  File "/zfs_data/Sources/betahex/betahex/training/supervised.py", line 99, in main    steps=50  File ".../venv/lib/python3.4/site-packages/tensorflow/python/util/deprecation.py", line 281, in new_func    return func(*args, **kwargs)  File ".../venvs/default/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 429, in fit    loss = self._train_model(input_fn=input_fn, hooks=hooks)  File ".../venv/lib/python3.4/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py", line 977, in _train_model    _, loss = mon_sess.run([model_fn_ops.train_op, model_fn_ops.loss])  File .../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 500, in __exit__    self._close_internal(exception_type)  File ".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 535, in _close_internal    self._sess.close()  File ".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 769, in close    self._sess.close()  File ".../venv/lib/python3.4/site-packages/tensorflow/python/training/monitored_session.py", line 866, in close    ignore_live_threads=True)  File ".../venv/lib/python3.4/site-packages/tensorflow/python/training/coordinator.py", line 389, in join    six.reraise(*self._exc_info_to_raise)  File "/usr/lib/python3.4/site-packages/six.py", line 686, in reraise    raise value  File ".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py", line 93, in _run    feed_dict = None if feed_fn is None else feed_fn()  File ".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py", line 175, in __call__    for column in self._ordered_dict_of_arrays.values()  File ".../venv/lib/python3.4/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py", line 175, in <listcomp>    for column in self._ordered_dict_of_arrays.values()  File ".../venv/lib/python3.4/site-packages/tables/array.py", line 656, in __getitem__    coords = self._point_selection(key)  File ".../venv/lib/python3.4/site-packages/tables/leaf.py", line 561, in _point_selection    coords[idx] = (coords + self.shape)[idx]ValueError: operands could not be broadcast together with shapes (256,) (4,) Closing remaining open files:data/hdf5/training.h5...done
performance	[Docs] Update wheels URLs to match latest TensorFlow release (1.1.0)The wheels available on the website are from the previous release (1.0.1) which still contain OpKernels errors that are solved at head (as well as on 1.1.0) and can be ignored but are confusing users prompting repeated reports of this issue.
performance	TensorBoard filter regressonSystem informationDocker image tensorflow/tensorflow:nightly (or 1.1.0rc2)Describe the problemStart a tensorboard processtensorboard --logdir /efs/log/atariand try and filter. It does not have any effect.
performance	label_image deadlocksI am on commit 14cd77b.I've added the following change that randomizes order of execution of tasks in thread pool:diff --git a/tensorflow/core/lib/core/threadpool.cc b/tensorflow/core/lib/core/threadpool.ccindex 50aec3e..03c4485 100644--- a/tensorflow/core/lib/core/threadpool.cc+++ b/tensorflow/core/lib/core/threadpool.cc@@ -20,6 +20,8 @@ limitations under the License. #include "tensorflow/core/platform/tracing.h" #include "tensorflow/core/platform/types.h"+#include <unistd.h>+ namespace tensorflow { namespace thread {@@ -34,6 +36,7 @@ ThreadPool::ThreadPool(Env* env, const string& name, int num_threads) ThreadPool::ThreadPool(Env* env, const ThreadOptions& thread_options,                        const string& name, int num_threads)     : name_(name) {+  rand_ = getpid();   CHECK_GE(num_threads, 1);   string name_prefix = "tf_" + name_;   for (int i = 0; i < num_threads; i++) {@@ -102,6 +105,7 @@ void ThreadPool::WorkerLoop() {         w.cv.wait(l);       }     }+    std::swap(pending_[0], pending_[rand_r(&rand_) % pending_.size()]);     // Pick up pending work     Item item = pending_.front();     pending_.pop_front();diff --git a/tensorflow/core/lib/core/threadpool.h b/tensorflow/core/lib/core/threadpool.hindex ef37dcf..ae1eef3 100644--- a/tensorflow/core/lib/core/threadpool.h+++ b/tensorflow/core/lib/core/threadpool.h@@ -66,6 +66,7 @@ class ThreadPool {   std::vector<Thread*> threads_;  // All threads   std::vector<Waiter*> waiters_;  // Stack of waiting threads.   std::deque<Item> pending_;      // Queue of pending work+  unsigned rand_;   TF_DISALLOW_COPY_AND_ASSIGN(ThreadPool); };Then run label_image as:while echo OK; do bazel-bin/tensorflow/examples/label_image/label_image; doneafter few iterations it deadlocks. All threads are blocked on condition variables, but tasks they are waiting for can't run because all thread pool threads are busy:(gdb) info threads  Id   Target Id         Frame   97   Thread 0x7f0d04038700 (LWP 74836) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  96   Thread 0x7f0d03837700 (LWP 74837) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  95   Thread 0x7f0d03036700 (LWP 74838) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  94   Thread 0x7f0d02835700 (LWP 74839) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  93   Thread 0x7f0d02034700 (LWP 74840) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  92   Thread 0x7f0d01833700 (LWP 74841) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  91   Thread 0x7f0d01032700 (LWP 74842) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  90   Thread 0x7f0d00831700 (LWP 74843) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  89   Thread 0x7f0cf3fff700 (LWP 74844) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  88   Thread 0x7f0cf37fe700 (LWP 74845) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  87   Thread 0x7f0cf2ffd700 (LWP 74846) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  86   Thread 0x7f0cf27fc700 (LWP 74847) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  85   Thread 0x7f0cf1ffb700 (LWP 74848) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  84   Thread 0x7f0cf17fa700 (LWP 74849) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  83   Thread 0x7f0cf0ff9700 (LWP 74850) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  82   Thread 0x7f0ce7fff700 (LWP 74851) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  81   Thread 0x7f0ce77fe700 (LWP 74852) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  80   Thread 0x7f0ce6ffd700 (LWP 74853) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  79   Thread 0x7f0ce67fc700 (LWP 74854) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  78   Thread 0x7f0ce5ffb700 (LWP 74855) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  77   Thread 0x7f0ce57fa700 (LWP 74856) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  76   Thread 0x7f0ce4ff9700 (LWP 74857) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  75   Thread 0x7f0cdffff700 (LWP 74858) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  74   Thread 0x7f0cdf7fe700 (LWP 74859) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  73   Thread 0x7f0cdeffd700 (LWP 74860) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  72   Thread 0x7f0cde7fc700 (LWP 74861) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  71   Thread 0x7f0cddffb700 (LWP 74862) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  70   Thread 0x7f0cdd7fa700 (LWP 74863) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  69   Thread 0x7f0cdcff9700 (LWP 74864) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  68   Thread 0x7f0cdc7f8700 (LWP 74865) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  67   Thread 0x7f0cdbff7700 (LWP 74866) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  66   Thread 0x7f0cdb7f6700 (LWP 74867) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  65   Thread 0x7f0cdaff5700 (LWP 74868) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  64   Thread 0x7f0cda7f4700 (LWP 74869) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  63   Thread 0x7f0cd9ff3700 (LWP 74870) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  62   Thread 0x7f0cd97f2700 (LWP 74871) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  61   Thread 0x7f0cd8ff1700 (LWP 74872) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  60   Thread 0x7f0cd3fff700 (LWP 74873) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  59   Thread 0x7f0cd37fe700 (LWP 74874) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  58   Thread 0x7f0cd2ffd700 (LWP 74875) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  57   Thread 0x7f0cd27fc700 (LWP 74876) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  56   Thread 0x7f0cd1ffb700 (LWP 74877) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  55   Thread 0x7f0cd17fa700 (LWP 74878) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  54   Thread 0x7f0cd0ff9700 (LWP 74879) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  53   Thread 0x7f0cd07f8700 (LWP 74880) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  52   Thread 0x7f0ccfff7700 (LWP 74881) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  51   Thread 0x7f0ccf7f6700 (LWP 74882) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  50   Thread 0x7f0cceff5700 (LWP 74883) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  49   Thread 0x7f0cce7f4700 (LWP 74884) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  48   Thread 0x7f0ccdff3700 (LWP 74885) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  47   Thread 0x7f0ccd7f2700 (LWP 74886) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  46   Thread 0x7f0cccff1700 (LWP 74887) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  45   Thread 0x7f0cc7fff700 (LWP 74888) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  44   Thread 0x7f0cc77fe700 (LWP 74889) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  43   Thread 0x7f0cc6ffd700 (LWP 74890) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  42   Thread 0x7f0cc67fc700 (LWP 74891) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  41   Thread 0x7f0cc5ffb700 (LWP 74892) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  40   Thread 0x7f0cc57fa700 (LWP 74893) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  39   Thread 0x7f0cc4ff9700 (LWP 74894) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  38   Thread 0x7f0cb7fff700 (LWP 74895) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  37   Thread 0x7f0cb77fe700 (LWP 74896) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  36   Thread 0x7f0cb6ffd700 (LWP 74897) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185---Type <return> to continue, or q <return> to quit---  35   Thread 0x7f0cb67fc700 (LWP 74898) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  34   Thread 0x7f0cb5ffb700 (LWP 74899) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  33   Thread 0x7f0cb57fa700 (LWP 74900) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  32   Thread 0x7f0cb4ff9700 (LWP 74901) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  31   Thread 0x7f0caffff700 (LWP 74902) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  30   Thread 0x7f0caf7fe700 (LWP 74903) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  29   Thread 0x7f0caeffd700 (LWP 74904) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  28   Thread 0x7f0cae7fc700 (LWP 74905) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  27   Thread 0x7f0cadffb700 (LWP 74906) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  26   Thread 0x7f0cad7fa700 (LWP 74907) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  25   Thread 0x7f0cacff9700 (LWP 74908) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  24   Thread 0x7f0ca7fff700 (LWP 74909) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  23   Thread 0x7f0ca77fe700 (LWP 74910) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  22   Thread 0x7f0ca6ffd700 (LWP 74911) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  21   Thread 0x7f0ca67fc700 (LWP 74912) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  20   Thread 0x7f0ca5ffb700 (LWP 74913) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  19   Thread 0x7f0ca57fa700 (LWP 74914) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  18   Thread 0x7f0ca4ff9700 (LWP 74915) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  17   Thread 0x7f0ca47f8700 (LWP 74916) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  16   Thread 0x7f0ca3ff7700 (LWP 74917) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  15   Thread 0x7f0ca37f6700 (LWP 74918) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  14   Thread 0x7f0ca2ff5700 (LWP 74919) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  13   Thread 0x7f0ca27f4700 (LWP 74920) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  12   Thread 0x7f0ca1ff3700 (LWP 74921) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  11   Thread 0x7f0ca17f2700 (LWP 74922) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  10   Thread 0x7f0ca0ff1700 (LWP 74923) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  9    Thread 0x7f0c9bfff700 (LWP 74924) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  8    Thread 0x7f0c9b7fe700 (LWP 74925) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  7    Thread 0x7f0c9affd700 (LWP 74926) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  6    Thread 0x7f0c9a7fc700 (LWP 74927) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  5    Thread 0x7f0c99ffb700 (LWP 74928) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  4    Thread 0x7f0c997fa700 (LWP 74929) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  3    Thread 0x7f0c98ff9700 (LWP 74930) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185  2    Thread 0x7f0c987f8700 (LWP 74931) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185* 1    Thread 0x7f0d0ad4c780 (LWP 74835) "label_image" pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185(gdb) thread 53[Switching to thread 53 (Thread 0x7f0cd07f8700 (LWP 74880))]#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185185 in ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S(gdb) bt#0  pthread_cond_wait@@GLIBC_2.3.2 () at ../nptl/sysdeps/unix/sysv/linux/x86_64/pthread_cond_wait.S:185#1  0x00007f0d09fb94bc in __gthread_cond_wait (__mutex=<optimized out>, __cond=<optimized out>)    at /build/buildd/gcc-4.8-4.8.4/build/x86_64-linux-gnu/libstdc++-v3/include/x86_64-linux-gnu/bits/gthr-default.h:864#2  std::condition_variable::wait (this=<optimized out>, __lock=...) at ../../../../../src/libstdc++-v3/src/c++11/condition_variable.cc:52#3  0x00000000004464fc in Eigen::Notification::WaitForNotification() ()#4  0x000000000064f49a in void Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>::packRhsAndKernel<Eigen::internal::packRhsAndKernelArg<float, float, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0>, Eigen::internal::blas_data_mapper<float, long, 0, 0>, long>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 8, 4, false, false> >(Eigen::internal::packRhsAndKernelArg<float, float, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0>, Eigen::internal::blas_data_mapper<float, long, 0, 0>, long>) ()#5  0x0000000000634b1f in std::_Function_handler<void (), std::_Bind<void (*(Eigen::internal::packRhsAndKernelArg<float, float, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0>, Eigen::internal::blas_data_mapper<float, long, 0, 0>, long>))(Eigen::internal::packRhsAndKernelArg<float, float, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 4, true, false, 0>, Eigen::internal::blas_data_mapper<float, long, 0, 0>, long>)> >::_M_invoke(std::_Any_data const&) ()#6  0x0000000000e44cef in std::_Function_handler<void (), tensorflow::thread::ThreadPoolDefaultImpl::ThreadPoolDefaultImpl(tensorflow::Env*, tensorflow::ThreadOptions const&, std::string const&, int)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()#7  0x00007f0d09fbca40 in std::(anonymous namespace)::execute_native_thread_routine (__p=<optimized out>) at ../../../../../src/libstdc++-v3/src/c++11/thread.cc:84#8  0x00007f0d0a217184 in start_thread (arg=0x7f0cd07f8700) at pthread_create.c:312#9  0x00007f0d09a2a34d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:111This come up during testing of a faster thread pool implementation that has distributed queues and so does not preserve FIFO order. But I think it can come up with current pool as well (maybe after some unrelated code changes, or maybe just due to unlucky scheduling order).Computational tasks running on a fixed-size thread pool must not ever block. Instead they should schedule continuations. Besides deadlocks blocking leads to serious CPU underutilization. I.e. on my machine label_image utilizes only about half of cores, because half of threads in pool are blocked waiting for other tasks.
performance	[cmake/feature request] provide USE_SYSTEM_xxx flags to skip dependency buildsTensorflow's cmake build will download and compile all of its dependency. Julia[1] does something similar to maximize its performance. However Julia provided some optional flags such as USE_SYSTEM_FFTW so users can compile Julia against the FFTW library provided by system package manager (e.g. apt/dpkg). I wish Tensorflow's cmake build could provide similar options to skip building its dependencies and just use the system provided one.[1] https://github.com/JuliaLang/julia/blob/master/Makefile#L243
performance	Quantized graph fails to work on NVIDIA Jetson TX1 architecture although it worked on a normal PC?System InformationHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:NoOS Platform and Distribution (i.e. Linux Ubuntu 16.0):Ubuntu 16.04 LTS on NVIDIA Jetson TX1 (Linux for Tegra 24.1)TensorFlow installed from (source or binary)?:Compiled from source and installed via this wheel available here: https://github.com/rwightman/tensorflow/releases/tag/v1.0.0-alpha-tegra-ugly_hackTensorFlow version (use command below):1.0 AlphaCUDA/cuDNN version:8.0/5.1GPU Model and Memory:Tegra X1, 4GBDescribe the problem clearlyWhen I ran a quantized graph on my laptop, it works quite as expected (just slightly lower accuracy compared to the frozen graph, while much lower size). However, when I transferred the exact same quantized graph to run on an Jetson TX1, the file gives me a highly inaccurate class prediction, at a 100% probability for the random class. On the other hand, when I tried to perform inference from the frozen graph (from which the quantized graph was derived) on both my laptop and the Jetson TX1, I got the exact same answers as expected.So I suspected it could have been an issue of data transfer causing the file to be slightly corrupted. I checked the files byte by byte at all points of transfer (from my laptop to memory stick, then memory stick to the Jetson), but I found the files are exactly the same. This is the command I used to check: cmp $old_file $new_file || echo "different files".Thus, I am suspecting it could be an issue of how tensorflow performs on the Jetson TX1 ARM architecture (aarch64). Is there anyway to verify this, and if it is indeed a performance issue on an ARM architecture, is there a way to resolve this?Thank you for your help.
performance	Segmentation fault in tensorflow::FileSystemRegistryImpl::RegisterSyntaxnet package was built, tf package ver 1.01 was installed from repo by pip as dependency. Fortunately tf installed following these instructions https://www.tensorflow.org/versions/r0.10/get_started/os_setup#create_the_pip_package_and_install works fine.[New LWP 31764][Thread debugging using libthread_db enabled]Using host libthread_db library "/lib/x86_64-linux-gnu/libthread_db.so.1".Core was generated by `python2 -c from syntaxnet import load_parser_ops'.Program terminated with signal SIGSEGV, Segmentation fault.#0  0x00007f3303cf0d47 in std::_Hash_bytes(void const*, unsigned long, unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6(gdb) bt#0  0x00007f3303cf0d47 in std::_Hash_bytes(void const*, unsigned long, unsigned long) () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6#1  0x00007f33065f509c in tensorflow::FileSystemRegistryImpl::Register(std::string const&, std::function<tensorflow::FileSystem* ()>) ()   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so#2  0x00007f33065f26b3 in tensorflow::Env::RegisterFileSystem(std::string const&, std::function<tensorflow::FileSystem* ()>) ()   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so#3  0x00007f3328d327b5 in _GLOBAL__sub_I_env.cc () from /usr/local/lib/python2.7/dist-packages/syntaxnet/parser_ops.so#4  0x00007f3332df04ea in call_init (l=<optimized out>, argc=argc@entry=3, argv=argv@entry=0x7ffe61a27428, env=env@entry=0x265a8b0) at dl-init.c:72#5  0x00007f3332df05fb in call_init (env=0x265a8b0, argv=0x7ffe61a27428, argc=3, l=<optimized out>) at dl-init.c:30#6  _dl_init (main_map=main_map@entry=0x2a41360, argc=3, argv=0x7ffe61a27428, env=0x265a8b0) at dl-init.c:120#7  0x00007f3332df5712 in dl_open_worker (a=a@entry=0x7ffe61a263e0) at dl-open.c:575#8  0x00007f3332df0394 in _dl_catch_error (objname=objname@entry=0x7ffe61a263d0, errstring=errstring@entry=0x7ffe61a263d8, mallocedp=mallocedp@entry=0x7ffe61a263cf,     operate=operate@entry=0x7f3332df5300 <dl_open_worker>, args=args@entry=0x7ffe61a263e0) at dl-error.c:187#9  0x00007f3332df4bd9 in _dl_open (file=0x7f332e1634cc "/usr/local/lib/python2.7/dist-packages/syntaxnet/parser_ops.so", mode=-2147483646,     caller_dlopen=0x7f33065fa9ea <tensorflow::internal::LoadLibrary(char const*, void**)+26>, nsid=-2, argc=<optimized out>, argv=<optimized out>, env=0x265a8b0)    at dl-open.c:660#10 0x00007f33325f6f09 in dlopen_doit (a=a@entry=0x7ffe61a26610) at dlopen.c:66#11 0x00007f3332df0394 in _dl_catch_error (objname=0x252e0d0, errstring=0x252e0d8, mallocedp=0x252e0c8, operate=0x7f33325f6eb0 <dlopen_doit>, args=0x7ffe61a26610)    at dl-error.c:187#12 0x00007f33325f7571 in _dlerror_run (operate=operate@entry=0x7f33325f6eb0 <dlopen_doit>, args=args@entry=0x7ffe61a26610) at dlerror.c:163#13 0x00007f33325f6fa1 in __dlopen (file=<optimized out>, mode=<optimized out>) at dlopen.c:87#14 0x00007f33065fa9ea in tensorflow::internal::LoadLibrary(char const*, void**) ()   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so#15 0x00007f33065f9b97 in tensorflow::(anonymous namespace)::PosixEnv::LoadLibrary(char const*, void**) ()   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so#16 0x00007f33064f6f93 in tensorflow::LoadLibrary(char const*, void**, void const**, unsigned long*) ()   from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so#17 0x00007f3304e11e67 in TF_LoadLibrary () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so#18 0x00007f3304d1206a in _wrap_TF_LoadLibrary () from /usr/local/lib/python2.7/dist-packages/tensorflow/python/_pywrap_tensorflow.so#19 0x00000000004c468a in PyEval_EvalFrameEx ()#20 0x00000000004c2765 in PyEval_EvalCodeEx ()#21 0x00000000004ca8d1 in PyEval_EvalFrameEx ()#22 0x00000000004c2765 in PyEval_EvalCodeEx ()#23 0x00000000004c2509 in PyEval_EvalCode ()#24 0x00000000004c061b in PyImport_ExecCodeModuleEx ()#25 0x00000000004bd6ee in ?? ()#26 0x00000000004afbad in ?? ()#27 0x00000000004af7e9 in PyImport_ImportModuleLevel ()#28 0x00000000004b0f78 in ?? ()#29 0x00000000004b0cb3 in PyObject_Call ()#30 0x00000000004ce5d0 in PyEval_CallObjectWithKeywords ()#31 0x00000000004c6ed6 in PyEval_EvalFrameEx ()#32 0x00000000004c2765 in PyEval_EvalCodeEx ()#33 0x00000000004c2509 in PyEval_EvalCode ()#34 0x0000000000521186 in PyRun_StringFlags ()#35 0x0000000000521dfc in PyRun_SimpleStringFlags ()#36 0x000000000049de94 in Py_Main ()#37 0x00007f333281a830 in __libc_start_main (main=0x49dab0 <main>, argc=3, argv=0x7ffe61a27428, init=<optimized out>, fini=<optimized out>,     rtld_fini=<optimized out>, stack_end=0x7ffe61a27418) at ../csu/libc-start.c:291#38 0x000000000049d9d9 in _start ()
performance	Typo in seq2seq.attention_wrapper.pyHi,I think there is a small typo in contrib.seq2seq.attention_wrapper.py, would someone like to check it?code url: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/seq2seq/python/ops/attention_wrapper.py#L471]I guess it should be probability_fn rather than cell_input_fn to be checked.Thanks.
performance	[feature] Mobile Integration with NNPACKCaffe2 use can use NNPACK for which it says:NNPACK, which specifically optimizes convolutions on ARMCurrently Caffe2 is optimized for ARM CPUs with NEON (basically any ARM CPU since 2012). Perhaps surprisingly, ARM CPUs outperform the on-board GPUs (our NNPACK ARM CPU implementation outperforms Apple’s MPSCNNConvolution for all devices except the iPhone 7).For a convolutional implementation, it is recommended to use NNPACK since that’s substantially faster (~2x-3x) than the standard im2col/sgemm implementation used in most frameworks.The readme for NNPACK lists Tensorflow as a framework that could potentially use it, though that has not yet happened.I believe that TF also avoids using the im2col/sgemm approach on mobile and instead uses the Eigen TensorConvolution. It would be good to benchmark these two options against each other and see if TF performance can be improved by using the NNPACK conv instead of the eigen conv. There is an open ticket to do this benchmarking: Maratyszcza/NNPACK#30.As a feature I suggest offering an NNPACK backed kernel to allow comparing vs Eigen.
performance	thread pool deadlocks on shutdownThreadPool dtor does not pop waiters from waiters_ list. As the result dead waiters are left on the list. If remaining tasks submit new tasks, thread pool deadlocks because some notifications are consumed by the leftover dead waiters instead of alive threads that should receive the notifications.Here is a simple test that does classical parallel decomposition and reliably deadlocks:static void BM_ParallelDivide(int iters, const char* impl) {  THREAD_POOL_IMPL_NAME = impl;  for (int i = 0; i < iters; i++) {    const int kTasks = 10;    const int kLevels = 22;    std::atomic<unsigned> count(kTasks * (1 << kLevels));    mutex done_lock;    condition_variable done;    bool done_flag = false;    std::function<void(int)> work;    ThreadPool pool(Env::Default(), "test", kNumThreads);    work = [&pool, &work, &count, &done_lock, &done, &done_flag](int level) {      if (level-- > 0) {        pool.Schedule([&work, level]() { work(level); });        pool.Schedule([&work, level]() { work(level); });        return;      }      delay();    };    for (int t = 0; t < kTasks; ++t) {      pool.Schedule([&work]() {        work(kLevels);      });    }  }}
performance	TensorFlow 60-80% slower than PyTorch on training Wide ResNetcc @tfboydFrom #7187 (comment)On an AWS p2.xlarge, using the tensorflow/tensorflow:1.0.1-devel-gpu Docker image as a base, I see ~270 ms per epoch while training a WRN-16-4 without dropout on CIFAR-10.Using a PyTorch implementation from https://github.com/xternalz/WideResNet-pytorch, I see instead ~150 ms per epoch for the same.My implementation of Wide ResNets uses NCHW and fused batch norm. It does use feed_dict for data loading, but I've observed with nvidia-smi that my GPU utilization stays near 100%.To reproduce:Clone https://github.com/4Catalyzer/dl-papers, and go to that directory.Check out the benchmark branch.Build the Docker image, which is based on the Docker hub image above:$ docker build -t dl-papers .Run the Docker image using NVIDIA Docker:$ nvidia-docker run --rm -it dl-papers /bin/bashRun the TF WRN-16-4 training:# python -m dl_papers.wide_resnet.train cifar10Observe the logged batch timings, then kill the process.In the same Docker container up the PyTorch Wide ResNet example:# cd ..# pip install http://download.pytorch.org/whl/cu80/torch-0.1.11.post5-cp27-none-linux_x86_64.whl# pip install torchvision tensorboard_logger# git clone https://github.com/xternalz/WideResNet-pytorch.git# cd WideResNet-pytorchRun PyTorch training:# python train.py --dataset cifar10 --layers 16 --widen-factor 4 -p 1Observe logged batch timings.
performance	Enable Fused Winograd by DefaultRight now fused Winograd is disabled by default. This is even though enabling this speeds up models considerable in the 3x3 case (see #9322 (comment)). What remains as far as issues, etc to get this faster conv enabled by default?/CC @yangzihao @tfboyd
performance	init_op and concurrent.futures freeze foreverSystem Information:OS Platform and Distribution: MAC OSXTensorFlow installed from: pip install tensorflowTensorFlow version : 1.0.0Python version : Python 3.6.1I found a  bug trying to run multiple agent in parallel using python, it boiled down to the code below:If i try to init an agent asynchronously after init an agent synchronously, it freezes foreverif i do it the other way around, everything is fineDoes anyone has an idea on this one?Source Code:import tensorflow as tfimport concurrent.futures# Very basic modelclass Agent(object):    def __init__(self):        graph = tf.Graph()        with graph.as_default():            self.Qs = tf.get_variable('Qs', shape=[1, 1])            self.init_op = tf.global_variables_initializer()        self.sess = tf.Session(graph=graph)        print('Before init_op')        self.sess.run(self.init_op)        print('After init_op')def execute_run():    print('In execute')    agent = Agent()print('*** First: we create an agent asynchronously')with concurrent.futures.ProcessPoolExecutor(1) as executor:    concurrent.futures.wait([executor.submit(execute_run)])print('*** Then: we create an agent synchronously')agent = Agent()print('So far, everything is fine')print('*** Finally: we create an agent asynchronously again')with concurrent.futures.ProcessPoolExecutor(1) as executor:    concurrent.futures.wait([executor.submit(execute_run)])print('You\'ll never see this as we  can\'t get passed the init_op')output:*** First: we create an agent asynchronouslyIn executeBefore init_opAfter init_op*** Then: we create an agent synchronouslyBefore init_opAfter init_opSo far, everything is fine*** Finally: we create an agent asynchronously againIn executeBefore init_op
performance	[XLA] Ptxas Error when TF_CPP_MIN_VLOG_LEVEL=2System InformationHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?: yesOS Platform and Distribution (i.e. Linux Ubuntu 16.0): Linux Ubuntu 14.04TensorFlow installed from (source or binary)?: sourceTensorFlow version (use command below): ('v1.1.0-rc2-219-g623dd83', '1.1.0-rc2')Bazel version (if compiling from source): 0.4.5-jdk7CUDA/cuDNN version: 7.5/5GPU Model and Memory: GeForce GTX TitanXExact command to reproduce: python test.py --batch_size 16 --step 20Describe the problem clearlyTo make tensorflow print the logs in VLOG(2), I set the TF_CPP_MIN_VLOG_LEVEL=2. After doing that, the program throws a fatal error. It seems that there's something wrong when compiling xla hlo_instruction to ptx.2017-04-21 14:35:23.158362: I tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:219] ptxas fatal   : SM version specified by .target is higher than default SM version assumed2017-04-21 14:35:23.158423: F tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:221] Invalid PTX. See the error message above for reasons.Source Code / LogsFull log can be found hereReproduce with command python test.py --batch_size 16 --step 20Code:from __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionimport osos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '2' # enable logging debug infoimport inspectimport numpy as npimport tensorflow as tfflags = tf.flagslogging = tf.loggingflags.DEFINE_integer("batch_size", 1, "inference batch size")flags.DEFINE_integer("step", 1, "step size for infernece")FLAGS = flags.FLAGSdef data_type():    return tf.float32class InputData(object):        def __init__(self, config):        self.batch_size = batch_size = config.batch_size        self.num_steps = num_steps = config.num_steps        self.hidden_size = hidden_size = config.hidden_size        self.input_data = tf.placeholder(data_type(), [batch_size, num_steps, hidden_size], name = 'input_data')class Config(object):    num_layers = 1    num_steps = 20    hidden_size = 256    batch_size = 20    vocab_size = 10000    init_scale = 0.1    num_iter = 50    warm_iter = 2class LSTMModel(object):    """ Only forward, No Embedding    """    def __init__(self, config, input_):        self._input = input_        self._input_data = self._input.input_data                batch_size = input_.batch_size        num_steps =  input_.num_steps        size = config.hidden_size        vocab_size = config.vocab_size        def lstm_cell():            if 'reuse' in inspect.getargspec(              tf.contrib.rnn.BasicLSTMCell.__init__).args:                print("reuse")                return tf.contrib.rnn.BasicLSTMCell(                    size, forget_bias=0., state_is_tuple=True,                    reuse = tf.get_variable_scope().reuse)            else:                print("not reuse")                return tf.contrib.rnn.BasicLSTMCell(                    size, forget_bias=0.0, state_is_tuple=True)        attn_cell = lstm_cell        cell = tf.contrib.rnn.MultiRNNCell(            [attn_cell() for _ in range(config.num_layers)], state_is_tuple=True)        self._initial_state = cell.zero_state(batch_size, data_type())        outputs = []        state = self._initial_state        with tf.variable_scope("RNN"):            for time_step in range(num_steps):                if time_step > 0 : tf.get_variable_scope().reuse_variables()                (cell_output, state) = cell(self._input.input_data[:, time_step, :], state)                outputs.append(cell_output)                self._output = tf.reshape(tf.concat(axis=1, values=outputs), [-1, size])        self._final_state = state        softmax_w = tf.get_variable(            "softmax_w", [size, vocab_size], dtype=data_type())        softmax_b = tf.get_variable("softmax_b", [vocab_size], dtype=data_type())        self._logits = tf.matmul(self._output, softmax_w) + softmax_b        return    @property    def initial_state(self):        return self._initial_state    @property    def logits(self):        return self._logits      @property    def input_data(self):        return self._input_datadef run_inference(session, model, input_data, sv) :    # initialize with a clean state    state = session.run(model.initial_state)    fetches = {}    fetches['logit'] = model.logits    feed_dict = {}    feed_dict[model.input_data] = input_data    for i, (c, h) in enumerate(model.initial_state):        feed_dict[c] = state[i].c        feed_dict[h] = state[i].h    session.run(fetches, feed_dict)def main(_):    # config    eval_config = Config()    eval_config.num_steps = FLAGS.step    eval_config.batch_size = FLAGS.batch_size    # generate random data    input_data = np.random.rand(eval_config.batch_size, eval_config.num_steps, eval_config.hidden_size).astype(np.float32)    with tf.Graph().as_default():        initializer = tf.random_uniform_initializer(-eval_config.init_scale,                                                     eval_config.init_scale)        with tf.name_scope('Inference'):            _input = InputData(eval_config)            with tf.variable_scope('Model', reuse=None, initializer=initializer):                model = LSTMModel(config=eval_config, input_=_input)        sv = tf.train.Supervisor()        sess_config = tf.ConfigProto(allow_soft_placement=True,                                     log_device_placement=False)        # enable xla        sess_config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1        # run inference        with sv.managed_session(config=sess_config) as session:            run_inference(session, model, input_data, sv)if __name__ == '__main__':    tf.app.run()
performance	Possibly serious bug in cuDNN RNNParamsSaveableRNNParamsSaveable appears to only save half of the weights when the RNN is bidirectional. See below.When the RNN is unidirectional, model.params_size() matches the total size of weights + biases returned by model.params_to_canonical(params)model = cudnn_rnn_ops.CudnnLSTM(num_layers=1, num_units=100, input_size=20, direction='unidirectional')params = tf.get_variable('cudnn_rnn_params', initializer=tf.random_uniform([model.params_size()]), validate_shape=False)model.params_size().eval(session=sess) # returns 48800sum([wts.eval(session=sess).shape[0] for wtss in model.params_to_canonical(params) for wts in wtss]) # returns 48800On the other hand, when the RNN is bidirectional, model.params_size() returns twice the size of the unidirectional case, which makes sense, but the size of model.params_to_canonical(params) is unchanged.model = cudnn_rnn_ops.CudnnLSTM(num_layers=1, num_units=100, input_size=20, direction='bidirectional')params = tf.get_variable('cudnn_rnn_params', initializer=tf.random_uniform([model.params_size()]), validate_shape=False)model.params_size().eval(session=sess) # returns 97600sum([wts.eval(session=sess).shape[0] for wtss in model.params_to_canonical(params) for wts in wtss]) # returns 48800I believe this may have been missed by tests because, as this TODO suggests, both the canonical and non-canonical versions are being saved and restored, and so even if only half the weights are being restored from the canonical version, the non-canonical weights can compensate and hide the problem.Am I missing something?
performance	`tensorflow.python.client.device_lib.list_local_devices()` BugI am trying to set up GPU configuration for Tensorflow. The step is very simple - Call tensorflow.python.client.device_lib.list_local_devices() to detect the number of gpu devices on the machine, and then set config for Tensorflow.  The following is the code for reproducing:from logging import getLoggerimport tensorflow as tffrom tensorflow.python.client import device_liblog = getLogger(__name__)def get_available_gpus():    """ Get available GPU devices info. """    local_device_protos = device_lib.list_local_devices()    return [x.name for x in local_device_protos if x.device_type == 'GPU']def test_gpu_memory_usage():    # Detect available GPU devices info.    log.info("On this machine, GPU devices: ", get_available_gpus())    # Set Tensorflow GPU configuration.    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.1)    tf_config=tf.ConfigProto(        allow_soft_placement=True,        device_count={'GPU': len(get_available_gpus())},        gpu_options=gpu_options,        log_device_placement=True)    session = tf.Session(config=tf_config)    # Mimick training process.    while True:        pass        test_gpu_memory_usage()If you run the above code, you could notice that even though you set GPU memory fraction per process to 0.1, it still allocates the whole GPU memory by looking at command nvidia-smi. However, if you don't call get_available_gpus(), the memory allocation works fine. That means, there might be a bug in device_lib.list_local_devices() to prevent setting up Tensorflow GPU memory usage.PS. My code runs on machine with GPU GeForce GTX 1080, CUDA 8.0, OS Ubuntu 16.04 and Python 3.5, and the above issue could be reproduced using either Tensorflow v.0.12, v.1.0 or v.1.1.
performance	grpc error in distributed tensorlfowpciBusID 0000:04:00.0Total memory: 11.17GiBFree memory: 11.10GiBI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   YI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:04:00.0)# E0422 12:13:21.315971987   26528 tcp_server_posix.c:148]     check for SO_REUSEPORT: {"created":"@1492834401.315943300","description":"OS Error","errno":92,"file":"external/grpc/src/core/lib/iomgr/socket_utils_common_posix.c","file_line":181,"os_error":"Protocol not available","syscall":"setsockopt(SO_REUSEPORT)"}I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:200] Initialize GrpcChannelCache for job ps -> {0 -> localhost:8865}I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:200] Initialize GrpcChannelCache for job worker -> {0 -> localhost:8866}I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:221] Started server with target: grpc://localhost:8865I try distributed tensorflow and start only one server and one worker, the model does not converge as the local version.
performance	[C++] xthread:  0xC0000005: Access violation reading location 0xFFFFFFFFFFFFFFFFI want to read frozen graph from file.So I have class A:class A{     std::shared_ptr<B> b_ptr;public:     A()     {         b_ptr.reset(new B());     }};class B:using namespace tensorflow;class B{     SessionOptions _sessionOptions;     std::unique_ptr<Session> _session;     GraphDef _graph;     std::shared_ptr<std::thread> _thread;public:     B()     {         graph::SetDefaultDevice("/cpu:0", &_graph);         ConfigProto& config = _sessionOptions.config; config.set_intra_op_parallelism_threads(1); _session.reset(NewSession(_sessionOptions));         ReadBinaryProto(Env::Default(), "path/to/graph", &_graph); _session->Create(_graph);         _thread.reset(new std::thread(&B::Task, this));     }     void Task();}And I have the problem mentioned above when I read frozen graph with ReadBinaryProto  I create session. If I comment a line _thread.reset(new std::thread(&B::Task, this)), this code will return successfully. If I comment all the code refered with tensorflow it will return successfully too.
performance	Build of tensor flow r1.1 w/ Google Cloud option enabled fails: incompatible C++ header and codeSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution (e.g., Linux Ubuntu 16.04):   OS X 10.10.3 (14D2134)TensorFlow installed from (source or binary):  github clone / source (r1.1)TensorFlow version (use command below): r1.1Bazel version (if compiling from source): 0.4.5-homebrewCUDA/cuDNN version:  N/A (not built with CUDA)GPU model and memory: N/A (not built with CUDA)Exact command to reproduce:configure build for CPU and with google cloud enabled,bazel build --config=opt //tensorflow/tools/pip_package:build_pip_packageDescribe the problemBuild of tensor flow for CPU / google cloud enabled fails for r1.1 (and also master),configure build for CPU and with google cloud enabled,bazel build --config=opt //tensorflow/tools/pip_package:build_pip_packageSource code / logsERROR: /Users/jshore/src/tensorflow/tensorflow/core/platform/cloud/BUILD:115:1: C++ compilation of rule '//tensorflow/core/platform/cloud:retrying_utils' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 93 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.tensorflow/core/platform/cloud/retrying_utils.cc:97:9: error: return type 'const tensorflow::Status' must match previous return type 'tensorflow::Status' when lambda expression has unspecified explicit return typereturn status;
performance	Distributed Tensorflow model is no faster than standaloneSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):I have taken the Resnet code from the Tensorflow model zoo and distributed it as according to https://www.tensorflow.org/deploy/distributedOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04.1 LTSTensorFlow installed from (source or binary):Official Tensorflow-GPU docker imageTensorFlow version (use command below):('v1.0.0-2378-g2259213', '1.1.0-rc0')Bazel version (if compiling from source):N/ACUDA/cuDNN version:Version 8GPU model and memory:Tested on multiple setups within a cluster4 machines with 2x Nvidia TitanX 12GB1 machine with 2x GeForce GTX 1080 8GBExact command to reproduce:The commands differ slightly between machines depending on cluster configuration, but for 1 PS and 2 workers it looks like this:CUDA_VISIBLE_DEVICES="" python resnet_main.py --dataset="cifar10" --train_data_path="/notebooks/cifar_data/data_batch*" --train_dir="/notebooks/tmp/resnet_model/train" --log_root="/notebooks/tmp/resnet_model" --job_name="ps" --task_index=0 --eval_data_path="/notebooks/cifar_data/test_batch.bin" --eval_dir="/notebooks/tmp/resnet_model/test"CUDA_VISIBLE_DEVICES=0 python resnet_main.py --dataset="cifar10" --train_data_path="/notebooks/cifar_data/data_batch*" --train_dir="/notebooks/tmp/resnet_model/train" --log_root="/notebooks/tmp/resnet_model" --job_name="worker" --task_index=0 --eval_data_path="/notebooks/cifar_data/test_batch.bin" --eval_dir="/notebooks/tmp/resnet_model/test"CUDA_VISIBLE_DEVICES=0 python resnet_main.py --dataset="cifar10" --train_data_path="/notebooks/cifar_data/data_batch*" --train_dir="/notebooks/tmp/resnet_model/train" --log_root="/notebooks/tmp/resnet_model" --job_name="worker" --task_index=1 --eval_data_path="/notebooks/cifar_data/test_batch.bin" --eval_dir="/notebooks/tmp/resnet_model/test"Describe the problemWhen running the Resnet model on CIFAR10 from the tf zoo in a distributed environment (asynchronous, between-graph replication), there is no performance gain.Running Resnet 110 on a single (non-distributed) machine, single GPU resulted in approximately 3 iterations per second. This is considered the baseline for any tests on the following configurations - all of which resulted in approximately the same number of iterations per second irrespective of configuration.Note: in all cases, each worker has their own dedicated GPU1 PS, 2 workers on one machine1 PS with dedicated GPU & 1 worker on one machine, 1 worker on another machine1 PS & 2 workers on one machine, 2 workers on another machine1 PS & 2 workers on one machine, 3 more machines with 2 workers each4 machines with 2 workers each, two of these with 1 PS each4 machines, each with 1 PS & 2 workersWhen starting up the workers, each would begin training as soon as it's ready, printing information to the terminal during/after each iteration. The difference is speed is visually noticeable - when there is only 1 worker running, it's as fast as I would expect. As more workers spin up, all of the existing workers slow down. In this way, I can see (with 8 terminals on my screen) the entire cluster slowing as more workers begin.I monitored system stats during training to rule things out as the bottleneck and found the following for each machine:CPU usage: CPU usage is not at 100% for any machineGPU usage: GPU usage repeatedly flickers between 0% and ~80% - once per iterationNetwork usage: Network bandwidth in/out for any given machine is never more than ~80% of its capacity. the network speed is limited to 1Gbps, and it doesn't reach this cap. We raised the limit to 2Gbps and saw no increased usage or performance.HDD usage: Batches are loaded from disk multi-threaded. I printed to the screen during file-access and it's practically instantaneous.For the input pipeline, I have also tried switching between tf.RandomShuffleQueue and tf.train.shuffle_batch and playing with the number of threads/min after deque etc for each of these batching methods to no avail.Source code / logsSource code files attached below - cifar_input.py has small modifications from the original input pipeline. The original cifar input code is the file cifar_input_orig.pyresnet_distrib.zipThank you in advance for any light you may be able to shed on this!
performance	Android ops - not supporting NCHW data formatHi,I'm using my custom tensorflow v1.0.1 model freezed and exported to Android arm-ABI-v7a (I compiled tensorflow 1.0.1 with selective registration for the models ops).As a training time optimization we tried to convert the data format to NCHW format (as written in the tensorflow performance tutorial).But now, when I run inference on Android, I get the following error in the logcat:E/native: tensorflow_inference_jni.cc:233 Error during inference: Invalid argument: CPU BiasOp only supports NHWC. [[Node: conv_layer_1/BiasAdd = BiasAdd[T=DT_FLOAT, data_format="NCHW", _device="/job:localhost/replica:0/task:0/cpu:0"](conv_layer_1/conv_l11, bc11_init)]]Are you going to add NCHW support for android CPU ops in the future versions?Thanks,EranSystem information*Have I written custom code: Yes - custom model:**OS Linux Ubuntu 16.04:**TensorFlow installed from source:**TensorFlow version 1.0.1:*Bazel version 0.4.5:**CUDA/cuDNN version 5.1.10:**GPU model and memory GTX 1080 TI:
performance	XLA "resnet 50" style example crash during graph buildingNote: The test code below was cobbled together from various un-credited sources.The example crashes, during the building of the reduce_mean.   It fails with quite a large stack, maybe some sort of stack overflow?  Without the last two 'block's (marked with #*****) the compilation succeeds.Perhaps it is as simple as it failing on my laptop (OS/X, 16GB RAM).import tensorflow as tfimport numpy as npdef _get_variable(name, shape, initializer, dtype=tf.float32):  return tf.get_variable(name,                         shape=shape,                         initializer=initializer,                         dtype=dtype)def inference(x):  with tf.variable_scope('scale1', use_resource=True):    x = conv(x, 7, 2, 64)    x = tf.nn.relu(x)  with tf.variable_scope('max_pool', use_resource=True):    x = max_pool(x, ksize=3, stride=2)  with tf.variable_scope('scale2-1', use_resource=True):    x = block(x, 1, 64, 256)  with tf.variable_scope('scale2-2', use_resource=True):    x = block(x, 1, 64, 256)  with tf.variable_scope('scale2-3', use_resource=True):    x = block(x, 1, 64, 256)  with tf.variable_scope('scale3-1', use_resource=True):    x = block(x, 2, 128, 512)  with tf.variable_scope('scale3-2', use_resource=True):    x = block(x, 1, 128, 512)  with tf.variable_scope('scale3-3', use_resource=True):    x = block(x, 1, 128, 512)  with tf.variable_scope('scale3-4', use_resource=True):    x = block(x, 1, 128, 512)  with tf.variable_scope('scale4-1', use_resource=True):    x = block(x, 2, 256, 1024)  with tf.variable_scope('scale4-2', use_resource=True):    x = block(x, 1, 256, 1024)  with tf.variable_scope('scale4-3', use_resource=True):    x = block(x, 1, 256, 1024)  with tf.variable_scope('scale4-4', use_resource=True):    x = block(x, 1, 256, 1024)  with tf.variable_scope('scale4-5', use_resource=True):    x = block(x, 1, 256, 1024)  with tf.variable_scope('scale4-6', use_resource=True):    x = block(x, 1, 256, 1024)  with tf.variable_scope('scale5-1', use_resource=True):    x = block(x, 2, 512, 2048)  with tf.variable_scope('scale5-2', use_resource=True):  #*****    x = block(x, 1, 512, 2048)  with tf.variable_scope('scale5-3', use_resource=True): #*****    x = block(x, 1, 512, 2048)  x = tf.reduce_mean(x, reduction_indices=[1, 2])  with tf.variable_scope('fc', use_resource=True):    x = fc(x, 1000)  return xdef block(x, first_stride, internal_filters, final_filters):  shape_in = x.get_shape()  shortcut = x  with tf.variable_scope('a', use_resource=True):    x = conv(x, 1, first_stride, internal_filters)    x = tf.nn.relu(x)  with tf.variable_scope('b', use_resource=True):    x = conv(x, 3, 1, internal_filters)    x = tf.nn.relu(x)  with tf.variable_scope('c', use_resource=True):    x = conv(x, 1, 1, final_filters)  with tf.variable_scope('shortcut', use_resource=True):    pad = int(x.get_shape()[-1] - shape_in[-1])    kernel = np.reshape(np.concatenate((np.identity(shape_in[-1], dtype=np.float32),                                        np.zeros([pad, shape_in[-1]]))),                        [1, 1, shape_in[-1], final_filters])    shortcut = tf.nn.conv2d(shortcut,                            kernel,                            [1,first_stride,first_stride,1],                            padding='SAME')  return tf.nn.relu(x + shortcut)def fc(x, num_units_out):  num_units_in = x.get_shape()[1]  weights_initializer = tf.truncated_normal_initializer(stddev=0.01)  weights = _get_variable('weights', shape=[num_units_in, num_units_out],                          initializer=weights_initializer)  biases = _get_variable('biases', shape=[num_units_out],                         initializer=tf.constant_initializer(0.0))  x = tf.nn.xw_plus_b(x, weights, biases)  return xdef conv(x, ksize, stride, filters_out):  filters_in = x.get_shape()[-1]  shape = [ksize, ksize, filters_in, filters_out]  initializer = tf.truncated_normal_initializer(stddev=0.1)  weights = _get_variable('weights', shape=shape, initializer=initializer)  return tf.nn.conv2d(x,                      weights,                      [1, stride, stride, 1],                      padding='SAME')def max_pool(x, ksize=3, stride=2):  return tf.nn.max_pool(x,                        ksize=[1, ksize, ksize, 1],                        strides=[1, stride, stride, 1],                        padding='SAME')## Main code#with tf.device("/job:localhost/replica:0/task:0/device:XLA_CPU:0"):  # Inputs  x = tf.placeholder(tf.float32, shape=[2, 224, 224, 4])  # Inference  logits = inference(x)sess = tf.InteractiveSession()sess.run(tf.global_variables_initializer())training_data = np.zeros([2, 224, 224, 4]);sess.run(logits, feed_dict={x: training_data})sess.close()
performance	Android Demo: Rotation on some devices broken.System informationAndroid:TensorFlow installed from source:TensorFlow version 1.0.0:N/ADescribe the problemThe Android Demo code seems to be a bit buggy on our Pixel C. I wanted to confirm that this isn't an issue with the TF code but it's a strange one.The Rotation in the demo apps on our Pixel C didn't seem to work correctly. It would give the value of 3 when it should have read 90. This meant that the input was basically on it's side. I found that for it to work that this line needed to be set to 0.sensorOrientation = rotation + screenOrientation; needed to besensorOrientation = 0;However, when used in landscape mode this didn't crop around the centre of the preview image but instead it created a square from the left edge.|------------------| ---------|                         |                  |          ||       CROP       |          ||     SQUARE       |          ||__________________|__________|When set to 0.The solution seemed to be to set the Orientation to 360.|-----|------------------|----|                         |     |                  |    ||     |        CROP      |    ||     |      SQUARE      |    ||_____|__________________|____|When set to 360.At the time (a couple of weeks ago) I recalled that it forced some code to run that would centre it as required for some other operations however going through the code to find it I can't. I think it was related to this but it doesn't make sense as to why 360 solved the issue.private void configureTransform(final int viewWidth, final int viewHeight) {    final Activity activity = getActivity();    if (null == textureView || null == previewSize || null == activity) {      return;    }    final int rotation = activity.getWindowManager().getDefaultDisplay().getRotation();    final Matrix matrix = new Matrix();    final RectF viewRect = new RectF(0, 0, viewWidth, viewHeight);    final RectF bufferRect = new RectF(0, 0, previewSize.getHeight(), previewSize.getWidth());    final float centerX = viewRect.centerX();    final float centerY = viewRect.centerY();    if (Surface.ROTATION_90 == rotation || Surface.ROTATION_270 == rotation) {      bufferRect.offset(centerX - bufferRect.centerX(), centerY - bufferRect.centerY());      matrix.setRectToRect(viewRect, bufferRect, Matrix.ScaleToFit.FILL);      final float scale =          Math.max(              (float) viewHeight / previewSize.getHeight(),              (float) viewWidth / previewSize.getWidth());      matrix.postScale(scale, scale, centerX, centerY);      matrix.postRotate(90 * (rotation - 2), centerX, centerY);    } else if (Surface.ROTATION_180 == rotation) {      matrix.postRotate(180, centerX, centerY);    }    textureView.setTransform(matrix);  }So I guess the question is that is this happening due to some strange hardware bug with the Pixel C or some coding error. I'm leaning towards the former as this is too bizarre to be caused by code but thought i'd open the discussion out as others trying to run the app in landscape may face similar issues.
performance	1080P image by SRGAN automatically killedWhen I use a small image for SRGAN training, it runs well, but when I use a 1080P image for generation, the process killed without any related log. The batch is 8 so I don't think it will run out all my GPU memory, also there's no fully connection layer in my SRGANgpu device: GTX 1060 6Gtf version: 1.0.0python version: 2.7if my code is required, pleasure to provide it
performance	[minor bug] tf1.0+ compatibility script doesn't handle old batch_matmul argumentstf 1.0 merges batch_matmul into matmul, but the compatibility script forgot to rename the arguments for batch_matmulwhat is needed is:adj_x --> transpose_aadj_y --> transpose_bI would be happy to write a quick PR.References:https://www.tensorflow.org/versions/r0.12/api_docs/python/https://www.tensorflow.org/api_docs/python/tf/matmul
performance	Using replace to evaluate multiple gradients during training in KerasI am a researcher in optimization and I am interested in testing algorithms for training DNNs using keras, and am now using tensorflow backend.In practice, I would like to do something a bit different from the other optimizers, I would like to compute the gradient at a slightly different value of the tensor of parameters than the current one, and the update I will make to the parameters will depend on both the current gradient and this other gradient.In practice this has proven more difficult than anticipated.See fchollet/keras#6175it was suggested I come to here for further suggestions.My code is a standard keras python code, the body doesmodel = Sequential()model.add(Dense(512, input_shape=(784,)))...model.compile(loss='categorical_crossentropy',optimizer = myopt,metrics=['accuracy'])history = model.fit(X_train, Y_train,batch_size=batch_size, nb_epoch=nb_epoch,verbose=1, validation_data=(X_test, Y_test))In the get_updates call function of my custom optimizer, it begins as usualdef get_updates(self, params, constraints, loss):    grads = self.get_gradients(loss, params)Now, I want to now get the gradients at a different value of grads. First I tried just defining another tensor of the same structure but different values and take the get_gradients, but of course the loss is a graph depending on params already. Then I tried changing params itself (then copying the old values of the tensor to another one, to replace params after the evaluation) but apparently as the forward pass was not made this was ineffective. As per the advice in the above github conversation in keras, I tried,    tempparams = [a+1. for a in params]    replace = {p:npm for p, npm in zip(params, tempparams)}    gradsn = [tf.contrib.graph_editor.graph_replace(g.op, replace) for g in grads]but this is still not OK, as I get the errorTypeError: Expected a type in (<class 'tensorflow.python.framework.ops.Operation'>), got: <class 'tensorflow.python.ops.variables.Variable'Thank you
performance	small error in DynamicAttentionWrapperSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Not relevantOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Not relevantTensorFlow installed from (source or binary):Not relevantTensorFlow version (use command below):1.1Bazel version (if compiling from source):Not relevantCUDA/cuDNN version:Not relevantGPU model and memory:Not relevantExact command to reproduce:Not relevantDescribe the problemline 465 in tensorflow/tensorflow/contrib/seq2seq/python/ops/dynamic_attention_wrapper.py says'''if not callable(cell_input_fn):.'''I think it should say'''if not callable(probability_fn):'''Source code / logsNone
performance	Compute gradient inside tf.while_loop using TensorArrayI was trying to call opt.compute_gradients() inside the while_loop, but it failed with the error message:AttributeError: 'WhileContext' object has no attribute 'pred'I found a similiar problem in stackoverflowtest code:batch_size = 2inputs = tf.ones((batch_size, 10))labels = tf.zeros((batch_size, 1))outputs = tf.layers.dense(inputs, units=1)loss = outputs - labelsloss_ta = tf.TensorArray(dtype=tf.float32, size=batch_size)loss_ta = loss_ta.unstack(loss)opt = tf.train.AdamOptimizer(0.1)init_grad = []vars_list = tf.trainable_variables()for var in vars_list:    init_grad.append(tf.zeros_like(var))i = tf.constant(0, dtype=tf.int32)def condition(i, *args):    return tf.less(i, batch_size)def loop_fn(i, gradients, all_loss):    loss_ = all_loss.read(i)    grads = opt.compute_gradients(loss_, vars_list)    for idx, (grad, var) in enumerate(grads):        gradients[idx] += grad    return i + 1, gradients, all_loss_, final_grad, _ = tf.while_loop(condition, loop_fn, [i, init_grad, loss_ta])train_op = opt.apply_gradients(zip(final_grad, vars_list))Seems like the problem is in the TensorArray, if I do not read loss from the TensorArray, it will be fine. Besides, I am using version1.0.1 on CPU
performance	numpy prod overflow during creating tensorI am trying to allocate super large tensor using tensorflow, but failed.https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/tensor_util.py#L417Above code uses numpy.prod to calculate shape size, and for numpy everything is typed, say if the shape is [500000000, 5], then numpy.prod returns -1794967296, it's very easy to reproduce it.So how about use int64 instead? int64 should be large enough for any tensor.Changing shape_size = np.prod(shape) to shape_size = np.prod(shape, dtype=np.int64) should fix it. Also about 100 lines of code using np.prod, could we change them all to int64?
performance	Tensorboard 0.0.0.0:6006 cannot work On Win7 but localhost:6006 worksI use tensorboard on Win7.Everyting works fine and the cmd shows "Starting TensorBoard b'47' at http://0.0.0.0:6006"But when I  input "http://0.0.0.0:6006" into chrome, nothing happens.I google for it but find limited answer.Then I input "http://localhost:6006" into chrome, the page comes out.
performance	terminate called after throwing an instance of 'std::bad_alloc', not out of memoryHi, I'm using Keras with tensorflow back-end to train a LSTM network, I was doing a grid search over the learning_rate and dropout factor with the fixed batch size of 64, It ran perfectly but in the middle of it was interrupted by signal 6: SIGABRT with the following error:terminate called after throwing an instance of 'std::bad_alloc'  what():  std::bad_allocIt should not be a memory allocation problem because it was running earlier for batch size of 64 which is not too much in my caseyou can find my system information(tf_env.txt) from the following link:https://www.dropbox.com/s/wcv8y88fh659zck/tf_env.txt?dl=0
performance	Inconsistent results when tf.sqrt() is applied to tensor versus element-wiseSystem informationOS Platform and Distribution (e.g., Linux Ubuntu 16.04): fedora 24TensorFlow installed from (source or binary): pipExact command to reproduce:import tensorflow as tfimport numpy as npstart = 0 linear_indices = (tf.range(start, 496) + 1) * 8 + 1 index = 495 - start  rind  = tf.sqrt(tf.cast(linear_indices, tf.float32)) - 63  rind1 = tf.gather(rind, index)linear_index = tf.gather(linear_indices, index)rind2 = tf.sqrt(tf.cast(linear_index, tf.float32)) - 63  session = tf.Session()print(session.run(rind1))print(session.run(rind2))Output:In [5]: %run calculation_test.py3.8147e-060.0Describe the problemThe order of operations gives different behavior in tf.gather. rind1 and rind2 tensors should have the same value (0).cc @altosaar
performance	Internally inconsistent results on GPU, not on CPUSystem InformationUbuntu 16.04 LTSCUDA 8.0cuDNN v5.1NVIDIA Tesla K80 (11439MiB)tensorflow 1.0.1 (bug also present in 1.1.0) [pip]keras 2.0.3 [python setup.py install]ProblemI can define a convnet that returns reasonable results with CPU, but returns a mixture of expected and nonsense results with GPU. The problem with the GPU processing is made clear by passing a set of "all ones" images to the net; the output should be identical for all 16 images, yet the outputs for the last one or two images differ drastically from the rest.I see this problem when using the GPU, but not with CPU.  No exceptions are raised, and there are no warnings beyond the usual TensorFlow library wasn't compiled to use ___ instructions, but these are available on your machine and could speed up CPU computations..I see this problem using tensorflow as my keras backend, but not when using theano as my backend.  That statement is true whether I set image_data_format to channels_last or channels_first, for either backend.I've found three changes to the model architecture defined below that make the problem go away: (1) change the number of filters, as described in more detail below, (2) remove the UpSampling2D layer, or (3) remove the  AveragePooling2D layer.  Given (3), this issue may be related to #8566 .CodeConsider the following convnet.import tensorflow as tffrom keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, AveragePooling2Dfrom keras.models import Modelimport numpy as npdef my_model(filters=65):    np.random.seed(0)    inputs = Input((None, None, 3))    conv1 = Conv2D(filters, (5,5), strides=(1,1), padding='same', activation='relu')(inputs)    conv1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv1)    conv2 = Conv2D(filters, (5,5), strides=(1,1), padding='same', activation='relu')(conv1)    conv2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv2)    conv3 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv2)    conv3 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv3)    conv4 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv3)    conv4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2))(conv4)    conv5 = Conv2D(filters, (3,3), strides=(1,1), padding='same', activation='relu')(conv4)    conv5_up = UpSampling2D(size=(8, 8))(conv5)    conv5_up = AveragePooling2D(pool_size=(8, 8), strides=(1,1), padding='same')(conv5_up)    return Model(inputs=inputs, outputs=conv5_up)We can test the self-consistency of this net by feeding it 16 "all ones" images.  The output features should be identical for each input image, since the input images are simply all ones.def test(filters=65, device='gpu'):    # Make a batch of 16 "images", ALL ONES.    img = np.ones((16, 512, 512, 3), dtype='float32')    with tf.device('/%s:0'%device):        model = my_model(filters)        features = model.predict(img)    # Compare features of 1st and 16th image.    # Since the input was all ones, they should agree.    inconsistent = np.any(features[0] != features[15])    if inconsistent:        print "Inconsistent!"The model architecture is parameterized by a single parameter, filters, the number of filters in each layer.  Interestingly, I see that the model inconsistency cares about powers of 2 in filters:• consistency for filters=1 through 64,• inconsistency for filters=65 through 127,• consistency for filters=128,• inconsistency for filters=129 through 150.The smallest model that shows the problem is at filters=65.  Below I show a single feature output for the 1st and 16th input images.  They should agree, but they don't.Features for 1st image (which is identical for images 1-15):Features for 16th image:As can be seen, the feature map for the 16th image differs dramatically from images 1-15, even though the inputs are identical (all ones).If I repeat this test with a filters=129 instead of filters=65, the bug appears earlier in the batch; the features for images 1-14 are identical, while the features for images 15 and 16 differ from the rest, and from each other.
performance	Check failed: NDIMS == dims() (2 vs. 1) when I build a svm modelwhen I build a svm model with tf.learn, it get error like this:F tensorflow/core/framework/tensor_shape.cc:36] Check failed: NDIMS == dims() (2 vs. 1)Asking for tensor of 2 dimensions from a tensor of 1 dimensionsI have ask a question in stackoverflow, It could be a issue according the reply:http://stackoverflow.com/questions/43638488/check-failed-ndims-dims-2-vs-1-when-i-build-a-svm-modelall the reproduce code here:import tensorflow as tfimport pandas as pdfrom tensorflow.contrib.learn.python.learn.estimators import svmdetailed_occupation_recode = tf.contrib.layers.sparse_column_with_hash_bucket(    column_name='detailed_occupation_recode',     hash_bucket_size = 1000)education = tf.contrib.layers.sparse_column_with_hash_bucket(    column_name='education',    hash_bucket_size=1000)# Continuous base columnsage = tf.contrib.layers.real_valued_column('age')wage_per_hour = tf.contrib.layers.real_valued_column('wage_per_hour')columns = ['age', 'detailed_occupation_recode', 'education', 'wage_per_hour','label']FEATURE_COLUMNS = [    # age, age_buckets, class_of_worker, detailed_industry_recode,    age, detailed_occupation_recode, education, wage_per_hour]LABEL_COLUMN = 'label'CONTINUOUS_COLUMNS = ['age', 'wage_per_hour']CATEGORICAL_COLUMNS = ['detailed_occupation_recode','education']df_train = pd.DataFrame([[12,'12','7th and 8th grade',40,'- 50000'],                [40,'45','7th and 8th grade',40, '50000+'],                [50,'50','10th grade',40,'50000+'],                [60,'30','7th and 8th grade',40,'- 50000']],                columns=['age', 'detailed_occupation_recode', 'education', 'wage_per_hour', 'label'])df_test = pd.DataFrame([[12,'12','7th and 8th grade',40,'- 50000'],                [40,'45','7th and 8th grade',40, '50000+'],                [50,'50','10th grade',40,'50000+'],                [60,'30','7th and 8th grade',40,'- 50000']],                columns=['age', 'detailed_occupation_recode', 'education', 'wage_per_hour', 'label'])df_train[LABEL_COLUMN] = (df_train[LABEL_COLUMN].apply(lambda x: '+' in x)).astype(int)df_test[LABEL_COLUMN] = (df_test[LABEL_COLUMN].apply(lambda x: '+' in x)).astype(int)dtypess = df_train.dtypesdef input_fn(df):    continuous_cols = {k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS}    categorical_cols = {k: tf.SparseTensor(        indices=[[i, 0] for i in range(df[k].size)],        values=df[k].values,        dense_shape=[df[k].size, 1]) for k in CATEGORICAL_COLUMNS}        feature_cols = dict(continuous_cols.items() + categorical_cols.items())    feature_cols['example_id'] = tf.constant([str(i+1) for i in range(df['age'].size)])    label = tf.constant(df[LABEL_COLUMN].values)    return feature_cols, labeldef train_input_fn():    return input_fn(df_train)def eval_input_fn():    return input_fn(df_test)model_dir = '../svm_model_dir'model = svm.SVM(example_id_column='example_id', feature_columns=FEATURE_COLUMNS, model_dir=model_dir)model.fit(input_fn=train_input_fn, steps=10)results = model.evaluate(input_fn=eval_input_fn, steps=1)for key in sorted(results):    print("%s: %s" % (key, results[key]))and the all error output text:WARNING:tensorflow:The default value of combiner will change from "sum" to "sqrtn" after 2016/11/01.WARNING:tensorflow:The default value of combiner will change from "sum" to "sqrtn" after 2016/11/01.WARNING:tensorflow:tf.variable_op_scope(values, name, default_name) is deprecated, use tf.variable_scope(name, default_name, values)WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.WARNING:tensorflow:From /Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:882: hinge_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.Instructions for updating:Use tf.losses.hinge_loss instead.WARNING:tensorflow:From /Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.Instructions for updating:Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.WARNING:tensorflow:From /Users/burness/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:882: hinge_loss (from tensorflow.contrib.losses.python.losses.loss_ops) is deprecated and will be removed after 2016-12-30.Instructions for updating:Use tf.losses.hinge_loss instead.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machineand could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machineand could speed up CPU computations.F tensorflow/core/framework/tensor_shape.cc:36] Check failed: NDIMS == dims() (2 vs. 1)Asking for tensor of 2 dimensions from a tensor of 1 dimensions[1]    66225 abort      python simple-tf-svm.py
performance	Tensorboard cannot load more than two event file in logdirSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes, Custom network structure and data pre-processing for my own task and dataset, modified based on current single GPU CIFAR-10 tutorial (which use the monitored session).OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 Pro 1703TensorFlow installed from (source or binary):Binary, install locally by using pip install .\xxx.whl in my miniconda environment, for the environment, pip freeze give the following informationappdirs==1.4.3bleach==1.5.0cycler==0.10.0html5lib==0.9999999Markdown==2.2.0matplotlib==2.0.0numpy==1.12.1olefile==0.44packaging==16.8Pillow==4.1.0protobuf==3.2.0pyparsing==2.2.0python-dateutil==2.6.0pytz==2017.2six==1.10.0tensorflow-gpu==1.1.0rc2Werkzeug==0.12.1TensorFlow version (use command below):Nightly build #149 (GPU Version), 1.1.0-rc2CUDA/cuDNN version:CUDA 8.0, cuDNN 5.1GPU model and memory:Quadro M1200, 4GB, WDDM modeDescribe the problemWhen restart the training (due to some hyper parameter adjustment) the third time, Tensorboard cannot load the new event file. It can only load the first two event file and after that scalar will stop refreshing.Powershell console gave the following output:[tensor] PS D:\Workspace\ConsorFlow> tensorboard.exe --logdir '../input_data/lpr_train_exp_01'WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.Starting TensorBoard b'52' at http://DESKTOP-P7T44AT:6006(Press CTRL+C to quit)WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.ERROR:tensorflow:Unable to get size of D:\Workspace\input_data\lpr_train_exp_01\events.out.tfevents.1493274079.DESKTOP-P7T44AT: D:\Workspace\input_data\lpr_train_exp_01\events.out.tfevents.1493274079.DESKTOP-P7T44ATWARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.WARNING:tensorflow:Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.WARNING:tensorflow:Found more than one metagraph event per run. Overwriting the metagraph with the newest event.WARNING:tensorflow:Detected out of order event.step likely caused by a TensorFlow restart. Purging expired events from Tensorboard display between the previous step: -1 (timestamp: -1) and current step: 17454 (timestamp: 1493310366.6493406). Removing 174 scalars, 76 histograms, 76 compressed histograms, 451 images, and 0 audio.The 'current step' 17454 in the output is the first step in my second restart.Information about event files:1st:   events.out.tfevents.14932740792nd:  events.out.tfevents.14933103393rd:   events.out.tfevents.1493352650About this problem in Ubuntu:I just switch to windows several days ago, such problem did not exist in Ubuntu (at least 14.04). I was using the exact same script, but with tensorflow version 1.01 (GPU, not nightly version), install following the offical instruction.Under windows, it was because of #7500, which leave me no choice but to install a nightly build.
performance	Runs regex filter doesn't work in tensorboard v1.1System informationCustom code, worked fine on 1.0OS: Linux Ubuntu 16.04installed binary via pip3TensorFlow version v1.1.0-rc0-61-g1ec6ed5, 1.1.0CUDA v8.0, cuDNN v5.1GTX 1070, 8GB RAMTo reproduce: run tensorboard, try to filter runs in web interface, nothing happensProblem descriptionRunning tensorboard with v1.1 gives me the following warnings in the console (repeated four times) once the web interface is opened:WARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404At first I ignored it, but it turns out that when examining the runs in the web interface, the regex filter for the runs doesn't work at all. This exact command in the exact same folder with the exact same logs worked without issue with v1.0.
performance	Error in //tensorflow/core:ops_array_grad_testOn a machine with a GPU, under the GPU configuration, I ran the command: bazel test -c opt --config=cuda //tensorflow/core:ops_array_grad_testand I got the following error (see highlight in bold font)exec ${PAGER:-/usr/bin/less} "$0" || exit 1I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so.7.0 locallyI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so.6.5 locallyI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so.7.0 locallyI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so locallyI tensorflow/stream_executor/dso_loader.cc:99] Couldn't open CUDA library libcurand.so.7.0. LD_LIBRARY_PATH:I tensorflow/stream_executor/cuda/cuda_rng.cc:333] Unable to load cuRAND DSO.Running main() from test_main.cc[==========] Running 4 tests from 1 test case.[----------] Global test environment set-up.[----------] 4 tests from ArrayGradTest[ RUN      ] ArrayGradTest.PackGradI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zeroI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:name: GeForce GTX 980major: 5 minor: 2 memoryClockRate (GHz) 1.2785pciBusID 0000:01:00.0Total memory: 4.00GiBFree memory: 3.91GiBI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   YI tensorflow/core/common_runtime/gpu/gpu_device.cc:680] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 3.62GiB bytes.I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x704a80000 extends to 0x7ec261000[       OK ] ArrayGradTest.PackGrad (481 ms)[ RUN      ] ArrayGradTest.UnpackGradI tensorflow/core/common_runtime/gpu/gpu_device.cc:680] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)[       OK ] ArrayGradTest.UnpackGrad (2 ms)[ RUN      ] ArrayGradTest.ConcatGradI tensorflow/core/common_runtime/gpu/gpu_device.cc:680] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)E tensorflow/core/common_runtime/executor.cc:273] Executor failed to create kernel. Not found: No registered 'ZerosLike' OpKernel for GPU devices compatible with node n8 = ZerosLikeT=DT_INT32[[Node: n8 = ZerosLikeT=DT_INT32]]**W tensorflow/core/common_runtime/executor.cc:1096] 0x7f70d3c21f10 Compute status: Not found: No registered 'ZerosLike' OpKernel for GPU devices compatible with node n8 = ZerosLikeT=DT_INT32[[Node: n8 = ZerosLikeT=DT_INT32]][[Node: dx = SymbolicGradient[Tin=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], Tout=[DT_INT32, DT_FLOAT, DT_FLOAT], f=Concat[N=2, T=DT_FLOAT], _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_dim_0/_1, _recv_x0_0/_3, _recv_x1_0/_5, _recv_dy_0/_7)]]W tensorflow/core/common_runtime/executor.cc:1096] 0x7f70d3c224b0 Compute status: Not found: No registered 'ZerosLike' OpKernel for GPU devices compatible with node n8 = ZerosLikeT=DT_INT32[[Node: n8 = ZerosLikeT=DT_INT32]][[Node: dx = SymbolicGradient[Tin=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], Tout=[DT_INT32, DT_FLOAT, DT_FLOAT], f=Concat[N=2, T=DT_FLOAT], _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_dim_0/_1, _recv_x0_0/_3, _recv_x1_0/_5, _recv_dy_0/_7)]][[Node: dx/_9 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_18_dx", tensor_type=DT_INT32, _device="/job:localhost/replica:0/task:0/cpu:0"]]**W tensorflow/core/common_runtime/executor.cc:1096] 0x7f70d3c224b0 Compute status: Not found: No registered 'ZerosLike' OpKernel for GPU devices compatible with node n8 = ZerosLikeT=DT_INT32**         [[Node: n8 = ZerosLikeT=DT_INT32]][[Node: dx = SymbolicGradient[Tin=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], Tout=[DT_INT32, DT_FLOAT, DT_FLOAT], f=Concat[N=2, T=DT_FLOAT], _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_dim_0/_1, _recv_x0_0/_3, _recv_x1_0/_5, _recv_dy_0/_7)]][[Node: dx/_11 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_20_dx", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]]W tensorflow/core/common_runtime/executor.cc:1096] 0x7f70d3c224b0 Compute status: Not found: No registered 'ZerosLike' OpKernel for GPU devices compatible with node n8 = ZerosLikeT=DT_INT32[[Node: n8 = ZerosLikeT=DT_INT32]][[Node: dx = SymbolicGradient[Tin=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], Tout=[DT_INT32, DT_FLOAT, DT_FLOAT], f=Concat[N=2, T=DT_FLOAT], _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_dim_0/_1, _recv_x0_0/_3, _recv_x1_0/_5, _recv_dy_0/_7)]][[Node: dx/_13 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_22_dx", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]]F tensorflow/core/ops/array_grad_test.cc:126] Check failed: ::tensorflow::Status::OK() == (sess->Run( {{"dim", test::AsScalar(dim)}, {"x0:0", x0}, {"x1:0", x1}, {"dy:0", dy}}, {"dx:0", "dx:1", "dx:2"}, {}, &out)) (OK vs. Not found: No registered 'ZerosLike' OpKernel for GPU devices compatible with node n8 = ZerosLikeT=DT_INT32[[Node: n8 = ZerosLikeT=DT_INT32]][[Node: dx = SymbolicGradient[Tin=[DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT], Tout=[DT_INT32, DT_FLOAT, DT_FLOAT], f=Concat[N=2, T=DT_FLOAT], _device="/job:localhost/replica:0/task:0/gpu:0"](_recv_dim_0/_1, _recv_x0_0/_3, _recv_x1_0/_5, _recv_dy_0/_7)]][[Node: dx/_9 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_18_dx", tensor_type=DT_INT32, _device="/job:localhost/replica:0/task:0/cpu:0"]])external/bazel_tools/tools/test/test-setup.sh: line 51:  9618 Aborted                 (core dumped)
performance	Statically-linked libraries in TF binary can cause symbol collisionsTensorFlow currently statically links all dependencies. This sometimes causes hard-to-diagnose crashes (e.g. segfaults) when another version of a dependency is loaded into the process. This can even happen within TensorFlow if separate TensorFlow .so's are loaded into the same Python process.Possible solutions would be to reduce the visibility of these symbols, dynamically link common libraries, or run TF in a separate process.Known problematic libraries:protobuf (#8403, #8394)OpenCL, OpenCV (#7378)Other related issues:#7480
performance	tf.while_loop much slower than static graph?I'm running on TF 1.1, and I've used tf.while_loop + TensorArray to implement dynamic unrolling of a type of recurrence that I previously unrolled statically through python code. The difference in speed is very dramatic, with forward inference being about 200x slower when dynamically unrolled, and backprop about 2x slower. Is this expected? Are there any tricks for optimization that I'm missing? This is on CPU. Performance gap on GPU is even larger.
performance	Failed to enqueue async memcpy from device to host, with latest code (relapse?)On a Linux machine with a GPU, with the GPU configuration, I ran the following command:bazel test -c opt --config=cuda //tensorflow/python:framework_function_testThen I got the following error, which seems to be similar to the closed issues. I'm using the latest code of the master branch#719#713I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so.7.0 locallyI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so.6.5 locallyI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so.7.0 locallyI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so locallyI tensorflow/stream_executor/dso_loader.cc:99] Couldn't open CUDA library libcurand.so.7.0. LD_LIBRARY_PATH:I tensorflow/stream_executor/cuda/cuda_rng.cc:333] Unable to load cuRAND DSO.I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:909] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zeroI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:name: GeForce GTX 980major: 5 minor: 2 memoryClockRate (GHz) 1.2785pciBusID 0000:01:00.0Total memory: 4.00GiBFree memory: 3.91GiBI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   YI tensorflow/core/common_runtime/gpu/gpu_device.cc:680] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.0KiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 8.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 32.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 64.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 128.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 256.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 512.00MiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.00GiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.00GiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.00GiBI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 3.62GiB bytes.I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x704a80000 extends to 0x7ec261000...I tensorflow/core/common_runtime/gpu/gpu_device.cc:680] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)..I tensorflow/core/common_runtime/gpu/gpu_device.cc:680] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:01:00.0)E tensorflow/stream_executor/cuda/cuda_driver.cc:1197] failed to enqueue async memcpy from device to host: CUDA_ERROR_INVALID_VALUE; host dst: 0x7f16e40008c0; GPU src: 0x265d480; size: 4=0x4F tensorflow/core/common_runtime/gpu/gpu_util.cc:232] GPU->CPU Memcpy failedexternal/bazel_tools/tools/test/test-setup.sh: line 51:   714 Aborted                 (core dumped) "$@"
performance	Duplicate variable shown in Tensorboard expected?System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):OS Platform and Distribution (e.g., Linux Ubuntu 16.04):MacOS Sierra 12.12.4TensorFlow installed from (source or binary):pipTensorFlow version (use command below):1.1.0 (CPU)Describe the problemI am trying to implement E2C (available from https://arxiv.org/pdf/1506.07365.pdf). Basically it is a neural network that is used for learning a transition model using neural networks. In the training set I have data of the form (X_t, X_t+1) where both X_t and X_t+1 needs to be transformed by an encoding network (e.g. a variational autoencoder). I use the following snippet for creating the encoding network (adapted from https://github.com/ericjang/e2c):    def encode(self, x, share=None):        fc = tf.contrib.layers.fully_connected        with tf.variable_scope('Encoder', reuse=share):            l1 = fc(x, 400, weights_initializer=tf.orthogonal_initializer(),                    activation_fn=tf.nn.relu)            l2 = fc(l1, 100, weights_initializer=tf.orthogonal_initializer(),                    activation_fn=tf.nn.relu)            return l2    def decode(self, z, share=None):        fc = tf.contrib.layers.fully_connected        with tf.variable_scope("Decoder", reuse=share):            l1 = fc(z, 100, weights_initializer=tf.orthogonal_initializer(1.1),                    activation_fn=tf.nn.relu)            l2 = fc(l1, 400, weights_initializer=tf.orthogonal_initializer(1.1),                    activation_fn=tf.nn.relu)            return fc(l2, self.x_dim,                      weights_initializer=tf.orthogonal_initializer(1.1),                      activation_fn=tf.nn.sigmoid)Then I would use something likeh_enc_t = encoder(X_t)h_enc_t_next = encoder(X_{t+1}, share=True)to create the encoded output for the model.The problem is that when visualizing this on Tensorboard, while it is sharing the variables by setting share=True for the variable scope, on the graph visulisation you will have Encoder and Encoder_1 instead of just a Decoder scope. Of course they took different input since we need to transform X_t and X_t+1, but shouldn't the network be wrapped in the same scope since underneath we are reusing the same weights? I wonder if it is a feature to have Encoder_1 and Encoder separately or it is a limitation of the variable scoping. The problem is illustrated in the screenshot below, you will see duplicates for 'Encoder' 'SampleQPhi" etc:However, I would expect something like this (as appeared in the paper) to be a more reasonable visualization (h_enc) with input x_t and x_t+1 are the same network:Many thanks in advance!
performance	Wrong path for absolute variable scopesUsing absolute paths for scopes is useful when structuring large models.We can enter a name scope from its absolute path by appending a slash:with tf.name_scope('foo'):  with tf.name_scope('bar/') as scope:    print(tf.constant(0).name)  # bar/Const:0    print(bar)  # barHowever, this does not work with variable scopes:with tf.variable_scope('foo'):  with tf.variable_scope('bar/') as bar:    print(tf.constant(0).name)  # bar/Const:0    print(bar.name)  # foo/bar/ (Expected: bar)The last line should print bar instead of foo/bar/.
performance	tf.pow(x, y) will freeze for negative integer ySystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yesOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, and macOS 10.12.4TensorFlow installed from (source or binary): binaryTensorFlow version (use command below): 1.1.0 on both operation systemsBazel version (if compiling from source): not compiled from sourceCUDA/cuDNN version: CPU only on Windows, while CUDA 8.0 on macOSGPU model and memory: Nvidia Titan X, 12GBExact command to reproduce: a short piece of Python codePython version: 3.5.2 (Anaconda) on Windows, 3.6.0 (Anaconda) on macOSDescribe the problemtf.pow(x, y) will freeze for negative integer y (and of course, integer x).  It will not freeze for negative floating number y.Source code / logsimport tensorflow as tfwith tf.Graph().as_default(), tf.Session().as_default():    print(tf.pow(5, -2).eval())  # this will not stop
performance	MNIST Tutorial Appears to Not Toggle XLA CompilationI have been using the JIT compilation/XLA tutorial (https://www.tensorflow.org/performance/xla/jit#step_3_run_with_xla), and it seems that whether or not XLA compilation happens doesn't depend on the statement on line 63 in mnist_softmax_xla.py. The comment above it says that line will turn on XLA JIT compilation. When I run with the two options explained on the page (--xla='' for compiling without XLA, and TF_XLA_FLAGS=--xla_generate_hlo_graph=.* for compiling with XLA), the second executes line 63 and the first does not. But, both seem to compute in exactly the same way, going through compiler/xla/service. The output for both runs is:Extracting /tmp/tensorflow/mnist/input_data/train-images-idx3-ubyte.gzExtracting /tmp/tensorflow/mnist/input_data/train-labels-idx1-ubyte.gzExtracting /tmp/tensorflow/mnist/input_data/t10k-images-idx3-ubyte.gzExtracting /tmp/tensorflow/mnist/input_data/t10k-labels-idx1-ubyte.gz2017-05-01 12:50:25.203870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.2017-05-01 12:50:25.203904: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.2017-05-01 12:50:25.232661: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices2017-05-01 12:50:25.232702: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Xpu present with 8 visible devices2017-05-01 12:50:25.233155: I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Host. Devices:2017-05-01 12:50:25.233165: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>2017-05-01 12:50:25.233894: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 8 visible devices2017-05-01 12:50:25.233903: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Xpu present with 8 visible devices2017-05-01 12:50:25.234360: I tensorflow/compiler/xla/service/service.cc:180] XLA service executing computations on platform Xpu. Devices:2017-05-01 12:50:25.234369: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (0): <undefined>, <undefined>2017-05-01 12:50:25.234372: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (1): <undefined>, <undefined>2017-05-01 12:50:25.234376: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (2): <undefined>, <undefined>2017-05-01 12:50:25.234379: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (3): <undefined>, <undefined>2017-05-01 12:50:25.234382: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (4): <undefined>, <undefined>2017-05-01 12:50:25.234385: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (5): <undefined>, <undefined>2017-05-01 12:50:25.234389: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (6): <undefined>, <undefined>2017-05-01 12:50:25.234392: I tensorflow/compiler/xla/service/service.cc:187]   StreamExecutor device (7): <undefined>, <undefined>0.9206
performance	Memory Leak from Deep Learning Training Step? (Finalized Graph)System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes, although my code is somewhat based on the MNIST deep learning tutorial.OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 14.04 VERSION="14.04.5 LTS, Trusty Tahr"TensorFlow installed from (source or binary):binary (I think, not 100% sure since it's been a few months since install. How can I check?)TensorFlow version (use command below):('v0.11.0-2614-g14aeb08-dirty', '0.12.0-rc0')Bazel version (if compiling from source):CUDA/cuDNN version:CUDA Version 8.0.44GPU model and memory:GeForce GTX 780M 4GBExact command to reproduce:self.sess.run(self.train_step, feed_dict={self.x: trainingdata, self.y_true: traininglabels, self.keepratio: self.training_keep_rate})Describe the problemI apologize if this is not an actual bug; I am relatively new to TensorFlow. I have posted on StackOverflow here and the only response I have gotten suggests filing a bug report here.If I comment the sess.run line above, and only that line, out (but still do all my pre-processing and validation/testing and such for a few thousand training batches), the memory leak does not happen.The leak is on the order of a few GB per hour (I am running Ubuntu, and have 16GB RAM + 16GB swap; the system becomes very laggy and unresponsive after 1-3 hours of running, when about 1/3-1/2 the RAM is used, which is a bit weird to me since I still have lots of RAM and the CPU is mostly free when this happens...)Here is some of the initializer code (only run once, at the beginning) if it is relevant:    with tf.name_scope('after_final_layer') as scope:        self.layer1 = weights["wc1"]        self.y_conv = network(self.x, weights, biases, self.keepratio)['out']        variable_summaries(self.y_conv)        # Note: Don't add a softmax reducer in the network if you are going to use this        # cross-entropy function        self.cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(self.y_conv, self.y_true, name = "softmax/cross_ent"), name = "reduce_mean")        self.train_step = tf.train.AdamOptimizer(learning_rate, name = "Adam_Optimizer").minimize(self.cross_entropy)        self.prediction = tf.argmax(self.y_conv, 1)        self.correct_prediction = tf.equal(self.prediction, tf.argmax(self.y_true, 1))        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))        if tensorboard:            # Merge all the summaries and write them out to the directory below            self.merged = tf.summary.merge_all()            self.my_writer = tf.summary.FileWriter('/home/james/PycharmProjects/AI_Final/my_tensorboard', graph=self.sess.graph)        # self.sess.run(tf.initialize_all_variables()) #old outdated way to do below        tf.global_variables_initializer().run(session=self.sess)        self.sess.graph.finalize() #make sure nothing new is added to graphNotice that I have finalized the graph, so nothing new should be added to it.Am I doing something wrong/is this expected behavior, or is this a real bug?I have attached the source code as well (two .py files in directory).  Note: I am happy put in the work to reduce the source to a minimal recreation of the bug, but first I'd like verification that 1) this would be helpful (i.e. that the above info is not enough) and that 2) this is probably a bug, and not just an obvious beginner mistake on my part.Thank you in advance.source.zip
performance	SIGSEGV with sparse_add and broadcastingSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):yes, enclosed belowOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04TensorFlow installed from (source or binary):binary via pipTensorFlow version (use command below):('v1.0.0-65-g4763edf-dirty', '1.0.1')Bazel version (if compiling from source):N/A, using pip installationCUDA/cuDNN version:N/A, CPU-onlyGPU model and memory:noneExact command to reproduce:from __future__ import print_functionimport numpy as npimport tensorflow as tfdense_sz = [1, 1000, 1000]dense = tf.constant(1.0, shape=dense_sz, dtype=tf.float32)sparse_sz = [10, 1000, 1000]nnz = 100nz_ind = np.random.choice(np.prod(sparse_sz), size=nnz, replace=False)nz_ind = np.unravel_index(nz_ind, dims=sparse_sz)nz_ind = np.array(nz_ind).Tassert np.all(nz_ind < np.array(sparse_sz)[None, :])# Ensure canonical ordering.ind = np.lexsort([nz_ind[:, i].flatten() for i in reversed(range(nz_ind.shape[1]))])nz_ind = nz_ind[ind, :]print('nz_ind\n', nz_ind)sparse_plc = tf.sparse_placeholder(tf.float32)sparse_sum = tf.sparse_add(dense, sparse_plc)init = tf.global_variables_initializer()with tf.Session() as sess:    sess.run(init)    print('after init')    res = sess.run(sparse_sum, feed_dict={sparse_plc: tf.SparseTensorValue(nz_ind, np.ones((nnz,)), sparse_sz)})    print('sum\n', res)Describe the problemRunning the code above results in[...]after initProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV)For lower values of nnz, (nnz = 1) it finishes fine quite often.[...]after initsum [[[ 1.  1.  1. ...,  1.  1.  1.]  [ 1.  1.  1. ...,  1.  1.  1.]  [ 1.  1.  1. ...,  1.  1.  1.]  ...,   [ 1.  1.  1. ...,  1.  1.  1.]  [ 1.  1.  1. ...,  1.  1.  1.]  [ 1.  1.  1. ...,  1.  1.  1.]]]Process finished with exit code 0Source code / logsSee above.
performance	Seg fault on session run when built with CMake and optimize for native arch enabledSystem info: Ubuntu 16.04 64 bit, gcc 5.4.0, Intel i5 CPUSegmentation fault occurs in Eigen when a certain AVX instruction is performed (see stack trace below). This occurs during session run of several convolutional neural network graphs.Tensorflow (checked out from the master branch today) is built using CMake with tensorflow_BUILD_SHARED_LIB enabled which generates a libtensorflow.so library file. This library file is linked to another C++ application which simply loads a graph and executes it.Disabling the CMake option tensorflow_OPTIMIZE_FOR_NATIVE_ARCH removes the error, but probably also reduce performance.Below is a nasty long stack trace, if you need any other info please let me know.Stack trace:#0 0x00007fffee19021b in _mm256_store_ps (__A=..., __P=0x7fff7c110cd0) at /usr/lib/gcc/x86_64-linux-gnu/5/include/avxintrin.h:854#1 Eigen::internal::pstore<float, float __vector(8)>(float*, float __vector(8) const&) (to=0x7fff7c110cd0, from=...)  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/AVX/PacketMath.h:260#2 0x00007fffefd255b5 in Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>::operator() (  this=0x7fff98fd4a67, blockA=0x7fff7c110cd0, lhs=..., depth=9, rows=8, stride=0, offset=0)  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/products/GeneralBlockPanelKernel.h:1767#3 0x00007fffeff65692 in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::pack_lhs (  this=0x7fff937fbbd0, m=1, k=0) at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContractionThreadPool.h:495#4 0x00007fffeff63758 in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper (this=0x7fff937fbbd0, start=1, end=2, k=0, rhs=false) at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContractionThreadPool.h:624#5 0x00007fffeff6369d in Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool)::{lambda()#1}::operator()() const (__closure=0x7fff7c1aaca0)  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorContractionThreadPool.h:628#6 0x00007fffeff73cca in std::_Bind<Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool)::{lambda()#1} ()>::__call<void>(std::tuple<>&&, std::_Index_tuple<>) (this=0x7fff7c1aaca0,  __args=<unknown type in /home/smistad/workspace/FAST/build_Release/lib/libtensorflow.so, CU 0xf277508, DIE 0xf39a603>) at /usr/include/c++/5/functional:1074#7 0x00007fffeff71a5d in std::_Bind<Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool)::{lambda()#1} ()>::operator()<, void>() (this=0x7fff7c1aaca0) at /usr/include/c++/5/functional:1133#8 0x00007fffeff6d3ac in std::_Function_handler<void (), std::_Bind<Eigen::TensorEvaluator<Eigen::TensorContractionOp<Eigen::array<Eigen::IndexPair<long>, 1ul> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>::Context<Eigen::internal::gemm_pack_lhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::M---Type <return> to continue, or q <return> to quit---akePointer>, 24, 8, 0, false, false>, Eigen::internal::gemm_pack_rhs<float, long, Eigen::internal::TensorContractionSubMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, 4, 0, false, false>, Eigen::internal::gebp_kernel<float, float, long, Eigen::internal::blas_data_mapper<float, long, 0, 0>, 24, 4, false, false>, Eigen::internal::TensorContractionInputMapper<float, long, 1, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::TensorContractionInputMapper<float, long, 0, Eigen::TensorEvaluator<Eigen::TensorReshapingOp<Eigen::DSizes<long, 2> const, Eigen::TensorImagePatchOp<-1l, -1l, Eigen::TensorMap<Eigen::Tensor<float const, 4, 1, long>, 16, Eigen::MakePointer> const> const> const, Eigen::ThreadPoolDevice>, Eigen::array<long, 1ul>, Eigen::array<long, 1ul>, 8, true, false, 0, Eigen::MakePointer>, Eigen::internal::blas_data_mapper<float, long, 0, 0> >::enqueue_packing_helper(long, long, long, bool)::{lambda()#1} ()> >::_M_invoke(std::_Any_data const&) (__functor=...) at /usr/include/c++/5/functional:1871#9 0x00007fffedeba4c8 in std::function<void ()>::operator()() const (this=0x7fff7c1aace0) at /usr/include/c++/5/functional:2267#10 0x00007fffedeb9da7 in tensorflow::thread::EigenEnvironment::ExecuteTask (this=0x21bd7a8, t=...) at /home/smistad/workspace/FAST/build_Release/external/tensorflow/src/tensorflow/tensorflow/core/lib/core/threadpool.cc:81#11 0x00007fffedebca71 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop (this=0x21bd7a0, thread_id=3)  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:232#12 0x00007fffedebade0 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::NonBlockingThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment)::{lambda()#1}::operator()() const ()  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:65#13 0x00007fffedebe462 in std::_Function_handler<void (), Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::NonBlockingThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment)::{lambda()#1}>::_M_invoke(std::_Any_data const&) (__functor=...) at /usr/include/c++/5/functional:1871#14 0x00007fffedeba4c8 in std::function<void ()>::operator()() const (this=0x3333350) at /usr/include/c++/5/functional:2267#15 0x00007fffedeb9aec in tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}::operator()() const (__closure=0x3333350)  at /home/smistad/workspace/FAST/build_Release/external/tensorflow/src/tensorflow/tensorflow/core/lib/core/threadpool.cc:56#16 0x00007fffedebbcb1 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) (__functor=...)  at /usr/include/c++/5/functional:1871#17 0x00007fffedeba4c8 in std::function<void ()>::operator()() const (this=0x3346398) at /usr/include/c++/5/functional:2267#18 0x00007fffedef50ca in std::_Bind_simple<std::function<void ()> ()>::_M_invoke<>(std::_Index_tuple<>) (this=0x3346398) at /usr/include/c++/5/functional:1531#19 0x00007fffedef5020 in std::_Bind_simple<std::function<void ()> ()>::operator()() (this=0x3346398) at /usr/include/c++/5/functional:1520#20 0x00007fffedef4fb0 in std::thread::_Impl<std::_Bind_simple<std::function<void ()> ()> >::_M_run() (this=0x3346380) at /usr/include/c++/5/thread:115#21 0x00007ffff6201c80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6#22 0x00007ffff5d1d6ba in start_thread (arg=0x7fff98fd5700) at pthread_create.c:333#23 0x00007ffff5a5382d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109
performance	Indexed Slices SupportHi,I am wondering what the reasoning behind IndexedSlices is and whether they are actually necessary. My understanding is that they are only constructed for the gradient of the gather op. Is there any other place in the Python API that IndexedSlices are being constructed? Now, even though they are only constructed there, there are special cases throughout the Python codebase for dealing with indexed slices. Is the performance benefit so important to justify all this special treatment code? I am asking because I am wondering if it is useful to implement that functionality in an API for a different language.And if I am to rephrase this question, should one put effort into adding support to the C++ API for indexed slices, or is their use a remnant of a design choice that is not that useful looking in retrospect?Thank you!
performance	Tensorboard Graph vizualisation crashes with Chrome/SafariServer system information== dockerfile image =============================================FROM tensorflow/tensorflow:latest-gpuRUN pip install tensorflow --upgradeRUN pip install tensorflow-gpu --upgrade== cat /etc/issue ===============================================Linux 479a65b403e2 4.4.0-59-generic #80-Ubuntu SMP Fri Jan 6 17:47:47 UTC 2017 x86_64 x86_64 x86_64 GNU/LinuxVERSION="14.04.5 LTS, Trusty Tahr"VERSION_ID="14.04"== are we in docker =============================================Yes== compiler =====================================================c++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4Copyright (C) 2013 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.== uname -a =====================================================Linux 479a65b403e2 4.4.0-59-generic #80-Ubuntu SMP Fri Jan 6 17:47:47 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux== check pips ===================================================numpy (1.12.1)protobuf (3.3.0)tensorflow (1.1.0)tensorflow-gpu (1.1.0)== check for virtualenv =========================================False== tensorflow import ============================================tf.VERSION = 1.1.0tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5Sanity check: array([1], dtype=int32)== env ==========================================================LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64:DYLD_LIBRARY_PATH is unset== nvidia-smi ===================================================Fri May  5 08:50:12 2017       +-----------------------------------------------------------------------------+| NVIDIA-SMI 375.26                 Driver Version: 375.26                    ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  TITAN X (Pascal)    Off  | 0000:01:00.0     Off |                  N/A || 24%   40C    P2    56W / 250W |   1793MiB / 12189MiB |      0%      Default |+-------------------------------+----------------------+----------------------+|   1  TITAN X (Pascal)    Off  | 0000:02:00.0     Off |                  N/A || 25%   45C    P2    55W / 250W |    312MiB / 12189MiB |      0%      Default |+-------------------------------+----------------------+----------------------+|   2  TITAN X (Pascal)    Off  | 0000:03:00.0     Off |                  N/A || 24%   43C    P2    53W / 250W |    312MiB / 12189MiB |      0%      Default |+-------------------------------+----------------------+----------------------+|   3  TITAN X (Pascal)    Off  | 0000:04:00.0     Off |                  N/A || 25%   44C    P2    53W / 250W |    312MiB / 12186MiB |      0%      Default |+-------------------------------+----------------------+----------------------+                                                                               +-----------------------------------------------------------------------------+| Processes:                                                       GPU Memory ||  GPU       PID  Type  Process name                               Usage      ||=============================================================================|+-----------------------------------------------------------------------------+== cuda libs  ===================================================/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.44Local machine informationMacOS Sierra 10.12.4 (16E195)Google Chrome 58.0.3029.96 (64-bit)Safari 10.1 (12603.1.30.0.34)Describe the problemI'm running Tensorboard on a server and visualizing the graph on my local machine.With the attached file that I generated using a custom script, Tensorboard crashes after a while of just moving the graph around or when I try to remove some modules from the main graph (100% crash after 4 modules removed).More specifically:In Safari only the browser freezes but I can still close it.In Chrome the browser freezes and then the whole OS, I don't even have haptic feedback anymore. On the otherhand Tensorboard is still running on the server and the Tensorboard webpage can be accessed by other computers.Source code / logsHere is the log-file containing just the graph that reproduces this issue 100% time on my end.events.out.tfevents.1493971052.c941b31be93a.zip
performance	Make EIGEN_MAX_ALIGN_BYTES available from PythonRemoving unnecessary memcpys when feeding a Numpy array with a feed_dict is a recurring feature request that has large performance implications.From what I can tell, @alextp implemented changes that avoid the memcpy if the input array is EIGEN_MAX_ALIGN_BYTES aligned. For a user to definitely avoid memcpy's on feeding, they would need to make sure their arrays are aligned to EIGEN_MAX_ALIGN_BYTES. Currently, there is no way to access EIGEN_MAX_ALIGN_BYTES from Python, so the user can't be sure what alignment is required.It would be nice if there was a C API call (and a corresponding Python one) to make EIGEN_MAX_ALIGN_BYTES available. This isn't a critical feature as the user can currently be very pessimistic on alignment requirements and (probably safely) 64-byte align their inputs.
performance	atrous_conv2d does not support NCHW formatAny plans to support NCHW format for atrous_conv2d?  As per the performance guidelines on TensorFlow website,  ops using NCHW format is faster than NHWC format for GPUs.
performance	tf.random_crop exception after upgrading to tf1.1 from tf1.0Please go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YesOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.4TensorFlow installed from (source or binary): binaryTensorFlow version (use command below):v1.1.0-rc0-61-g1ec6ed5 1.1.0Bazel version (if compiling from source):CUDA/cuDNN version: 8.0/5.1GPU model and memory: Tesla m40 / 12 gbExact command to reproduce:You can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemThe tf.random_crop gives exception even when it receives input of valid size. assertion failed: [Need value.shape >= size, got ] [224 224 3] [224 224 3]Source code / logsFile "../foo.py", line 1356, in _pp_augmentaug = tf.random_crop(aug, [crop_size[0], crop_size[1], aug_dim3])File "/usr/local/anaconda3/envs/tf1.1/lib/python3.5/site-packages/tensorflow/python/ops/random_ops.py", line 303, in random_crop["Need value.shape >= size, got ", shape, size])File "/usr/local/anaconda3/envs/tf1.1/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py", line 121, in Assertcondition, data, summarize, name="Assert")File "/usr/local/anaconda3/envs/tf1.1/lib/python3.5/site-packages/tensorflow/python/ops/gen_logging_ops.py", line 39, in _assertsummarize=summarize, name=name)File "/usr/local/anaconda3/envs/tf1.1/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py", line 768, in apply_opop_def=op_def)File "/usr/local/anaconda3/envs/tf1.1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 2336, in create_oporiginal_op=self._default_original_op, op_def=op_def)File "/usr/local/anaconda3/envs/tf1.1/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 1228, in initself._traceback = _extract_stack()InvalidArgumentError (see above for traceback): assertion failed: [Need value.shape >= size, got ] [224 224 3] [224 224 3][[Node: image_filters/train_tower_0/random_crop_1/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_INT32], summarize=3, _device="/job:localhost/replica:0/task:0/cpu:0"](image_filters/train_tower_0/random_crop_1/All/_29, image_filters/train_tower_0/random_crop_1/Assert/Assert/data_0, image_filters/train_tower_0/random_crop_1/Shape/_31, image_filters/train_tower_0/random_crop_1/size/_33)]][[Node: image_filters/train_tower_0/DecodeRaw_1/_93 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/gpu:0", send_device="/job:localhost/replica:0/task:0/cpu:0", send_device_incarnation=1, tensor_name="edge_232_image_filters/train_tower_0/DecodeRaw_1", tensor_type=DT_UINT8, _device="/job:localhost/replica:0/task:0/gpu:0"]]
performance	Tensorflow causes SIGSEGV in numpyx_train Examples Loaded = (55000, 784)y_train Examples Loaded = (55000, 10)[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.][New Thread 0x7ffff2211700 (LWP 6011)][New Thread 0x7ffff2a12700 (LWP 6012)][New Thread 0x7fffd33a4700 (LWP 6013)][Thread 0x7fffd33a4700 (LWP 6013) exited][Thread 0x7ffff2a12700 (LWP 6012) exited][Thread 0x7ffff2211700 (LWP 6011) exited]Program received signal SIGSEGV, Segmentation fault.0x00007ffff716602f in _int_free (av=0x7ffff74a8760 <main_arena>,p=, have_lock=0) at malloc.c:39963996malloc.c: No such file or directory.gdb backtrace report(gdb) bt#0  0x00007ffff716602f in _int_free (av=0x7ffff74a8760 <main_arena>,p=, have_lock=0) at malloc.c:3996#1  0x00007ffff2ad9ef0 in ?? ()from /home/shreeranga/PP/Exp/venvs/lib/python2.7/site-packages/numpy/core/..0#2  0x00007ffff2ad4770 in ?? ()from /home/shreeranga/PP/Exp/venvs/lib/python2.7/site-packages/numpy/core/..0#3  0x00007ffff2ad486a in ?? ()from /home/shreeranga/PP/Exp/venvs/lib/python2.7/site-packages/numpy/core/..0#4  0x00007ffff2a28e09 in ?? ()from /home/shreeranga/PP/Exp/venvs/lib/python2.7/site-packages/numpy/core/..0#5  0x00007ffff2a26e7f in ?? ()from /home/shreeranga/PP/Exp/venvs/lib/python2.7/site-packages/numpy/core/..0#6  0x00000000009649e0 in ?? ()#7  0x00007ffff521f1c8 in __frame_dummy_init_array_entry ()from /home/shreeranga/PP/Exp/venvs/lib/python2.7/site-packages/numpy/core/..o#8  0x00007fffffffdc00 in ?? ()#9  0x00007ffff2ae7cd1 in ?? ()
performance	Optimized compiled Tensorflow uses almost 2x more memory than non-optimized binarySystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yesOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04TensorFlow installed from (source or binary): BothTensorFlow version (use command below): ('v1.0.0-65-g4763edf-dirty', '1.0.1') (compiled at the same git commit of the binary version)Bazel version (if compiling from source): 0.4.5CUDA/cuDNN version: N/A (CPU only)GPU model and memory: N/AExact command to reproduce:import pdbimport numpy as npimport tensorflow as tfdef get_layer(input_size, output_size, name):    # W_val is loaded from a file using numpy.load    W_val = np.random.normal(scale=0.1, size=(input_size, output_size)).astype(np.float32)    W = tf.get_variable(name='W_{}'.format(name), shape=(input_size, output_size),                        initializer=tf.constant_initializer(value=W_val, dtype=tf.float32),                        dtype=tf.float32)    b = tf.get_variable(name='b_{}'.format(name), shape=(output_size,),                        initializer=tf.constant_initializer(value=0.1, dtype=tf.float32),                        dtype=tf.float32)    return W, bsessions = []for i in range(3):    g = tf.Graph()    with g.as_default():        W1, b1 = get_layer(158238, 900, '1')        W2, b2 = get_layer(900, 1000, '2')        W3, b3 = get_layer(1000, 1, '3')        init = tf.global_variables_initializer()    session = tf.Session(graph=g)    session.run(init)    print 'Loaded {}'.format(i)    sessions.append(session)pdb.set_trace()Describe the problemAfter running the code snippet under the non-optimized binary Tensorflow installation, the used memory is ~6GB. However, when the same snippet is run with Tensorflow compiled with -c opt --copt=-march=native directives, the memory usage is ~11GB (1.8x larger).Note that there's no memory-usage difference when I use tf.truncated_normal(stddev=0.1...) instead of tf.constant_initializer with a numpy array.Not sure if this is a bug, or a side-effect of the optimized version or if there's something I can do to optimize memory usage?Source code / logsI can attach chrome traces if necessary.
performance	'Tensor' object has no attribute 'initializer' after import from meta graphSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution: Darwin Austins-MBP 16.5.0 Darwin Kernel Version 16.5.0: Fri Mar  3 16:52:33 PST 2017; root:xnu-3789.51.2~3/RELEASE_X86_64 x86_64Mac OS X 10.12.4TensorFlow installed from (source or binary):binaryTensorFlow version (use command below):v1.1.0-rc0-61-g1ec6ed5 1.1.0Bazel version (if compiling from source):0.4.5CUDA/cuDNN version:NoneGPU model and memory:NoneExact command to reproduce: Ref to Codestensorflow importtf.VERSION = 1.1.0tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5Sanity check: array([1], dtype=int32)Describe the problemAfter export and import a meta graph with uninitialized local variables,You can not inittialize them with sess.run(tf. local_variables_initializer()), causeTF do not register variable's proto function with key 'LOCAL_VARIABLES' and whenexport meta graph to protobuf, source code can not find to_proto function from repository.Source code / logsimport tensorflow as tfgraph = tf.Graph()with graph.as_default():    x = tf.Variable(1, collections=[tf.GraphKeys.LOCAL_VARIABLES])    y = tf.Variable(1)    z = x + yorigin_meta_graph = tf.train.export_meta_graph(graph=graph)new_graph = tf.Graph()with new_graph.as_default():    tf.train.import_meta_graph(origin_meta_graph)    init = tf.local_variables_initializer()with tf.Session() as sess:    sess.run(init)Traceback (most recent call last):  File "/Users/austin/workspace/aip/3rd/tensorflow/tensorflow/test.py", line 12, in <module>    init = tf.local_variables_initializer()  File "/Users/austin/workspace/aip/3rd/tensorflow/venv/lib/python3.6/site-packages/tensorflow/python/ops/variables.py", line 1184, in local_variables_initializer    return variables_initializer(local_variables())  File "/Users/austin/workspace/aip/3rd/tensorflow/venv/lib/python3.6/site-packages/tensorflow/python/ops/variables.py", line 1149, in variables_initializer    return control_flow_ops.group(*[v.initializer for v in var_list], name=name)  File "/Users/austin/workspace/aip/3rd/tensorflow/venv/lib/python3.6/site-packages/tensorflow/python/ops/variables.py", line 1149, in <listcomp>    return control_flow_ops.group(*[v.initializer for v in var_list], name=name)AttributeError: 'Tensor' object has no attribute 'initializer'import tensorflow as tfgraph = tf.Graph()with graph.as_default():    x = tf.Variable(1, collections=[tf.GraphKeys.LOCAL_VARIABLES])    y = tf.Variable(1)    z = x + yorigin_meta_graph = tf.train.export_meta_graph(graph=graph)new_graph = tf.Graph()with new_graph.as_default():    tf.train.import_meta_graph(origin_meta_graph)print(graph.get_collection(tf.GraphKeys.LOCAL_VARIABLES))print(new_graph.get_collection(tf.GraphKeys.LOCAL_VARIABLES))[<tf.Variable 'Variable:0' shape=() dtype=int32_ref>][<tf.Tensor 'Variable:0' shape=() dtype=int32_ref>]As it show above, in origin graph local_variable collection is a list of tf.Variablebut in the new graph, is a list of tf.TensorWork aroundAdd following registration in your model coreOR Ref to this PRfrom tensorflow.core.framework import variable_pb2from tensorflow.python.framework import opsfrom tensorflow.python.ops import variablesfrom tensorflow.python.framework.ops import register_proto_functionregister_proto_function(    ops.GraphKeys.LOCAL_VARIABLES,    proto_type=variable_pb2.VariableDef,    to_proto=variables.Variable.to_proto,    from_proto=variables.Variable.from_proto)
performance	Segmentation fault on help(tf.train.SequenceExample)I was trying to try and test the tf.train.SequenceExample class, but it wasn't in the official docs and using help crashed Python. Does anyone know how to use it or how to solve this issue?
performance	Large page fault causes slow performance while using gpuSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YesOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04TensorFlow installed from (source or binary):binary, using pip install tensorflow-gpu==1.0.1TensorFlow version (use command below):1.0.1Bazel version (if compiling from source):CUDA/cuDNN version:8.0/5.1GPU model and memory:nvidia gtx1080, 8gDescribe the problemI have observed a large amount of page fault while running the provided sample code on gpu, and this causes a serious performance drawdown.The key parts of the output of /usr/bin/time -v python sample.py are:System time (seconds): 7.28  Percent of CPU this job got: 85%  Elapsed (wall clock) time (h:mm:ss or m:ss): 0:22.41 Minor (reclaiming a frame) page faults: 684695  Involuntary context switches: 164 File system inputs: 0  File system outputs: 8  There are 684k page faults,  and the gpu-volatile usage is only about 30%.I am very hesitating to ask for help here, because on another system with exact os, software and gpu, this issue does not appears, I have posted on stackoverflow to compare two systems hereIs that possible that tensorflow handles different hardwares differently? It looks to me that the gpu-cpu I/O may have caused this issue, and I suspect that I need to configure my hardware settings somewhere, but don't know how.Things I have tried:Upgrade BIOS to the latest version and reset default settings.Call Asus(my motherboard and gpu vendor) customer service for help.Inject LD_PRELOAD="/usr/lib/libtcmalloc.so" to .bashrc file.Source code / logsHere is the sample code I used to testimport tensorflow as tfimport numpy as npfrom tqdm import trangenp.random.seed(111)h,w = 3000, 2000steps = 1000x = tf.placeholder(dtype=tf.float32, shape=[h, w], name='x')t = tf.constant(np.random.random(size=[w, w]), dtype=tf.float32)m = tf.matmul(x,t)x0 = np.random.random(size=[h, w])sess = tf.Session()for i in trange(steps):    x0 = sess.run(m, feed_dict={x: x0})The attachment contains: Nvidia-smi output, /usr/bin/time -v output, hardware specs in html format, chrome trace timeline.sysB.zip
performance	memory leak when implement rnn attention decoderSystem information== cat /etc/issue ===============================================Linux quad 4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/LinuxVERSION="16.04 LTS (Xenial Xerus)"VERSION_ID="16.04"== are we in docker =============================================No== compiler =====================================================c++ (Ubuntu 4.9.4-2ubuntu1~16.04) 4.9.4Copyright (C) 2015 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.== uname -a =====================================================Linux quad 4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux== check pips ===================================================numpy (1.12.1)protobuf (3.3.0)tensorflow-gpu (1.1.0)== check for virtualenv =========================================True== tensorflow import ============================================tf.VERSION = 1.1.0tf.GIT_VERSION = v1.1.0-rc0-61-g1ec6ed5tf.COMPILER_VERSION = v1.1.0-rc0-61-g1ec6ed5Sanity check: array([1], dtype=int32)== env ==========================================================LD_LIBRARY_PATH is unsetDYLD_LIBRARY_PATH is unset== nvidia-smi ===================================================Tue May  9 12:16:54 2017+-----------------------------------------------------------------------------+| NVIDIA-SMI 375.39                 Driver Version: 375.39                    ||-------------------------------+----------------------+----------------------+| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC || Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. ||===============================+======================+======================||   0  GeForce GTX TIT...  Off  | 0000:05:00.0     Off |                  N/A || 22%   47C    P0    76W / 250W |      0MiB / 12205MiB |      0%      Default |+-------------------------------+----------------------+----------------------+|   1  GeForce GTX TIT...  Off  | 0000:06:00.0     Off |                  N/A || 22%   60C    P2   129W / 250W |  11713MiB / 12207MiB |     80%      Default |+-------------------------------+----------------------+----------------------+|   2  GeForce GTX TIT...  Off  | 0000:09:00.0     Off |                  N/A || 22%   49C    P0    83W / 250W |      0MiB / 12207MiB |      0%      Default |+-------------------------------+----------------------+----------------------+|   3  GeForce GTX TIT...  Off  | 0000:0A:00.0     Off |                  N/A || 24%   63C    P2   117W / 250W |  11713MiB / 12207MiB |     70%      Default |+-------------------------------+----------------------+----------------------++-----------------------------------------------------------------------------+| Processes:                                                       GPU Memory ||  GPU       PID  Type  Process name                               Usage      ||=============================================================================||    1     21558    C   python3                                      11709MiB ||    3     21346    C   python3                                      11709MiB |+-----------------------------------------------------------------------------+== cuda libs  ===================================================/usr/local/cuda-7.5/doc/man/man7/libcudart.7/usr/local/cuda-7.5/doc/man/man7/libcudart.so.7/usr/local/cuda-7.5/lib64/libcudart_static.a/usr/local/cuda-7.5/lib64/libcudart.so.7.5.18/usr/local/cuda-7.5/lib/libcudart_static.a/usr/local/cuda-7.5/lib/libcudart.so.7.5.18/usr/local/cuda-8.0/doc/man/man7/libcudart.7/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7/usr/local/cuda-8.0/lib64/libcudart_static.a/usr/local/cuda-8.0/lib64/libcudart.so.8.0.27Describe the problemWhen we try to implement a complex network which contain a rnn attention decoder, It will consume all the memory after several days. I extract the decoder in a test file, the memory still grow in a slower speed. also found that if change softmax to sigmoid, memory doesn't leak.Source code / logstest code:# __author__ = "liusiye"# -*- coding: utf-8 -*-import tensorflow as tffrom tensorflow.contrib.rnn import GRUCell, MultiRNNCellfrom os import getpidimport psutilimport gcimport tensorflow as tfimport numpy as npprocess = psutil.Process(getpid())B, T, H = 20, 60, 256layer_num = 4def apply_attention(encoding, rnn_output):    ''' encoding: [t, b, h1]        rnn_output: [b, h2]    '''    T, B, H1 = encoding.get_shape().as_list()    _, H2 = rnn_output.get_shape().as_list()    with tf.variable_scope('attention'):        w_encoder = tf.get_variable(            name='W_encoder',            shape=[H1, H1],            initializer=tf.random_uniform_initializer(-0.01, 0.01))        w_decoder = tf.get_variable(            name='W_decoder',            shape=[H2, H1],            initializer=tf.random_uniform_initializer(-0.01, 0.01))        w_attention = tf.get_variable(            name='W_attention',            shape=[H1, 1],            initializer=tf.random_uniform_initializer(-0.01, 0.01))    r_decoder = tf.matmul(rnn_output, w_decoder)  # [b, h1]    r_encoder = tf.matmul(tf.reshape(encoding, [-1, H1]), w_encoder)    r_encoder = tf.reshape(r_encoder, [T, B, H1])    # [t, b, h] -> [t * b, h] -> [t, b, h]    r_attention = tf.tanh(r_encoder + r_decoder)  # [t, b, h1]    attention = tf.matmul(tf.reshape(r_attention, [-1, H1]), w_attention)    attention = tf.nn.softmax(tf.reshape(attention, [T, B]), dim=0)    #attention = tf.nn.sigmoid(tf.reshape(attention, [T, B]))    encoding = tf.transpose(encoding, perm=[2, 0, 1])  # [t, b, h1]->[h1, t, b]    context = tf.reduce_sum(encoding * attention, axis=1)  # [h1, b]    return tf.transpose(context)  # [b, h1]def rnn_attention_decoder_test():    encoding = tf.get_variable(name='encoding', shape=[T, B, H], dtype=tf.float32)    rnn_outputs = []  # t * [b, h]    scope = tf.get_variable_scope()    zero_input = tf.constant(0, shape=[B, H], dtype=tf.float32)    cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.GRUCell(H) for i in range(layer_num)], state_is_tuple=True)    state = cell.zero_state(B, tf.float32)    with tf.variable_scope(scope) as outer_scope:        for t in range(T):#T):            attention_input = zero_input            rnn_input = apply_attention(encoding, attention_input)            rnn_output, state = cell(rnn_input, state)            rnn_outputs.append(rnn_output)            outer_scope.reuse_variables()    return tf.stack(rnn_outputs, axis=1), state  # t * [b, h] -> [b, t, h]with tf.Session() as sess, tf.variable_scope('model'):    with tf.variable_scope('model', reuse=None):        tensor_lists_test = rnn_attention_decoder_test()    init_op = tf.group(        tf.global_variables_initializer(),        tf.local_variables_initializer()    )    sess.run(init_op)    sess.graph.finalize()    for step in range(100000):        after = process.memory_percent()        if step > 0:            print("MEMORY CHANGE %.7f -> %.7f" % (before, after))        before = process.memory_percent()        sess.run(tensor_lists_test)        gc.collect()log:2017-05-09 09:27:55.435870: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.2017-05-09 09:27:55.435903: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.2017-05-09 09:27:55.435909: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.2017-05-09 09:27:55.435913: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.2017-05-09 09:27:55.435916: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.2017-05-09 09:27:55.732204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: name: GeForce GTX TITAN Xmajor: 5 minor: 2 memoryClockRate (GHz) 1.2405pciBusID 0000:09:00.0Total memory: 11.92GiBFree memory: 11.81GiB2017-05-09 09:27:55.732232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 2017-05-09 09:27:55.732238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y 2017-05-09 09:27:55.732247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:09:00.0)MEMORY CHANGE 1.1297021 -> 1.3666840MEMORY CHANGE 1.3666840 -> 1.3666840MEMORY CHANGE 1.3666840 -> 1.3697929MEMORY CHANGE 1.3697929 -> 1.3697929MEMORY CHANGE 1.3697929 -> 1.3729200MEMORY CHANGE 1.3729200 -> 1.3733208MEMORY CHANGE 1.3733208 -> 1.3733208MEMORY CHANGE 1.3733208 -> 1.3737215MEMORY CHANGE 1.3737215 -> 1.3768487MEMORY CHANGE 1.3768487 -> 1.3799758MEMORY CHANGE 1.3799758 -> 1.3803644MEMORY CHANGE 1.3803644 -> 1.3834976MEMORY CHANGE 1.3834976 -> 1.3834976MEMORY CHANGE 1.3834976 -> 1.3838862MEMORY CHANGE 1.3838862 -> 1.3838862MEMORY CHANGE 1.3838862 -> 1.3842870MEMORY CHANGE 1.3842870 -> 1.3846878MEMORY CHANGE 1.3846878 -> 1.3850885MEMORY CHANGE 1.3850885 -> 1.3850885MEMORY CHANGE 1.3850885 -> 1.3850885MEMORY CHANGE 1.3850885 -> 1.3850885MEMORY CHANGE 1.3850885 -> 1.3850885MEMORY CHANGE 1.3850885 -> 1.3854771MEMORY CHANGE 1.3854771 -> 1.3854771MEMORY CHANGE 1.3854771 -> 1.3854771MEMORY CHANGE 1.3854771 -> 1.3858779MEMORY CHANGE 1.3858779 -> 1.3858779MEMORY CHANGE 1.3858779 -> 1.3858779MEMORY CHANGE 1.3858779 -> 1.3858779MEMORY CHANGE 1.3858779 -> 1.3858779MEMORY CHANGE 1.3858779 -> 1.3858779MEMORY CHANGE 1.3858779 -> 1.3862665MEMORY CHANGE 1.3862665 -> 1.3866673MEMORY CHANGE 1.3866673 -> 1.3866673MEMORY CHANGE 1.3866673 -> 1.3870680MEMORY CHANGE 1.3870680 -> 1.3870680MEMORY CHANGE 1.3870680 -> 1.3870680MEMORY CHANGE 1.3870680 -> 1.3870680MEMORY CHANGE 1.3870680 -> 1.3870680MEMORY CHANGE 1.3870680 -> 1.3870680MEMORY CHANGE 1.3870680 -> 1.3870680MEMORY CHANGE 1.3870680 -> 1.3874688MEMORY CHANGE 1.3874688 -> 1.3874688MEMORY CHANGE 1.3874688 -> 1.3878695MEMORY CHANGE 1.3878695 -> 1.3878695MEMORY CHANGE 1.3878695 -> 1.3882581MEMORY CHANGE 1.3882581 -> 1.3882581MEMORY CHANGE 1.3882581 -> 1.3886589MEMORY CHANGE 1.3886589 -> 1.3886589MEMORY CHANGE 1.3886589 -> 1.3890597MEMORY CHANGE 1.3890597 -> 1.3894604MEMORY CHANGE 1.3894604 -> 1.3894604MEMORY CHANGE 1.3894604 -> 1.3898612MEMORY CHANGE 1.3898612 -> 1.3898612MEMORY CHANGE 1.3898612 -> 1.3902619MEMORY CHANGE 1.3902619 -> 1.3906627MEMORY CHANGE 1.3906627 -> 1.3906627MEMORY CHANGE 1.3906627 -> 1.3906627MEMORY CHANGE 1.3906627 -> 1.3906627MEMORY CHANGE 1.3906627 -> 1.3906627MEMORY CHANGE 1.3906627 -> 1.3906627MEMORY CHANGE 1.3906627 -> 1.3906627MEMORY CHANGE 1.3906627 -> 1.3906627MEMORY CHANGE 1.3906627 -> 1.3937898MEMORY CHANGE 1.3937898 -> 1.3937898MEMORY CHANGE 1.3937898 -> 1.3937898MEMORY CHANGE 1.3937898 -> 1.3937898MEMORY CHANGE 1.3937898 -> 1.3937898MEMORY CHANGE 1.3937898 -> 1.3937898MEMORY CHANGE 1.3937898 -> 1.3937898MEMORY CHANGE 1.3937898 -> 1.3937898MEMORY CHANGE 1.3937898 -> 1.3941906MEMORY CHANGE 1.3941906 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3945913MEMORY CHANGE 1.3945913 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3949921MEMORY CHANGE 1.3949921 -> 1.3953929MEMORY CHANGE 1.3953929 -> 1.3953929MEMORY CHANGE 1.3953929 -> 1.3953929MEMORY CHANGE 1.3953929 -> 1.3953929MEMORY CHANGE 1.3953929 -> 1.3953929MEMORY CHANGE 1.3953929 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3957936MEMORY CHANGE 1.3957936 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3961944MEMORY CHANGE 1.3961944 -> 1.3965951MEMORY CHANGE 1.3965951 -> 1.3965951MEMORY CHANGE 1.3965951 -> 1.3965951MEMORY CHANGE 1.3965951 -> 1.3969959MEMORY CHANGE 1.3969959 -> 1.3969959MEMORY CHANGE 1.3969959 -> 1.3969959MEMORY CHANGE 1.3969959 -> 1.3969959MEMORY CHANGE 1.3969959 -> 1.3969959MEMORY CHANGE 1.3969959 -> 1.3969959MEMORY CHANGE 1.3969959 -> 1.3969959MEMORY CHANGE 1.3969959 -> 1.3969959MEMORY CHANGE 1.3969959 -> 1.3973967MEMORY CHANGE 1.3973967 -> 1.3973967MEMORY CHANGE 1.3973967 -> 1.3973967MEMORY CHANGE 1.3973967 -> 1.3973967MEMORY CHANGE 1.3973967 -> 1.3977974MEMORY CHANGE 1.3977974 -> 1.3977974
performance	how to get image shape after decode in C++System informationOS Platform and Distribution: DebianTensorFlow installed from (source or binary): sourceTensorFlow version (use command below): 1.0.1Bazel version (if compiling from source): 0.4.5CUDA/cuDNN version: cuda-8.0, cudnn5.1.5GPU model and memory: 12GBI follow the tutorial of inception label_image,source codes ,README.md , I can compile and run the demo c++ code successfully.I want to adapt this demo to my own project, the input images to my own Network is height fixed, while width varies accordingly, for example, the original image is size of 64x100, and I want to resize it to 32x50, as I said 32 is the new_height, and I want to know original image size after reading from the file, how can I get width=100 and height=64? then I can get new_width = new_height/height x width=32/64x100=50the following is a small piece of the image_recognition tutorial C++ codes, resize is hard coded to a pre-define size, I try float_caster.shape(), tensor(), float_caster.dimension(0), etc, all failed(float_caster, file_reader are all not Tensor, I don't know why Google design like this, really slow down the development, and I find no documentation about this), is there any easy way to get the image size? or cast the tensorflow::Ouput type to Tensor?one possible way is first use opencv to load the image, and resize it, then copy the elements to tensor like this example pixel by pixel, but the performance is the main problem and it seems hard to compile tensorflow along with opencv.  Any one knows some methods using tensorflow's API?Thanks in advance!// Given an image file name, read in the data, try to decode it as an image,// resize it to the requested size, and then scale the values as desired.Status ReadTensorFromImageFile(string file_name, const int input_height,                               const int input_width, const float input_mean,                               const float input_std,                               std::vector<Tensor>* out_tensors) {  auto root = tensorflow::Scope::NewRootScope();  using namespace ::tensorflow::ops;  // NOLINT(build/namespaces)  string input_name = "file_reader";  string output_name = "normalized";  auto file_reader =      tensorflow::ops::ReadFile(root.WithOpName(input_name), file_name);  // Now try to figure out what kind of file it is and decode it.  const int wanted_channels = 3;  tensorflow::Output image_reader;  if (tensorflow::StringPiece(file_name).ends_with(".png")) {    image_reader = DecodePng(root.WithOpName("png_reader"), file_reader,                             DecodePng::Channels(wanted_channels));  } else if (tensorflow::StringPiece(file_name).ends_with(".gif")) {    image_reader = DecodeGif(root.WithOpName("gif_reader"), file_reader);  } else {    // Assume if it's neither a PNG nor a GIF then it must be a JPEG.    image_reader = DecodeJpeg(root.WithOpName("jpeg_reader"), file_reader,                              DecodeJpeg::Channels(wanted_channels));  }  // Now cast the image data to float so we can do normal math on it.  auto float_caster =      Cast(root.WithOpName("float_caster"), image_reader, tensorflow::DT_FLOAT);  // The convention for image ops in TensorFlow is that all images are expected  // to be in batches, so that they're four-dimensional arrays with indices of  // [batch, height, width, channel]. Because we only have a single image, we  // have to add a batch dimension of 1 to the start with ExpandDims().  auto dims_expander = ExpandDims(root, float_caster, 0);  // Bilinearly resize the image to fit the required dimensions.  auto resized = ResizeBilinear(      root, dims_expander,      Const(root.WithOpName("size"), {input_height, input_width}));  // Subtract the mean and divide by the scale.  Div(root.WithOpName(output_name), Sub(root, resized, {input_mean}),      {input_std});  // This runs the GraphDef network definition that we've just constructed, and  // returns the results in the output tensor.  tensorflow::GraphDef graph;  TF_RETURN_IF_ERROR(root.ToGraphDef(&graph));  std::unique_ptr<tensorflow::Session> session(      tensorflow::NewSession(tensorflow::SessionOptions()));  TF_RETURN_IF_ERROR(session->Create(graph));  TF_RETURN_IF_ERROR(session->Run({}, {output_name}, {}, out_tensors));  return Status::OK();}
performance	Bijector caching breaks when used with TransformedDistributionCurrently, the caching that Bijector objects do to avoid unnecessary calculations does not work when the bijector is used in a TransformedDistribution object. I believe the culprit is the reshaping that the distribution object does here; when we call Bijector.inverse on the output, the Bijector object cannot tell that this is merely a reshaped version of what it calculated previously.My use case is to sample from a TransformedDistribution and then later calculate the log probability of that sample.This issue is particularly a problem when using a bijector whose inverse is numerically delicate (in my case, I'm chaining together softplus bijectors and my own custom affine bijector).I'm willing to work on a fix for this problem, but I'm not sure what the best way to do it is (adding caching to the TransformedDistribution code might work, but that seems like code duplication).System informationOS Platform and Distribution: Ubuntu 16.04TensorFlow installed from: SourceTensorFlow version: v1.1.0-rc2-773-g7fa0cf3 (commit 7fa0cf3)Bazel version: 0.4.5
performance	Bug of CPU detection?System informationLinux 4.9.0-kali4-686-pae #1 SMP Debian 4.9.25-1kali1 (2017-05-04) i686 GNU/LinuxTensorFlow installed from source codeTensorFlow version : 1.0.1Bazel version : 0.4.2CUDA/cuDNN version: NoneGPU model and memory: None== cat /etc/issue ===============================================Linux 4.9.0-kali4-686-pae #1 SMP Debian 4.9.25-1kali1 (2017-05-04) i686 GNU/LinuxVERSION="2017.1"VERSION_ID="2017.1"== are we in docker =============================================No== compiler =====================================================c++ (Debian 6.3.0-16) 6.3.0 20170425Copyright (C) 2016 Free Software Foundation, Inc.This is free software; see the source for copying conditions.  There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.== uname -a =====================================================Linux 4.9.0-kali4-686-pae #1 SMP Debian 4.9.25-1kali1 (2017-05-04) i686 GNU/Linux== check pips ===================================================numpy (1.12.1)== check for virtualenv =========================================False== tensorflow import ============================================Traceback (most recent call last):File "", line 1, in File "tensorflow/init.py", line 24, in from tensorflow.python import *File "tensorflow/python/init.py", line 72, in raise ImportError(msg)ImportError: Traceback (most recent call last):File "tensorflow/python/init.py", line 61, in from tensorflow.python import pywrap_tensorflowImportError: cannot import name pywrap_tensorflowFailed to load the native TensorFlow runtime.See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_errorfor some common reasons and solutions.  Include the entire stack traceabove this error message when asking for help.== env ==========================================================LD_LIBRARY_PATH is unsetDYLD_LIBRARY_PATH is unset== nvidia-smi ===================================================== cuda libs  ===================================================Describe the problemI compiled it from source,  and got this fatal error when try to import tensorflow in python3.5.3:Python 3.5.3 (default, Jan 19 2017, 14:11:04)[GCC 6.3.0 20170118] on linuxType "help", "copyright", "credits" or "license" for more information.>>> import tensorflowF tensorflow/core/platform/cpu_feature_guard.cc:35] The TensorFlow library was compiled to use SSE instructions, but these aren't available on your machine.AbortedAnd here is the information of my CPU:.......processor    : 3vendor_id    : GenuineIntelcpu family    : 6model        : 37model name    : Intel(R) Core(TM) i3 CPU       M 370  @ 2.40GHzstepping    : 5microcode    : 0x4cpu MHz        : 933.000cache size    : 3072 KBphysical id    : 0siblings    : 4core id        : 2cpu cores    : 2apicid        : 5initial apicid    : 5fdiv_bug    : nof00f_bug    : nocoma_bug    : nofpu        : yesfpu_exception    : yescpuid level    : 11wp        : yesflags        : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe nx rdtscp lm constant_tsc arch_perfmon pebs bts xtopology nonstop_tsc aperfmperf eagerfpu pni dtes64 monitor ds_cpl vmx est tm2 ssse3 cx16 xtpr pdcm pcid sse4_1 sse4_2 popcnt lahf_lm tpr_shadow vnmi flexpriority ept vpid dtherm aratbugs        :bogomips    : 4787.91clflush size    : 64cache_alignment    : 64address sizes    : 36 bits physical, 48 bits virtual......that's all.
performance	Tensorflow consumes much more memory than expectedMy model has four CPU variables:[500M, 3] tf.int32[500M] tf.float32[500M] tf.float32 (FTRL accumulate slot)[500M] tf.float32 (FTRL linear slot)expected memory consumption should be (500M * 6) * 4 = 12G, however tensorflow used 20G memory.When I increased 500M to 1B, total memory usage is 40G, seems tensorflow do allocate much more memory than needed, any idea? By the way I am not using any tcmalloc stuff.I also used timeline show_memory to print allocated tensor size, everything is consistent with my calculating.
performance	C API ExceptionHi,The C API method "TF_GraphGetTensorNumDims" throws an exception with message "Node X was not found in the graph" even for valid nodes that are in the graph. This tends to happen with the outputs of particular ops (e.g., reshape and matmul). I think it may have to do with shape inference after looking at the C API implementation but I'm not sure what's wrong. Is there something I need to do to enable shape inference when compiling the shared library? I thought that was enabled by default. Or is there something else that's broken?Thank you,Anthony
performance	TensorBoard --logdir=c:\foo supportSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):no.  I am working with the full example to get the tensorboard to work.  I changed the file directory for the logs into something on my system:train_writer = tf.summary.FileWriter('D:/logs_dt' + '/train', sess.graph)test_writer = tf.summary.FileWriter('D:/logs_dt' + '/test')OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Window 10TensorFlow installed from (source or binary):binary with GPUTensorFlow version (use command below):1.1.0Bazel version (if compiling from source):n/aCUDA/cuDNN version:CUDA 8.0cuDNN v5 for CUDA 8.0 (27 May 2016)GPU model and memory:NVIDIA GTX 1070 4GBExact command to reproduce:from windows cmd:tensorboard --logdir='D:\logs_dt'You can collect some of this information using our environment capture script:tf_env.txtpython1.1.0Describe the problemI'm not seeing anything on the tensorboard at all.  I can see where the log director(ies) is/are created by the tutorial script, and the subdirectories /test and /train are there with the event data present.  I point the tensorboard to the populated log directory with the following command,  but it cannot see the event files.  Nothing is present in tensorboard, and I'm redirected back to the tutorials.tensorboard --logdir='D:\logs_dt'Source code / logstensor_board_hello.ziplogs_dt.zip
performance	Unexpected error at contrib.seq2seq's BeamSearchDecoderSystem informationOS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOSTensorFlow installed from (source or binary): SourceTensorFlow version (use command below):  v1.1.0-rc2-773-g7fa0cf39fBazel version (if compiling from source):  0.4.5CUDA/cuDNN version:  NoneGPU model and memory: CPUDescribe the problemI encountered an unexpected error at tf.contrib.seq2seq's BeamSearchDecoder, when the beam width is smaller than number of vocabs.This is a part of _beam_search_step operation in beam_search_decoder.py:  scores = _get_scores(      log_probs=total_probs,      sequence_lengths=new_prediction_lengths,      length_penalty_weight=length_penalty_weight)  time = ops.convert_to_tensor(time, name="time")  # During the first time step we only consider the initial beam  scores_flat = control_flow_ops.cond(      time > 0,      lambda: array_ops.reshape(scores, [batch_size, -1]),      lambda: scores[:, 0])  # Pick the next beams according to the specified successors function  next_beam_scores, word_indices = nn_ops.top_k(scores_flat, k=beam_width)  next_beam_scores.set_shape([static_batch_size, beam_width])  word_indices.set_shape([static_batch_size, beam_width])Since the shape of scores is [batch_size, beam_width, vocab_size],  the shape of scores_flat is[batch_size, vocab_size] at time step 0. However, if k < shape[-1] in nn.top_k operation, it just throws InvalidArgumentError: input must have at least k columns. Thus the code just throws an error and dies.I think code should be modified to handle cases where vocab_size ** n < beam_width, or at least throw an appropriate error message when the input is vocab_size < beam_width.
performance	Function decode_raw ignoring parameter little_endian.little_endian parameter in decode_raw takes no effect. I had a look at the C++ source code (tensorflow/tensorflow/core/kernels/decode_raw_op.cc), you are just using reinterpret_cast without any awareness of this parameter.
performance	Exporting and loading models with crossed_columns gives errorsSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):yes, see belowOS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu 16.04TensorFlow installed from (source or binary):binaryTensorFlow version (use command below):1.1.0Describe the problemI trained a LinearClassifier that includes a crossed_column. When I export it and then load and run it again I get an error message: "ValueError: No op named SparseFeatureCross in defined operations".Source code / logsTo train and export the model I used the following python script:import tensorflow as tffrom tensorflow.contrib.learn.python.learn.utils import input_fn_utilsdef input_fn():    features = {'a': tf.constant([[1],[2]]),                'b': tf.constant([[3],[4]]) }    labels = tf.constant([0, 1])    return features, labelsfeature_a = tf.contrib.layers.sparse_column_with_integerized_feature("a", bucket_size=10)feature_b = tf.contrib.layers.sparse_column_with_integerized_feature("b", bucket_size=10)feature_c = tf.contrib.layers.crossed_column([feature_a, feature_b], hash_bucket_size=100)feature_columns = [feature_a, feature_b, feature_c]model = tf.contrib.learn.LinearClassifier(feature_columns=feature_columns)model.fit(input_fn=input_fn, steps=10)feature_spec = tf.contrib.layers.create_feature_spec_for_parsing(feature_columns)serving_input_fn = input_fn_utils.build_parsing_serving_input_fn(feature_spec)model.export_savedmodel('simple-cross/export', serving_input_fn)To load and run the model I used the following python script:import tensorflow as tfdef _int_feature(value):  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))with tf.Session() as session:    model = tf.saved_model.loader.load(session, ['serve'], "simple-cross/export/1494601566/")    probs = tf.get_default_graph().get_tensor_by_name('linear/binary_logistic_head/predictions/probabilities:0')    feature_dict = {'a': _int_feature(value=0),                    'b': _int_feature(value=5)}    example = tf.train.Example(features=tf.train.Features(feature=feature_dict)).SerializeToString()    feed_dict = { 'input_example_tensor:0' : [example] }    print(session.run(probs, feed_dict=feed_dict))(BTW: is this the best way to import/run a saved model? It feels like plugging in constants like linear/binary_logistic_head/predictions/probabilities:0 isn't the way to go.)This results in the following error:ValueError: No op named SparseFeatureCross in defined operations.NotesWhen I add the importfrom tensorflow.contrib.learn.python.learn.utils import input_fn_utilsto the load/run script, it magically works.Unfortunately, I like to run the model from Java as well, and in Java there is no analogous workaround AFAIK (input_fn_utils doesn't exist there).
performance	Bug in census_widendeep.py downloading of test dataSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): noOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04TensorFlow installed from (source or binary): nightly buildsTensorFlow version (use command below): 1.1.0-rc2Describe the problemThere seems to be an error in the downloading of the test data in the distributed training example census_widendeep.py. The test data is loaded from the file before the file is actually downloaded (lines 152-153):test_file = open(test_file_path)urllib.urlretrieve(test_data_url, test_file_path)
performance	MPI based communication path for tensor exchange operationsThis pull request adds an additional communication path to TensorFlow that allows Tensors to be exchanged using MPI based Send and Recieve routines when running distributed TensorFlow. TThe used MPI implementation will pick the most optimal path available between the two communication points allowing the user to take advantage of high performance networks such as Infiniband.Certain MPI implementations allow direct data-transfers from GPU buffers (CUDA Aware / GPUDirect RDMA), this option can be enabled using an environment variable. See the README for more details.Note: Be aware of the known problems that results in unpredictable behavior for certain complex networks. Any help/insight on that from other MPI experts would be appreciated.
performance	distributed runtime leaking memory on windowsSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): noOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10TensorFlow installed from (source or binary): binaryTensorFlow version (use command below): b'unknown' 1.1.0Bazel version (if compiling from source):CUDA/cuDNN version:GPU model and memory:Exact command to reproduce: follow https://www.tensorflow.org/deploy/distributedDescribe the problemThe memory footprint for parameter server keep growing.The cause is a memory leak in a windows specific path in grpc which is fixed here:grpc/grpc@fa242cbI filed the issue issue so others don't need to spend the time debugging it and as reason to update the grpc version.
performance	XLA "Aborted (core dumped)"OS: Ubuntu/Linux (16.04)TensorFlow: Compiled from sourceTensorFlow Version: r1.1Bazel Version: 0.4.5CUDA/CuDNN Versions: 8.0/5.1GPU Model/Memory: TitanX/12GbAfter turning on XLA JIT compiling, TF fails with a core dump.2017-05-14 14:50:38.673877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: name: TITAN X (Pascal)major: 6 minor: 1 memoryClockRate (GHz) 1.531pciBusID 0000:06:00.0Total memory: 11.90GiBFree memory: 11.75GiB2017-05-14 14:50:38.673951: W tensorflow/stream_executor/cuda/cuda_driver.cc:485] creating context when one is currently active; existing: 0x3cb69602017-05-14 14:50:38.900484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 1 with properties: name: TITAN X (Pascal)major: 6 minor: 1 memoryClockRate (GHz) 1.531pciBusID 0000:05:00.0Total memory: 11.90GiBFree memory: 11.67GiB2017-05-14 14:50:38.901416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 1 2017-05-14 14:50:38.901427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y Y 2017-05-14 14:50:38.901430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 1:   Y Y 2017-05-14 14:50:38.901437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:06:00.0)2017-05-14 14:50:38.901441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:1) -> (device: 1, name: TITAN X (Pascal), pci bus id: 0000:05:00.0)2017-05-14 14:50:38.979726: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 2 visible devices2017-05-14 14:50:38.979748: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 12 visible devices2017-05-14 14:50:38.981294: I tensorflow/compiler/xla/service/service.cc:183] XLA service 0x4a7a7b0 executing computations on platform Host. Devices:2017-05-14 14:50:38.981305: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (0): <undefined>, <undefined>2017-05-14 14:50:38.981438: I tensorflow/compiler/xla/service/platform_util.cc:58] platform CUDA present with 2 visible devices2017-05-14 14:50:38.981446: I tensorflow/compiler/xla/service/platform_util.cc:58] platform Host present with 12 visible devices2017-05-14 14:50:38.982608: I tensorflow/compiler/xla/service/service.cc:183] XLA service 0x4a42c80 executing computations on platform CUDA. Devices:2017-05-14 14:50:38.982619: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (0): TITAN X (Pascal), Compute Capability 6.12017-05-14 14:50:38.982623: I tensorflow/compiler/xla/service/service.cc:191]   StreamExecutor device (1): TITAN X (Pascal), Compute Capability 6.12017-05-14 14:51:53.443289: F tensorflow/compiler/xla/service/algebraic_simplifier.cc:768] Check failed: user->operand(reshape_or_broadcast_operand_index) == reshape_or_broadcast (0x7f30bc938e70 vs. 0x7f30bcb3e340)Aborted (core dumped)
performance	tf.gradients runtime scales suboptimally with size of the graphtf.gradients can be inefficient on large graphs and it runtime increases with size of the graph, even when the amount of work it needs to do is constant. This inefficiency is apparent when trying to differentiate small parts of large graph many times.Discovered when trying to scale to 8 GPUs using data parallelism using 8 identical copies of model -- time spent inside gradients grows for each new replica even though replicas are identical and independent. We are calling tf.gradients many times (calling tf.gradients on parts of model in order to do memory saving gradients trick), our largest models spend >2 hours inside tf.gradients.I've profiled the runs and saw that most of the time is spent inside_MarkReachedOps(from_ops, reached_ops) inside gradients_impl.pyIt's called as follows  reached_ops = [False] * (graph._last_id + 1)  for op in to_ops:    reached_ops[op._id] = TrueYou can see that it's using Python list initialized with the size of the entire graph so this initialization step would grow with size of the graph.Profile of the _MarkReachedOps when calling when calling tf gradients 560 times, with each gradient call adding 35 nodes on average, and total size of the graph being 200k nodesLine #      Hits         Time  Per Hit   % Time  Line Contents==============================================================   101                                           @profile   102                                           def _MarkReachedOps(from_ops, reached_ops):   103                                             """Mark all ops reached from "from_ops".   104                                              105                                             Args:   106                                               from_ops: list of Operations.   107                                               reached_ops: list of booleans, indexed by operation id.   108                                             """   109       568         1967      3.5      0.0    queue = collections.deque()   110       568         4835      8.5      0.0    queue.extend(from_ops)   111  39912648     14661885      0.4      8.4    while queue:   112  39912080     17079278      0.4      9.8      op = queue.popleft()   113  39912080     41203709      1.0     23.7      if not reached_ops[op._id]:   114  28997056     21267924      0.7     12.2        reached_ops[op._id] = True   115  58483932     42196549      0.7     24.2        for output in op.outputs:   116  29486876     37595214      1.3     21.6          queue.extend(output.consumers())Possible solutions could be a more efficient implementation of _PendingCount, or a different algorithm for tf.gradients which is more efficient for large graphs
performance	Session#run method's feed_dict argument implicitly converts typesSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes?OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.12.3TensorFlow installed from (source or binary): binaryTensorFlow version (use command below): 1.1.0Bazel version (if compiling from source): NACUDA/cuDNN version: NoneGPU model and memory: NoneExact command to reproduce: (see below)Describe the problemHi TensorFlow humans! Thanks so much for making TensorFlow!Right now, if you feed a floating point array into a integral placeholder type, it will be converted implicitly. To my knowledge, most python operations will not implicitly convert.The implicit conversion potentially creates convenience, but of course it also creates the opportunity for a hard-to-see bug. In my case, I lost about 1 day to find this bug and experienced great sadness. That probably says more about me than it does about TF.Still, my feeling is that it is a more sensible default to require the user to do the conversion explicitly. Alternatively, perhaps it would be logical to log a warning to the user.Note that, to my knowledge, TF operations like tf.equal require both tensors to have the same type. So users might have a belief that that TF and Session#run require them to be fairly explicit about types.If it would be likely to be accepted, I am happy to write a patch for TF that warns the user when they feed a tensor of the wrong type.Thanks for reading this issue!Source code / logsimport numpy as npimport tensorflow as tfsession = tf.Session()convert_implicitly = tf.placeholder(tf.int64, [None])float_input = np.random.uniform(size = 10)result = session.run(    convert_implicitly,    feed_dict = { convert_implicitly: float_input })print(result)Output>> python test.py2017-05-14 18:20:22.524862: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.2017-05-14 18:20:22.524890: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.2017-05-14 18:20:22.524906: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine andcould speed up CPU computations.[0 0 0 0 0 0 0 0 0 0]
performance	graph_editor copy_with_input_replacements doesn't update colocation constraintsIt seems if you try to use graph_editor to make copy of a model to place on another device, the new graph will still refer to old version inside colocation constraints.This causes errors like below when trying to run resulting graph.tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot colocate nodes 'gradients/Max_1_1_grad/mul' and 'gradients/AddN_13: Cannot merge devices with incompatible ids: '/GPU:0' and '/GPU:1'More natural might be to update colocation constraints to point to newly created copies of ops.Test case  import tensorflow.contrib.graph_editor as ge  tf.reset_default_graph()  with tf.device('/cpu:0'):    a = tf.ones((), name='a')    with tf.get_default_graph().colocate_with(a):      b = tf.add(a, 1, name='b')  g = tf.get_default_graph()  ops = g.get_operations()  copied_sgv, info = ge.copy_with_input_replacements(ge.sgv(ops),                                                       {})  print(tf.get_default_graph().as_graph_def())You will see that newly created b_1 op will refer to old op anode {  name: "b/y_1"  op: "Const"  device: "/device:CPU:0"  attr {    key: "_class"    value {      list {        s: "loc:@a"      }    }  }@purpledog
performance	Go: SIGSEGV when using int32 instead of int64 and missing error in Resize functionsProblemIn Go, some operation causes a SIGSEGV when using an int32 instead of an int64 (and I have reasons to believe that the same will happen when using float instead of double and vice-versa).The Resize* operations don't define the output shape correctly when the input is not a "batch": they just let the dimensions undefined instead of raising some errors.The tests below are commented so I hope that's enough to let you understand what the problems are.Source code / logspackage poc_testimport (        "fmt"        //tf "github.com/tensorflow/tensorflow/tensorflow/go"        "github.com/tensorflow/tensorflow/tensorflow/go/op"        "testing")func TestResizeWithoutBatchIsNoSense(t *testing.T) {        // Create root scope        root := op.NewScope()        // Define graph        // 1: read image content        imagePath := "test.jpg"        contents := op.ReadFile(root.SubScope("ReadFile"), op.Const(root.SubScope("filename"), imagePath))        // 2: decode Jpeg        value := op.DecodeJpeg(root.SubScope("DecodeJpeg"), contents, op.DecodeJpegChannels(3))        // I'd like to add noise to the image, so I'd like to define a nose tensor with the same shape of the image        // Just to be sure that the image shape is fully defined, I resize it        resize1 := op.ResizeNearestNeighbor(root.SubScope("ResizeArea"), value, op.Const(root.SubScope("size"), []int32{int32(80), int32(80)}))        // If the size parameter is an int32, no error is raised but the operation is no sense        // Because it returns ? instead of [80, 80, 3]        // The reason is taht Resize* methods requires a batch of images: should raise an error?        fmt.Println("Shape with int32: ", resize1.Shape().String())        if dims64, err := resize1.Shape().ToSlice(); err != nil {                                                                                                                                                                                                                              fmt.Println(dims64)                                                                                                                                                                                                                                                    } else {                                                                                                                                                                                                                                                                               t.Error("Error: ", err.Error())                                                                                                                                                                                                                                        }                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             // I expect a fully defined shape                                                                                                                                                                                                                                              if !resize1.Shape().IsFullySpecified() {                                                                                                                                                                                                                                               t.Error("Not defined shape")                                                                                                                                                                                                                                           }                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             // create the batch and see how things changes                                                                                                                                                                                                                                 batch := op.ExpandDims(root.SubScope("expand"), value, op.Const(root.SubScope("axis"), []int32{0}))                                                                                                                                                                            resize1 = op.ResizeNearestNeighbor(root.SubScope("ResizeArea"), batch, op.Const(root.SubScope("size"), []int32{int32(80), int32(80)}))                                                                                                                                         fmt.Println("Shape with int32 and input as a batch: ", resize1.Shape().String())                                                                                                                                                                                               if dims64, err := resize1.Shape().ToSlice(); err == nil {                                                                                                                                                                                                                              fmt.Println(dims64)                                                                                                                                                                                                                                                    } else {                                                                                                                                                                                                                                                                               fmt.Println("Error: ", err.Error())                                                                                                                                                                                                                                    }                                                                                                                                                                                                                                                                              // Now the things have sense and the shape is defined and equals to [ 1, 80, 80, 3]                                                                                                                                                                                    }                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             func TestResizeWithIn64ShapeSigSegvs(t *testing.T) {                                                                                                                                                                                                                                   defer func() {                                                                                                                                                                                                                                                                         if r := recover(); r != nil {                                                                                                                                                                                                                                                          t.Error("Panic!")                                                                                                                                                                                                                                                      }                                                                                                                                                                                                                                                                      }()        // Create root scope        root := op.NewScope()        // Define graph        // 1: read image content        imagePath := "test.jpg"        contents := op.ReadFile(root.SubScope("ReadFile"), op.Const(root.SubScope("filename"), imagePath))        // 2: decode Jpeg        value := op.DecodeJpeg(root.SubScope("DecodeJpeg"), contents, op.DecodeJpegChannels(3))        // However, changing int32 with int64 breaks everyting (no matter if I use `batch` or `value`)        resize2 := op.ResizeArea(root.SubScope("ResizeArea2"), value, op.Const(root.SubScope("size2"), []int64{int64(80), int64(80)}))        // This operation causes a SIGSEGV        fmt.Println("Shape value: ", resize2.Shape())        fmt.Println("Shape with int64: ", resize2.Shape().String())        // In short, chaning int32 with int64 causes SIGSEGV. It looks like kernels are not registered to handle both types        // This can bring the code to be a mess to debug, because If I'd like to, for example, add noise to an image        // I have to generate a set of values with the same shape of the input images.        // Using the one with the defined shape (the batch) I'd like to use the output of Shape().ToSlice()        // But I can't.}func TestGenerateNoiseWithInt32Shape(t *testing.T) {        defer func() {                if r := recover(); r != nil {                        t.Error("Panic!")                }        }()        // Create root scope        root := op.NewScope()        // Define graph        // 1: read image content        imagePath := "test.jpg"        contents := op.ReadFile(root.SubScope("ReadFile"), op.Const(root.SubScope("filename"), imagePath))        // 2: decode Jpeg        value := op.DecodeJpeg(root.SubScope("DecodeJpeg"), contents, op.DecodeJpegChannels(3))        batch := op.ExpandDims(root.SubScope("expand"), value, op.Const(root.SubScope("axis"), []int32{0}))        resize1 := op.ResizeNearestNeighbor(root.SubScope("ResizeArea"), batch, op.Const(root.SubScope("size"), []int32{int32(80), int32(80)}))        fmt.Println("Shape with int32 and input as a batch: ", resize1.Shape().String())        if dims64, err := resize1.Shape().ToSlice(); err != nil {                fmt.Println(dims64)        } else {                fmt.Println("Error: ", err.Error())        }        dims64, _ := resize1.Shape().ToSlice()        noise := op.ParameterizedTruncatedNormal(root.SubScope("ParameterizedTruncatedNormal"),                op.Const(root.SubScope("shape"), dims64),                op.Const(root.SubScope("means"), 0.),                op.Const(root.SubScope("stddev"), 1.),                op.Const(root.SubScope("minvals"), 0.),                op.Const(root.SubScope("maxvals"), 1.))        fmt.Println(noise)        // ^ This operation causes SIGSEGV        // I have to convert dims64 to a slice of int32 and then the operation works}func TestGenerateNoiseWithInt64Shape(t *testing.T) {        // Create root scope        root := op.NewScope()        // Define graph        // 1: read image content        imagePath := "test.jpg"        contents := op.ReadFile(root.SubScope("ReadFile"), op.Const(root.SubScope("filename"), imagePath))        // 2: decode Jpeg        value := op.DecodeJpeg(root.SubScope("DecodeJpeg"), contents, op.DecodeJpegChannels(3))        batch := op.ExpandDims(root.SubScope("expand"), value, op.Const(root.SubScope("axis"), []int32{0}))        resize1 := op.ResizeNearestNeighbor(root.SubScope("ResizeArea"), batch, op.Const(root.SubScope("size"), []int32{int32(80), int32(80)}))        fmt.Println("Shape with int32 and input as a batch: ", resize1.Shape().String())        if dims64, err := resize1.Shape().ToSlice(); err != nil {                fmt.Println(dims64)        } else {                fmt.Println("Error: ", err.Error())        }        dims64, _ := resize1.Shape().ToSlice()        var dims []int32 = make([]int32, len(dims64))        for i, dim := range dims64 {                dims[i] = int32(dim)        }        noise := op.ParameterizedTruncatedNormal(root.SubScope("ParameterizedTruncatedNormal"),                op.Const(root.SubScope("shape"), dims64),                op.Const(root.SubScope("means"), 0.),                op.Const(root.SubScope("stddev"), 1.),                op.Const(root.SubScope("minvals"), 0.),                op.Const(root.SubScope("maxvals"), 1.))        fmt.Println(noise.Shape().String())}System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): yesOS Platform and Distribution (e.g., Linux Ubuntu 16.04): ArchlinuxTensorFlow installed from (source or binary): sourceTensorFlow version (use command below): 1.1.0-rc2Bazel version (if compiling from source): 0.4.5CUDA/cuDNN version: cuda 8, cudnn 5.1GPU model and memory:  GeForce GTX 1080Exact command to reproduce: go test
performance	Incorrect Timing Stats Reported by tfprofSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): I have added profiling code as shown below to the cifar10 code ([https://github.com/tensorflow/models/tree/master/tutorials/image/cifar10]).OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04TensorFlow installed from (source or binary): SourceTensorFlow version (use command below): ('v1.1.0-rc2-773-g7fa0cf3', '1.1.0-rc2')Bazel version (if compiling from source):CUDA/cuDNN version:8.0/6.0GPU model and memory:NVIDIA Quadra K1200 4GBDescribe the problemWhile doing profiling by tfprof I get the following statsTiming and Memoryconv1/weights (19.20KB/76.80KB, 8us/18us)conv1/weights/ExponentialMovingAverage (19.20KB/38.40KB, 6us/8us)conv1/weights/ExponentialMovingAverage/read (19.20KB/19.20KB, 2us/2us)conv1/weights/read (19.20KB/19.20KB, 2us/2us)conv2/BiasAdd (4.72MB/4.72MB, 225us/225us)conv2/Conv2D (4.72MB/4.72MB, 2.34ms/2.34ms)conv2/L2Loss (4B/4B, 21us/21us)conv2/biases (256B/1.02KB, 8us/58us)conv2/biases/ExponentialMovingAverage (256B/512B, 7us/49us)conv2/biases/ExponentialMovingAverage/read (256B/256B, 42us/42us)Floating Point Operations_TFProfRoot (0/5.23b flops)conv2/Conv2D (3.77b/3.77b flops)conv1/Conv2D (707.79m/707.79m flops)gradients/local3/MatMul_grad/MatMul (226.49m/226.49m flops)gradients/local3/MatMul_grad/MatMul_1 (226.49m/226.49m flops)local3/MatMul (226.49m/226.49m flops)gradients/local4/MatMul_grad/MatMul (18.87m/18.87m flops)gradients/local4/MatMul_grad/MatMul_1 (18.87m/18.87m flops)local4/MatMul (18.87m/18.87m flops)conv1/BiasAdd (4.72m/4.72m flops)conv2/BiasAdd (1.18m/1.18m flops)gradients/softmax_linear/MatMul_grad/MatMul (491.52k/491.52k flops)gradients/softmax_linear/MatMul_grad/MatMul_1 (491.52k/491.52k flops)softmax_linear/MatMul (491.52k/491.52k flops)Computing Floating Point Performance for Conv2D operation gives surprising results: It comes out to be 3.77b/2.34ms = 1618 GFLOPS which is more than the manufacturer prescribed peak performance of 1052 GFLOPS. The timing stats seem to be wrong. This is impossible.Source code / logs run_metadata = tf.RunMetadata()    with tf.train.MonitoredTrainingSession(        checkpoint_dir=FLAGS.train_dir,        hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),               tf.train.NanTensorHook(loss),               _LoggerHook()],        config=tf.ConfigProto(            log_device_placement=FLAGS.log_device_placement,             graph_options=tf.GraphOptions(build_cost_model=1))) as mon_sess:      while not mon_sess.should_stop():        #Disable Profiling         # mon_sess.run(train_op)        #Enable Profiling         mon_sess.run(train_op, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),         run_metadata=run_metadata)        analysis = tf.contrib.tfprof.model_analyzer.print_model_analysis(        tf.get_default_graph(),        run_meta=run_metadata,        tfprof_options=tf.contrib.tfprof.model_analyzer.PRINT_ALL_TIMING_MEMORY)``
performance	contrib.layers.avg_pool2d raises warnings when serializing metagraphSystem informationOS Platform and Distribution: Ubuntu 14.04 LTSTensorFlow installed from: sourceTensorFlow version:  ('v1.1.0-rc2-1015-gf2047a3', '1.1.0-rc2')Bazel version: 0.4.5CUDA/cuDNN version: 8.0/5.1.5GPU model and memory: Maxwell Titan X (12 GiB)Overview of problemSince updating to the most recent version (as of yesterday) of TensorFlow, I've started seeing the following ominous warning when serializing a wide resnet variant that I've been using for acoustic modeling:WARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.Type is unsupported, or the types of the items don't match field type in CollectionDef.'dict' object has no attribute 'name'However, a metagraphdef does export and I am able to successfully use it to recreate the trained model. After playing around with simpler architectures, it looks like the problem comes from the average pooling I do at the end, which involves a call to tf.contrib.layers.avg_pool2d. For a trivial example that elicits this warning, please see the script athttps://gist.github.com/nryant/1f69cda71fd6a468fa5641855199f843
performance	Tensorboard 404 ErrorsSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N/AOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10TensorFlow installed from (source or binary): pipTensorFlow version (use command below): 1.1.0Bazel version (if compiling from source):CUDA/cuDNN version:5.1GPU model and memory:k40 12gbExact command to reproduce: launch tensorboardDescribe the problemTensorboard is 404'ing on a lot of resources. See the error messages below. I think I saw a similar issue somewhere so this may be a duplicate. You're probably aware but thought i'd file just in case.Source code / logsWARNING:tensorflow:path ../external\weblas_weblas_js/file/weblas.map.json not found, sending 404WARNING:tensorflow:path ../external\web_animations_js/web-animations-next-lite.min.js.map not found, sending 404WARNING:tensorflow:path ../external\weblas_weblas_js/file/weblas.map.json not found, sending 404WARNING:tensorflow:path ../external\web_animations_js/web-animations-next-lite.min.js.map not found, sending 404WARNING:tensorflow:path ../external\data/plugin/text/runs not found, sending 404WARNING:tensorflow:path ../external\data/plugin/text/runs not found, sending 404WARNING:tensorflow:path ../external\data/plugin/text/runs not found, sending 404WARNING:tensorflow:path ../external\data/plugin/text/runs not found, sending 404
performance	graph_editor.copy_with_input_replacements crashes for some orderings of inputsGraph editor copy_with_input_replacements  visits nodes in order provided, and assumes that op referenced by "op._original_op" has already already been visited. When this assumption is false, it fails with KeyError inside transform.pyReproducible caseimport tensorflow as tfimport numpy as npimport tensorflow.contrib.graph_editor as geif __name__=='__main__':  params = tf.Variable(1, dtype=np.float32, name="params")  temp = tf.reduce_sum(params, name="sum_temp")  cost1 = tf.square(temp, name="cost1")  gradients1 = tf.gradients([cost1], [params])  ops = tf.get_default_graph().get_operations()  ops = list(sorted(ops, key=lambda op: op.name))  copied_sgv, info = ge.copy_with_input_replacements(ge.sgv(ops), {})It fails with following errorTraceback (most recent call last):  File "graph_editor_test.py", line 13, in <module>    copied_sgv, info = ge.copy_with_input_replacements(ge.sgv(ops), {})  File "/Users/yaroslav/anaconda/envs/memory/lib/python3.5/site-packages/tensorflow/contrib/graph_editor/transform.py", line 620, in copy_with_input_replacements    sgv, dst_graph, dst_scope, src_scope, reuse_dst_scope=reuse_dst_scope)  File "/Users/yaroslav/anaconda/envs/memory/lib/python3.5/site-packages/tensorflow/contrib/graph_editor/transform.py", line 436, in __call__    self._copy_ops(info)  File "/Users/yaroslav/anaconda/envs/memory/lib/python3.5/site-packages/tensorflow/contrib/graph_editor/transform.py", line 450, in _copy_ops    op_, op_outputs_ = self.transform_op_handler(info, op)  File "/Users/yaroslav/anaconda/envs/memory/lib/python3.5/site-packages/tensorflow/contrib/graph_editor/transform.py", line 173, in copy_op_handler    original_op = info.transform_original_op_handler(info, op._original_op)  File "/Users/yaroslav/anaconda/envs/memory/lib/python3.5/site-packages/tensorflow/contrib/graph_editor/transform.py", line 125, in transform_op_if_inside_handler    return info.transformed_ops[op]KeyError: <tf.Operation 'sum_temp' type=Sum>A work-around is to clear _original_op entries for all opsdef clear_original_ops(ops):  for op in ops:    op._original_op = None@purpledog
performance	Convolution_transpose layer now gives an error (Tensorflow 1.0.0).I am implementing an architecture with conv and conv_transpose layers and this is what I am giving the convolution transpose layer:    ('convolution_transpose', dict(num_outputs=96, kernel_size=[41, 11],                                     stride=[2, 1], padding="SAME", scope='dec_block_1'))and this is what I get/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)    175       current_args = current_scope[key_func].copy()    176       current_args.update(kwargs)--> 177     return func(*args, **current_args)    178   _add_op(func)    179   setattr(func_with_args, '_key_op', _key_op(func))/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in convolution2d_transpose(inputs, num_outputs, kernel_size, stride, padding, data_format, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)   1123         _scope=sc,   1124         _reuse=reuse)-> 1125     outputs = layer.apply(inputs)   1126    1127     # Add variables to collections./usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py in apply(self, inputs, **kwargs)    301       Output tensor(s).    302     """--> 303     return self.__call__(inputs, **kwargs)    304     305 /usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py in __call__(self, inputs, **kwargs)    267           input_shapes = [x.get_shape() for x in input_list]    268           if len(input_shapes) == 1:--> 269             self.build(input_shapes[0])    270           else:    271             self.build(input_shapes)/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/convolutional.py in build(self, input_shape)   1048                                   regularizer=self.bias_regularizer,   1049                                   trainable=True,-> 1050                                   dtype=self.dtype)   1051     else:   1052       self.bias = None/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)    986       collections=collections, caching_device=caching_device,    987       partitioner=partitioner, validate_shape=validate_shape,--> 988       custom_getter=custom_getter)    989 get_variable_or_local_docstring = (    990     """%s/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)    888           collections=collections, caching_device=caching_device,    889           partitioner=partitioner, validate_shape=validate_shape,--> 890           custom_getter=custom_getter)    891     892   def _get_partitioned_variable(self,/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)    339           reuse=reuse, trainable=trainable, collections=collections,    340           caching_device=caching_device, partitioner=partitioner,--> 341           validate_shape=validate_shape)    342     else:    343       return _true_getter(/usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py in variable_getter(getter, name, shape, dtype, initializer, regularizer, trainable, **kwargs)    256           name, shape, initializer=initializer, regularizer=regularizer,    257           dtype=dtype, trainable=trainable,--> 258           variable_getter=functools.partial(getter, **kwargs))    259     260     # Build (if necessary) and call the layer, inside a variable scope./usr/local/lib/python3.5/dist-packages/tensorflow/python/layers/base.py in _add_variable(self, name, shape, dtype, initializer, regularizer, trainable, variable_getter)    206                                initializer=initializer,    207                                dtype=dtype,--> 208                                trainable=trainable and self.trainable)    209     # TODO(sguada) fix name = variable.op.name    210     if variable in existing_variables:/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in layer_variable_getter(getter, *args, **kwargs)   1308       getter = functools.partial(current_custom_getter, getter)   1309     kwargs['rename'] = rename-> 1310     return _model_variable_getter(getter, *args, **kwargs)   1311   return layer_variable_getter   1312 /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/layers.py in _model_variable_getter(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, **_)   1297       regularizer=regularizer, collections=collections, trainable=trainable,   1298       caching_device=caching_device, partitioner=partitioner,-> 1299       custom_getter=getter)   1300    1301 /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)    175       current_args = current_scope[key_func].copy()    176       current_args.update(kwargs)--> 177     return func(*args, **current_args)    178   _add_op(func)    179   setattr(func_with_args, '_key_op', _key_op(func))/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in model_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter)    266                  trainable=trainable, collections=collections,    267                  caching_device=caching_device, device=device,--> 268                  partitioner=partitioner, custom_getter=custom_getter)    269   return var    270 /usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py in func_with_args(*args, **kwargs)    175       current_args = current_scope[key_func].copy()    176       current_args.update(kwargs)--> 177     return func(*args, **current_args)    178   _add_op(func)    179   setattr(func_with_args, '_key_op', _key_op(func))/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/ops/variables.py in variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter)    223                   collections=collections,    224                   caching_device=caching_device,--> 225                   partitioner=partitioner)    226     227 /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape)    331           initializer=initializer, regularizer=regularizer, reuse=reuse,    332           trainable=trainable, collections=collections,--> 333           caching_device=caching_device, validate_shape=validate_shape)    334     335     if custom_getter is not None:/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape)    682         caching_device=caching_device,    683         dtype=variable_dtype,--> 684         validate_shape=validate_shape)    685     self._vars[name] = v    686     logging.vlog(1, "Created variable %s with shape %s and init %s", v.name,/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope)    224           name=name,    225           dtype=dtype,--> 226           expected_shape=expected_shape)    227     228   def __str__(self):/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variables.py in _init_from_args(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, expected_shape)    301             with ops.name_scope("Initializer"),  ops.device(None):    302               self._initial_value = ops.convert_to_tensor(--> 303                   initial_value(), name="initial_value", dtype=dtype)    304               shape = (self._initial_value.get_shape()    305                        if validate_shape else tensor_shape.unknown_shape())/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/variable_scope.py in <lambda>()    671       else:    672         init_val = lambda: initializer(--> 673             shape.as_list(), dtype=dtype, partition_info=partition_info)    674         variable_dtype = dtype.base_dtype    675 TypeError: __init__() got multiple values for argument 'dtype'The same code worked on Tensorflow 0.12.
support	Not found error : Key tower/fully_connected/weights not found in checkpointWhat related GitHub issues or StackOverflow threads have you found by searching the web for your problem?#6263Environment infoOperating System: Google Cloud PlatformLogs or other output that would be helpful(If logs are large, please upload as attachment or provide link).python eval.py --eval_data_pattern='gs://youtube8m-ml-us-east1/1/frame_level/validate/validate*.tfrecord' --train_dir=$BUCKET_NAME/LstmModel --run_once=TrueCaused by op u'save/RestoreV2_2', defined at:File "eval.py", line 332, in app.run()File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 44, in run_sys.exit(main(_sys.argv[:1] + flags_passthrough))File "eval.py", line 328, in mainevaluate()File "eval.py", line 309, in evaluatesaver = tf.train.Saver(tf.global_variables())File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py", line 1040, in initself.build()File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py", line 1070, in buildrestore_sequentially=self._restore_sequentially)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py", line 675, in buildrestore_sequentially, reshape)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py", line 402, in _AddRestoreOpstensors = self.restore_op(filename_tensor, saveable, preferred_shard)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py", line 242, in restore_op[spec.tensor.dtype])[0])File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py", line 668, in restore_v2dtypes=dtypes, name=name)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 763, in apply_opop_def=op_def)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2327, in create_oporiginal_op=self._default_original_op, op_def=op_def)File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1226, in initself._traceback = _extract_stack()NotFoundError (see above for traceback): Key tower/fully_connected/weights not found in checkpoint[[Node: save/RestoreV2_2 = RestoreV2[dtypes=[DT_FLOAT], _device="/job:localhost/replica:0/task:0/cpu:0"](_recv_save/Const_0, save/RestoreV2_2/tensor_names, save/RestoreV2_2/shape_and_slices)]]
support	[Tensorflow]RuntimeError: Graph is finalized and cannot be modified.Environment infoOperating System:Ubuntu 14.04cuda 8.0 + cudnn 5.1I'm running a Cifar-10 tutorial from [https://www.tensorflow.org/tutorials/deep_cnn]And I modified the code a lot.Specifically, I want the model can evaluate simultaneously while training, thus I can get a curve of precision. And I don't have ideal how the cifar10_eval.py and checkpoints work out. So I added an evaluation function to train( ) in cifar10_train.py, and I tried to run the evaluation function every 100 global_step. And then I got this:    RuntimeError: Graph is finalized and cannot be modified.Here is my evaluation function in cifar10.py:  def evaluation():    images_e, labels_e = inputs(eval_data=True)    logits_e = inference(images_e)    correct_pred = tf.equal(tf.argmax(logits_e, 1), tf.argmax(labels_e, 1))    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))    print('%s: accuracy @ 1 = %.3f' % (datetime.now(), accuracy))    tf.summary.scalar('accuracy', accuracy)And here is the call (the last few lines) :   def after_run(self, run_context, run_values):    if self._step % FLAGS.log_frequency == 0:      current_time = time.time()      duration = current_time - self._start_time      self._start_time = current_time      loss_value = run_values.results      examples_per_sec = FLAGS.log_frequency * FLAGS.batch_size / duration      sec_per_batch = float(duration / FLAGS.log_frequency)      format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '                    'sec/batch)')      print (format_str % (datetime.now(), self._step, loss_value,                           examples_per_sec, sec_per_batch))    if self._step % EVAL_STEP == 0:       print('evaluation\n')      cifar10.evaluation()I don't know how to solve it. I do searched the Internet before but there is no similar situation. Is this caused by I called inference() twice in one global_step or else? Any suggestions would be helpful. Thank you!
support	how to read more than one tfrecord files once?I want to do validation during training, but how to read two tfrecord files once, one is for training and annother one is for validation
support	valgrind helloworld.py throws 7805 errorsNOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.For general support from the community, see StackOverflow.To make bugs and feature requests more easy to find and organize, we close issues that are deemedout of scope for GitHub Issues and point people to StackOverflow.For bugs or installation issues, please provide the following information.The more information you provide, the more easily we will be able to offerhelp and advice.What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?Several issues report memory leaks, but only for specific uses of Tensorflow:https://raw.githubusercontent.com/aymericdamien/TensorFlow-Examples/master/examples/1_Introduction/helloworld.py#700#4151http://stackoverflow.com/questions/35695183/tensorflow-memory-leak-even-while-closing-sessionEnvironment infoOperating System:Linux, Ubuntu 14.04Installed version of CUDA and cuDNN:(please attach the output of ls -l /path/to/cuda/lib/libcud*):❯ ls -l /usr/local/cuda-8.0/lib64/libcud*-rw-r--r-- 1 root root   556000 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudadevrt.alrwxrwxrwx 1 root root       16 Jan 26 18:51 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0lrwxrwxrwx 1 root root       19 Jan 26 18:51 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.61-rw-r--r-- 1 root root   415432 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.61-rw-r--r-- 1 root root   775162 Jan 26 18:48 /usr/local/cuda-8.0/lib64/libcudart_static.alrwxrwxrwx 1 root root       13 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5lrwxrwxrwx 1 root root       17 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5-rw-r--r-- 1 root root 79337624 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5-rw-r--r-- 1 root root 69756172 Mar  9 14:14 /usr/local/cuda-8.0/lib64/libcudnn_static.aIf installed from binary pip package, provide:A link to the pip package you installed:pip install tensorflowThe output from python -c "import tensorflow; print(tensorflow.__version__)".(env) ❯ python -c "import tensorflow; print(tensorflow.__version__)"1.0.1If installed from source, provideI'm listing both because I encountered the problem using both source and pip package.The commit hash (git rev-parse HEAD)~/tensorflow r1.0*❯ git rev-parse HEADe895d5ca395c2362df4f5c8f08b68501b41f8a98The output of bazel version❯ bazel version............Build label: 0.4.4Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jarBuild time: Wed Feb 1 18:54:21 2017 (1485975261)Build timestamp: 1485975261Build timestamp as int: 1485975261If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)valgrind python helloworld.pyHere, helloworld.py refers to https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/1_Introduction/helloworld.py.While there are certain cases in which memory violations are not a problem, I am trying to track down a segfault from using Tensorflow with Ros and Gazebo. It's very difficult to know whether one of the memory issues already present in Tensorflow is  responsible.Final summary is as follows:==18112== HEAP SUMMARY:==18112==     in use at exit: 8,356,021 bytes in 99,634 blocks==18112==   total heap usage: 775,798 allocs, 676,164 frees, 352,616,777 bytes allocated==18112== ==18112== LEAK SUMMARY:==18112==    definitely lost: 154,618 bytes in 82 blocks==18112==    indirectly lost: 0 bytes in 0 blocks==18112==      possibly lost: 1,745,007 bytes in 32,420 blocks==18112==    still reachable: 6,456,396 bytes in 67,132 blocks==18112==         suppressed: 0 bytes in 0 blocks==18112== Rerun with --leak-check=full to see details of leaked memory==18112== ==18112== For counts of detected and suppressed errors, rerun with: -v==18112== Use --track-origins=yes to see where uninitialised values come from==18112== ERROR SUMMARY: 7713 errors from 159 contexts (suppressed: 0 from 0)What other attempted solutions have you tried?None.Logs or other output that would be helpful(If logs are large, please upload as attachment or provide link).This gist contains the full output of valgrind python helloworld.py.
support	error running tensorflow trained model c++Hello,I am working on Tensorflow on c++ with other network. I trained facenet on MS-Celeb-1M then i created my graph.pb. I modified the example provided here : https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image in order to test my network.In main.cpp:string graph = "data/graph1.pb";string output_layer = "InceptionResnetV1/Repeat/block35_5/Relu";I get this error if I test :Running model failed: Invalid argument: You must feed a value for placeholder tensor 'phase_train'     with dtype bool [[Node: phase_train = Placeholderdtype=DT_BOOL, shape=[], _device="/job:localhost/replica:0/task:0    /cpu:0"]]
support	BasicDecoder errorHi,I am trying to use BasicDecoder for a sequence-to-sequence translation model and I get error:InvalidArgumentError (see above for traceback): assertion failed: [Expected shape for Tensor sequence_length:0 is ] [1] [ but saw shape: ] [64] [[Node: rnn/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_STRING, DT_INT32], summarize=3, _device="/job:localhost/replica:0/task:0/cpu:0"](rnn/All/_2029, rnn/Assert/Assert/data_0, rnn/stack/_2031, rnn/Assert/Assert/data_2, rnn/Shape_1/_2033)]] [[Node: rnn/while/Identity_12/_2727 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/gpu:5", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_4293_rnn/while/Identity_12", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:5"](^_clooprnn/while/multi_rnn_cell/cell_5/lstm_cell/zeros/_208)]]I can't figure it out, sequence_length tensor should be batch-sized and it is and error messege suggests that it should be [1]. This would be a case when a list of Tensors would be used instead of one fat tensor [time, batch_size, 1]My target_vocab_size is 500Ksize of RNN = 64, for testingdec_inp : <tf.Tensor 'embedded_inputs_1:0' shape=(100, ?, 64) dtype=float32>decoder seq len is batch-sized (64) <tf.Tensor 'decoder_seq_len:0' shape=(?,) dtype=int32>tf.version'1.1.0-rc0'W_target_emb = tf.Variable(tf.random_uniform([target_vocab_size, size], -1.0, 1.0), name="W_target_emb")half = tf.constant(0.5)dec_inp = tf.cast(tf.stack(self.decoder_inputs), tf.float32)dec_inp = tf.reshape(dec_inp,[encoder_max_size, -1, size], name = "embedded_inputs")if not forward_only:#helper = seq2seq.TrainingHelper(inputs = target_embedded_chars, sequence_length = self.decoder_seq_len, time_major=True)helper = seq2seq.ScheduledEmbeddingTrainingHelper(inputs = dec_inp,  sequence_length = self.decoder_seq_len, embedding = W_target_emb, sampling_probability = half, time_major=True)else:helper = seq2seq.GreedyEmbeddingHelper(dec_inp,    start_tokens=self.decoder_inputs[0],   end_token=data_utils.EOS_ID)decoder_cell = LSTMBlockCell(num_units=size)decoder_cell = MultiRNNCell([DeviceWrapper(ResidualWrapper(decoder_cell),device="/gpu:%d" % i) for i in range(8) ])my_decoder = seq2seq.BasicDecoder(cell=decoder_cell,helper=helper,initial_state=encoder_final_state)decoder_outputs, decoder_state = seq2seq.dynamic_decode(my_decoder, output_time_major=False, parallel_iterations=32,   swap_memory = True)
support	Crashing when trying distributed implementationHi, I start saying that I'm a new Tensorflow user :-)I was trying to test the potential speed-up due to a distributed implementation vs. a sequential one, so I came up with the following:A script sequentially computing matmul of two matrices with themselves and then adding them upA script that distributes the two computations to different devices and then sum them up in a third deviceThe problem is the following: if I run the code below with matrices' dimensions of 100x100, it works. If I run the same with dimensions 1000x1000, the following error occurs:tensorflow.python.framework.errors_impl.InternalError: {"created":"@1490890419.097000000","description":"RST_STREAM","file":"C:\tf_jenkins\home\workspace\release-win\DEVICE\cpu\OS\windows\cmake_build\grpc\src\grpc\src\core\ext\transport\chttp2\transport\frame_rst_stream.c","file_line":107,"http2_error":1}I can't figure it out, so any help would be appreciated...Here is the distributed code (after 3 local Servers have been created):import tensorflow as tfimport timecluster = tf.train.ClusterSpec({"local": ["localhost:2222", "localhost:2223", "localhost:2224"]})with tf.device("/job:local/task:1"):    print('task 1')    x1 = tf.Variable(tf.zeros([1000,1000])+10, dtype=tf.float32, name=None)    _matmul_1 = tf.matmul(x1,x1)with tf.device("/job:local/task:0"):    print('task 0')    x0 = tf.Variable(tf.zeros([1000,1000])+10, dtype=tf.float32, name=None)    _matmul_0 = tf.matmul(x0, x0)with tf.device("/job:local/task:2"):    print('task 2')    _matmul_ = tf.add(_matmul_0,_matmul_1)time4 = time.clock()sess = tf.Session("grpc://localhost:2222")print('session')init = tf.global_variables_initializer()sess.run(init)print(sess.run(_matmul_))time5 = time.clock()print(time5-time4)
support	How to have a "static" like variable inside a functionThe StackOverflow website does not work for logging in. Sorry, I have to post my question here.I want a simple test. A simple function F(x), inside which mean and variance are calculated from the input x. Meanwhile, I also want to keep two "static" like variables (like in C) avg_mean, avg_variance. So that every time F is called avg_mean and avg_variance are updated based on their previous values.Also, I want to have two sets of "avg_mean, avg_variance" for different scopes. My test codes are as below, but the avg_mean and avg_variance are only the values calculated from the last call and does not include the influence from the first call. If I remove the two "reuse_variables()" lines, the program does not run.Could anyone help what should I do? By the way, please help withOUT using tf.contrib libs please, because those are not fully supported in Windows now. Thank you.import tensorflow as tfdef getsta(x):print('getsta start...')params_shape = [x.get_shape()[-1]]decay=0.9mean = tf.get_variable('mean', [1], tf.float32,initializer=tf.constant_initializer(0.0, tf.float32))variance = tf.get_variable('howvariance', [1], tf.float32,initializer=tf.constant_initializer(1.0, tf.float32))avg_mean = tf.get_variable('avg_mean', [1], tf.float32,initializer=tf.constant_initializer(0.0, tf.float32))avg_variance = tf.get_variable('avg_variance', [1], tf.float32,initializer=tf.constant_initializer(0.0, tf.float32))mean, variance = tf.nn.moments(x, [0], name='moments')avg_mean -= (1.0 - decay) * (avg_mean - mean)avg_variance -= (1.0 - decay) * (avg_variance - variance)return x, mean, variance, avg_mean, avg_variancedef main(argv=None):x1 = tf.constant([1,2,3,4], tf.float32)x2 = tf.constant([5,6,7,8], tf.float32)x3 = tf.constant([1,3,5,7], tf.float32)x4 = tf.constant([4,8,12,16], tf.float32)with tf.variable_scope("AAA") as scopeA:y1, mean1, variance1, avg_mean1, avg_variance1 = getsta(x1)scopeA.reuse_variables()y1, mean1, variance1, avg_mean1, avg_variance1 = getsta(x2)with tf.variable_scope("BBB") as scopeB:y2, mean2, variance2, avg_mean2, avg_variance2 = getsta(x3)scopeB.reuse_variables()y2, mean2, variance2, avg_mean2, avg_variance2 = getsta(x4)sess = tf.InteractiveSession()sess.run(tf.global_variables_initializer())print(sess.run([y1, mean1, variance1, avg_mean1, avg_variance1]))print(sess.run([y2, mean2, variance2, avg_mean2, avg_variance2]))if name == 'main':tf.app.run(main=main)
support	How to print and write "Predictions" into a file?predictions = tf.argmax(logits, 1) ######this predictions!!!!!!!!!!!!!!    labels = tf.squeeze(labels)    # Define the metrics:    names_to_values, names_to_updates = slim.metrics.aggregate_metric_map({        'Accuracy': slim.metrics.streaming_accuracy(predictions, labels),        'Predictions': slim.metrics.streaming_precision(predictions, labels),        'Recall@5': slim.metrics.streaming_recall_at_k(            logits, labels, 5)    })    # Print the summaries to screen.    for name, value in names_to_values.iteritems():      summary_name = 'eval/%s' % name      op = tf.summary.scalar(summary_name, value, collections=[])      op = tf.Print(op, [value], summary_name)      tf.add_to_collection(tf.GraphKeys.SUMMARIES, op)I try lots of ways, but I fail to print or write "predictions".I want to print  the test results("predictions")  of a model and write it into aaa.txt, and how?THANKS.
support	Tensorboard showing problems under keras callbacksMy code runs well without any errors showing. However, when I use the commandtensorboard --logdir = "my path", it shows nothing. I want someone to help me! Thanks.tensorflow 1.0.1 keras 2.0  and python 3.4And I found the debug shows:INFO:tensorflow:TensorBoard is in debug mode.INFO:tensorflow:Starting TensorBoard in directory /home/lk/lkINFO:tensorflow:TensorBoard path_to_run is: {'/home/lk/lk/=': None}INFO:tensorflow:Event Multiplexer initializing.INFO:tensorflow:Event Multiplexer done initializingINFO:tensorflow:TensorBoard reload process beginningINFO:tensorflow:Starting AddRunsFromDirectory: /home/lk/lk/=INFO:tensorflow:Done with AddRunsFromDirectory: /home/lk/lk/=INFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer_INFO:tensorflow:Beginning EventMultiplexer.Reload()INFO:tensorflow:Finished with EventMultiplexer.Reload()_INFO:tensorflow:TensorBoard done reloading. Load took 0.002 secsINFO:tensorflow:TensorBoard is tag: b'41'Starting TensorBoard b'41' on port 6006(You can navigate to http://127.0.1.1:6006)of which between INFO:tensorflow:Beginning EventMultiplexer.Reload() and INFO:tensorflow:Finished with EventMultiplexer.Reload(). There is no debuging information.
support	could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERRORHi,I installed tensorflow 1.0.1 GPU version on my Macbook Pro with GeForce GT 750M. Also installed CUDA 8.0.71 and cuDNN 5.1. I am running  a tf code that works fine with non CPU tensorflow but on GPU version , I get this error (once a while it works too).I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)E tensorflow/stream_executor/cuda/cuda_dnn.cc:397] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERRORE tensorflow/stream_executor/cuda/cuda_dnn.cc:364] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAMF tensorflow/core/kernels/conv_ops.cc:605] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms)What is happening here? Is there a bug in tensorflow. Please advise.Thanks
support	image_retraining/retrain.py not foundEnvironment infoOperating System: Windows 10Installed version of CUDA and cuDNN:cuda_8.0.61_win10.execudnn-8.0-windows10-x64-v5.1I have installed tensorflow for gpu using pip install tensorflow-gpu( also downloaded the nightly for vanishing certain warnings)tensorflow_gpu-1.1.0rc0-cp35-cp35m-win_amd64.whlWhat am I trying to do?I want to use the tensorflow for poets for transfer learning on my images ## ### WITHOUT USING DOCKERWhat my problem is?The tensorflow directory in the site-packages does not have the image_retraining folder at all.But the tensorflow-master-cpu on github has examples/image_retraining. It has many other files and directories.My question is..Can I copy and paste the tensorflow/examples/image_retraining or the tensorflow subfolder to my tensorflow folder in site-packages?orDo I install tensorflow for cpu ? Will the retraining work?I don't want to use docker. Please help me @Carmezim
support	ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directoryI am trying to use tensorflow-gpu on my system. I have re-installed it many times, it gives the error give below. But when I use tensorflow-cpu it works fine. I have cuda 8.0 toolkit installed and cudnn 5.1Traceback (most recent call last):  File "finetune.py", line 17, in <module>    import tensorflow as tf  File "/home/saurabh/code/env/local/lib/python2.7/site-packages/tensorflow/__init__.py", line 24, in <module>    from tensorflow.python import *  File "/home/saurabh/code/env/local/lib/python2.7/site-packages/tensorflow/python/__init__.py", line 72, in <module>    raise ImportError(msg)ImportError: Traceback (most recent call last):  File "/home/saurabh/code/env/local/lib/python2.7/site-packages/tensorflow/python/__init__.py", line 61, in <module>    from tensorflow.python import pywrap_tensorflow  File "/home/saurabh/code/env/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 28, in <module>    _pywrap_tensorflow = swig_import_helper()  File "/home/saurabh/code/env/local/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py", line 24, in swig_import_helper    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directoryFailed to load the native TensorFlow runtime.See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_errorfor some common reasons and solutions.  Include the entire stack traceabove this error message when asking for help.
support	regarding the ValueError: inputs must be a list of at least one Tensor with the same dtype and shapeThere is a program that defines the loss function as follows:reg_loss_col = tf.GraphKeys.REGULARIZATION_LOSSESweight_loss = tf.add_n(tf.get_collection(reg_loss_col),name='reg_loss')Running the program raises the following error messageFile "/home/ decoder/kitti_multiloss.py", line 86, in lossname='reg_loss')File "/devl /tensorflow/tf_0.12/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py", line 1827, in add_nraise ValueError("inputs must be a list of at least one Tensor with the "ValueError: inputs must be a list of at least one Tensor with the same dtype and shapeI am curious how to print out the tensor information of the first parameter tf.get_collection(reg_loss_col) in tf.add_n, so that I can figure out why this cause the error.
support	Can't register new xla deviceI'm trying to register a fake 'xpu' device to use with xla, but it hasn't been working. I've gotten Tensorflow to build after making the changes found in the attached file (diffOutput.txt, the output from git diff). But, when I run the following sample code:import argparseimport sysimport tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_datafrom tensorflow.python.client import timelineFLAGS = Nonedef main(_):    config = tf.ConfigProto(log_device_placement=True)    jit_level = 0    if FLAGS.xla:        # Turns on XLA JIT compilation.        jit_level = tf.OptimizerOptions.ON_1        print('XLA flag on')    config.graph_options.optimizer_options.global_jit_level = jit_level    run_metadata = tf.RunMetadata()    # Creates a session with log_device_placement set to True.    with tf.Session(config=config) as sess:        # Creates a graph.        with tf.device('/job:localhost/replica:0/task:0/device:XLA_XPU:0'):        #with tf.device('/device:CPU:0'):            a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0],                            shape=[2, 3], name='a')            b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0],                            shape=[3, 2], name='b')            c = tf.matmul(a, b)        # Runs the op.        print(sess.run(c,              options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),              run_metadata=run_metadata))        trace = timeline.Timeline(step_stats=run_metadata.step_stats)        with open('timeline.ctf.json', 'w') as trace_file:            trace_file.write(trace.generate_chrome_trace_format())if __name__ == "__main__":    parser = argparse.ArgumentParser()    parser.add_argument('--data_dir', type=str,            default='/tmp/tensorflow/mnist/input_data',            help='Directory for storing input data')    parser.add_argument(              '--xla', type=bool, default=True, help='Turn xla via JIT on')    FLAGS, unparsed = parser.parse_known_args()    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)I get the error:InvalidArgumentError (see above for traceback): Cannot assign a device to node 'MatMul': Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:XLA_XPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0 [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/device:XLA_XPU:0"](a, b)]]What else needs to change in order for my code to work?
support	ResourceExhaustedI get the following error when running in GPU on AWS p2-xlarge:I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1205162d00 of size 256I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x120517b100 of size 73984I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a5ba00 of size 96000I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215a8a800 of size 96000I tensorflow/core/common_runtime/bfc_allocator.cc:687] Free at 0x1215affb00 of size 263424I tensorflow/core/common_runtime/bfc_allocator.cc:693]      Summary of in-use Chunks by size: I tensorflow/core/common_runtime/bfc_allocator.cc:696] 24 Chunks of size 256 totalling 6.0KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 13 Chunks of size 512 totalling 6.5KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 12 Chunks of size 1280 totalling 15.0KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 1792 totalling 8.8KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2560 totalling 2.5KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 3584 totalling 17.5KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 6144 totalling 6.0KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 8 Chunks of size 25600 totalling 200.0KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 29184 totalling 28.5KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1386 Chunks of size 96000 totalling 126.89MiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 131328 totalling 128.2KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 233 Chunks of size 192000 totalling 42.66MiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 7 Chunks of size 204800 totalling 1.37MiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 232192 totalling 226.8KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 257792 totalling 251.8KiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2640128 totalling 2.52MiBI tensorflow/core/common_runtime/bfc_allocator.cc:696] 5 Chunks of size 19200000 totalling 91.55MiBI tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 265.87MiBI tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats: Limit:                   279314432InUse:                   278784768MaxInUse:                278976768NumAllocs:                    4097MaxAllocSize:             19200000W tensorflow/core/common_runtime/bfc_allocator.cc:274] ****************************************************************************************************W tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 375.0KiB.  See logs for memory state.W tensorflow/core/framework/op_kernel.cc:975] Resource exhausted: OOM when allocating tensor with shape[300,320]I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 3720 get requests, put_count=1106 evicted_count=1000 eviction_rate=0.904159 and unsatisfied allocation rate=0.998387I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110I'm using TensorFlow R0.12.1 and Session code is:# Launch the graphconfig = tf.ConfigProto(log_device_placement=True)config.gpu_options.allocator_type = 'BFC'sess = tf.Session(config = config)init = tf.global_variables_initializer()sess.run(init)timestart = datetime.datetime.now() # Start time in secondstimeprev  = datetime.datetime.now() # Start time in secondscountprev = 0ratelist = []boxcarcount = 10X_train = X_train.astype(np.float32)  # Cast to float32 from float64print("Starting training...")# Perform Training steps with "batch_size" iterations at each loopstep = 1while step * batch_size <= training_iters:    # Note: type(X_train) = float32    # Note: type(y_train) = int32    # Note: type(step)       = int    # Note: type(batch_size) = int    batch_xs =         extract_batch_size(X_train, step, batch_size)    batch_ys = one_hot(extract_batch_size(y_train, step, batch_size),LabelMax)    # Fit training using batch data    output, loss, acc = sess.run(        [optimizer, cost, accuracy],        feed_dict={            Xin   : batch_xs,             Ytrue : batch_ys,            keep_prob: DO_keep_prob        }    )    train_losses.append(loss)    train_accuracies.append(acc)My question: is there a way to allocate more memory in the GPU?This seems like a really small data set to be using?!?!?Thanks.
support	Problem with seq2seq models in prediction@mrry Hi, I am confused with a prediction problem implemented in TensorFlow seq2seq.
support	Android: Invalid argument: No OpKernel was registered to support Op 'PaddingFIFOQueue' with these attrsI encountered a problem when using a multibox model to make inference on android platform (using c++ api, just like the android demo). The error says something like this:tensorflow_jni.cc:361 Error during inference: Invalid argument: No OpKernel was registered to support Op 'PaddingFIFOQueue' with these attrs[[Node: prefetch_queue = PaddingFIFOQueuecapacity=500, component_types=[DT_FLOAT, DT_FLOAT, DT_BOOL, DT_UINT8, DT_STRING, DT_INT64], container="", shapes=[[-1], [-1,4], [-1], [-1,-1,3], [], [-1]], shared_name=""]]
support	tensorflow/core/util/ctc/ctc_loss_calculator.cc:144] No valid path foundNOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.You must complete this information or else your issue will be closedHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:TensorFlow installed from (source or binary)?:TensorFlow version:Bazel version (if compiling from source):CUDA/cuDNN version:GPU Model and Memory:Exact command to reproduce:Describe the problem clearlySource Code / LogsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem
support	Problems freezing the graphHave I written custom code (as opposed to using a stock example script provided in TensorFlow)?:Please see below for how to replicate the problems. Zip attachment contains two pieces of very small code.TensorFlow installed from (source or binary)?:binary - 1.1TensorFlow version:1.1Bazel version (if compiling from source):Not applicableCUDA/cuDNN version:Recent but not latest.  8.0, V8.0.44GPU Model and Memory:Tesla K20 4 GBExact command to reproduce:See below....Describe the problem clearlyWe have a problem related to saving the operations as constants while freezing using the algorithm in the attached files.The problem can be easily replicated by trying to freeze the graphs generated by the toy example in textsum https://github.com/tensorflow/models/tree/master/textsum .Models are trained with the following command:bazel-bin/textsum/seq2seq_attention --mode=train --article_key=article --abstract_key=abstract --data_path=textsum/data/data --vocab_path=textsum/data/vocab --log_root=textsum/log_root --train_dir=textsum/log_root/trainThen freeze_2_textsum.py is called with the following syntax:python freeze_2_textsum.pyCommand in our case was:python freeze_2_textsum.py --model_folder=./log_root/ --outputnodes=global_stepIn this case, we are able to find the saved constants in the frozen_model.pb file.But when we try the same syntax for the trained graph in our project, we could not find the constants in the frozen model.pb file, while the freeze_2_textsum.py script prints the log message that "13 ops were converted to constants"This problem leads to the following error while running the session in our test script:"Attempting to use uninitialized value model/generate_embedding_RNN_output/BiRNN/BW/BasicLSTMCell/Linear/Bias"cmd line for test script:python test_tf_frozen_txtsum.pySource Code / LogsFreezing_problem.zip
support	tensorflow installation issueI have been following the Tensorflow installation guide to install tensorflow r.1.0. Since out network system does not have direct internet access to outside, so I installed it as following in the active virtualenv environment(virtualenv-test) bash-4.1$ pip3 install -t --upgrade /data/pythonlibs/tensorflow-1.0.1-cp34-cp34m-linux_x86_64.whlProcessing /data/dsp_emerging/ugwz/pythonlibs/tensorflow-1.0.1-cp34-cp34m-linux_x86_64.whlHowever, I got the following error message, what does it mean?Collecting six>=1.10.0 (from tensorflow==1.0.1)Retrying (Retry(total=4, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x2b623e22bcc0>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/six/Retrying (Retry(total=3, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x2b623e22bd68>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/six/Retrying (Retry(total=2, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x2b623e113fd0>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/six/Retrying (Retry(total=1, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x2b623e115358>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/six/Retrying (Retry(total=0, connect=None, read=None, redirect=None)) after connection broken by 'NewConnectionError('<pip._vendor.requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x2b623e115438>: Failed to establish a new connection: [Errno -2] Name or service not known',)': /simple/six/Could not find a version that satisfies the requirement six>=1.10.0 (from tensorflow==1.0.1) (from versions: )No matching distribution found for six>=1.10.0 (from tensorflow==1.0.1)
support	How to reinitialize state prior to inference with RNNI have an RNN graph which has been trained in TF with good accuracy, but when it runs in Android (using libtensorflow_inference.so) it runs poorly.  I have a hypothesis that the problem is due to the statefulness of the RNN.  It is my understanding that during training the RNN state is reinitialized to a fresh state with each minibatch.  However, when running in reallife, it is running continuously without the state being refreshed.  Thus causing anomalous results.Is there a way to force the state to be refreshed when running in an Android environment?  I note that the java interface (tensorflowinferenceinterface.java) has no such method.I have also documented this inquiry in SO nine days ago, but had no response: link.
support	tensorflow1.1 rnn lstm:ValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights....Environment infoOperating System: Ubuntu 14.04.5 LTSInstalled version of CUDA and cuDNN:No CUDA, I use CPU-only.Pip version: pip 1.5.4Python version: 2.7.6Operating System: Ubuntu 14.04.5 LTSTensorflow version: tensorflow-1.1.0rc0-cp27-none-linux_x86_64 , CPU-onlyDescription:I was testing the tutorial example of LSTM .my main function  train_rnn_classify.py:import tensorflow as tfimport numpy as npimport osimport timeimport datetimefrom rnn_model import RNN_Modelimport data_helperflags =tf.app.flagsFLAGS = flags.FLAGSflags.DEFINE_integer('batch_size',64,'the batch_size of the training procedure')flags.DEFINE_float('lr',0.1,'the learning rate')flags.DEFINE_float('lr_decay',0.6,'the learning rate decay')flags.DEFINE_integer('vocabulary_size',20000,'vocabulary_size')flags.DEFINE_integer('emdedding_dim',128,'embedding dim')flags.DEFINE_integer('hidden_neural_size',128,'LSTM hidden neural size')flags.DEFINE_integer('hidden_layer_num',1,'LSTM hidden layer num')flags.DEFINE_string('dataset_path','/home/hadoop/lstm/subj0.pkl','dataset path')flags.DEFINE_integer('max_len',40,'max_len of training sentence')flags.DEFINE_integer('valid_num',100,'epoch num of validation')flags.DEFINE_integer('checkpoint_num',1000,'epoch num of checkpoint')flags.DEFINE_float('init_scale',0.1,'init scale')flags.DEFINE_integer('class_num',2,'class num')flags.DEFINE_float('keep_prob',0.5,'dropout rate')flags.DEFINE_integer('num_epoch',60,'num epoch')flags.DEFINE_integer('max_decay_epoch',30,'num epoch')flags.DEFINE_integer('max_grad_norm',5,'max_grad_norm')flags.DEFINE_string('out_dir',os.path.abspath(os.path.join(os.path.curdir,"runs")),'output directory')flags.DEFINE_integer('check_point_every',10,'checkpoint every num epoch ')class Config(object):    hidden_neural_size=FLAGS.hidden_neural_size    vocabulary_size=FLAGS.vocabulary_size    embed_dim=FLAGS.emdedding_dim    hidden_layer_num=FLAGS.hidden_layer_num    class_num=FLAGS.class_num    keep_prob=FLAGS.keep_prob    lr = FLAGS.lr    lr_decay = FLAGS.lr_decay    batch_size=FLAGS.batch_size    num_step = FLAGS.max_len    max_grad_norm=FLAGS.max_grad_norm    num_epoch = FLAGS.num_epoch    max_decay_epoch = FLAGS.max_decay_epoch    valid_num=FLAGS.valid_num    out_dir=FLAGS.out_dir    checkpoint_every = FLAGS.check_point_everydef evaluate(model,session,data,global_steps=None,summary_writer=None):    correct_num=0    total_num=len(data[0])    for step, (x,y,mask_x) in enumerate(data_helper.batch_iter(data,batch_size=FLAGS.batch_size)):         fetches = model.correct_num         feed_dict={}         feed_dict[model.input_data]=x         feed_dict[model.target]=y         feed_dict[model.mask_x]=mask_x         model.assign_new_batch_size(session,len(x))         state = session.run(model._initial_state)         for i , (c,h) in enumerate(model._initial_state):            feed_dict[c]=state[i].c            feed_dict[h]=state[i].h         count=session.run(fetches,feed_dict)         correct_num+=count    accuracy=float(correct_num)/total_num    dev_summary = tf.scalar_summary('dev_accuracy',accuracy)    dev_summary = session.run(dev_summary)    if summary_writer:        summary_writer.add_summary(dev_summary,global_steps)        summary_writer.flush()    return accuracydef run_epoch(model,session,data,global_steps,valid_model,valid_data,train_summary_writer,valid_summary_writer=None):    for step, (x,y,mask_x) in enumerate(data_helper.batch_iter(data,batch_size=FLAGS.batch_size)):        feed_dict={}        feed_dict[model.input_data]=x        feed_dict[model.target]=y        feed_dict[model.mask_x]=mask_x        model.assign_new_batch_size(session,len(x))        fetches = [model.cost,model.accuracy,model.train_op,model.summary]        state = session.run(model._initial_state)        for i , (c,h) in enumerate(model._initial_state):            feed_dict[c]=state[i].c            feed_dict[h]=state[i].h        cost,accuracy,_,summary = session.run(fetches,feed_dict)        train_summary_writer.add_summary(summary,global_steps)        train_summary_writer.flush()        valid_accuracy=evaluate(valid_model,session,valid_data,global_steps,valid_summary_writer)        if(global_steps%100==0):            print("the %i step, train cost is: %f and the train accuracy is %f and the valid accuracy is %f"%(global_steps,cost,accuracy,valid_accuracy))        global_steps+=1    return global_stepsdef train_step():    print("loading the dataset...")    config = Config()    eval_config=Config()    eval_config.keep_prob=1.0    train_data,valid_data,test_data=data_helper.load_data(FLAGS.max_len,batch_size=config.batch_size)    print("begin training")    # gpu_config=tf.ConfigProto()    # gpu_config.gpu_options.allow_growth=True    with tf.Graph().as_default(), tf.Session() as session:        initializer = tf.random_uniform_initializer(-1*FLAGS.init_scale,1*FLAGS.init_scale)        with tf.variable_scope("model",reuse=None,initializer=initializer):            model = RNN_Model(config=config,is_training=True)        with tf.variable_scope("model",reuse=True,initializer=initializer):            valid_model = RNN_Model(config=eval_config,is_training=False)            test_model = RNN_Model(config=eval_config,is_training=False)        #add summary        # train_summary_op = tf.merge_summary([model.loss_summary,model.accuracy])        train_summary_dir = os.path.join(config.out_dir,"summaries","train")        train_summary_writer =  tf.train.SummaryWriter(train_summary_dir,session.graph)        # dev_summary_op = tf.merge_summary([valid_model.loss_summary,valid_model.accuracy])        dev_summary_dir = os.path.join(eval_config.out_dir,"summaries","dev")        dev_summary_writer =  tf.train.SummaryWriter(dev_summary_dir,session.graph)        #add checkpoint        checkpoint_dir = os.path.abspath(os.path.join(config.out_dir, "checkpoints"))        checkpoint_prefix = os.path.join(checkpoint_dir, "model")        if not os.path.exists(checkpoint_dir):            os.makedirs(checkpoint_dir)        saver = tf.train.Saver(tf.all_variables())        tf.initialize_all_variables().run()        global_steps=1        begin_time=int(time.time())        for i in range(config.num_epoch):            print("the %d epoch training..."%(i+1))            lr_decay = config.lr_decay ** max(i-config.max_decay_epoch,0.0)            model.assign_new_lr(session,config.lr*lr_decay)            global_steps=run_epoch(model,session,train_data,global_steps,valid_model,valid_data,train_summary_writer,dev_summary_writer)            if i% config.checkpoint_every==0:                path = saver.save(session,checkpoint_prefix,global_steps)                print("Saved model chechpoint to{}\n".format(path))        print("the train is finished")        end_time=int(time.time())        print("training takes %d seconds already\n"%(end_time-begin_time))        test_accuracy=evaluate(test_model,session,test_data)        print("the test data accuracy is %f"%test_accuracy)        print("program end!")def main(_):    train_step()if __name__ == "__main__":    tf.app.run()model code rnn_model.py   :`import tensorflow as tfimport numpy as npclass RNN_Model(object):    def __init__(self,config,is_training=True):        self.keep_prob=config.keep_prob        self.batch_size=tf.Variable(0,dtype=tf.int32,trainable=False)        num_step=config.num_step        self.input_data=tf.placeholder(tf.int32,[None,num_step])        self.target = tf.placeholder(tf.int64,[None])        self.mask_x = tf.placeholder(tf.float32,[num_step,None])        class_num=config.class_num        hidden_neural_size=config.hidden_neural_size        vocabulary_size=config.vocabulary_size        embed_dim=config.embed_dim        hidden_layer_num=config.hidden_layer_num        self.new_batch_size = tf.placeholder(tf.int32,shape=[],name="new_batch_size")        self._batch_size_update = tf.assign(self.batch_size,self.new_batch_size)        #build LSTM network        lstm_cell = tf.contrib.rnn.BasicLSTMCell(hidden_neural_size,forget_bias=0.0,state_is_tuple=True)        if self.keep_prob<1:            lstm_cell =  tf.contrib.rnn.DropoutWrapper(                lstm_cell,output_keep_prob=self.keep_prob            )        cell = tf.contrib.rnn.MultiRNNCell([lstm_cell]*hidden_layer_num,state_is_tuple=True)        self._initial_state = cell.zero_state(self.batch_size,dtype=tf.float32)        #embedding layer        with tf.device("/cpu:0"),tf.name_scope("embedding_layer"):            embedding = tf.get_variable("embedding",[vocabulary_size,embed_dim],dtype=tf.float32)            inputs=tf.nn.embedding_lookup(embedding,self.input_data)        if self.keep_prob<1:            inputs = tf.nn.dropout(inputs,self.keep_prob)        out_put=[]        state=self._initial_state        with tf.variable_scope("LSTM_layer"):            for time_step in range(num_step):                if time_step>0: tf.get_variable_scope().reuse_variables()                (cell_output,state)=cell(inputs[:,time_step,:],state)                out_put.append(cell_output)        out_put=out_put*self.mask_x[:,:,None]        with tf.name_scope("mean_pooling_layer"):            out_put=tf.reduce_sum(out_put,0)/(tf.reduce_sum(self.mask_x,0)[:,None])        with tf.name_scope("Softmax_layer_and_output"):            softmax_w = tf.get_variable("softmax_w",[hidden_neural_size,class_num],dtype=tf.float32)            softmax_b = tf.get_variable("softmax_b",[class_num],dtype=tf.float32)            self.logits = tf.matmul(out_put,softmax_w)+softmax_b        with tf.name_scope("loss"):            self.loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=self.target,logits=self.logits+1e-10,)            self.cost = tf.reduce_mean(self.loss)        with tf.name_scope("accuracy"):            self.prediction = tf.argmax(self.logits,1)            correct_prediction = tf.equal(self.prediction,self.target)            self.correct_num=tf.reduce_sum(tf.cast(correct_prediction,tf.float32))            self.accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32),name="accuracy")        #add summary        loss_summary = tf.contrib.deprecated.scalar_summary("loss",self.cost)        #add summary        accuracy_summary=tf.contrib.deprecated.scalar_summary("accuracy_summary",self.accuracy)        if not is_training:            return        self.globle_step = tf.Variable(0,name="globle_step",trainable=False)        self.lr = tf.Variable(0.0,trainable=False)        tvars = tf.trainable_variables()        grads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, tvars),                                      config.max_grad_norm)        # Keep track of gradient values and sparsity (optional)        grad_summaries = []        for g, v in zip(grads, tvars):            if g is not None:                grad_hist_summary = tf.summary.histogram("{}/grad/hist".format(v.name), g)                sparsity_summary = tf.contrib.deprecated.scalar_summary("{}/grad/sparsity".format(v.name), tf.nn.zero_fraction(g))                grad_summaries.append(grad_hist_summary)                grad_summaries.append(sparsity_summary)        self.grad_summaries_merged = tf.summary.merge(grad_summaries)        self.summary =tf.summary.merge([loss_summary,accuracy_summary,self.grad_summaries_merged])        optimizer = tf.train.GradientDescentOptimizer(self.lr)        optimizer.apply_gradients(zip(grads, tvars))        self.train_op=optimizer.apply_gradients(zip(grads, tvars))        self.new_lr = tf.placeholder(tf.float32,shape=[],name="new_learning_rate")        self._lr_update = tf.assign(self.lr,self.new_lr)    def assign_new_lr(self,session,lr_value):        session.run(self._lr_update,feed_dict={self.new_lr:lr_value})    def assign_new_batch_size(self,session,batch_size_value):        session.run(self._batch_size_update,feed_dict={self.new_batch_size:batch_size_value})`data handle code  data_helper.py:import numpy as npimport cPickle as pkl#file pathdataset_path='/home/hadoop/lstm/subj0.pkl'def set_dataset_path(path):    dataset_path=pathdef load_data(max_len,batch_size,n_words=20000,valid_portion=0.1,sort_by_len=True):    f=open(dataset_path,'rb')    print ('load data from %s',dataset_path)    train_set = np.array(pkl.load(f))    test_set = np.array(pkl.load(f))    f.close()    train_set_x,train_set_y = train_set    #train_set length    n_samples= len(train_set_x)    #shuffle and generate train and valid dataset    sidx = np.random.permutation(n_samples)    n_train = int(np.round(n_samples * (1. - valid_portion)))    valid_set_x = [train_set_x[s] for s in sidx[n_train:]]    valid_set_y = [train_set_y[s] for s in sidx[n_train:]]    train_set_x = [train_set_x[s] for s in sidx[:n_train]]    train_set_y = [train_set_y[s] for s in sidx[:n_train]]    train_set = (train_set_x, train_set_y)    valid_set = (valid_set_x, valid_set_y)    #remove unknow words    def remove_unk(x):        return [[1 if w >= n_words else w for w in sen] for sen in x]    test_set_x, test_set_y = test_set    valid_set_x, valid_set_y = valid_set    train_set_x, train_set_y = train_set    train_set_x = remove_unk(train_set_x)    valid_set_x = remove_unk(valid_set_x)    test_set_x = remove_unk(test_set_x)    def len_argsort(seq):        return sorted(range(len(seq)), key=lambda x: len(seq[x]))    if sort_by_len:        sorted_index = len_argsort(test_set_x)        test_set_x = [test_set_x[i] for i in sorted_index]        test_set_y = [test_set_y[i] for i in sorted_index]        sorted_index = len_argsort(valid_set_x)        valid_set_x = [valid_set_x[i] for i in sorted_index]        valid_set_y = [valid_set_y[i] for i in sorted_index]        sorted_index = len_argsort(train_set_x)        train_set_x = [train_set_x[i] for i in sorted_index]        train_set_y = [train_set_y[i] for i in sorted_index]    train_set=(train_set_x,train_set_y)    valid_set=(valid_set_x,valid_set_y)    test_set=(test_set_x,test_set_y)    new_train_set_x=np.zeros([len(train_set[0]),max_len])    new_train_set_y=np.zeros(len(train_set[0]))    new_valid_set_x=np.zeros([len(valid_set[0]),max_len])    new_valid_set_y=np.zeros(len(valid_set[0]))    new_test_set_x=np.zeros([len(test_set[0]),max_len])    new_test_set_y=np.zeros(len(test_set[0]))    mask_train_x=np.zeros([max_len,len(train_set[0])])    mask_test_x=np.zeros([max_len,len(test_set[0])])    mask_valid_x=np.zeros([max_len,len(valid_set[0])])    def padding_and_generate_mask(x,y,new_x,new_y,new_mask_x):        for i,(x,y) in enumerate(zip(x,y)):            #whether to remove sentences with length larger than maxlen            if len(x)<=max_len:                new_x[i,0:len(x)]=x                new_mask_x[0:len(x),i]=1                new_y[i]=y            else:                new_x[i]=(x[0:max_len])                new_mask_x[:,i]=1                new_y[i]=y        new_set =(new_x,new_y,new_mask_x)        del new_x,new_y        return new_set    train_set=padding_and_generate_mask(train_set[0],train_set[1],new_train_set_x,new_train_set_y,mask_train_x)    test_set=padding_and_generate_mask(test_set[0],test_set[1],new_test_set_x,new_test_set_y,mask_test_x)    valid_set=padding_and_generate_mask(valid_set[0],valid_set[1],new_valid_set_x,new_valid_set_y,mask_valid_x)    return train_set,valid_set,test_set#return batch datasetdef batch_iter(data,batch_size):    #get dataset and label    x,y,mask_x=data    x=np.array(x)    y=np.array(y)    data_size=len(x)    num_batches_per_epoch=int((data_size-1)/batch_size)    for batch_index in range(num_batches_per_epoch):        start_index=batch_index*batch_size        end_index=min((batch_index+1)*batch_size,data_size)        return_x = x[start_index:end_index]        return_y = y[start_index:end_index]        return_mask_x = mask_x[:,start_index:end_index]        # if(len(return_x)<batch_size):        #     print(len(return_x))        #     print return_x        #     print return_y        #     print return_mask_x        #     import sys        #     sys.exit(0)        yield (return_x,return_y,return_mask_x)When I open a terminal and runpython train_rnn_classify.pythen  has error:Traceback (most recent call last):  File "train_rnn_classify.py", line 176, in <module>    tf.app.run()  File "/home/hadoop/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/app.py", line 48, in run    _sys.exit(main(_sys.argv[:1] + flags_passthrough))  File "train_rnn_classify.py", line 172, in main    train_step()  File "train_rnn_classify.py", line 128, in train_step    valid_model = RNN_Model(config=eval_config,is_training=False)  File "/home/hadoop/lstm/rnn_model.py", line 51, in __init__    (cell_output,state)=cell(inputs[:,time_step,:],state)  File "/home/hadoop/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py", line 953, in __call__    cur_inp, new_state = cell(cur_inp, cur_state)  File "/home/hadoop/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py", line 235, in __call__    with _checked_scope(self, scope or "basic_lstm_cell", reuse=self._reuse):  File "/home/hadoop/anaconda2/lib/python2.7/contextlib.py", line 17, in __enter__    return self.gen.next()  File "/home/hadoop/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py", line 93, in _checked_scope    "the argument reuse=True." % (scope_name, type(cell).__name__))ValueError: Attempt to have a second RNNCell use the weights of a variable scope that already has weights: 'model/LSTM_layer/multi_rnn_cell/cell_0/basic_lstm_cell'; and the cell was not constructed as BasicLSTMCell(..., reuse=True).  To share the weights of an RNNCell, simply reuse it in your second calculation, or create a new one with the argument reuse=True.Why can't I run this example?How to solve this  problem?Thank you all for your kind help!!!
support	NotFoundError while restoring inception_v3 modelHi,I am trying to make use of inception_v3 model from https://github.com/tensorflow/models/tree/master/slimAfter downloading the model as described in the webpage, I wanted to restore the model usingsaver = tf.train.Saver()saver.restore(sess, 'model/inception_v3.ckpt')And I get this error:NotFoundError (see above for traceback): Tensor name "InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/biases" not found in checkpoint files model/inception_v3.ckptUpon inspection of tf.trainable_variables(), i find the variable with name -"InceptionV3/Mixed_6d/Branch_1/Conv2d_0c_7x1/biases:0"Is the suffix :0 causing this error ? If not how can i load this model ?I raised this issue @tensorflow/models, but unfortunately, I did not get any response.Thanks in advance!
support	hi everyone! im having this issue when trying to import tensorflow, i've tried all the techniques i've found on stackoverflow and here at GH but they still don't workPython 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32Type "help", "copyright", "credits" or "license" for more information.import tensorflow as tfTraceback (most recent call last):File "C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 18, in swig_import_helperreturn importlib.import_module(mname)File "C:\python35\lib\importlib_init_.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)File "", line 986, in _gcd_importFile "", line 969, in _find_and_loadFile "", line 958, in _find_and_load_unlockedFile "", line 666, in _load_unlockedFile "", line 577, in module_from_specFile "", line 906, in create_moduleFile "", line 222, in _call_with_frames_removedImportError: DLL load failed: Le module spécifié est introuvable.During handling of the above exception, another exception occurred:Traceback (most recent call last):File "C:\python35\lib\site-packages\tensorflow\python_init_.py", line 66, in from tensorflow.python import pywrap_tensorflowFile "C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 21, in _pywrap_tensorflow = swig_import_helper()File "C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 20, in swig_import_helperreturn importlib.import_module('pywrap_tensorflow')File "C:\python35\lib\importlib_init.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)ImportError: No module named '_pywrap_tensorflow'During handling of the above exception, another exception occurred:Traceback (most recent call last):File "", line 1, in File "C:\python35\lib\site-packages\tensorflow_init_.py", line 24, in from tensorflow.python import *File "C:\python35\lib\site-packages\tensorflow\python_init_.py", line 72, in raise ImportError(msg)ImportError: Traceback (most recent call last):File "C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 18, in swig_import_helperreturn importlib.import_module(mname)File "C:\python35\lib\importlib_init_.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)File "", line 986, in _gcd_importFile "", line 969, in _find_and_loadFile "", line 958, in _find_and_load_unlockedFile "", line 666, in _load_unlockedFile "", line 577, in module_from_specFile "", line 906, in create_moduleFile "", line 222, in _call_with_frames_removedImportError: DLL load failed: Le module spécifié est introuvable.During handling of the above exception, another exception occurred:Traceback (most recent call last):File "C:\python35\lib\site-packages\tensorflow\python_init_.py", line 66, in from tensorflow.python import pywrap_tensorflowFile "C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 21, in _pywrap_tensorflow = swig_import_helper()File "C:\python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py", line 20, in swig_import_helperreturn importlib.import_module('pywrap_tensorflow')File "C:\python35\lib\importlib_init.py", line 126, in import_modulereturn _bootstrap._gcd_import(name[level:], package, level)ImportError: No module named '_pywrap_tensorflow'Failed to load the native TensorFlow runtime.See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_errorfor some common reasons and solutions.  Include the entire stack traceabove this error message when asking for help.
support	TensorFlow crashing when batching audioI have tried to create an audio processing model using tensorflow.contrib.ffmpeg. The code I wrote consistently crashes the python process on my OS X. I have provided both the code and a piece of crash report on this stackoverflow question.http://stackoverflow.com/questions/43377986/batching-audio-data-in-tensorflow/Is this a bug or am I doing something wrong?
support	XLA: Help understanding compute path for HLO graph@aidan-plenert-macdonald and I are trying to figure out how the HLO graph is being passed around during xla computations. I'm moving computations over to a new device and am attempting to intercept the graph to see how it's represented, in order to replicate the structure.A list of the files where I added print statements is included below. Almost none of them print (only Registrar initialization in hlo_graph_dumper.cc, the Transfer functions in client.cc and service.cc, and the CpuCompiler and XpuCompiler initializations), and I've added statements in almost every function in the attached files.Where is the HLO graph being assembled and dumped? How do I access the HLO graph?Note: the 'xpu' folder/files are for my new device - they're replicas of the 'cpu' folder/files in compiler/xla/service, with all mentions of 'cpu' changed to 'xpu'. List of files with print statements:./compiler/aot/compile.cc./compiler/jit/encapsulate_subgraphs_pass.cc./compiler/jit/mark_for_compilation_pass.cc./compiler/tf2xla/kernels/batch_matmul_op.cc./compiler/tf2xla/kernels/gather_op.cc./compiler/tf2xla/xla_compiler.cc./compiler/xla/client/client.cc./compiler/xla/service/cpu/cpu_compiler.cc./compiler/xla/service/hlo_computation.cc./compiler/xla/service/hlo_graph_dumper.cc./compiler/xla/service/layout_assignment.cc./compiler/xla/service/service.cc./compiler/xla/service/user_computation.cc./compiler/xla/service/xpu/xpu_compiler.cc./compiler/xla/service/xpu/xpu_executable.cc./compiler/xla/tests/hlo_test_base.cc./core/common_runtime/function.cc./core/common_runtime/graph_optimizer.cc
support	encoder_inputs and decoder_inputs of a sequence to sequence model.Hello,I've read the tutorial about seq2seq on the website and still can't figure out how my inputs have to be;here's my problem:each of my inputs is a matrix with fixed number of columns but a variable number of rows( each matrix has its number of rows). And the same thing for my outputs.how to build the encoder and decoder inputs?Thanks in advance.
support	Restoring RNN model from checkpoint fails when hidden layer width is not equal to input/output widthHi, I'm not sure whether this is actually a bug, or I'm doing something wrong, so please treat accordingly.I have an RNN model defined as following:import tensorflow as tfnn_layers = 3def RNN(x, weights, out_biases, input_size, n_steps, nn_hidden, keep_prob, forget_bias=0.0):    # Input data shape: (batch_size, n_steps, input_size)    # Output data shape: (batch_size, output_size)    # Permute, reshape and split to get n_steps tensors of shape (batch_size, input_size)    x = tf.transpose(x, [1, 0, 2])    x = tf.reshape(x, [-1, input_size])    x = tf.split(axis=0, num_or_size_splits=n_steps, value=x)        # define RNN structure        #layer_cell = tf.contrib.rnn.BasicLSTMCell(nn_hidden, forget_bias=forget_bias)    layer_cell = tf.contrib.rnn.GRUCell(nn_hidden)        cell = tf.contrib.rnn.DropoutWrapper(layer_cell, output_keep_prob=keep_prob)    cell = tf.contrib.rnn.MultiRNNCell([cell] * nn_layers)    output, state = tf.contrib.rnn.static_rnn(cell, x, dtype=tf.float32)        pred = tf.matmul(output[-1], weights["out"]) + out_biases["out"]            return preddef vs3_RNN(x, input_size, n_steps, nn_hidden, output_size, keep_prob, forget_bias=0.0):        # Define weights -- output layer    weights = {        'out': tf.Variable(tf.random_normal([nn_hidden, output_size]), name="smax_w")    }    out_biases = {        'out': tf.Variable(tf.random_normal([output_size]), name="smax_b")    }        pred = RNN(x, weights, out_biases, input_size, n_steps, nn_hidden, keep_prob, forget_bias=forget_bias)        return predI use the vs3_RNN method for both training and testing. The size of my input and output vectors (input_size, output_size) is 500. When I set the width of my hidden layer (nn_hidden) to 500, everything works great. However, when I set it to something else, I can train the model and save the checkpoint fine -- but when I try to restore the model from checkpoint, I get an error message.Here's a stack trace with nn_hidden equal to 600:Traceback (most recent call last):  File "thdvector/vs3_service.py", line 43, in <module>    saver.restore(sess, tf.train.latest_checkpoint(SAVEDIR))  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1439, in restore    {self.saver_def.filename_tensor_name: save_path})  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 767, in run    run_metadata_ptr)  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 965, in _run    feed_dict_string, options, run_metadata)  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1015, in _do_run    target_list, options, run_metadata)  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1035, in _do_call    raise type(e)(node_def, op, message)tensorflow.python.framework.errors_impl.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [500] rhs shape= [600] [[Node: save/Assign = Assign[T=DT_FLOAT, _class=["loc:@rnn/multi_rnn_cell/cell_0/gru_cell/candidate/biases"], use_locking=true, validate_shape=true, _device="/job:localhost/replica:0/task:0/cpu:0"](rnn/multi_rnn_cell/cell_0/gru_cell/candidate/biases, save/RestoreV2)]]Caused by op u'save/Assign', defined at:  File "thdvector/vs3_service.py", line 41, in <module>    saver = tf.train.Saver()  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1051, in __init__    self.build()  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1081, in build    restore_sequentially=self._restore_sequentially)  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 675, in build    restore_sequentially, reshape)  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 414, in _AddRestoreOps    assign_ops.append(saveable.restore(tensors, shapes))  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 155, in restore    self.op.get_shape().is_fully_defined())  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_state_ops.py", line 47, in assign    use_locking=use_locking, name=name)  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 763, in apply_op    op_def=op_def)  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 2395, in create_op    original_op=self._default_original_op, op_def=op_def)  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 1264, in __init__    self._traceback = _extract_stack()InvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [500] rhs shape= [600] [[Node: save/Assign = Assign[T=DT_FLOAT, _class=["loc:@rnn/multi_rnn_cell/cell_0/gru_cell/candidate/biases"], use_locking=true, validate_shape=true, _device="/job:localhost/replica:0/task:0/cpu:0"](rnn/multi_rnn_cell/cell_0/gru_cell/candidate/biases, save/RestoreV2)]]I have tried this with either GRUCell or BasicLSTMCell, and I get the error message regardless.Here's the code that run that tries to restore the checkpoint and fails:x = tf.placeholder("float", [1, n_steps, input_size], name="x_in")        pred = vs_model.vs3_RNN(x, input_size, n_steps, nn_hidden, output_size, keep_prob=testing_keep_prob, forget_bias=forget_bias)        init = tf.global_variables_initializer()        with tf.Session() as sess:        sess.run(init)        print("Variables initialized")                saver = tf.train.Saver()        #saver = tf.train.import_meta_graph(META)        saver.restore(sess, tf.train.latest_checkpoint(SAVEDIR))        print("Model restored from " + str(SAVEDIR))        ...Thanks.
support	Keras + tensorflow + P100 : cudaErrorNotSupported = 71 errorAllow me please to cross post, upon sugestion, an error faced in using keras with tensorflow with machine equipped with P100 fchollet/keras#6054Apologies if this has been reported already at some other place, I have been googling for it quite a bit, with my colleague without success.While running the simple mnist example (https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py) with keras+tensorflow using P100 GPGPU we encounter an issue at the intersection of keras/tensorflow/cudaUsing TensorFlow backend.I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locallyI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locallyI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:name: Tesla P100-PCIE-16GBmajor: 6 minor: 0 memoryClockRate (GHz) 1.3285pciBusID 0000:02:00.0Total memory: 15.89GiBFree memory: 15.51GiBI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0: YI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:02:00.0)F tensorflow/core/common_runtime/gpu/gpu_device.cc:121] Check failed: err == cudaSuccess (71 vs. 0)srun: error: nid02011: task 0: Abortedsrun: Terminating job step 1262138.0we are using keras 2.0.2, tensorflow 1.0.0. cuda 8.0.53.We seem to be having this issue both in python2.7.12 and python3.5.2 (keras 1.2 and 2.0 ...)Bare tensorflow runtest are going fine, which lead us to think that this is really at the intersection of keras/tensorflow/cuda.The same test runs fine on various machine with the same version of the software but with TitanX GPGPU.seem to be tracing this back tohttps://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/core/common_runtime/gpu/gpu_device.cc#L121http://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html#group__CUDART__TYPES_1g3f51e3575c2178246db0a94a430e0038"""cudaErrorNotSupported = 71This error indicates the attempted operation is not supported on the current system or device."""I am clueless on where to look next to solve this issue. I would greatly appreciate any feedback and guidance on this matter.
support	In ExponentialMovingAverage class in python/training/moving_averages.py, which op will first be executed,  opt_op or maintain_average_op?Recently, I checked the code about moving averages. But I confused about which operation will first be executed, the opt_op which apply the gradient to the variable, or the maintain_average_op which maintain and update the shadow variable? I find that the following code:with tf.control_dependencies([opt_op]): training_op = tf.group(maintain_averages_op)training_op depends on both opt_op and maintain_averages_op. But how about the relation of opt_op   and maintain_averages_op? Which one will be executed first?
support	AttributeError: module 'tensorflow.contrib.seq2seq' has no attribute 'rnn_decoder'System informationOS and Env: Windows 7, Python 3.5.1TensorFlow installed from: binary, pip install tensorflowTensorFlow version: 1.0.1Describe the problemAfter upgrading from TF 0.9 to TF 1.0.1, am unable to find seq2seq.rnn_decoder(). Updated the imports to include seq2seq module (TF 0.9: tensorflow.python.ops, TF 1.0: tensorflow.contrib).On exploring the new API, I noticed a similar function: dynamic_rnn_decoder. Unfortunately, dynamic_rnn_decoder has different signature than rnn_decoder, and a simple function name change fails.The AskWhat's the equivalent of seq2seq.rnn_decoder() in TF 1.0+?Source code (TF 0.9)seq2seq.rnn_decoder(inputs_split, self.initial_state, self.cell, loop_function=loop if test else None, scope='lstm_vars')
support	incorrect datasets path in tutorial: tf.contrib.learn.datasets.base.load_csv_with_headerThe path for loading the iris dataset " tf.contrib.learn.datasets.base.load_csv_with_header" in the tutorial is incorrect:# Load datasets. training_set = tf.contrib.learn.datasets.base.load_csv_with_header( filename=IRIS_TRAINING, target_dtype=np.int, features_dtype=np.float32) test_set = tf.contrib.learn.datasets.base.load_csv_with_header( filename=IRIS_TEST, target_dtype=np.int, features_dtype=np.float32)I believe it should be something closer to the README here:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/README.md`import tensorflow.contrib.learn.python.learn as learnfrom sklearn import datasets, metricsiris = datasets.load_iris()`
support	Android Demo app & Yolo 2 - OutOfMemoryErrorI have successfully run Android Demo with Tiny Yolo (graph-tiny-yolo-voc.pb - 60mb),:  private static final String YOLO_MODEL_FILE = "file:///android_asset/graph-yolo-voc.pb";  private static final int YOLO_INPUT_SIZE = 416;  private static final String YOLO_INPUT_NAME = "input";  private static final String YOLO_OUTPUT_NAMES = "output";  private static final int YOLO_BLOCK_SIZE = 32;  private static final boolean USE_YOLO = true;I also decided to try Yolo 2 (graph-yolo-voc.pb - 193mb),but I get OutOfMemoryError when I run TF DetectMy phone has 3 GB of RAMBut I know that is just android java limit and has nothing to do with current available/free memoryand we can use NDK to bypass this limit.I also tried to run with:     <activity android:name="org.tensorflow.demo.DetectorActivity"                  android:largeHeap="true"but didn't helpAnd also:<activity android:name="org.tensorflow.demo.DetectorActivity"                  android:largeHeap="true"                  android:hardwareAccelerated="false"App runs ok, but nothing happens, it just shows black screen, no camera frames..Is there a way to run app with big .pb files?TensorFlowInferenceInterface needs AssetManager and string file name, then I guess it just uses default java IO to read file,mb it's better to process all of this with NDK somehow?
support	Tf.gradients returning all zeroes when called on result of a tf.gradient callI have the following code snippet:interpolates = alpha*real_data + ((1-alpha)*fake_data)disc_interpolates = Discriminator(interpolates)gradients = tf.gradients(disc_interpolates, [interpolates])[0]second_grad = tf.gradients(gradients[0], [interpolates])[0]Where Discriminator corresponds to a neural network. The first call to tf.gradients is working correctly and I get back non-zero slope values in the gradients variable. However whenever I try to find the second derivative by applying tf.gradients to the gradients variable, my result is always a vector of zeroes.Is this expected behavior or should I be able to find the second derivatives of my neural net?
support	Resource Exhausted and Initialization Errors on gpuHello,I have been facing a resource exhausted error on my gpu for a couple of days and can't seem to figure out how to fix it.So, i have been training custom made conv net on a kaggle dataset for facial recognition with the 53% accuracy..it currently has four convolutional + maxpooling layers followed by 2 fully connected layersMy convolutional layers currently have a stride of (2,2) but since that results in loss of information i wanted to reduce the strides to (1,1). This is a snippet of the various error i'm facingTraining on the dataInternalError                             Traceback (most recent call last)/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)1021     try:-> 1022       return fn(*args)1023     except errors.OpError as e:/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)1003                                  feed_dict, fetch_list, target_list,-> 1004                                  status, run_metadata)1005/home/carnd/anaconda3/envs/dl/lib/python3.5/contextlib.py in exit(self, type, value, traceback)65             try:---> 66                 next(self.gen)67             except StopIteration:/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py in raise_exception_on_not_ok_status()468           compat.as_text(pywrap_tensorflow.TF_Message(status)),--> 469           pywrap_tensorflow.TF_GetCode(status))470   finally:InternalError: Dst tensor is not initialized.[[Node: zeros_28 = Constdtype=DT_FLOAT, value=Tensor<type: float shape: [2304,1152] values: [0 0 0]...>, _device="/job:localhost/replica:0/task:0/gpu:0"]]During handling of the above exception, another exception occurred:InternalError                             Traceback (most recent call last) in ()2 print("Training on the data")3 with tf.Session() as sess:----> 4     sess.run(tf.global_variables_initializer())56     for epoch in range(epochs):/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)765     try:766       result = self._run(None, fetches, feed_dict, options_ptr,--> 767                          run_metadata_ptr)768       if run_metadata:769         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)963     if final_fetches or final_targets:964       results = self._do_run(handle, final_targets, final_fetches,--> 965                              feed_dict_string, options, run_metadata)966     else:967       results = []/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)1013     if handle is None:1014       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,-> 1015                            target_list, options, run_metadata)1016     else:1017       return self._do_call(_prun_fn, self._session, handle, feed_dict,/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)1033         except KeyError:1034           pass-> 1035       raise type(e)(node_def, op, message)10361037   def _extend_graph(self):InternalError: Dst tensor is not initialized.[[Node: zeros_28 = Constdtype=DT_FLOAT, value=Tensor<type: float shape: [2304,1152] values: [0 0 0]...>, _device="/job:localhost/replica:0/task:0/gpu:0"]]Caused by op 'zeros_28', defined at:File "/home/carnd/anaconda3/envs/dl/lib/python3.5/runpy.py", line 184, in _run_module_as_main"main", mod_spec)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/runpy.py", line 85, in _run_codeexec(code, run_globals)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/main.py", line 3, in app.launch_new_instance()File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/traitlets/config/application.py", line 658, in launch_instanceapp.start()File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelapp.py", line 474, in startioloop.IOLoop.instance().start()File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/ioloop.py", line 177, in startsuper(ZMQIOLoop, self).start()File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/ioloop.py", line 887, in starthandler_func(fd_obj, events)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py", line 275, in null_wrapperreturn fn(*args, **kwargs)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py", line 440, in _handle_eventsself._handle_recv()File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py", line 472, in _handle_recvself._run_callback(callback, msg)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py", line 414, in _run_callbackcallback(*args, **kwargs)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py", line 275, in null_wrapperreturn fn(*args, **kwargs)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py", line 276, in dispatcherreturn self.dispatch_shell(stream, msg)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py", line 228, in dispatch_shellhandler(stream, idents, msg)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py", line 390, in execute_requestuser_expressions, allow_stdin)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/ipkernel.py", line 196, in do_executeres = shell.run_cell(code, store_history=store_history, silent=silent)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/zmqshell.py", line 501, in run_cellreturn super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py", line 2717, in run_cellinteractivity=interactivity, compiler=compiler, result=result)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py", line 2821, in run_ast_nodesif self.run_code(code, result):File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py", line 2881, in run_codeexec(code_obj, self.user_global_ns, self.user_ns)File "", line 47, in optimizer = tf.train.AdamOptimizer().minimize(cost)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py", line 298, in minimizename=name)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py", line 412, in apply_gradientsself._create_slots(var_list)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/training/adam.py", line 119, in _create_slotsself._zeros_slot(v, "m", self._name)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py", line 656, in _zeros_slotnamed_slots[var] = slot_creator.create_zeros_slot(var, op_name)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/training/slot_creator.py", line 121, in create_zeros_slotval = array_ops.zeros(primary.get_shape().as_list(), dtype=dtype)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py", line 1370, in zerosoutput = constant(zero, shape=shape, dtype=dtype, name=name)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py", line 169, in constantattrs={"value": tensor_value, "dtype": dtype_value}, name=name).outputs[0]File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 2395, in create_oporiginal_op=self._default_original_op, op_def=op_def)File "/home/carnd/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py", line 1264, in initself._traceback = _extract_stack()InternalError (see above for traceback): Dst tensor is not initialized.[[Node: zeros_28 = Constdtype=DT_FLOAT, value=Tensor<type: float shape: [2304,1152] values: [0 0 0]...>, _device="/job:localhost/replica:0/task:0/gpu:0"]]The error faced in the previous training run of the network was a resource exhausted error which i have commented on in another issue#9400 (comment)I am using  a g2.2x large ec2 instance on aws amazon with a 32gb storage volumeHere is a link to the original unbroken codehttps://github.com/vijpandaturtle/facial-expressionsAnd here is the dataset of 48x48 pixel images(around 35000 images)https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challengeThanks
support	scan in theano and tensorflowThere is a function written with theano:`import numpy as npimport theano as theanoimport theano.tensor as Tdef forward_prop_step(x_t, s_t1_prev, s_t2_prev):            # This is how we calculated the hidden state in a simple RNN. No longer!            # s_t = T.tanh(U[:,x_t] + W.dot(s_t1_prev))            # Word embedding layer            x_e = E[:,x_t]            # GRU Layer 1            z_t1 = T.nnet.hard_sigmoid(U[0].dot(x_e) + W[0].dot(s_t1_prev) + b[0])            r_t1 = T.nnet.hard_sigmoid(U[1].dot(x_e) + W[1].dot(s_t1_prev) + b[1])            c_t1 = T.tanh(U[2].dot(x_e) + W[2].dot(s_t1_prev * r_t1) + b[2])            s_t1 = (T.ones_like(z_t1) - z_t1) * c_t1 + z_t1 * s_t1_prev            # GRU Layer 2            z_t2 = T.nnet.hard_sigmoid(U[3].dot(s_t1) + W[3].dot(s_t2_prev) + b[3])            r_t2 = T.nnet.hard_sigmoid(U[4].dot(s_t1) + W[4].dot(s_t2_prev) + b[4])            c_t2 = T.tanh(U[5].dot(s_t1) + W[5].dot(s_t2_prev * r_t2) + b[5])            s_t2 = (T.ones_like(z_t2) - z_t2) * c_t2 + z_t2 * s_t2_prev            # Final output calculation            # Theano's softmax returns a matrix with one row, we only need the row            o_t = T.nnet.softmax(V.dot(s_t2) + c)[0]return [o_t, s_t1, s_t2]`I have tried to rewrite it with tensorflow:`import numpy as np, tensorflow as tf, operatordef forward_prop_step(x_t, s_t1_prev, s_t2_prev):                        # This is how we calculated the hidden state in a simple RNN. No longer!                        # s_t = T.tanh(U[:,x_t] + W.dot(s_t1_prev))                        # Word embedding layer                        x_e = E[:,x_t]                        # GRU Layer 1                        z_t1 = tf.nn.sigmoid(tf.reduce_sum(tf.multiply(U[0], x_e)) + tf.reduce_sum(tf.multiply(W[0], s_t1_prev)) + b[0])                        r_t1 = tf.nn.sigmoid(tf.reduce_sum(tf.multiply(U[1], x_e)) + tf.reduce_sum(tf.multiply(W[1], s_t1_prev)) + b[1])                        c_t1 = tf.nn.tanh(tf.reduce_sum(tf.multiply(U[2], x_e)) + tf.reduce_sum(tf.multiply(W[2], (s_t1_prev * r_t1))) + b[2])                        s_t1 = (tf.ones_like(z_t1) - z_t1) * c_t1 + z_t1 * s_t1_prev                        # GRU Layer 2                        z_t2 = tf.nn.sigmoid(tf.reduce_sum(tf.multiply(U[3], s_t1)) + tf.reduce_sum(tf.multiply(W[3], s_t2_prev)) + b[3])                        r_t2 = tf.nn.sigmoid(tf.reduce_sum(tf.multiply(U[4], s_t1)) + tf.reduce_sum(tf.multiply(W[4], s_t2_prev)) + b[4])                        c_t2 = tf.nn.tanh(tf.reduce_sum(tf.multiply(U[5], s_t1)) + tf.reduce_sum(tf.multiply(W[5], (s_t2_prev * r_t2))) + b[5])                        s_t2 = (tf.ones_like(z_t2) - z_t2) * c_t2 + z_t2 * s_t2_prev                        # Final output calculation                        # Tensorflow's softmax returns a matrix with one row, we only need the row                        o_t = tf.nn.softmax(tf.reduce_sum(tf.multiply(V, s_t2)) + c)[0]                        return [o_t, s_t1, s_t2]`In theano, scan function is called to perform "forward_prep_step" function in a loop:`[o, s, s2], updates = theano.scan(            forward_prop_step,            sequences=x,            truncate_gradient=self.bptt_truncate,            outputs_info=[None,                           dict(initial=T.zeros(self.hidden_dim)),dict(initial=T.zeros(self.hidden_dim))])`There is a scan function in tensorflow as well, but they don't get the same parameters. How could be the transformation of scan function above, into tensorflow scan function?
support	Create kernel failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]()iPhone6 und tensorflow/tensorflow/contrib/ios_examples/simple/I have this Error! Hife!2017-04-25 18:19:07.181759: I /Users/liyong/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:149] Session created.2017-04-25 18:19:07.181966: I /Users/liyong/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:152] Graph created.2017-04-25 18:19:07.642122: I /Users/liyong/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:157] Creating session.2017-04-25 18:19:08.422609: E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]().  Registered:  2017-04-25 18:19:08.422813: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]().  Registered:   [[Node: _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]2017-04-25 18:19:08.425927: E /Users/liyong/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/simple/RunModelViewController.mm:221] Running model failed: Not found: No registered '_Arg' OpKernel for CPU devices compatible with node _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]().  Registered:   [[Node: _arg_input_0_0 = _Arg[T=DT_FLOAT, index=0, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]2017-04-25 18:19:08.426901: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BatchToSpace" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "crops"')2017-04-25 18:19:08.426969: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BatchToSpace" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "crops"')2017-04-25 18:19:08.427017: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SpaceToBatch" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tpaddings" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "paddings"')2017-04-25 18:19:08.427041: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SpaceToBatch" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tpaddings" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "paddings"')2017-04-25 18:19:08.427073: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Requantize" device_type: "CPU" constraint { name: "Tinput" allowed_values { list { type: DT_QINT32 } } } constraint { name: "out_type" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.427122: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RequantizationRange" device_type: "CPU" constraint { name: "Tinput" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.427146: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedReshape" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: "shape"')2017-04-25 18:19:08.427166: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedReshape" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: "shape"')2017-04-25 18:19:08.427186: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedMaxPool" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.427206: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedAvgPool" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.427371: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedMul" device_type: "CPU" constraint { name: "T1" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "T2" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "Toutput" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.427407: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedMatMul" device_type: "CPU" constraint { name: "T1" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "T2" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "Toutput" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.427452: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedInstanceNorm" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.427646: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedBiasAdd" device_type: "CPU" constraint { name: "T1" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "T2" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "out_type" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.427697: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedBiasAdd" device_type: "CPU" constraint { name: "T1" allowed_values { list { type: DT_QINT8 } } } constraint { name: "T2" allowed_values { list { type: DT_QINT8 } } } constraint { name: "out_type" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.427737: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedRelu6" device_type: "CPU" constraint { name: "Tinput" allowed_values { list { type: DT_QINT32 } } } constraint { name: "out_type" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.427760: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedRelu6" device_type: "CPU" constraint { name: "Tinput" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "out_type" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.428026: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedRelu" device_type: "CPU" constraint { name: "Tinput" allowed_values { list { type: DT_QINT32 } } } constraint { name: "out_type" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.428054: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedRelu" device_type: "CPU" constraint { name: "Tinput" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "out_type" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.428077: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizeV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.428098: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizeV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT8 } } }')2017-04-25 18:19:08.428270: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizeV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT16 } } }')2017-04-25 18:19:08.428319: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizeV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT16 } } }')2017-04-25 18:19:08.428341: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizeV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.428366: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizeDownAndShrinkRange" device_type: "CPU" constraint { name: "Tinput" allowed_values { list { type: DT_QINT32 } } } constraint { name: "out_type" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.428461: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "AddN" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.428482: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "AddN" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.428502: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ArgMin" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "dimension"')2017-04-25 18:19:08.428543: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ArgMin" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "dimension"')2017-04-25 18:19:08.428564: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ArgMax" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "dimension"')2017-04-25 18:19:08.428653: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ArgMax" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "dimension"')2017-04-25 18:19:08.428676: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "AvgPoolGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "orig_input_shape"')2017-04-25 18:19:08.428695: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "AvgPool" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.428732: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "AvgPool" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_HALF } } }')2017-04-25 18:19:08.428755: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BatchNormWithGlobalNormalizationGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.428892: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BroadcastGradientArgs" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "s0" host_memory_arg: "s1" host_memory_arg: "r0" host_memory_arg: "r1"')2017-04-25 18:19:08.429034: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BroadcastGradientArgs" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "s0" host_memory_arg: "s1" host_memory_arg: "r0" host_memory_arg: "r1"')2017-04-25 18:19:08.429056: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_HostCast" device_type: "GPU" host_memory_arg: "x" host_memory_arg: "y"')2017-04-25 18:19:08.429090: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_HostCast" device_type: "CPU"')2017-04-25 18:19:08.429238: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ConcatOffset" device_type: "GPU" host_memory_arg: "concat_dim" host_memory_arg: "shape" host_memory_arg: "offset"')2017-04-25 18:19:08.429406: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ConcatOffset" device_type: "CPU"')2017-04-25 18:19:08.429433: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ConcatV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "axis"')2017-04-25 18:19:08.429456: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ConcatV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "axis"')2017-04-25 18:19:08.429564: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ConcatV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "axis"')2017-04-25 18:19:08.429815: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ConcatV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT8 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "axis"')2017-04-25 18:19:08.429871: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ConcatV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT16 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "axis"')2017-04-25 18:19:08.429896: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ConcatV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT16 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "axis"')2017-04-25 18:19:08.429920: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ConcatV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT32 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "axis"')2017-04-25 18:19:08.429997: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ConcatV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "axis"')2017-04-25 18:19:08.430316: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Placeholder" device_type: "GPU"')2017-04-25 18:19:08.430334: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "PlaceholderV2" device_type: "CPU"')2017-04-25 18:19:08.430365: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Placeholder" device_type: "CPU"')2017-04-25 18:19:08.430412: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "OnesLike" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.430511: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "OnesLike" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.430535: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ZerosLike" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.430554: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ZerosLike" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.430595: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Fill" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "dims"')2017-04-25 18:19:08.430616: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Fill" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "dims"')2017-04-25 18:19:08.430636: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Fill" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: "dims"')2017-04-25 18:19:08.430714: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Const" device_type: "CPU"')2017-04-25 18:19:08.430737: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BatchNormWithGlobalNormalization" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.430753: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Abort" device_type: "CPU"')2017-04-25 18:19:08.430769: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ControlTrigger" device_type: "CPU"')2017-04-25 18:19:08.430784: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "LoopCond" device_type: "CPU"')2017-04-25 18:19:08.430821: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefNextIteration" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.430940: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefNextIteration" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } }')2017-04-25 18:19:08.430963: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefNextIteration" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.431032: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefNextIteration" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.431109: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefNextIteration" device_type: "CPU"')2017-04-25 18:19:08.431125: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "NextIteration" device_type: "CPU"')2017-04-25 18:19:08.431145: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefExit" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.431254: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefExit" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.431387: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefEnter" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.431408: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefEnter" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } }')2017-04-25 18:19:08.431428: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefEnter" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.431572: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefEnter" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.431596: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Enter" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.431616: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Enter" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } }')2017-04-25 18:19:08.431635: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Enter" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.431705: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Enter" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.431957: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Enter" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_RESOURCE } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.431988: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefMerge" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "value_index"')2017-04-25 18:19:08.432009: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefMerge" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } } host_memory_arg: "value_index"')2017-04-25 18:19:08.432030: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefMerge" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "inputs" host_memory_arg: "output" host_memory_arg: "value_index"')2017-04-25 18:19:08.432252: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefMerge" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } host_memory_arg: "inputs" host_memory_arg: "output" host_memory_arg: "value_index"')2017-04-25 18:19:08.432286: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefMerge" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_RESOURCE } } } host_memory_arg: "inputs" host_memory_arg: "output" host_memory_arg: "value_index"')2017-04-25 18:19:08.432304: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ControlTrigger" device_type: "GPU"')2017-04-25 18:19:08.432322: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Merge" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "value_index"')2017-04-25 18:19:08.432342: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Merge" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } } host_memory_arg: "value_index"')2017-04-25 18:19:08.432558: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Merge" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "inputs" host_memory_arg: "output" host_memory_arg: "value_index"')2017-04-25 18:19:08.432584: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Merge" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } host_memory_arg: "inputs" host_memory_arg: "output" host_memory_arg: "value_index"')2017-04-25 18:19:08.432607: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Merge" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_RESOURCE } } } host_memory_arg: "inputs" host_memory_arg: "output" host_memory_arg: "value_index"')2017-04-25 18:19:08.432624: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefMerge" device_type: "CPU"')2017-04-25 18:19:08.432883: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Merge" device_type: "CPU"')2017-04-25 18:19:08.432955: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefSelect" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "index"')2017-04-25 18:19:08.433006: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefSelect" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "index"')2017-04-25 18:19:08.433030: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefSwitch" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "pred"')2017-04-25 18:19:08.433053: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefSwitch" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "data" host_memory_arg: "pred" host_memory_arg: "output_false" host_memory_arg: "output_true"')2017-04-25 18:19:08.433164: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefSwitch" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } } host_memory_arg: "data" host_memory_arg: "pred" host_memory_arg: "output_false" host_memory_arg: "output_true"')2017-04-25 18:19:08.433683: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefSwitch" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } host_memory_arg: "data" host_memory_arg: "pred" host_memory_arg: "output_false" host_memory_arg: "output_true"')2017-04-25 18:19:08.433715: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Switch" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "pred"')2017-04-25 18:19:08.433829: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Switch" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "data" host_memory_arg: "pred" host_memory_arg: "output_false" host_memory_arg: "output_true"')2017-04-25 18:19:08.434041: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Switch" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } } host_memory_arg: "data" host_memory_arg: "pred" host_memory_arg: "output_false" host_memory_arg: "output_true"')2017-04-25 18:19:08.434068: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Switch" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } host_memory_arg: "data" host_memory_arg: "pred" host_memory_arg: "output_false" host_memory_arg: "output_true"')2017-04-25 18:19:08.434091: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefSwitch" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "pred"')2017-04-25 18:19:08.434111: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefSwitch" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "pred"')2017-04-25 18:19:08.434243: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Switch" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "pred"')2017-04-25 18:19:08.434264: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Switch" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "pred"')2017-04-25 18:19:08.434285: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Conv2DBackpropInput" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } label: "eigen_tensor"')2017-04-25 18:19:08.434305: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Conv2DBackpropInput" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } label: "custom"')2017-04-25 18:19:08.434443: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Conv2DBackpropInput" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.434466: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Conv2DBackpropFilter" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } label: "eigen_tensor"')2017-04-25 18:19:08.434487: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedConcat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: "concat_dim"')2017-04-25 18:19:08.434526: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedConcat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: "concat_dim"')2017-04-25 18:19:08.434567: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Conv2DBackpropFilter" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } label: "custom"')2017-04-25 18:19:08.434641: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Conv2DBackpropFilter" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.434662: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FusedPadConv2D" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.434682: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FusedResizeAndPadConv2D" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.434703: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "CropAndResizeGradImage" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "image_size"')2017-04-25 18:19:08.434757: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "PlaceholderV2" device_type: "GPU"')2017-04-25 18:19:08.434835: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "CropAndResizeGradBoxes" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.434856: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "CropAndResizeGradBoxes" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.434876: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "CropAndResize" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "crop_size"')2017-04-25 18:19:08.434896: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "CropAndResize" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "crop_size"')2017-04-25 18:19:08.434942: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "CTCGreedyDecoder" device_type: "CPU"')2017-04-25 18:19:08.435029: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BiasAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.435049: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BiasAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435068: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Add" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435087: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RealDiv" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435158: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Div" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435178: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Div" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_UINT8 } } }')2017-04-25 18:19:08.435247: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApproximateEqual" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435268: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApproximateEqual" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } }')2017-04-25 18:19:08.435287: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Equal" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435306: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Greater" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435341: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GreaterEqual" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435490: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "IsFinite" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435511: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Less" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435643: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SpaceToBatchND" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tblock_shape" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tpaddings" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "block_shape" host_memory_arg: "paddings"')2017-04-25 18:19:08.435674: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SpaceToBatchND" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tblock_shape" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tpaddings" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "block_shape" host_memory_arg: "paddings"')2017-04-25 18:19:08.435743: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Log" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435784: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "LogicalNot" device_type: "CPU"')2017-04-25 18:19:08.435917: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Minimum" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435940: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Mul" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.435958: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Mul" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.436025: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ReciprocalGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436045: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "InvGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436083: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RsqrtGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436104: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BroadcastArgs" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "s0" host_memory_arg: "s1" host_memory_arg: "r0"')2017-04-25 18:19:08.436124: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Rsqrt" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436273: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Select" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.436327: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Select" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436346: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Sign" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436365: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SigmoidGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436418: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Sigmoid" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436482: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Sqrt" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436540: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SquaredDifference" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "x" host_memory_arg: "y" host_memory_arg: "z"')2017-04-25 18:19:08.436564: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SquaredDifference" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436582: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Sub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436601: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Sub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.436663: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TanhGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436684: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "AssignSub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.436702: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "AssignSub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436836: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "AssignAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.436859: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "AssignAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.436879: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SpaceToDepth" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.437030: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SpaceToDepth" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.437089: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "DepthToSpace" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.437110: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "DepthToSpace" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.437128: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Reciprocal" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.437147: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "DynamicPartition" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.437211: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "DynamicPartition" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.437232: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "DynamicStitch" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "indices"')2017-04-25 18:19:08.437252: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "DynamicStitch" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "indices"')2017-04-25 18:19:08.437271: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FakeQuantWithMinMaxVarsPerChannelGradient" device_type: "CPU"')2017-04-25 18:19:08.437289: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FakeQuantWithMinMaxVarsPerChannel" device_type: "CPU"')2017-04-25 18:19:08.437305: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FakeQuantWithMinMaxVarsGradient" device_type: "CPU"')2017-04-25 18:19:08.437432: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FakeQuantWithMinMaxVars" device_type: "CPU"')2017-04-25 18:19:08.437452: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FakeQuantWithMinMaxArgsGradient" device_type: "CPU"')2017-04-25 18:19:08.437471: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FusedBatchNormGrad" device_type: "CPU"')2017-04-25 18:19:08.437488: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FusedBatchNorm" device_type: "CPU"')2017-04-25 18:19:08.437509: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Gather" device_type: "CPU" constraint { name: "Tparams" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.437550: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Gather" device_type: "CPU" constraint { name: "Tparams" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.437687: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Gather" device_type: "CPU" constraint { name: "Tparams" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.437809: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Gather" device_type: "CPU" constraint { name: "Tparams" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.437834: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "DepthwiseConv2dNative" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.437854: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StopGradient" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.438011: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StopGradient" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } }')2017-04-25 18:19:08.438050: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Dequantize" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.438072: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Dequantize" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT8 } } }')2017-04-25 18:19:08.438091: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Dequantize" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT16 } } }')2017-04-25 18:19:08.438109: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Dequantize" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT16 } } }')2017-04-25 18:19:08.438176: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Dequantize" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.438198: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "PreventGradient" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.438217: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "PreventGradient" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } }')2017-04-25 18:19:08.438237: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Identity" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.438256: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Identity" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } }')2017-04-25 18:19:08.438379: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefIdentity" device_type: "CPU"')2017-04-25 18:19:08.438397: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "PreventGradient" device_type: "CPU"')2017-04-25 18:19:08.438413: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StopGradient" device_type: "CPU"')2017-04-25 18:19:08.438428: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Identity" device_type: "CPU"')2017-04-25 18:19:08.438465: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "InTopK" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.438483: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "InTopK" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.438502: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ParallelConcat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.438573: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ParallelConcat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.438595: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_ParallelConcatStart" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.438614: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_ParallelConcatStart" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.438633: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefIdentity" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.438683: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefIdentity" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } }')2017-04-25 18:19:08.438841: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ParseSingleSequenceExample" device_type: "CPU"')2017-04-25 18:19:08.438870: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_ParallelConcatUpdate" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.438946: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_ParallelConcatUpdate" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.438964: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Print" device_type: "CPU"')2017-04-25 18:19:08.439073: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Assert" device_type: "CPU"')2017-04-25 18:19:08.439105: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "LRN" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.439127: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MatMul" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } label: "eigen"')2017-04-25 18:19:08.439310: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MatMul" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } label: "eigen"')2017-04-25 18:19:08.439333: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Assign" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.439386: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Assign" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.439416: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MatMul" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.439434: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MatMul" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.439506: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MaxPoolGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.439527: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MaxPoolGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.439622: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MaxPool" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.439661: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MaxPool" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.439690: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MirrorPad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tpaddings" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "paddings"')2017-04-25 18:19:08.439883: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MirrorPad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tpaddings" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "paddings"')2017-04-25 18:19:08.439906: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "NonMaxSuppression" device_type: "CPU"')2017-04-25 18:19:08.440020: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "OneHot" device_type: "CPU" constraint { name: "TI" allowed_values { list { type: DT_UINT8 } } } constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "depth"')2017-04-25 18:19:08.440046: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "OneHot" device_type: "CPU" constraint { name: "TI" allowed_values { list { type: DT_INT32 } } } constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "depth"')2017-04-25 18:19:08.440219: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "OneHot" device_type: "CPU" constraint { name: "TI" allowed_values { list { type: DT_INT64 } } } constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "depth"')2017-04-25 18:19:08.440246: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "OneHot" device_type: "CPU" constraint { name: "TI" allowed_values { list { type: DT_UINT8 } } } constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "depth"')2017-04-25 18:19:08.440287: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "OneHot" device_type: "CPU" constraint { name: "TI" allowed_values { list { type: DT_INT32 } } } constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "depth"')2017-04-25 18:19:08.440312: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "OneHot" device_type: "CPU" constraint { name: "TI" allowed_values { list { type: DT_INT64 } } } constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "depth"')2017-04-25 18:19:08.440423: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Pack" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.440443: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Pack" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.440490: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Pack" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } }')2017-04-25 18:19:08.440516: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Pad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "paddings"')2017-04-25 18:19:08.440536: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Pad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "paddings"')2017-04-25 18:19:08.440611: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyMomentum" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var" host_memory_arg: "accum"')2017-04-25 18:19:08.440629: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "PaddingFIFOQueue" device_type: "CPU"')2017-04-25 18:19:08.440645: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FakeQueue" device_type: "CPU"')2017-04-25 18:19:08.440660: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Cast" device_type: "CPU"')2017-04-25 18:19:08.440676: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueClose" device_type: "CPU"')2017-04-25 18:19:08.440708: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "PaddingFIFOQueueV2" device_type: "CPU"')2017-04-25 18:19:08.440861: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueDequeueUpToV2" device_type: "CPU"')2017-04-25 18:19:08.440898: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueDequeueUpTo" device_type: "CPU"')2017-04-25 18:19:08.440921: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayWriteV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.440941: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayWriteV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.440958: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueDequeueV2" device_type: "CPU"')2017-04-25 18:19:08.440974: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueEnqueueManyV2" device_type: "CPU"')2017-04-25 18:19:08.440989: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueEnqueueMany" device_type: "CPU"')2017-04-25 18:19:08.441050: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueEnqueueV2" device_type: "CPU"')2017-04-25 18:19:08.441075: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Softsign" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.441128: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Softsign" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.441152: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyFtrl" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.441176: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyFtrl" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.441248: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StackPush" device_type: "CPU"')2017-04-25 18:19:08.441265: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueEnqueue" device_type: "CPU"')2017-04-25 18:19:08.441285: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Any" device_type: "CPU" constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "reduction_indices"')2017-04-25 18:19:08.441425: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Max" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.441451: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Max" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.441621: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BatchToSpaceND" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tblock_shape" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tcrops" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "block_shape" host_memory_arg: "crops"')2017-04-25 18:19:08.441651: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BatchToSpaceND" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tblock_shape" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tcrops" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "block_shape" host_memory_arg: "crops"')2017-04-25 18:19:08.441675: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Mean" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.441820: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Mean" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.441847: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TopKV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.441867: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TopKV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.441887: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Min" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442038: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Min" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442185: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Prod" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442209: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Prod" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442226: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefExit" device_type: "CPU"')2017-04-25 18:19:08.442246: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Sum" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442384: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Sum" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442414: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_HALF } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442439: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_HALF } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.442463: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442627: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.442671: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442697: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.442718: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "EluGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.442784: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Relu6Grad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442868: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Relu6Grad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.442891: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Relu6" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.442928: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Relu6" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.442950: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ReluGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.443026: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ReluGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.443044: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ImmutableConst" device_type: "CPU"')2017-04-25 18:19:08.443063: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Relu" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.443082: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Relu" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.443220: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "FakeQuantWithMinMaxArgs" device_type: "CPU"')2017-04-25 18:19:08.443244: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Reshape" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tshape" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "shape"')2017-04-25 18:19:08.443407: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Reshape" device_type: "CPU" constraint { name: "Tshape" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "shape"')2017-04-25 18:19:08.443445: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySizeV2" device_type: "CPU"')2017-04-25 18:19:08.443462: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayCloseV3" device_type: "CPU"')2017-04-25 18:19:08.443478: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueCloseV2" device_type: "CPU"')2017-04-25 18:19:08.443497: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResizeBilinearGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.443518: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResizeNearestNeighborGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "size"')2017-04-25 18:19:08.443584: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResizeNearestNeighborGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "size"')2017-04-25 18:19:08.443606: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResizeNearestNeighbor" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "size"')2017-04-25 18:19:08.443626: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResizeNearestNeighbor" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "size"')2017-04-25 18:19:08.443643: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RestoreSlice" device_type: "CPU"')2017-04-25 18:19:08.443904: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Concat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "concat_dim"')2017-04-25 18:19:08.443960: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Concat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "concat_dim"')2017-04-25 18:19:08.443980: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Concat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: "concat_dim"')2017-04-25 18:19:08.443999: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Concat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT8 } } } host_memory_arg: "concat_dim"')2017-04-25 18:19:08.444017: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Concat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT16 } } } host_memory_arg: "concat_dim"')2017-04-25 18:19:08.444179: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Concat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT16 } } } host_memory_arg: "concat_dim"')2017-04-25 18:19:08.444209: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Concat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: "concat_dim"')2017-04-25 18:19:08.444230: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Concat" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: "concat_dim"')2017-04-25 18:19:08.444255: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "InvertPermutation" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "x" host_memory_arg: "y"')2017-04-25 18:19:08.444278: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Reverse" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "dims"')2017-04-25 18:19:08.444480: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Reverse" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "dims"')2017-04-25 18:19:08.444526: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ReverseSequence" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tlen" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.444581: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ReverseSequence" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tlen" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.444604: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ReverseSequence" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tlen" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.444692: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ReverseSequence" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tlen" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.444711: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SaveSlices" device_type: "CPU"')2017-04-25 18:19:08.444726: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Save" device_type: "CPU"')2017-04-25 18:19:08.444742: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayClose" device_type: "CPU"')2017-04-25 18:19:08.444825: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MergeV2Checkpoints" device_type: "CPU"')2017-04-25 18:19:08.444842: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RestoreV2" device_type: "CPU"')2017-04-25 18:19:08.444904: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SaveV2" device_type: "CPU"')2017-04-25 18:19:08.444921: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ParseExample" device_type: "CPU"')2017-04-25 18:19:08.444986: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "shape"')2017-04-25 18:19:08.445011: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } } host_memory_arg: "shape"')2017-04-25 18:19:08.445035: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "shape"')2017-04-25 18:19:08.445244: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } } host_memory_arg: "shape"')2017-04-25 18:19:08.445271: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdUpdate" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.445294: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdUpdate" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.445316: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdUpdate" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.445471: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdUpdate" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.445529: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyMomentum" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.445554: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyMomentum" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.445704: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterSub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.445730: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterSub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.445752: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterSub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.445775: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterSub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.445943: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterDiv" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.445968: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterDiv" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.445990: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterDiv" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.446029: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterDiv" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.446317: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Size" device_type: "CPU" constraint { name: "out_type" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "output"')2017-04-25 18:19:08.446342: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Size" device_type: "CPU" constraint { name: "out_type" allowed_values { list { type: DT_INT64 } } } host_memory_arg: "output"')2017-04-25 18:19:08.446363: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.446400: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.446534: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.446557: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.446647: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.446689: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.446774: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.446904: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdAdd" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.446926: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_Recv" device_type: "CPU"')2017-04-25 18:19:08.446944: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_HostSend" device_type: "GPU" host_memory_arg: "tensor"')2017-04-25 18:19:08.446964: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyAdadelta" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.447107: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.447136: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.447154: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_Send" device_type: "GPU"')2017-04-25 18:19:08.447285: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "LinSpace" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "start" host_memory_arg: "stop" host_memory_arg: "num" host_memory_arg: "output"')2017-04-25 18:19:08.447357: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.447429: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_HostRecv" device_type: "GPU" host_memory_arg: "tensor"')2017-04-25 18:19:08.447454: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "LinSpace" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "start" host_memory_arg: "stop" host_memory_arg: "num" host_memory_arg: "output"')2017-04-25 18:19:08.447479: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Range" device_type: "CPU" constraint { name: "Tidx" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "start" host_memory_arg: "limit" host_memory_arg: "delta" host_memory_arg: "output"')2017-04-25 18:19:08.447722: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Range" device_type: "CPU" constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "start" host_memory_arg: "limit" host_memory_arg: "delta" host_memory_arg: "output"')2017-04-25 18:19:08.447744: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_HostRecv" device_type: "CPU"')2017-04-25 18:19:08.447761: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "DeleteSessionTensor" device_type: "CPU"')2017-04-25 18:19:08.447781: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionTensor" device_type: "GPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "handle"')2017-04-25 18:19:08.447801: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionTensor" device_type: "GPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "handle"')2017-04-25 18:19:08.447984: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionTensor" device_type: "GPU" constraint { name: "dtype" allowed_values { list { type: DT_BOOL } } } host_memory_arg: "handle"')2017-04-25 18:19:08.448005: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionTensor" device_type: "CPU"')2017-04-25 18:19:08.448024: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionHandleV2" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "handle"')2017-04-25 18:19:08.448063: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionHandleV2" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "handle"')2017-04-25 18:19:08.448086: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionHandleV2" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } } host_memory_arg: "handle"')2017-04-25 18:19:08.448162: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionHandle" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "handle"')2017-04-25 18:19:08.448184: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionHandle" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "handle"')2017-04-25 18:19:08.448204: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionHandle" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } } host_memory_arg: "handle"')2017-04-25 18:19:08.448287: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_Recv" device_type: "GPU"')2017-04-25 18:19:08.448331: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionHandleV2" device_type: "CPU"')2017-04-25 18:19:08.448352: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterMul" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.448536: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterMul" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.448562: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterMul" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.448583: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterMul" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.448746: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Rank" device_type: "CPU" host_memory_arg: "output"')2017-04-25 18:19:08.448769: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ShapeN" device_type: "CPU" constraint { name: "out_type" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "output"')2017-04-25 18:19:08.448789: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ShapeN" device_type: "CPU" constraint { name: "out_type" allowed_values { list { type: DT_INT64 } } } host_memory_arg: "output"')2017-04-25 18:19:08.448806: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "VariableV2" device_type: "CPU"')2017-04-25 18:19:08.448855: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Shape" device_type: "CPU" constraint { name: "out_type" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "output"')2017-04-25 18:19:08.448879: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Shape" device_type: "CPU" constraint { name: "out_type" allowed_values { list { type: DT_INT64 } } } host_memory_arg: "output"')2017-04-25 18:19:08.448982: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "LogSoftmax" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.449110: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Softmax" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.449132: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "CheckNumerics" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.449151: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SoftplusGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.449170: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SoftplusGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.449348: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Slice" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "begin" host_memory_arg: "size"')2017-04-25 18:19:08.449390: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Slice" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "begin" host_memory_arg: "size"')2017-04-25 18:19:08.449435: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Slice" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: "begin" host_memory_arg: "size"')2017-04-25 18:19:08.449456: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SoftsignGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.449475: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SoftsignGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.449545: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedConv2D" device_type: "CPU" constraint { name: "Tinput" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "Tfilter" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "out_type" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.449591: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseMatMul" device_type: "CPU" constraint { name: "Ta" allowed_values { list { type: DT_BFLOAT16 } } } constraint { name: "Tb" allowed_values { list { type: DT_BFLOAT16 } } }')2017-04-25 18:19:08.449613: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseMatMul" device_type: "CPU" constraint { name: "Ta" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tb" allowed_values { list { type: DT_BFLOAT16 } } }')2017-04-25 18:19:08.449867: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseMatMul" device_type: "CPU" constraint { name: "Ta" allowed_values { list { type: DT_BFLOAT16 } } } constraint { name: "Tb" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.449894: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseMatMul" device_type: "CPU" constraint { name: "Ta" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tb" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.449916: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayReadV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.449940: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayReadV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.449957: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueDequeueMany" device_type: "CPU"')2017-04-25 18:19:08.450118: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseToDense" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.450145: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseToDense" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.450167: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseToDense" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.450190: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseToDense" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.450369: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseToDense" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.450395: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseToDense" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.450449: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseToDense" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.450473: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseToDense" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.450578: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StackClose" device_type: "GPU" host_memory_arg: "handle"')2017-04-25 18:19:08.450602: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StackPop" device_type: "GPU" constraint { name: "elem_type" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "handle"')2017-04-25 18:19:08.450647: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StackPop" device_type: "GPU" constraint { name: "elem_type" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "handle" host_memory_arg: "elem"')2017-04-25 18:19:08.450671: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StackPop" device_type: "GPU" constraint { name: "elem_type" allowed_values { list { type: DT_BOOL } } } host_memory_arg: "handle" host_memory_arg: "elem"')2017-04-25 18:19:08.450760: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Stack" device_type: "GPU" host_memory_arg: "handle"')2017-04-25 18:19:08.450778: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ShardedFilespec" device_type: "CPU"')2017-04-25 18:19:08.450794: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Stack" device_type: "CPU"')2017-04-25 18:19:08.450813: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Exit" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.450862: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Exit" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } }')2017-04-25 18:19:08.450895: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Exit" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.450916: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Exit" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.450978: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StackPop" device_type: "CPU"')2017-04-25 18:19:08.451002: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StridedSliceGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "shape" host_memory_arg: "begin" host_memory_arg: "end" host_memory_arg: "strides"')2017-04-25 18:19:08.451070: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StridedSliceGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "shape" host_memory_arg: "begin" host_memory_arg: "end" host_memory_arg: "strides"')2017-04-25 18:19:08.451101: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StridedSliceGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: "shape" host_memory_arg: "begin" host_memory_arg: "end" host_memory_arg: "strides"')2017-04-25 18:19:08.451181: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayCloseV3" device_type: "GPU" host_memory_arg: "handle"')2017-04-25 18:19:08.451357: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayCloseV2" device_type: "GPU" host_memory_arg: "handle"')2017-04-25 18:19:08.451381: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Square" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.451398: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayClose" device_type: "GPU" host_memory_arg: "handle"')2017-04-25 18:19:08.451431: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayCloseV2" device_type: "CPU"')2017-04-25 18:19:08.452321: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "NoOp" device_type: "GPU"')2017-04-25 18:19:08.452347: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySizeV2" device_type: "GPU" host_memory_arg: "handle" host_memory_arg: "size"')2017-04-25 18:19:08.452406: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySizeV3" device_type: "CPU"')2017-04-25 18:19:08.452446: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySplitV3" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.452489: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySplitV3" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.452511: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StridedSliceAssign" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "begin" host_memory_arg: "end" host_memory_arg: "strides"')2017-04-25 18:19:08.452774: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StridedSliceAssign" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "begin" host_memory_arg: "end" host_memory_arg: "strides"')2017-04-25 18:19:08.452800: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StridedSliceAssign" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: "begin" host_memory_arg: "end" host_memory_arg: "strides"')2017-04-25 18:19:08.452907: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StringJoin" device_type: "CPU"')2017-04-25 18:19:08.452928: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGradV2" device_type: "GPU" host_memory_arg: "handle" host_memory_arg: "grad_handle"')2017-04-25 18:19:08.452944: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueDequeue" device_type: "CPU"')2017-04-25 18:19:08.453024: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "PlaceholderWithDefault" device_type: "CPU"')2017-04-25 18:19:08.453041: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGrad" device_type: "CPU"')2017-04-25 18:19:08.453056: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "NoOp" device_type: "CPU"')2017-04-25 18:19:08.453072: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "CTCBeamSearchDecoder" device_type: "CPU"')2017-04-25 18:19:08.453109: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySplitV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.453132: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySplitV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.453169: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BiasAddGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.453236: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BiasAddGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.453259: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySplit" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.453364: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySplit" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.453411: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Neg" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.453431: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "NextIteration" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.453552: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "NextIteration" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } }')2017-04-25 18:19:08.453628: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "NextIteration" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.453649: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "NextIteration" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_STRING } } } host_memory_arg: "data" host_memory_arg: "output"')2017-04-25 18:19:08.453690: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdSub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.453798: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdSub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.453822: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdSub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.453943: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterNdSub" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.453968: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayScatterV3" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.454149: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayScatterV3" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.454176: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayUnpack" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.454195: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayUnpack" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.454246: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454279: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454347: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454370: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT8 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454391: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454460: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454567: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcat" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454590: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcat" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454611: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcat" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454651: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcat" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT8 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454745: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcat" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454768: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcat" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.454788: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.454808: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.454941: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.454963: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT8 } } }')2017-04-25 18:19:08.454982: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.455020: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_BFLOAT16 } } }')2017-04-25 18:19:08.455037: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Restore" device_type: "CPU"')2017-04-25 18:19:08.455061: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.455132: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.455156: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.455180: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.455322: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayScatterV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.455345: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayScatterV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.455370: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.455394: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.455419: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.455584: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.455609: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Unpack" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.455629: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Unpack" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.455726: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var"')2017-04-25 18:19:08.455794: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } host_memory_arg: "var"')2017-04-25 18:19:08.455815: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.455861: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.455894: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.455914: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT8 } } }')2017-04-25 18:19:08.455979: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.456000: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGatherV2" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_BFLOAT16 } } }')2017-04-25 18:19:08.456017: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArray" device_type: "CPU"')2017-04-25 18:19:08.456115: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ReverseV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "axis"')2017-04-25 18:19:08.456157: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ReverseV2" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tidx" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "axis"')2017-04-25 18:19:08.456293: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "IsVariableInitialized" device_type: "CPU"')2017-04-25 18:19:08.456316: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayPack" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.456405: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayPack" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.456426: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayPack" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.456445: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayPack" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT8 } } }')2017-04-25 18:19:08.456524: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayPack" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.456544: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayPack" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_BFLOAT16 } } }')2017-04-25 18:19:08.456565: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Elu" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.456627: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayWriteV3" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.456664: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayWriteV3" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.456725: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_Send" device_type: "CPU"')2017-04-25 18:19:08.456742: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "RefEnter" device_type: "CPU"')2017-04-25 18:19:08.456761: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayWrite" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.456901: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayWrite" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.456921: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGradV3" device_type: "GPU" host_memory_arg: "handle" host_memory_arg: "grad_handle"')2017-04-25 18:19:08.456940: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyAdam" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.457066: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGrad" device_type: "GPU" host_memory_arg: "handle" host_memory_arg: "grad_handle"')2017-04-25 18:19:08.457089: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Softplus" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.457108: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Softplus" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.457125: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGradV3" device_type: "CPU"')2017-04-25 18:19:08.457140: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGradV2" device_type: "CPU"')2017-04-25 18:19:08.457186: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayV3" device_type: "CPU"')2017-04-25 18:19:08.457283: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayV2" device_type: "CPU"')2017-04-25 18:19:08.457302: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TileGrad" device_type: "CPU" host_memory_arg: "multiples"')2017-04-25 18:19:08.457322: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGather" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.457341: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGather" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.457378: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGather" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QUINT8 } } }')2017-04-25 18:19:08.457401: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGather" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT8 } } }')2017-04-25 18:19:08.457480: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGather" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.457501: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayGather" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_BFLOAT16 } } }')2017-04-25 18:19:08.457594: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "LogicalAnd" device_type: "CPU"')2017-04-25 18:19:08.457640: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Exp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.457659: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySizeV3" device_type: "GPU" host_memory_arg: "handle" host_memory_arg: "size"')2017-04-25 18:19:08.457804: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Tile" device_type: "CPU" constraint { name: "Tmultiples" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "multiples"')2017-04-25 18:19:08.457828: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TopK" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.457848: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TopK" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.457871: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_HALF } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.457896: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_HALF } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.458022: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.458047: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.458071: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.458095: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.458247: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Pow" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.458274: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var" host_memory_arg: "mg" host_memory_arg: "ms" host_memory_arg: "mom"')2017-04-25 18:19:08.458296: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayReadV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.458316: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayReadV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.458439: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var" host_memory_arg: "ms" host_memory_arg: "mom"')2017-04-25 18:19:08.458478: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "LoopCond" device_type: "GPU" host_memory_arg: "input" host_memory_arg: "output"')2017-04-25 18:19:08.458495: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Variable" device_type: "CPU"')2017-04-25 18:19:08.458516: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var" host_memory_arg: "accum"')2017-04-25 18:19:08.458538: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } host_memory_arg: "var" host_memory_arg: "accum"')2017-04-25 18:19:08.458747: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SplitV" device_type: "CPU" constraint { name: "Tlen" allowed_values { list { type: DT_INT32 } } } constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "size_splits" host_memory_arg: "split_dim"')2017-04-25 18:19:08.458872: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SplitV" device_type: "CPU" constraint { name: "Tlen" allowed_values { list { type: DT_INT64 } } } constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "size_splits" host_memory_arg: "split_dim"')2017-04-25 18:19:08.459022: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SplitV" device_type: "CPU" constraint { name: "Tlen" allowed_values { list { type: DT_INT32 } } } constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "size_splits" host_memory_arg: "split_dim"')2017-04-25 18:19:08.459209: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SplitV" device_type: "CPU" constraint { name: "Tlen" allowed_values { list { type: DT_INT64 } } } constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "size_splits" host_memory_arg: "split_dim"')2017-04-25 18:19:08.459237: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SplitV" device_type: "CPU" constraint { name: "Tlen" allowed_values { list { type: DT_INT32 } } } constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: "size_splits" host_memory_arg: "split_dim"')2017-04-25 18:19:08.459361: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SplitV" device_type: "CPU" constraint { name: "Tlen" allowed_values { list { type: DT_INT64 } } } constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: "size_splits" host_memory_arg: "split_dim"')2017-04-25 18:19:08.459512: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyAdam" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var" host_memory_arg: "m" host_memory_arg: "v"')2017-04-25 18:19:08.459645: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueSize" device_type: "CPU"')2017-04-25 18:19:08.459665: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BiasAddV1" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.459684: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BiasAddV1" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.459723: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_HALF } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.459842: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_HALF } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.459867: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.459946: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.460054: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.460306: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.460357: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StackClose" device_type: "CPU"')2017-04-25 18:19:08.460379: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Maximum" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.460439: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyAdadelta" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.460704: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyAdadelta" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.460732: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyMomentum" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.460755: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyMomentum" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.460828: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterUpdate" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.461054: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterUpdate" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.461081: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterUpdate" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.461103: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ScatterUpdate" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.461126: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyAdadelta" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.461255: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyAdadelta" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.461278: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StackPush" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "handle"')2017-04-25 18:19:08.461299: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StackPush" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "handle" host_memory_arg: "elem" host_memory_arg: "output"')2017-04-25 18:19:08.461320: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StackPush" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_BOOL } } } host_memory_arg: "handle" host_memory_arg: "elem" host_memory_arg: "output"')2017-04-25 18:19:08.461451: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyMomentum" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.461475: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyFtrl" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.461499: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyFtrl" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.461610: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyFtrl" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var" host_memory_arg: "accum" host_memory_arg: "linear"')2017-04-25 18:19:08.461679: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.461699: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyFtrl" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.461762: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "var" host_memory_arg: "gradient_accumulator" host_memory_arg: "gradient_squared_accumulator"')2017-04-25 18:19:08.461793: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } } host_memory_arg: "var" host_memory_arg: "gradient_accumulator" host_memory_arg: "gradient_squared_accumulator"')2017-04-25 18:19:08.461868: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "var" host_memory_arg: "gradient_accumulator" host_memory_arg: "gradient_squared_accumulator"')2017-04-25 18:19:08.461896: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } } host_memory_arg: "var" host_memory_arg: "gradient_accumulator" host_memory_arg: "gradient_squared_accumulator"')2017-04-25 18:19:08.462044: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySize" device_type: "CPU"')2017-04-25 18:19:08.462124: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MaxPoolGradGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.462146: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MaxPoolGradGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.462211: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.462236: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.462395: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.462423: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.462447: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var" host_memory_arg: "gradient_accumulator" host_memory_arg: "gradient_squared_accumulator"')2017-04-25 18:19:08.462607: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } host_memory_arg: "var" host_memory_arg: "gradient_accumulator" host_memory_arg: "gradient_squared_accumulator"')2017-04-25 18:19:08.462708: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Tanh" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.462744: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Inv" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.462761: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Squeeze" device_type: "CPU"')2017-04-25 18:19:08.462779: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.462924: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyAdagradDA" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } }')2017-04-25 18:19:08.462947: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayRead" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.462967: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayRead" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.462984: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Enter" device_type: "CPU"')2017-04-25 18:19:08.463003: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var" host_memory_arg: "accum"')2017-04-25 18:19:08.463047: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.463166: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.463193: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.463264: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.463373: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "InvertPermutation" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.463398: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.463423: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.463518: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.463616: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SparseApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.463639: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.463677: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyProximalGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } }')2017-04-25 18:19:08.463716: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Exit" device_type: "CPU"')2017-04-25 18:19:08.463798: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueDequeueManyV2" device_type: "CPU"')2017-04-25 18:19:08.463819: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayScatter" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.463839: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayScatter" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.463879: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MirrorPadGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tpaddings" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "paddings"')2017-04-25 18:19:08.463921: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "MirrorPadGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tpaddings" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "paddings"')2017-04-25 18:19:08.464117: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyAdadelta" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var" host_memory_arg: "accum" host_memory_arg: "accum_update"')2017-04-25 18:19:08.464154: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "GetSessionHandle" device_type: "CPU"')2017-04-25 18:19:08.464174: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.464195: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.464343: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.464367: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT8 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.464388: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.464408: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArrayConcatV3" device_type: "CPU" constraint { name: "dtype" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: "lengths" host_memory_arg: "handle"')2017-04-25 18:19:08.464548: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.464567: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QueueSizeV2" device_type: "CPU"')2017-04-25 18:19:08.464604: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceApplyGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "var"')2017-04-25 18:19:08.464626: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SqrtGrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.464642: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "_HostSend" device_type: "CPU"')2017-04-25 18:19:08.464661: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Conv2D" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.464735: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResizeBilinear" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "size"')2017-04-25 18:19:08.464756: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResizeBilinear" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "size"')2017-04-25 18:19:08.464774: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TemporaryVariable" device_type: "CPU"')2017-04-25 18:19:08.464792: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ExpandDims" device_type: "CPU" constraint { name: "Tdim" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "dim"')2017-04-25 18:19:08.464844: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "DestroyTemporaryVariable" device_type: "CPU"')2017-04-25 18:19:08.464865: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TruncateDiv" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_UINT8 } } }')2017-04-25 18:19:08.464954: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.464976: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyProximalAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } }')2017-04-25 18:19:08.464992: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ShardedFilename" device_type: "CPU"')2017-04-25 18:19:08.465013: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "BroadcastArgs" device_type: "GPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "s0" host_memory_arg: "s1" host_memory_arg: "r0"')2017-04-25 18:19:08.465053: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Split" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "split_dim"')2017-04-25 18:19:08.465155: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Split" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "split_dim"')2017-04-25 18:19:08.465176: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Split" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: "split_dim"')2017-04-25 18:19:08.465193: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Where" device_type: "CPU"')2017-04-25 18:19:08.465299: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "SoftmaxCrossEntropyWithLogits" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.465323: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StridedSlice" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "begin" host_memory_arg: "end" host_memory_arg: "strides"')2017-04-25 18:19:08.465475: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StridedSlice" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: "begin" host_memory_arg: "end" host_memory_arg: "strides"')2017-04-25 18:19:08.465501: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "StridedSlice" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: "begin" host_memory_arg: "end" host_memory_arg: "strides"')2017-04-25 18:19:08.465527: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Transpose" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_INT32 } } } constraint { name: "Tperm" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "perm"')2017-04-25 18:19:08.465550: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Transpose" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tperm" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "perm"')2017-04-25 18:19:08.465676: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "Transpose" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_BFLOAT16 } } } constraint { name: "Tperm" allowed_values { list { type: DT_INT32 } } } host_memory_arg: "perm"')2017-04-25 18:19:08.465702: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.465726: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyAdagrad" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.465868: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_HALF } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.465895: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_HALF } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.465919: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.465973: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.466096: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT32 } } }')2017-04-25 18:19:08.466123: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ResourceSparseApplyCenteredRMSProp" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_DOUBLE } } } constraint { name: "Tindices" allowed_values { list { type: DT_INT64 } } }')2017-04-25 18:19:08.466248: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "ApplyGradientDescent" device_type: "CPU" constraint { name: "T" allowed_values { list { type: DT_FLOAT } } }')2017-04-25 18:19:08.466276: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "QuantizedBatchNormWithGlobalNormalization" device_type: "CPU" constraint { name: "Tinput" allowed_values { list { type: DT_QUINT8 } } } constraint { name: "out_type" allowed_values { list { type: DT_QINT32 } } }')2017-04-25 18:19:08.466431: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "TensorArraySize" device_type: "GPU" host_memory_arg: "handle" host_memory_arg: "size"')2017-04-25 18:19:08.466453: I tensorflow/core/framework/op_kernel.cc:996] OpKernel ('op: "DeleteSessionTensor" device_type: "GPU" host_memory_arg: "handle"')
support	dynamic_rnn: session.run with train_step behaves differently than train_step run aloneSystem information4.4.0-72-generic #93-Ubuntu SMP Fri Mar 31 14:07:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linuxvia pip1.0.0-65-g4763edf-dirty 1.0.1cuda-8.0 + cudnn-5.1.10GeForce GTX 760 + 1996MiBDescribe the problemConsider the following pieces of code:Variant 1loop:    feed_dict = {c_state: current_state.c, h_state: current_state.h, ...}    loss_sum, current_state, _ = sess.run([reduce_sum(loss), final_state, train_step], feed_dict=feed_dict)Variant 2loop:    feed_dict = {...}    loss_sum, current_state = sess.run([reduce_sum(loss), final_state], feed_dict=feed_dict)    train_step.run(feed_dict)Variant 3loop:    feed_dict = {...}    loss_sum, current_state = sess.run([reduce_sum(loss), final_state], feed_dict=feed_dict)    sess.run([train_step], feed_dict=feed_dict)Variant 1 breaks after a couple of iterations (15 in my case) by raising a "ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[200,10,25600]" exception whereas Variant 2 and Variant 3 do not.train_step is a minimize operation (optimizer doesn't matter) on a dynamic_rnn with a given initial_state and a single layer of LSTM cells.I cannot imagine the reason why Variant 1 needs more and more memory whereas the other both don't. Seems like something's wrong here.SO question: http://stackoverflow.com/questions/43620353/resourceexhaustederror-when-using-session-run-instead-of-train-step-run-in-a-loo
support	return type of `tf.reduce_any`I find that if the input tensor has type bool, the output of tf.reduce_any has type 'uint8'. My question is, why not bool? In the document, it says it is equivalent to np.any, but the latter return bool.Same applied to  tf.reduce_all.
support	graph_transforms tool obfuscate_names won't workSystem informationOS Platform and Distribution : Ubuntu 16.04GIT_VERSION: v1.1.0-rc0-61-g1ec6ed5Tensorflow Version: 1.1.0bazel-bin/tensorflow/tools/graph_transforms/transform_graph \--in_graph=MYMODEL.pb \--out_graph=MYMODEL_OPT.pb \--inputs='input_feed:0,Squeeze_1:0,lstm/state_feed:0' \--outputs='lstm/initial_state:0,softmax:0,lstm/state:0' \--transforms='  obfuscate_names'Bug: Model as follows (Inception V3) -> (LSTM)I used the graph_transform tool to obfuscate names using the obfuscate_names command for android deployment. model seems to work fine on android but when I try to obfuscate names problems start to surface.logsCaused by: java.io.IOException: Not a valid TensorFlow Graph serialization: Node 'rY' expects to be colocated with unknown node 'logits/biases'                                                                                 at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:392)                                                                                 at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:96)                                                                                 at com.example.thisismohit.local.MainActivity.onCreate(MainActivity.java:158)                                                                                  at android.app.Activity.performCreate(Activity.java:6283)                                                                                  at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1119)                                                                                  at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2646)                                                                                  at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2758)                                                                                  at android.app.ActivityThread.access$900(ActivityThread.java:177)                                                                                  at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1448)                                                                                  at android.os.Handler.dispatchMessage(Handler.java:102)                                                                                  at android.os.Looper.loop(Looper.java:145)                                                                                  at android.app.ActivityThread.main(ActivityThread.java:5942)                                                                                  at java.lang.reflect.Method.invoke(Native Method)                                                                                  at java.lang.reflect.Method.invoke(Method.java:372)                                                                                  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1400)                                                                                  at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:1195)
support	AttributeError: 'Tensor' object has no attribute '_displayhook'I'm running TensorFlow on Zeppelin with Python 3.5.2, the TensorFlow version is 1.0.1.It shows up AttributeError: 'Tensor' object has no attribute '_displayhook' error when I was running a Gaussian Distribution.import tensorflow as tfimport matplotlib.pyplot as pltn_values = 32x = tf.linspace(-3.0, 3.0, n_values)sigma = 1.0mean = 0.0a = tf.exp(tf.negative(tf.pow(x - mean, 2.0) / (2.0 * tf.pow(sigma, 2.0))))b = (sigma * tf.sqrt(2.0 * 3.1415))z = a / b
support	load a checkpoint and use it to create a new graphsystem information:I am using the latest Tensorflow code on Ubuntu 16.04problem:because the tensorflow SSD can't directly output the final bounding box that i want, so i want to use the orginal checkpoint to create my graph. But i failed, i really wish someone could help me!!! Thanks!!error:i get the error:Traceback (most recent call last):  File "haha.py", line 43, in <module>    select_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)  File "/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py", line 120, in ssd_bboxes_select    select_threshold, img_shape, num_classes, decode)  File "/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py", line 70, in ssd_bboxes_select_layer    localizations_layer = ssd_bboxes_decode(localizations_layer, anchors_layer)  File "/home/wahaha/documents/haha/SSD-Tensorflow-master/nets/np_methods.py", line 35, in ssd_bboxes_decode    (-1, l_shape[-2], l_shape[-1]))  File "/usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py", line 224, in reshape    return _wrapit(a, 'reshape', newshape, order=order)  File "/usr/lib/python2.7/dist-packages/numpy/core/fromnumeric.py", line 48, in _wrapit    result = getattr(asarray(obj), method)(*args, **kwds)ValueError: total size of new array must be unchangedSource codeimport osimport mathimport randomimport numpy as npimport tensorflow as tfslim = tf.contrib.slimimport matplotlib.image as mpimgimport syssys.path.append('../')from nets import ssd_vgg_300, ssd_common, np_methodsfrom preprocessing import ssd_vgg_preprocessinggpu_options = tf.GPUOptions(allow_growth=True)config = tf.ConfigProto(log_device_placement=False, gpu_options=gpu_options)with tf.Graph().as_default() as g:    with g.name_scope('haha'):net_shape = (300, 300)data_format = 'NHWC'select_threshold=0.5nms_threshold=.45# Create graphimage_input=tf.placeholder(tf.float32,shape=[None,None,3],name='input')height = image_input.shape[0]width = image_input.shape[1]image_pre, labels_pre, bboxes_pre, bbox_img = ssd_vgg_preprocessing.preprocess_for_eval(image_input, None, None, net_shape, data_format, resize=ssd_vgg_preprocessing.Resize.WARP_RESIZE)image_4d = tf.expand_dims(image_pre, 0)# Define the SSD model.reuse = True if 'ssd_net' in locals() else Nonessd_net = ssd_vgg_300.SSDNet()with slim.arg_scope(ssd_net.arg_scope(data_format=data_format)):predictions, localisations, _, _ = ssd_net.net(image_4d, is_training=False, reuse=reuse)ssd_anchors = ssd_net.anchors(net_shape)rclasses, rscores, rbboxes = np_methods.ssd_bboxes_select(predictions, localisations, ssd_anchors,select_threshold=select_threshold, img_shape=net_shape, num_classes=2, decode=True)    rbboxes = np_methods.bboxes_clip(rbbox_img, rbboxes)rclasses, rscores, rbboxes = np_methods.bboxes_sort(rclasses, rscores, rbboxes, top_k=400)rclasses, rscores, rbboxes = np_methods.bboxes_nms(rclasses, rscores, rbboxes, nms_threshold=nms_threshold)    # Resize bboxes to original image shape. Note: useless for Resize.WARP!rbboxes = np_methods.bboxes_resize(rbbox_img, rbboxes)temp=tf.stack([height,width,height,width])rbboxes=rbboxes*tempfacePredictions=rbboxessaver = tf.train.Saver()image_test=np.ones((500,500,3))with tf.Session(config=config) as sess:sess.run(tf.global_variables_initializer())saver.restore(sess, "/home/wahaha/documents/haha/SSD-Tensorflow-master/log/model.ckpt-50000")predictions_val=facePredictions.eval(feed_dict={image_input:image_test})output_graph_def = tf.graph_until.convert_variables_to_constants(sess, g.as_graph_def, output_node_names=['haha'])with tf.gfile.FastGFile(hahaFace.pb, mode = 'wb') as f:f.write(output_graph_def.SerializeToString())
support	Tensorflow inconsistence results every runPlease go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):OS Platform and Distribution (e.g., Linux Ubuntu 16.04):TensorFlow installed from (source or binary):TensorFlow version (use command below):Bazel version (if compiling from source):CUDA/cuDNN version:GPU model and memory:Exact command to reproduce:You can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.Source code / logsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
support	eval() error about variable_scope()I run the code from official tutorial:https://www.tensorflow.org/programmers_guide/variable_scopewith tf.variable_scope("foo", initializer=tf.constant_initializer(0.4)):    v = tf.get_variable("v", [1])    assert v.eval() == 0.4  # Default initializer as set above.    w = tf.get_variable("w", [1], initializer=tf.constant_initializer(0.3))    assert w.eval() == 0.3  # Specific initializer overrides the default.    with tf.variable_scope("bar"):        v = tf.get_variable("v", [1])        assert v.eval() == 0.4  # Inherited default initializer.    with tf.variable_scope("baz", initializer=tf.constant_initializer(0.2)):        v = tf.get_variable("v", [1])        assert v.eval() == 0.2  # Changed default initializerthe problem as below:Cannot evaluate tensor using eval(): No default session is registered. Use with sess.as_default() or pass an explicit session to eval(session=sess)with tf.Session():    with tf.variable_scope("foo", initializer=tf.constant_initializer(0.4)):        v = tf.get_variable("v", [1])        assert v.eval() == 0.4  # Default initializer as set above.        w = tf.get_variable("w", [1], initializer=tf.constant_initializer(0.3))        assert w.eval() == 0.3  # Specific initializer overrides the default.        with tf.variable_scope("bar"):            v = tf.get_variable("v", [1])            assert v.eval() == 0.4  # Inherited default initializer.        with tf.variable_scope("baz", initializer=tf.constant_initializer(0.2)):            v = tf.get_variable("v", [1])            assert v.eval() == 0.2  # Changed default initializerwhen i try with session the problem changed as below:Attempting to use uninitialized value foo/v [[Node: foo/v/_0 = _Send[T=DT_FLOAT, client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_4_foo/v", _device="/job:localhost/replica:0/task:0/gpu:0"](foo/v)]]this problem in both windows and linuxthe platform is :windows10 , python3.5 , tf.version 0.12.1ubuntu, python2.7  , tf.version  1.1.0-rc2how can I solve this problem?
support	Changing default type from tf.int32 to tf.int64I am trying to allocate very large variables inside single-box, but the default out_type of some operators are tf.int32, it's too small as most modern data center machines have more than 100G memory.Here is the operators I found:tf.shape(input, name=None, out_type=tf.int32)tf.size(input, name=None, out_type=tf.int32)tf.shape_n(input, out_type=None, name=None), out_type defaults to tf.int32For example if I have one [500000000000] tensor, tf.shape fails with the following error message inside Windows:OverflowError: Python int too large to convert to C longLinux has the same issue and chooses overflow instead of raising exceptions.
support	is model ready when Fine-tuning in distributed caseWhen we finetune a model on a different task, only a part of vars in the model are restored from the pretrained task and others are left as initial values.As many docs recommends(page1 page2), when training with a local graph, we restore the pretrained model after running the global init op(call restoring in "init_fn" if MonitoredSession or supervisor is included).But in the distributed case, does global init op make "model_ready" returns true before the restoring-model called? other non-chief nodes will use the "not ready" values.
support	how can creat the module clstm((convolution Long short-term memory)) in tensorflowI wish to implement clstm's network architecture in the tensorflow, to facilitate extension and modifications to the network. already create in module?
support	tf.random_crop  assert erroneouslyPlease go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow):yesOS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 14.04TensorFlow installed from (source or binary):binaryTensorFlow version (use command below):1.1.0Bazel version (if compiling from source):CUDA/cuDNN version:8.0GPU model and memory:TitanX Geforce 16GExact command to reproduce:You can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemI use tf.random_crop for image augmentation, the original image was "232x232x3" rgb image. when I try to do random_crop it to "224x224x3",  the assert occurs  as following, seems very strange:"InvalidArgumentError (see above for traceback): assertion failed: [Need value.shape >= size, got ] [232 232 3] [224 224 3]"Source code / logs    def img_augmentation(self, image_tensor):        # resize image        resize_image = tf.image.resize_images(             image_tensor, [self.IMAGE_HEIGHT, self.IMAGE_WIDTH], method=0, align_corners=False)        padded_image = tf.image.pad_to_bounding_box(            resize_image, 4, 4, self.IMAGE_HEIGHT+8, self.IMAGE_WIDTH+8)        print "padded_image shape:", padded_image.get_shape()        # random crop image        distorted_image = tf.random_crop(            padded_image,  [self.IMAGE_HEIGHT, self.IMAGE_WIDTH, self.NUM_CHANNELS])logs:Caused by op u'random_crop/Assert/Assert', defined at:  File "model.py", line 315, in <module>    m.start_train()  File "model.py", line 236, in start_train    ins = ImageLabelInputStreams(self.graph,self.config)  File "/home/guoqingpei/Project/EXPERIMENT/model/inputPipeline.py", line 62, in __init__    train_image = self.img_augmentation(train_image)  File "/home/guoqingpei/Project/EXPERIMENT/model/inputPipeline.py", line 132, in img_augmentation    padded_image,  [self.IMAGE_HEIGHT, self.IMAGE_WIDTH, self.NUM_CHANNELS])  File "/home/guoqingpei/guoqp/local/lib/python2.7/site-packages/tensorflow/python/ops/random_ops.py", line 303, in random_crop    ["Need value.shape >= size, got ", shape, size])  File "/home/guoqingpei/guoqp/local/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_ops.py", line 121, in Assert    condition, data, summarize, name="Assert")  File "/home/guoqingpei/guoqp/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py", line 39, in _assert    summarize=summarize, name=name)  File "/home/guoqingpei/guoqp/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 768, in apply_op    op_def=op_def)  File "/home/guoqingpei/guoqp/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 2336, in create_op    original_op=self._default_original_op, op_def=op_def)  File "/home/guoqingpei/guoqp/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 1228, in __init__    self._traceback = _extract_stack()InvalidArgumentError (see above for traceback): assertion failed: [Need value.shape >= size, got ] [232 232 3] [224 224 3] [[Node: random_crop/Assert/Assert = Assert[T=[DT_STRING, DT_INT32, DT_INT32], summarize=3, _device="/job:localhost/replica:0/task:0/cpu:0"](random_crop/All/_11, random_crop/Assert/Assert/data_0, random_crop/Shape/_13, random_crop/size/_15)]] [[Node: random_crop/Assert/Assert/_18 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/gpu:0", send_device="/job:localhost/replica:0/task:0/cpu:0", send_device_incarnation=1, tensor_name="edge_42_random_crop/Assert/Assert", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"]()]]
support	tf.where bugSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NOOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04TensorFlow installed from (source or binary): binaryTensorFlow version (use command below): 1.1.0Bazel version (if compiling from source):CUDA/cuDNN version:cuda 8.0 cuDNN 5.0GPU model and memory: 1060 6GBExact command to reproduce:import tensorflow as tfimport numpy as npif __name__ == '__main__':    bool_lists = np.array([[False, True, True, False],                           [False, False, True, True]])    k = tf.Variable(tf.zeros(shape=[2, 4], dtype=tf.int32))    where_val = []    bool_ops = []    k_opes = []    where_ops = []    for j in range(bool_lists.shape[0]):        for i in range(bool_lists.shape[1]):            bool_i = tf.constant(bool_lists[j, i], dtype=tf.bool)            bool_ops.append(bool_i)            where_val.append(k[j, i].assign(tf.where(bool_lists[j, i], i, k[j, i])))            tf_i = tf.constant(i, dtype=tf.int32)            where_ops.append(tf.where(bool_i, tf_i, k[j, i]))            k_opes.append(k[j, i])    with tf.control_dependencies(where_val):        k = tf.identity(k)The results of above code is:[[0 1 2 3][0 1 2 3]][False, True, True, False, False, False, True, True][0, 1, 2, 3, 0, 1, 2, 3][0, 1, 2, 3, 0, 1, 2, 3]I think the right result of k's value should be:[[0 1 2 0][0 0 2 3]]I just update my tensorflow for 1.0 to 1.1.0. I remember  version 1.0 is right.The following is results from tf 1.0:[[0 1 2 0][0 0 2 3]][False, True, True, False, False, False, True, True][0, 1, 2, 0, 0, 0, 2, 3][0, 1, 2, 0, 0, 0, 2, 3]
support	Unable to freeze Keras layers in a Tensorflow workflow.I'm trying to freeze Keras layers in a Tensorflow workflow. It seems that the flag trainable does not work in tf.contrib.keras. This is how I define the graph :sess = tf.Session()K.set_session(sess)labels = tf.placeholder(tf.float32, shape=(None, 1))user_id_input = tf.placeholder(tf.float32, shape=(None, 1))item_id_input = tf.placeholder(tf.float32, shape=(None, 1))max_user_id = all_ratings['user_id'].max()max_item_id = all_ratings['item_id'].max()embedding_size = 30user_embedding = Embedding(output_dim=embedding_size, input_dim=max_user_id+1, input_length=1, name='user_embedding', trainable=all_trainable)(user_id_input)item_embedding = Embedding(output_dim=embedding_size, input_dim=max_item_id+1, input_length=1, name='item_embedding', trainable=all_trainable)(item_id_input)user_vecs = Flatten()(user_embedding)item_vecs = Flatten()(item_embedding)input_vecs = concatenate([user_vecs, item_vecs])x = Dense(30, activation='relu')(input_vecs)x1 = Dropout(0.5)(x)x2 = Dense(30, activation='relu')(x1)y = Dense(1, activation='sigmoid')(x2)loss = tf.reduce_mean(binary_crossentropy(labels, y))train_step = tf.train.AdamOptimizer(0.004).minimize(loss)Then I just train the model :with sess.as_default():train_step.run(..)Everything is working fine when the trainable flag is set to True. Then when I set it to False, it does not freeze the layers.I also tried to minimize only over the variable that I want to train by using train_step_freeze = tf.train.AdamOptimizer(0.004).minimize(loss, var_list=[user_embedding]), and I get :('Trying to optimize unsupported type ', <tf.Tensor 'Placeholder_33:0' shape=(?, 1) dtype=float32>)Is it possible to use Keras layers in Tensorflow and freeze them ?
support	Convolution of zero length input gives junk gradientsSystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): YesOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04TensorFlow installed from (source or binary): sourceTensorFlow version (use command below): 1.1Bazel version (if compiling from source): 0.4.5CUDA/cuDNN version: N/AGPU model and memory: N/AExact command to reproduce: python3 junk_gradients.pyDescribe the problemWhen you pass a zero length input to tf.conv1d and then calculate gradients, you will get junk values. I think it's reading from uninitialized memory because it's nondeterministic and can be very small or very large positive or negative values or NaNs.The expected behavior is that the gradients should all be 0 because the weights aren't making any contribution to the loss.In the application I am writing the input has a variable length (including 0) but for this minimal example I've set it to a constant (tf.ones([0,2])).If you force the convolution to always have an input with length > 0 then the bug goes away. I've included that in the reproduction code under the variable 'remove_bug'.For me, with this reduced example, the gradients are always junk but vary widely. You might see 0s if it happens to read from zeroed out memory. Hopefully the bug will show up if you just run it a few times.Source code / logsimport tensorflow as tfremove_bug = Falsevals = tf.ones([0,2])if remove_bug: # hack it to not actually have zero length    vals = tf.concat([tf.ones([2, 2]), vals], 0)# At this point 'vals' will either have length 0 or 2 if the bug was removedfilter = tf.Variable(tf.ones([2, 2, 2]))conv = tf.nn.conv1d(tf.expand_dims(vals, 0), filter, 2, 'SAME')[0]# At this point 'conv' will either have length 0 or 1 if the bug was removedif remove_bug:    conv = conv[1:] # slice off hack, make 'conv' zero length again# At this point 'conv' will have length 0 whether or not the bug was removed.optimizer = tf.train.GradientDescentOptimizer(0.01)grads = [g for g, _ in optimizer.compute_gradients(conv)]with tf.Session() as sess:    sess.run(tf.global_variables_initializer())    gs = sess.run(grads)print(gs)
support	Tensorboard parsing graph.pbtxt failed after uploaded by by web UISystem informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.12.4TensorFlow installed from (source or binary): install binary with cpu version by pip based on Python 2.7.13TensorFlow version (use command below): ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')Bazel version (if compiling from source): noneCUDA/cuDNN version: only use cpu versionGPU model and memory: noneExact command to reproduce: just upload event file by web UI on 'GRAPH'Describe the problemAfter uploaded the event file by web UI('GRAPH' table), it failed at the point of parsing graph.pbtxt with the error 'Cannot read property '' of undefined' as below. But it works fine for the cmd of 'tensorboard --logdir=xxx'.Error info from chrome dev tool(console):tf-tensorboard.html:9827 Uncaught TypeError: Cannot read property '' of undefinedat addAttribute (tf-tensorboard.html:9827)at tf-tensorboard.html:9859at readHandler (tf-tensorboard.html:9729)at FileReader.file.onload (tf-tensorboard.html:9744)
support	MatchPath ImplementationHi,I can't seem to find the implementation of the "MatchPath" function. I understand this depends on the environment being used, but is there a default implementation somewhere? I want to find out the details of how the path patterns are treated in TensorFlow so I can write a converter from a TF pattern to a regex and use it within another language that has no access to the TF file IO library.Thanks,Anthony
support	Unable to build tensorflow for Java in WindowsAs many may have this problem, I am unable to build tensorflow for Java in Windows. I need to build tensorflow for Java with GPU support in Windows. I followed all the directions specified, and I get the following error message:Thank you!$ bazel build --config opt //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jniERROR: C:/development/projects/tensorflow/tensorflow/java/BUILD:142:1: error loading package 'tensorflow/java/src/main/native': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):File "C:/development/projects/tensorflow/third_party/gpus/cuda_configure.bzl", line 958_create_cuda_repository(repository_ctx)File "C:/development/projects/tensorflow/third_party/gpus/cuda_configure.bzl", line 846, in _create_cuda_repository_get_cuda_config(repository_ctx)File "C:/development/projects/tensorflow/third_party/gpus/cuda_configure.bzl", line 656, in _get_cuda_config_cudnn_install_basedir(repository_ctx)File "C:/development/projects/tensorflow/third_party/gpus/cuda_configure.bzl", line 211, in _cudnn_install_basedirauto_configure_fail("Cannot find cudnn install path....)File "C:/development/projects/tensorflow/third_party/gpus/cuda_configure.bzl", line 128, in auto_configure_failfail("%sAuto-Configuration Error:%s ...))Auto-Configuration Error: Cannot find cudnn install path.and referenced by '//tensorflow/java:libtensorflow_jni.so'.ERROR: Analysis of target '//tensorflow/java:libtensorflow_jni' failed; build aborted.INFO: Elapsed time: 2.365sPlease go to Stack Overflow for help and support:http://stackoverflow.com/questions/tagged/tensorflowIf you open a GitHub issue, here is our policy:It must be a bug or a feature request.The form below must be filled out.Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.System informationHave I written custom code (as opposed to using a stock example script provided in TensorFlow): NoOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, msys2 64bitTensorFlow installed from (source or binary): SourceTensorFlow version (use command below): 1.1.0Bazel version (if compiling from source): 0.4.5CUDA/cuDNN version: 8.0/6.0GPU model and memory: Quadro K5200Exact command to reproduce: bazel build --config opt //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jniYou can collect some of this information using our environment capture script:https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.shYou can obtain the TensorFlow version withpython -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"Describe the problemDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.Source code / logsInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
support	Find an error in mnist_softmax.pySystem informationOS Platform and Distribution (Mac os):TensorFlow installed from (binary):TensorFlow version (master):Describe the problemIn mnist_softmax.py,there is a difference between github an the web of Tensorflow(https://www.tensorflow.org/versions/r0.12/tutorials/mnist/beginners/index.html),and the code on github has error in line 57,58.Source code / logsI replaced cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_)) with cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1])).And it works.
