question when run distributed tensorflow

when I run the distributed tensorflow , I met this problem described below on one of the\ worker:
Traceback (most recent call last):
File "dis_convae.py", line 277, in 
, cost,step = sess.run([train_op_1, model_one_cost,global_step], feed_dict={model_one_X: input})
File "/home/master/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 778, in run
run_metadata_ptr)
File "/home/master/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 982, in _run
feed_dict_string, options, run_metadata)
File "/home/master/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1032, in _do_run
target_list, options, run_metadata)
File "/home/master/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1052, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: NodeDef missing attr 'use_nesterov' from Op<name=ApplyAdam; signature=var:Ref(T), m:Ref(T), v:Ref(T), beta1_power:T, beta2_power:T, lr:T, beta1:T, beta2:T, epsilon:T, grad:T -> out:Ref(T); attr=T:type,allowed=[DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]; attr=use_locking:bool,default=false; attr=use_nesterov:bool,default=false>; NodeDef: Adam/update_Variable_1/ApplyAdam = ApplyAdam[T=DT_FLOAT, _class=["loc:@Variable_1"], use_locking=false, _device="/job:ps/replica:0/task:0/device:CPU:0"](Variable_1, Variable_1/Adam, Variable_1/Adam_1, beta1_power/read, beta2_power/read, Adam/learning_rate_S147, Adam/beta1_S149, Adam/beta2_S151, Adam/epsilon_S153, gradients/Add_grad/tuple/control_dependency_1_S155)
Does anyone know how to solve it?