tf.nn.conv2d on GPU with data_format='NHWC' gives corrupted result for specific shapes

Basically what the title says.
For an image of size (1096, 2449) EXACTLY, not 1097 or 1095 or 2448 or 2450 (but 2451 for some reason produces the same effect). The bottom part of the convolution result gets corrupted. It only affects convolution done on the GPU with the 'NHWC' data format.
Honestly, it feels more of a cuDNN bug than anything, but not sure where to post it otherwise.
Important note : I am on Ubuntu 14.04 hence I can not try tensorflow 1.5 which needs CUDA 9 which needs 16.04. So my test is done on 1.4 with cuda8 and cuDNNv6.

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04
TensorFlow installed from (source or binary): pip install 1.4 tensorflow-gpu
TensorFlow version (use command below): v1.4.0-19-ga52c8d9 1.4.1
Python version: 3.5
CUDA/cuDNN version: cuda 8 cudnn 6
GPU model and memory: TITAN X Pascal
Exact command to reproduce:

import tensorflow as tf
from tensorflow.contrib import layers
sess=tf.InteractiveSession()
h, w = 1096, 2449
input_img = tf.placeholder(tf.float32, shape=(None, h, w, 3))
filters = np.random.randn(1,1,3,2)
with tf.device('/cpu:0'):
    out_cpu = tf.nn.conv2d(input_img, filter=filters, strides=(1,1,1,1), padding='VALID')
with tf.device('/gpu:0'):
    out_gpu = tf.nn.conv2d(input_img, filter=filters, strides=(1,1,1,1), padding='VALID')
    # The following actually works if you manually transpose to use the NCHW data_format
    # tmp = tf.transpose(input_img, (0,3,1,2))
    # out_gpu = tf.nn.conv2d(tmp, filter=filters, strides=(1,1,1,1), padding='VALID', data_format='NCHW')
    # out_gpu = tf.transpose(out_gpu, (0,2,3,1))

out1, out2 = sess.run((out_cpu, out_gpu), feed_dict={
    input_img: np.random.randn(1, h, w, 3)
})
plt.imshow(np.linalg.norm(out1-out2 , axis=-1)[0])
plt.colorbar()
Plotting the difference between the CPU conv and the GPU conv :