TF 1.8 benchmark distributed run failed

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Linux Ubuntu 16.04
TensorFlow installed from source with verbs support
TensorFlow version:
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
('v1.8.0-1-g8753e2e', '1.8.0')
Python version: 2.7
Bazel version: 0.9 ,0.10
GCC/Compiler version: 5.4
CUDA/cuDNN version: 9.1 ,7.0
GPU model and memory: P100, 16GB
Exact command to reproduce:

On first node:
CUDA_VISIBLE_DEVICES='' python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 1 --job_name ps --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True &
python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 1 --job_name worker --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True
On second node:
CUDA_VISIBLE_DEVICES='' python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 0 --job_name ps --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True &
python ~/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py --model inception3 --batch_size 64 --ps_hosts 11.11.11.47:10001,11.11.11.48:10002 --worker_hosts 11.11.11.47:20001,11.11.11.48:20002 --task_index 0 --job_name worker --num_gpus 1 --variable_update=distributed_replicated --cross_replica_sync=True
Problem
I'm running benchmark ( master branch) on two hosts with error:
2018-05-08 14:55:30.598759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:04:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-05-08 14:55:30.979461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:06:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-05-08 14:55:31.325185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:07:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-05-08 14:55:31.676291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 3 with properties:
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:08:00.0
totalMemory: 15.90GiB freeMemory: 15.61GiB
2018-05-08 14:55:31.685309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2, 3
2018-05-08 14:55:32.760916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-05-08 14:55:32.760978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2 3
2018-05-08 14:55:32.760986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y Y Y
2018-05-08 14:55:32.760991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N Y Y
2018-05-08 14:55:32.760997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   Y Y N Y
2018-05-08 14:55:32.761002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 3:   Y Y Y N
2018-05-08 14:55:32.762303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:0 with 15133 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
2018-05-08 14:55:33.097816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:1 with 15133 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-16GB, pci bus id: 0000:06:00.0, compute capability: 6.0)
2018-05-08 14:55:33.431088: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:2 with 15133 MB memory) -> physical GPU (device: 2, name: Tesla P100-PCIE-16GB, pci bus id: 0000:07:00.0, compute capability: 6.0)
2018-05-08 14:55:33.735570: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:worker/replica:0/task:0/device:GPU:3 with 15133 MB memory) -> physical GPU (device: 3, name: Tesla P100-PCIE-16GB, pci bus id: 0000:08:00.0, compute capability: 6.0)
2018-05-08 14:55:34.010006: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> 11.11.11.47:10001, 1 -> 11.11.11.48:10002}
2018-05-08 14:55:34.010056: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:20001, 1 -> 11.11.11.48:20002}
2018-05-08 14:55:34.016202: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:332] Started server with target: grpc://localhost:20001
TensorFlow:  1.8
Model:       inception3
Dataset:     imagenet (synthetic)
Mode:        training
SingleSess:  False
Batch size:  128 global
64 per device
Num batches: 100
Num epochs:  0.01
Devices:     ['/job:worker/task:0/gpu:0']
Data format: NCHW
Layout optimizer: False
Optimizer:   sgd
Variables:   distributed_replicated
Sync:        True
Generating model
W0508 14:55:41.537986 139727489328896 tf_logging.py:126] From /root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py:1525: init (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2018-05-08 14:55:53.359721: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1
2018-05-08 14:56:00.360362: E tensorflow/core/distributed_runtime/master.cc:269] Master init: Unavailable: OS Error
I0508 14:56:00.440299 139727489328896 tf_logging.py:116] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.UnavailableError'>, OS Error
Traceback (most recent call last):
File "/root/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py", line 60, in 
app.run(main)  # Raises error on invalid flags, unlike tf.app.run()
File "/usr/local/lib/python2.7/dist-packages/absl/app.py", line 274, in run
_run_main(main, argv)
File "/usr/local/lib/python2.7/dist-packages/absl/app.py", line 238, in _run_main
sys.exit(main(argv))
File "/root/benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py", line 56, in main
bench.run()
File "/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 1306, in run
return self._benchmark_cnn()
File "/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py", line 1535, in _benchmark_cnn
start_standard_services=start_standard_services) as sess:
File "/usr/lib/python2.7/contextlib.py", line 17, in enter
return self.gen.next()
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py", line 1000, in managed_session
self.stop(close_summary_writer=close_summary_writer)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py", line 828, in stop
ignore_live_threads=ignore_live_threads)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py", line 389, in join
six.reraise(*self._exc_info_to_raise)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py", line 989, in managed_session
start_standard_services=start_standard_services)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py", line 726, in prepare_or_wait_for_session
init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py", line 285, in prepare_session
sess.run(init_op, feed_dict=init_feed_dict)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 900, in run
run_metadata_ptr)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1135, in _run
feed_dict_tensor, options, run_metadata)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1316, in _do_run
run_metadata)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 1335, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnavailableError: OS Error