Multi-GPU for LSTM

I am experimenting with multi-gpu feedforwarding for LSTM models, by feeding two batches of sequences through a LSTM model. Here are two cases I am testing:
Single-GPU: simply pass the two batches sequentially on 1 GPU
Two-GPU: 2 parallel GPUs where each GPU takes care of one batch. My code is in the attached file (.txt --> .py).
However, instead of being 2X faster, the two-GPU case runs even slightly slower than the single-GPU case. It seems that even if I am initiating 2 GPU threads, the 2 batches are processed still sequentially, rather than in a parallel manner.
Does anyone see anything wrong with my code, or give any insight on how to do debugging? Your help would be highly appreciated.
lstm_multi_gpu.txt