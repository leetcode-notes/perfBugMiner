Weird grouping of tf.layers ops in TensorBoard graph visualization

This doesn't always happen, but sometimes when stacking multiple tf.layers, variables get placed in previous layers' graphical boxes. Setting variable_scope prevents this, but it's still a bit confusing as to why this is happening. It could have something to do with how tf.layers decide on a scope name automatically.
An example on TensorFlow 1.0.0-rc0 (but I think this also happens on the current PyPI release):

x = tf.layers.conv2d(x, ...)
x = tf.layers.conv2d(x, ...)
x = tf.layers.conv2d(x, ...)
As it's hard to reproduce, I think it could be related to having multiple runs in the same TensorBoard, and some kind of namespace collision happening.