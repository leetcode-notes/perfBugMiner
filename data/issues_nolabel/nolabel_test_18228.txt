why the convolution network output changes when i have already fixed the parameters of the convolution and only feed the net with same input?

Sorry to bother, but i have trouble with the convolution in tensorflow.
I am working with the network as below, input shape is [1,256,256,33], go through some convs, and after them i add a fully connected layer( not show in this picture). i fix the parameters of the convs, and try to train the fc layer.
However, i found something weird... the network won't converge at all, so i only feed the network with one same input to test whether the network has any problem and print the output of each layer every iteration.
and i found that the output of 'conv6' changes, though my net has been fixed.
but the output of 'conv5_1' doesn't change at all!....
so i changed the stride of conv6... and when i change the stride of conv6 from 2 to 1, the output of conv6 doesn't change either.... So the net is very weird to me.... the stride of conv6 decides whether it changes?
Could anyone help me? thanks!!!
[my network ('is training' is false]
    conv1 = conv(data, 3, 3, 64, 1, 1, name='conv1', is_training=is_training)
    conv1_1 = conv(conv1, 3, 3, 64, 1, 1, name='conv1_1', is_training=is_training)
    conv2 = conv(conv1_1, 3, 3, 128, 2, 2, name='conv2', is_training=is_training)
    conv2_1 = conv(conv2, 3, 3, 128, 1, 1, name='conv2_1', is_training=is_training)    
    conv3 = conv(conv2_1, 3, 3, 256, 2, 2, name='conv3', is_training=is_training)
    conv3_1 = conv(conv3, 3, 3, 256, 1, 1, name='conv3_1', is_training=is_training)
    conv4 = conv(conv3_1, 3, 3, 512, 2, 2, name='conv4', is_training=is_training)
    conv4_1 = conv(conv4, 3, 3, 512, 1, 1, name='conv4_1', is_training=is_training)
    conv5 = conv(conv4_1, 3, 3, 512, 2, 2, name='conv5', is_training=is_training)
    conv5_1 = conv(conv5, 3, 3, 512, 1, 1, name='conv5_1', is_training=is_training)
    conv6 = conv(conv5_1, 3, 3, 1024, 2, 2, name='conv6', is_training=is_training)
[the conv definition]
def conv(inputs,k_h,k_w,c_o,s_h,s_w,name,relu=True,padding='SAME',group=1,biased=True,is_training=False):

    c_i = inputs.get_shape()[-1]
    convolve = lambda i, k: tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)
    with tf.variable_scope(name) as scope:
        
      if is_training:
        initializer = slim.xavier_initializer()
        weights_regularizer = slim.l2_regularizer(5e-4)
      else:
        initializer = None
        weights_regularizer = None

      kernel = make_var('weights', shape=[k_h, k_w, c_i / group, c_o],is_training=is_training,initializer=initializer ,regularizer=weights_regularizer)

      output = convolve(inputs, kernel)
      if biased:
        biases = make_var('biases', [c_o],is_training=is_training)
        output = tf.nn.bias_add(output, biases)
      if relu:
        output= tf.nn.relu(output, name=scope.name)
      return output
[make_var definition]
    def make_var( name, shape,is_training, initializer=None,regularizer=None):

      return tf.get_variable(name, shape,initializer= initializer,regularizer=regularizer,trainable=is_training)