tf.nn.max_pool works incorrectly with option:  data_format="NCHW" on GPU

The max_pooling operation seems to be ignorant of the data_format option of "NCHW" and treat the input data as "NHWC"



with tf.device('/gpu:0'):
...     a=tf.zeros((100,3,224,224))
...     b=tf.nn.max_pool(a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding="SAME",data_format="NCHW")
...
b
<tf.Tensor 'MaxPool:0' shape=(100, 2, 112, 224) dtype=float32>



I think the shape of the 'b' variable should be (100,3,112,112) instead of (100, 2, 112, 224). The max pooling operations seems to operate on the wrong axis.
What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
None
Environment info
Operating System:
Ubuntu LTS 16.04
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
-rw-r--r-- 1 root root   558720 sept. 15  2016 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 sept. 15  2016 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 sept. 15  2016 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root   415432 sept. 15  2016 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 sept. 15  2016 /usr/local/cuda-8.0/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 oct.   5 10:46 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 oct.   5 10:46 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 oct.   5 10:46 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 oct.   5 10:46 /usr/local/cuda-8.0/lib64/libcudnn_static.a
If installed from binary pip package, provide:

A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.1-cp35-cp35m-linux_x86_64.whl
The output from python -c "import tensorflow; print(tensorflow.__version__)".
1.0.1

If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
with tf.device('/gpu:0'):
...     a=tf.zeros((100,3,224,224))
...     b=tf.nn.max_pool(a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],padding="SAME",data_format="NCHW")
...
b
<tf.Tensor 'MaxPool:0' shape=(100, 2, 112, 224) dtype=float32>
What other attempted solutions have you tried?
None
Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).