Conditional input to a sequence to sequence model (word+character hybrid network)

I need to create a sequence to sequence model where in the encoder and decoder are both LSTM networks but the encoder takes the inputs from either of the following cases
1.Normal vector representation of a word (Embedding vector) - when the word input is present in the vocabulary
2.Output of another LSTM network - when the word is out of vocabulary and a separate character based LSTM is used to generate an embedding on the fly
Consider the following example sentence:
"The brown fox jumped over the lazy dog"
Assume these are the words present in the vocabulary: The, brown, jumped, over, dog - These words are fed to the seq2seq encoder as such
out of vocabulary(OOV) words are: fox, lazy - These words are passed to a character LSTM and the output of the same is passed to the seq2seq model along with the above words
These both word level and character level encoder needs to be trained end to end simultaneously. How do we model the input layer of the seq2seq model to achieve this scenario?
Reference paper:
http://aclweb.org/anthology/P/P16/P16-1100.pdf