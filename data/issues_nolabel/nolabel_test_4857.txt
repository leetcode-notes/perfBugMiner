tf.extract_image_patches Trying stride only on row

Hi, Tried to use tf.extract_image_patche() of a tensor [N, sequence_length, embeding_size, 1] to do n-gram with patch size [1,sequence_length-#gram+1, embedding_size, 1]. Thus I set the stride to be [1,1,0,1]. However this leds to the error: ZeroDivisionError: integer division or modulo by zero
Is there a way to only stride on one dim and avoid this error?
below is the skeleton of my code and error message:
self.embedded_chars = tf.nn.embedding_lookup(W, self.input_x)
self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)
slic = tf.(self.embedded_chars_expanded, [1,i,embedding_size,1], [1,1,0,1], [1,1,1,1], 'VALID')

---------------------------------------------------------------------------
ZeroDivisionError                         Traceback (most recent call last)
/home/zijia/nlp/A2/train.py in <module>()
     85             embedding_size=FLAGS.embedding_dim,
     86             n_gram=FLAGS.n_gram,
---> 87             l2_reg_lambda=FLAGS.l2_reg_lambda)
     88
     89         # Define Training procedure

/home/zijia/nlp/A2/text_cnn.py in __init__(self, sequence_length, num_classes, vocab_size, embedding_size, n_gram, l2_reg_lambda)
     32                 grams = [ self.embedded_chars_expanded ]
     33                 for i in range(2,n_gram+1):
---> 34                     slic = tf.extract_image_patches(self.embedded_chars_expanded, [1,i,embedding_size,1], [1,1,0,1], [1,1,1,1], 'VALID')
     35                     print slic.get_shape()
     36                     slic = tf.reduce_sum( slic, 3 )

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.pyc in extract_image_patches(images, ksizes, strides, rates, padding, name)
    918   result = _op_def_lib.apply_op("ExtractImagePatches", images=images,
    919                                 ksizes=ksizes, strides=strides, rates=rates,
--> 920                                 padding=padding, name=name)
    921   return result
    922

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)
    701           op = g.create_op(op_type_name, inputs, output_types, name=scope,
    702                            input_types=input_types, attrs=attr_protos,
--> 703                            op_def=op_def)
    704           outputs = op.outputs
    705           return _Restructure(ops.convert_n_to_tensor(outputs),

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)
   2317                     original_op=self._default_original_op, op_def=op_def)
   2318     if compute_shapes:
-> 2319       set_shapes_for_outputs(ret)
   2320     self._add_op(ret)
   2321     self._record_op_seen_by_control_dependencies(ret)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)
   1709       raise RuntimeError("No shape function registered for standard op: %s"
   1710                          % op.type)
-> 1711   shapes = shape_func(op)
   1712   if shapes is None:
   1713     raise RuntimeError(

/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.pyc in _ExtractImagePatchesShape(op)
   2290                                                             ksize_c_eff,
   2291                                                             stride_r, stride_c,
-> 2292                                                             padding)
   2293
   2294   out_depth = None if in_depth is None else ksize_r * ksize_c * int(in_depth)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc in get2d_conv_output_size(input_height, input_width, filter_height, filter_width, row_stride, col_stride, padding_type)
    182   return get_conv_output_size((input_height, input_width),
    183                               (filter_height, filter_width),
--> 184                               (row_stride, col_stride), padding_type)
    185
    186

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc in get_conv_output_size(input_size, filter_size, strides, padding_type)
    159     output_size = [
    160         _valid(in_dim, k_dim, s_dim)
--> 161         for in_dim, k_dim, s_dim in zip(input_size, filter_size, strides)
    162     ]
    163   elif padding_type == b"SAME":

/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.pyc in _valid(in_dim, k_dim, s_dim)
    153     def _valid(in_dim, k_dim, s_dim):
    154       if in_dim is not None and k_dim is not None:
--> 155         return (in_dim - k_dim + s_dim) // s_dim
    156       else:
    157         return None

ZeroDivisionError: integer division or modulo by zero