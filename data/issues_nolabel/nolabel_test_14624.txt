Bug: using regularizer for shared variables in tf.cond branches

Please go to Stack Overflow for help and support:
https://stackoverflow.com/questions/tagged/tensorflow
If you open a GitHub issue, here is our policy:

It must be a bug or a feature request.
The form below must be filled out.
It shouldn't be a TensorBoard issue. Those go here.

Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.13.1
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.3.0
Python version: 2.7
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce:

Describe the problem
Setting the regularizer of a shared variable in tf.cond branches gives an unexpected behaviour - only one copy of the regularization op is added to tf.GraphKeys.REGULARIZATION_LOSSES. This is different from adding operations to a collection explicitly. And optimizing the regularization loss doesn't raise an error.
Source code
import tensorflow as tf
from tensorflow.contrib.layers.python.layers import regularizers


def regularised_model(is_training):
    scope_name = 'foo'
    with tf.variable_scope(scope_name) as scope:
        if is_training:
            scope.reuse_variables()
        y = tf.get_variable(
            name='y', shape=(),
            initializer=tf.constant_initializer(1.0),
            regularizer=regularizers.l2_regularizer(scale=0.1, scope=scope_name))
        reg = tf.nn.l2_loss(y) * 0.1
        tf.add_to_collection('test_collection', reg)
    return y

binary_flag = tf.placeholder(dtype=tf.bool, shape=())
y_cond = tf.cond(binary_flag,
                 lambda: regularised_model(False),
                 lambda: regularised_model(True))

reg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
assert(len(reg_loss) == 1)
output = y_cond + reg_loss[0]
opt = tf.train.AdamOptimizer(0.1).minimize(output)

reg_test = tf.get_collection('test_collection')
assert(len(reg_test) == 2)
output_reg_true = y_cond + reg_test[0]
output_reg_false = y_cond + reg_test[1]


with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(sess.run(output_reg_true, feed_dict={binary_flag: True})) # 1.05
    print(sess.run(output_reg_false, feed_dict={binary_flag: False})) # 1.05

    print(sess.run(output, feed_dict={binary_flag: True})) # 1.05
    
    print(sess.run([opt], feed_dict={binary_flag: True})) # [None]
    print(sess.run([opt], feed_dict={binary_flag: False})) # [None]

    print(sess.run(output, feed_dict={binary_flag: False})) # Error: Retval[0] does not have value

Log
1.05
1.05
1.05
[None]
[None]
Traceback (most recent call last):
  File "test_tf_cond.py", line 43, in <module>
    print(sess.run(output, feed_dict={binary_flag: False})) # Error: Retval[0] does not have value
  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 895, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1321, in _do_run
    options, run_metadata)
  File "/usr/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value