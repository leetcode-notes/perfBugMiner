TF API r1.2 Keras TimeDistributed wrapper error

import tensorflow.contrib.keras as K
model = K.models.Sequential()
model.add(K.layers.LSTM(150, batch_input_shape=(batch_size, n_in, encoded_length), stateful=True))
model.add(K.layers.RepeatVector(n_out))
model.add(K.layers.LSTM(150, return_sequences=True, stateful=True))
model.add(K.layers.TimeDistributed(K.layers.Dense(encoded_length, activation='softmax')))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])
AttributeError: module 'tensorflow.contrib.keras.api.keras.layers' has no attribute 'TimeDistributed'
Is there way to avoid that error?
System info:
Windows 10
TensorFlow r1.2
Python 3.6
Miniconda3
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
TensorFlow installed from (source or binary):
TensorFlow version (use command below):
Bazel version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
You can obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.