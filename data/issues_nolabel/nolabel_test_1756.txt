Ran out of memory trying to allocate.....

Operating System: Ubuntu 14.04
Tensor Flow: 0.7.1 (install with pip, 64-bit GPU version)
My issue is that Tensor Flow is telling me that it has run out of memory when constructing my Convolutional Neural Network. However, according to my calculations, my network should be able to fit well within the memory of my GPU.
Here is my network structure:

Input image: 256x256, one channel
Convolutional layer 1: 48 filters of size 11x11, max pool with 4x4 kernel and 4x4 stride
Convolutional layer 2: 128 filters of size 5x5, max pool with 2x2 kernel and 2x2 stride
Convolutional layer 3: 128 filters of size 3x3, no max pool
Fully-connected layer 4: 128 * 32 * 32 input nodes and 1024 output nodes
Fully-connected layer 5: 1024 input nodes and 10 output nodes


So, according to my calculations, the number of parameters are as follows:

Convolutional layer 1: 48 * 11 * 11 + 48 = 5,856
Convolutional layer 2: 128 * 48 * 5 * 5 + 128 = 153,728
Convolutional layer 3: 128 * 128 * 3 * 3 + 128 = 147,584
Fully-connected layer 4: 128 * 64 * 64 * 1024 + 1024 = 536,871,936
Fully-connected layer 5: 10 * 1024 + 10 = 10,250


Total:  537,189,354 (~ 2150 MB with float32 data)


And the memory required (number of nodes) to store one image on the network is:

Input: 256 * 256 = 65,536
Convolutional layer 1: 48 * 256 * 256 = 3,145,728
Convolutional layer 2: 128 * 64 * 64 = 524,288
Convolutional layer 3: 128 * 32 * 32 = 131,072
Fully-connected layer 4: 1024
Fully-connected layer 5: 10

Total:  3,802,122 (~ 1.52 MB with float32 data)


So the shared parameters require 2150 MB of memory, and each image requires 1.52 MB of memory.
Now, my graphics card is the NVIDA GeForce GTX 780 Ti, which has 3072 MB of memory. However, when I run the above network, even with a training minibatch size of 1, I get the following error form Tensor Flow:

Ran out of memory trying to allocate 600.0KiB.
Compute status: Resource exhausted: OOM when allocating tensor with shape[5,5,48,128]


Why am I getting this error? According to my calculations, the weights for the network should be able to fit on my GPU, even without any training images.

The full output from Tensor Flow can be found here: https://jpst.it/GKtY