CUDA Fail in Tensorflow Inference on Jetson TX2

Hi,
I am getting CUDA fail error for model inference on Jetson TX2 aarch64. I have built the TF source (Version 1.3) for python 3.5 from this github repo:
https://github.com/jetsonhacks/installTensorFlowTX2

Ubuntu 16.04
Bazel 0.5.2
CUDA 8
cuDNN 6.

The relevant discussion on NVIDIA dev forum directed me to post this here:
https://devtalk.nvidia.com/default/topic/1029256/jetson-tx2/cuda-fail-when-running-tensorflow-inference/post/5236860/
TF does work for smaller sized models, but for larger sized models the inference fails. I appreciate if you can please take look at this.