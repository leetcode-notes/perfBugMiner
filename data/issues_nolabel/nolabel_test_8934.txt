complex weight for LSTM?

I am having complex input and output for LSTM, and it looks like I have to initialize LSTM weights as complex tensor. Below is my code:
rnn_size = 128
cell = core_rnn_cell.BasicLSTMCell(rnn_size, state_is_tuple=False)
print 'initiate LSTM cell: ',cell
num_layers = 1
batch_size = 1
seq_length = T.shape[0]
initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)
learning_rate = 0.003
input_data = tf.placeholder(tf.complex64, [seq_length-1, 3],name='input_data')
target_data = tf.placeholder(tf.complex64, [seq_length-1, 3],name = 'target_data')
lr = tf.Variable(learning_rate, trainable=False, name="learning_rate")
K = 3
output_size = K + K*(K+1)/2 
embedding_size = 128
with tf.variable_scope("coordinate_embedding"):
#     real_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = "complex_weight_real")
#     imag_w = tf.Variable(tf.truncated_normal([total_arg_size, output_size], stddev=0.1), name = "complex_weight_imag")
#     matrix = tf.complex(real_w, imag_w)
    real_embedding_w = tf.get_variable("real_embedding_w", [K, embedding_size])
    imag_embedding_w = tf.get_variable("imag_embedding_w", [K, embedding_size])
    embedding_w = tf.complex(real_embedding_w, imag_embedding_w)
    real_embedding_b = tf.get_variable("real_embedding_b", [embedding_size])
    imag_embedding_b = tf.get_variable("imag_embedding_b", [embedding_size])
    embedding_b = tf.complex(real_embedding_b, imag_embedding_b)

with tf.variable_scope("rnnlm"): 
    real_output_w = tf.get_variable("real_output_w", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)
    imag_output_w = tf.get_variable("imag_output_w", [rnn_size, output_size], initializer=tf.truncated_normal_initializer(stddev=0.01), trainable=True)
    output_w = tf.complex(real_output_w, imag_output_w)
    real_output_b = tf.get_variable("real_output_b", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)
    imag_output_b = tf.get_variable("imag_output_b", [output_size], initializer=tf.constant_initializer(0.01), trainable=True)
    output_b = tf.complex(real_output_b, imag_output_b)
inputs = tf.split(input_data, seq_length-1, 0)
states = []
initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)
state = initial_state
outputs = []
predict_initial_state = cell.zero_state(batch_size=batch_size, dtype=tf.complex64)
predict_input =  tf.placeholder(tf.complex64, [1,  2])
predict_sequence = 100
index =0
predict_outputs = []
output, new_state = cell(inputs[i], state)

But I have the below error, but I checked the documentation and didn't find out how to initialize the weights of LSTM cell as complex tensors.
ValueError: An initializer for variable basic_lstm_cell/weights of <dtype: 'complex64'> is required

Could anyone give me some hint on this? Thanks in advance!