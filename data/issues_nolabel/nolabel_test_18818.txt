Using out-of-graph Reward in Reinforcement Learning with Iterator in tf.data

When the reward value is generated from a script that is not computed in Tensorflow graph, like ROUGE score in text summarization or BLEU score in machine translation.
We first use the graph to generate a prediction result, then calculate the reward value out of the graph, and then feed the value into the graph to update the parameters of our model by policy gradients.
If we use session.run, this will cause recomputation that is mentioned in #672.
Although recomputation does not cost very much, when we use the tf.dataset with Iterator, the dataset pointer will move to the next sample when calling session.run function.
In #672, they suggest to use partitial_run instead of session.run. But partitial_run can only fetch the tensor, but it can not execute the operation.
So can you add a feature that can move the pointer of Iterator backward? or fix the pointer when calling the session.run function?