Asynchronous Training Issue for Distributed Tensorflow

I guess this issue may not be supposed to show up here, and I apologize for opening the ticket here, but really want to be clear about asynchronous training with Distributed Tensorflow. I posted my question on StackOverflow: http://stackoverflow.com/questions/43147435/how-does-asynchronous-training-work-in-distributed-tensorflow, but I got two opposite answers and didn't know which one is the correct. I read the TF docs and example code multiple times, but they're still confused me. So I really appreciate if I could get some official interpretations on asynchronous training.