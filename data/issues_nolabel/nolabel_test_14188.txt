Retval[0] does not have value in a multithreaded context with FIFOQueue and  tf.scan(...)

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I provide a working script showing the buggy behaviour
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.4.0
Python version: 2.7.12
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: none
GPU model and memory: GeForce GTX 280M 1GB

Note: I reproduced the buggy behaviour on different platforms too: macOS High Sierra, openSUSE 42.3 and with Tensorflow 1.3
problem context
I found the buggy behaviour in one of the helper methods the queue loader of the DeepSpeech project (ctc_label_dense_to_sparse). That implementation is partially clumsy in particular when using tf.scan where a scan history context is not used. Nevertheless the algorithm should have worked under any circumstances. I could reduce the problem scenario to a small standalone example. This example uses a number of threads for filling a queue from which batches are requested by dequeu_up_to (the same buggy behaviour if replaced by dequeue_many). Afterwards the batch is postproccessed. For this postprocessing I provided the buggy version (function_buggy, using tf.scan) and an own implementation (function_ok). Both versions produce the same output data in cases there the buggy versions does not fail.
buggy behaviour description
Very often, but not always a test with a larger batch_size and smaller thread_count leads to the following output: tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value. I include the complete log in the next section. With a larger thread_count and smaller batch_size it works. If the switch-Parameter --use_buggy_version is set to 0 (False) no choice of batch_size and thread_count produces a bug. This proves that the problem is located in the buggy function and the rest of the workflow is OK. I could prove that an implementation without the tf.scan works fine too. In experiments using the context in tf.scan instead of ignoring it didn't change the behaviour. Even as tf.scan doesn't make much sense in the context it was used for in DeepSpeech it  should not have failed and its correct function is essential for many tensorflow based projects. And maybe a similar flaw is hidden in the other "Higher Order operators" too: tf.map_fn, tf.foldl, tf.foldr
log
usage: scan_bug_demo.py [-h] [--batch_size BATCH_SIZE]
[--thread_count THREAD_COUNT]
[--use_buggy_version USE_BUGGY_VERSION]
batch_size=15
thread_count=1
use_buggy_version=True
using buggy implementation: True
Traceback (most recent call last):
File "scan_bug_demo.py", line 127, in 
retval = do_it(batch_size, thread_count, use_buggy_version, rnd_seed)
File "scan_bug_demo.py", line 99, in do_it
coord.join(queue_threads)
File "/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py", line 389, in join
six.reraise(*self._exc_info_to_raise)
File "scan_bug_demo.py", line 92, in do_it
res = sess.run(batch)
File "/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 889, in run
run_metadata_ptr)
File "/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1120, in _run
feed_dict_tensor, options, run_metadata)
File "/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1317, in _do_run
options, run_metadata)
File "/home/uli/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1336, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Retval[0] does not have value
bug demonstration python source
import tensorflow as tf
from random import Random
from threading import Thread
import numpy as np
import sys
from argparse import ArgumentParser
def function_buggy(value_sequence_lengths):
max_len = tf.reduce_max(value_sequence_lengths)
max_value_seuence_lenght_tns = tf.expand_dims(max_len, 0)
init = tf.expand_dims(tf.cast(tf.fill(max_value_seuence_lenght_tns, 0), tf.bool), 0)

def scan_function(previous_state, current_input):
    return tf.expand_dims(tf.range(max_len), 0) < current_input

retval = tf.squeeze(tf.scan(scan_function, value_sequence_lengths, initializer=init, parallel_iterations=1),
                    axis=[1])

return retval

def function_ok(value_sequence_lengths):
max_len = tf.reduce_max(value_sequence_lengths)
value_sequence_lengths_shape = tf.shape(value_sequence_lengths)
x_repeated_lenghts = tf.tile(tf.expand_dims(value_sequence_lengths, 1), (1, max_len))
y_repeated_x_indices = tf.tile(tf.expand_dims(tf.range(max_len), 0), (value_sequence_lengths_shape[0], 1))

retval = y_repeated_x_indices < x_repeated_lenghts

return retval

class BatchProvider(object):
def init(self, batch_size, function, thread_count, rnd_seed):
self._coord = None
self.batch_size = batch_size
self._random = Random(rnd_seed)
self._capacity = 2 * batch_size
self._thread_count = thread_count
self._queue = tf.FIFOQueue(shapes=[[]], dtypes=[tf.int32], capacity=self._capacity)
self._y_length = tf.placeholder(tf.int32, [])
self._enqueue_op = self._queue.enqueue(self._y_length)
self._close_op = self._queue.close(cancel_pending_enqueues=True)
self._function = function
def start_queue_threads(self, session, coord):
    self._coord = coord
    batch_threads = [Thread(target=self._populate_batch_queue, args=(session,)) for i in range(self._thread_count)]
    for batch_thread in batch_threads:
        self._coord.register_thread(batch_thread)
        batch_thread.daemon = True
        batch_thread.start()
    return batch_threads

def close_queue(self, session):
    session.run(self._close_op)

def _populate_batch_queue(self, session):
    while True:
        length = self._random.randint(5, 10)
        target_len = length
        try:
            self._enqueue_op.run(session=session, feed_dict={self._y_length: target_len})
        except tf.errors.CancelledError:
            return

def next_batch(self):
    target_lengths = self._queue.dequeue_up_to(self.batch_size)
    retval = self._function(target_lengths)
    return retval

def do_it(batch_size, thread_count, use_buggy_version, rnd_seed):
function = function_buggy if use_buggy_version else function_ok
batch_provider = BatchProvider(batch_size=batch_size, function=function,
                               thread_count=thread_count, rnd_seed=rnd_seed)

sess = tf.Session()

coord = tf.train.Coordinator()
queue_threads = batch_provider.start_queue_threads(sess, coord)
batch = batch_provider.next_batch()

try:
    for _ in range(1):
        if coord.should_stop():
            break
        res = sess.run(batch)
        print batch
        print res
except Exception, ex:
    coord.request_stop(ex)
finally:
    batch_provider.close_queue(sess)
    coord.join(queue_threads)
    sess.close()

return res

if name == 'main':
args = sys.argv[1:]
argparser = ArgumentParser()
argparser.add_argument("--batch_size", dest="batch_size", type=int, default=15)
argparser.add_argument("--thread_count", dest="thread_count", type=int, default=1)
argparser.add_argument("--use_buggy_version", dest="use_buggy_version", type=int, default=True)
if len(args) == 0:
argparser.print_usage()
parsed = argparser.parse_args(args=args)
batch_size = parsed.batch_size
thread_count = parsed.thread_count
use_buggy_version = parsed.use_buggy_version
print "batch_size=" + str(batch_size)
print "thread_count=" + str(thread_count)
print "use_buggy_version=" + str(use_buggy_version)

rnd_seed = Random().random()

print "using buggy implementation: " + str(use_buggy_version)
retval = do_it(batch_size, thread_count, use_buggy_version, rnd_seed)
print "success"