memory issues

Hi,
It seems the memory allocation of tensorflow is rather inefficient. I have been running a single layer rnn with 256 batch size, 124 length and dim of 512, it constantly gets memory not enough error for my 4GB 980. In theory, the model size is much less than 1GB
no matter how large the batch size I set, it always use up all the 4GB memory, which is unreasonable. I have been compiling tensorflow from the source and BFC memory allocator is set as default.
I think the memory problem was also mentioned here
soumith/convnet-benchmarks#66
and mentioned by many other users. In compare with Theano and Torch, tensorflow can only experiment with smaller models.
Are there any solutions to this? This is a major problem that stops me from experimenting with tensorflow.
Many thanks!!