Relevant fluctuations in activations depending on batch size, at test time

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04
TensorFlow installed from (source or binary):
TensorFlow version (use command below): v1.3.0-rc2-20-g0787eee 1.3.0
Python version: 3.5.2
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 8.0
GPU model and memory: GeForce GTX 1080 8GB
Exact command to reproduce:

Describe the problem
I'm using the slim implementation of resnet-v1-50 . The logits seem to change depending on the test batch_size used.
I would expect some instability due to parallelism mechanisms on GPU, but I found out this behavior after the model's accuracy changed when batch_size changed. Thus, some fluctuations might be so big that they change predictions, which is not irrelevant.
If this is not a bug, is there a way to prevent this / what is the recommended way to evaluate our models?
Source code / logs
I attach source code that tests this scenario. It was tested on tf version 1.3 .
to run: python test_batch_size.py --batch_size=1
It prints the logits for the first frame of the batch. It saves the frame so you can be sure it's the very same frame. It loads all the weights from a checkpoint, and batchnorm is disabled with is_training=False.
please vary the batch_size argument, and see that the activations change.
https://www.dropbox.com/s/ns9j84t02zifdaa/test_batch_size.zip?dl=0