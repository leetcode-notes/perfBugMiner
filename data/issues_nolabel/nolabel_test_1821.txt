Basic Lstm cell giving NAN loss and 0 acuraccy.

Environment info
Operating System: Ubuntu 14.04
Installed version of CUDA and cuDNN:  7.5 cudnnv4.0
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
-rw-r--r-- 1 root root 189170 Mär 29 12:20 /usr/local/cuda/lib/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Mär 29 12:20 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Mär 29 12:20 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 311596 Mär 29 12:20 /usr/local/cuda/lib/libcudart.so.7.5.18
-rw-r--r-- 1 root root 558020 Mär 29 12:20 /usr/local/cuda/lib/libcudart_static.a

If installed from binary pip package, provide:

Which pip package you installed. sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
The output from python -c "import tensorflow; print(tensorflow.version)".

I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.7.1


Hi,
I had modified this code to accept an input 4096 vector with 16 time steps.
and changed very little.
The loss is always nan and acuraccy 0.
I have tried several combinations of Learningrate/batchsize/optimizers with no change.
Here Is my code.
Output
Iter 640, Minibatch Loss= nan, Training Accuracy= 0.75000
Testing Accuracy: 0.75
Iter 1280, Minibatch Loss= nan, Training Accuracy= 0.75000
Testing Accuracy: 0.0
Iter 1920, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.0
Iter 2560, Minibatch Loss= nan, Training Accuracy= 0.01562
Testing Accuracy: 0.0
Iter 3200, Minibatch Loss= nan, Training Accuracy= 0.01562
Testing Accuracy: 0.0
Iter 3840, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.0
Iter 4480, Minibatch Loss= nan, Training Accuracy= 0.03125
Testing Accuracy: 0.0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 4696 get requests, put_count=4701 evicted_count=1000 eviction_rate=0.212721 and unsatisfied allocation rate=0.21678
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:256] Raising pool_size_limit_ from 256 to 281
Iter 5120, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.0
Iter 5760, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.0
Iter 6400, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.015625
Iter 7040, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.0
Iter 7680, Minibatch Loss= nan, Training Accuracy= 0.00000
Testing Accuracy: 0.015625
Iter 8320, Minibatch Loss= nan, Training Accuracy= 0.00000

Any ideas on y this is happening?