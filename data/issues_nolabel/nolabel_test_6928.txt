how to resolve warning: Unable to load cuDNN DSO

Hello,
I recently installed tensorflow GPU version 0.12.1 and python 3.5.2 for windows.
There is CUDA GTX660 driver already installed on my PC.
I am trying some sample programs and when ever i am using import tensorflow  I get a warning and then the result. How to resolve the issue ? What else should I be installing ?
I tried to download cuDNN, select all in cuDNN Dowload Survey will make any difference? I will be working on RNN implementations and have many FFT calculations.
At the moment, I choose deeplearning framework -> tensorflow library and I have downloaded cuDNN v5.1 Library for Windows 10 which gave me a "cudnn-8.0-windows10-x64-v5.1.zip" file , but there is no executable file or something to install.  should I be copying those in to any folder or did i downloaded the wrong one ?
C:\Users\raady\AppData\Local\Programs\Python\Python35\python.exe "D:/Lab Project Files/TF/Practice Files/test.py" I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:119] Couldn't open CUDA library cudnn64_5.dll I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:3459] Unable to load cuDNN DSO I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally WARNING:tensorflow:From D:/Lab Project Files/TF/Practice Files/test.py:4 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02. Instructions for updating: Usetf.global_variables_initializerinstead. I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties: name: GeForce GTX 660 major: 3 minor: 0 memoryClockRate (GHz) 1.0325 pciBusID 0000:01:00.0 Total memory: 2.00GiB Free memory: 1.65GiB I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0 I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0: Y I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 660, pci bus id: 0000:01:00.0)