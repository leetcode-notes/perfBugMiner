global_step/sec is always zeros in the tensorflow distributed log

When I use the tensorflow distributed version to train a model of classify of the text.
I find the global_step variable in the log of parameter server is always zero. At the same time, the worker log doesn't update any more.
After 30 minutes, there is no change in the situation.
But when I use the nvidia-smi to check the situation of the gpu, I find the process which is working in the gpu.
this is my global_step code:
global_step = tf.Variable(0, name="global_step", trainable=False)
Does anyone who know how to solve it?