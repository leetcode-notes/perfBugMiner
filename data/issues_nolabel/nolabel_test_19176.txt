selu alpha: why a different value from the ref paper?

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
TensorFlow version (use command below): 1.8.0

Describe the problem
In the source, I see that the value of the alpha constant chosen for the selu activation is 1.7580993408473768599402175208123.
However, in the reference paper  given in the documentation, the value is 1.673263242354377.
Why the difference? If there is published work about this update could you please add it to the documentation. If not could you please motivate this choice?
Source code / logs
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/relu_op_functor.h#L139