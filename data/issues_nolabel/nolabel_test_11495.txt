MultiGPU multi-session

It would be nice if there is an official way to do limit devices initialised by tensorflow other than the os level environment variable settings specifically as in this answer posted by @mrry in stackoverflow. As of my understanding the setup mentioned in another answer by @mrry will not prevent tensorflow from grabbing all the GPU resources available on a same workstation at initialization as it is in by tf.train.Server().  It would be essentially helpful for those sharing a machine among multiple users, so that they could independently initiate tensorflow graphs in different GPU units. Although this could be achieved via nvidia-dockeror other resource orchestration tools, a native API would be a great addition to tensorflow.  Please ignore this if there is already an official way or my understanding is wrong.