Checkpoints continue to grow after the first restore

System information


No


OS Platform and Distribution: Mac OS X, v 10.13.2


TensorFlow installed from: binary


TensorFlow version: v1.3.0-rc1-5211-gab0fcac 1.5.0-dev20171126


Python version: Python 3.5.0


Bazel version: N/A


GCC/Compiler version: N/A


CUDA/cuDNN version: N/A


GPU model and memory: Intel Iris Pro 1536 MB


Exact command to reproduce: N/A


Have I written custom code: N/A


Describe the problem
The parameter max_to_keep of the Saver class does not seem to have effect once a model and its training variables are restored. In other words, the first time I train my model, the saver is keeping only max_to_keep checkpoints. Then I interrupt the training. Later, when I resume it, the number of checkpoints keeps going without any apparent limit.
Related issues

#5929
#6326