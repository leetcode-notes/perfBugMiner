Tensorflow Data Corruption after Training

GitHub issues are for bugs / installation problems / feature requests.
For general support from the community, see StackOverflow.
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.
For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
Environment info
Operating System: Mac OSX El Capitan
If installed from binary pip package, provide:

Which pip package you installed.

The latest tensorflow.

The output from python -c "import tensorflow; print(tensorflow.__version__)".

0.10.0rc0
Steps to reproduce


In order to reproduce, I have used the main function:
import Input
import Process
import time
import numpy as np
import os
import tensorflow as tf
from datetime import datetime
FLAGS = tf.app.flags.FLAGS
def train():
with tf.Session() as sess:

    images, labels = Process.inputs()

    forward_propgation_results = Process.forward_propagation(images)

    cost, train_loss = Process.error(forward_propgation_results, labels)

    image_summary_t = tf.image_summary(images.name, images, max_images = 2)

    summary_op = tf.merge_all_summaries()

    init = tf.initialize_all_variables()

    saver = tf.train.Saver()

    sess.run(init)

    saver = tf.train.Saver(tf.all_variables())

    tf.train.start_queue_runners(sess = sess)

    train_dir = "/Users/Zanhuang/Desktop/NNP/model.ckpt"

    summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)

    for step in range(100):
        start_time = time.time()
        print(sess.run([train_loss, cost]))
        duration = time.time() - start_time
        if step % 1 == 0:
            num_examples_per_step = FLAGS.batch_size
            examples_per_sec = num_examples_per_step / duration
            sec_per_batch = float(duration)

            format_str = ('%s: step %d, (%.1f examples/sec; %.3f ''sec/batch)')
            print (format_str % (datetime.now(), step, examples_per_sec, sec_per_batch))

            summary_str = sess.run(summary_op)
            summary_writer.add_summary(summary_str, step)


            if step % 2 == 0:
                checkpoint_path = os.path.join(FLAGS.data_dir, 'model.ckpt')
                saver.save(sess, checkpoint_path, global_step = step)

def main(argv = None):
train()
if name == 'main':
tf.app.run()


Then the computation graph seems normal while running but after a few minutes after, the displayed images (in a similar to cifar10 format) shifts and turns into weird unrecognizable colors and the training loss which is normally descending normally is now displayed chaotically. This is all sudden after a few reloads a few minutes after training. I am absolutely sure there is nothing wrong with my hard drive.
What have you tried?

I have tried retraining.

Logs or other output that would be helpful
(If logs are large, please upload as attachment).