`tf.reduce_min/max/mean` returns uninitialized value on tensors with zero-size dimension

I find that tf.reduce_min/max/mean returns uninitialized value (nan for example) on tensors with a zero-size dimension. This would cause problems, for example, when computing loss in an object detection problem, where an input image may contain no object. Please consider defining its behaviour on such inputs, e.g. outputing zeros, raising errors, etc.
Environment info

Operating System: Ubuntu 14.04 LTS
CUDA 7.5, cuDNN 4.0
TF version: 0.9.0rc0, pip version (gpu, python 2.7)

Steps to reproduce
import tensorflow as tf
with tf.Session():
  print(tf.reduce_max(tf.constant(-1.0, shape=[0, 10])).eval())

Output:
-3.40282e+38

Also works for tf.reduce_min, tf.reduce_mean, but not for tf.reduce_sum.