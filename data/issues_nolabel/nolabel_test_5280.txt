Ubuntu 16.04 - GPU-enabled binary for Python3.5 in Anaconda - NVidia Compute Capability 2.1 GPU not detected

Issue
I have an old GPU (GTX 560 Ti) with a power compute of 2.1, according to the Nvidia website.
I am using Anaconda3 on Ubuntu, and I used the following binary to install Tensorflow:
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl

Tensorflow is running, but trying the Tensorflow.org test about using GPUs, I get this output:
Device mapping: no known devices.
I tensorflow/core/common_runtime/direct_session.cc:252] Device mapping:

MatMul_5: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:819] MatMul_5: /job:localhost/replica:0/task:0/cpu:0

Trying a manual device placement using with tf.device('/gpu:0'):, I get
InvalidArgumentError: Cannot assign a device to node 'MatMul_4': Could not satisfy explicit device specification '/device:GPU:0' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0
     [[Node: MatMul_4 = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/device:GPU:0"](a_4, b_4)]]

What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I found this [https://github.com/tensorflow/tensorflow/issues/227](old issue): Compute capability < 3.5. The OP had the same GPU, but it was for a build from source.
Environment info
Operating System: Ubuntu 16.04
Installed version of CUDA and cuDNN: 8.0.27 + 5.1.5
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
-rw-r--r-- 1 root root   560184 Okt 29 20:06 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Okt 29 20:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Okt 29 20:06 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27
-rwxr-xr-x 1 root root   394472 Okt 29 20:05 /usr/local/cuda/lib64/libcudart.so.8.0.27
-rw-r--r-- 1 root root   737516 Okt 29 20:06 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 79337624 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Okt 29 20:11 /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:

A link to the pip package you installed:

export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp35-cp35m-linux_x86_64.whl


The output from python -c "import tensorflow; print(tensorflow.__version__)".

0.11.0rc1

If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I tried the example in the test from the link above:
# Creates a graph.
with tf.device('/gpu:0'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
  c = tf.matmul(a, b)
# Creates a session with log_device_placement set to True.
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
# Runs the op.
print sess.run(c)