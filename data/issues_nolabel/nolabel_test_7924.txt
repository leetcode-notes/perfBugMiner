tf.train.import_meta_graph('model.meta') cannot handle seq2seq models with attention?

Environment:
Ubuntu 16.04
TensorFlow v1.0.0
When attempting to import a saved graph using "tf.train.import_meta_graph('model.meta')," I get the following error:
Traceback (most recent call last):
  File "test_load.py", line 19, in <module>
    new_saver = tf.train.import_meta_graph('model.meta')
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py", line 1577, in import_meta_graph **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.py", line 498, in import_scoped_meta_graph producer_op_list=producer_op_list)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py", line 259, in import_graph_def raise ValueError('No op named %s in defined operations.' % node.op)
ValueError: No op named attn_add_fun_f32f32f32 in defined operations.

This error isn't thrown when I retrain my model without attention and import the graph with the same line of code.
Is loading a model trained with attention not currently supported?
Thanks!