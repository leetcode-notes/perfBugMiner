Use Tensorflow in conjunction with PyTorch/Theano

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 0.12.1
Python version: 2.7.10
Bazel version (if compiling from source): None
CUDA/cuDNN version: 5.1
GPU model and memory: 1080-Ti
Exact command to reproduce: None

Describe the problem
I'm trying to use Tensorflow in conjunction with PyTorch (I built the model in Tensorflow to generate vector representations and PyTorch trains on top of those). However, the problem is that PyTorch runs out of memory because TF will replicate the model in ALL available CUDA devices. In this case CUDA_VISIBLE_DEVICES is not helpful, and I tried GPU device tf.device("/gpu:0") but Tensorflow still fills up all GPUs' memory.
Is there some way to actually limit Tensorflow's GPU usage to one and free up the other for other DL libraries like PyTorch or Theano?