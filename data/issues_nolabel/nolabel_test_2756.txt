Dataset in GPU memory: updating specific elements in existing tf.Variable

My machine has a Titan X card so I would like to use the memory as efficient as possible to avoid expensive data transfer between the CPU and GPU. Therefore, I want to have as many images as possible (let's say 5 GB) on the GPU memory inside a tf.Variable or tf.constant. However, I also want to update these data tensors after a number of iterations (e.g. a replay memory). For training, I then only need to send sample indices to the GPU and use tf.slice to generate a training batch.
My question is what the correct way is to update specific elements in an existing tf.Variable? I already found methods using tf.scatter_update and tf.slice:
http://stackoverflow.com/questions/34685947/adjust-single-value-within-tensor-tensorflow
http://stackoverflow.com/questions/37593960/set-k-largest-elements-of-a-tensor-to-zero-in-tensorflow
But these methods seem cumbersome and tricky. Are there better ways of updating existing variables?