Let build_server.sh take whl file URL as an input argument.

This make it possible to test OSS GRPC distributed runtime in
dist_test/remote_test.sh against a release build.
Usage example:

Build the server using a release whl file. (Obviously this means that
the Linxu CPU PIP release build has to pass first.)
$ export DOCKER_VERSION_TAG="0.11.0rc1"
$ tensorflow/tools/dist_test/build_server.sh
tensorflow/tf_grpc_test_server:${DOCKER_VERSION_TAG}
http://ci.tensorflow.org/view/Release/job/release-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-${DOCKER_VERSION_TAG}-cp27-none-linux_x86_64.whl
--test

2. Run remote_test.sh:
  $ export TF_DIST_DOCKER_NO_CACHE=1
  $ export
TF_DIST_SERVER_DOCKER_IMAGE="tensorflow/tf_grpc_test_server:${DOCKER_VERSION_TAG}"
$ export TF_DIST_GCLOUD_PROJECT="my-project"
$ export TF_DIST_GCLOUD_COMPUTE_ZONE="my-zone"
$ export TF_DIST_CONTAINER_CLUSTER="my-cluster"
$ export TF_DIST_GCLOUD_KEY_FILE="/path/to/my/key.json"
$ tensorflow/tools/dist_test/remote_test.sh
      "http://ci.tensorflow.org/view/Release/job/release-matrix-cpu/TF_BUILD_CONTAINER_TYPE=CPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=cpu-slave/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-${DOCKER_VERSION_TAG}-cp27-none-linux_x86_64.whl"