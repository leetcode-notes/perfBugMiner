Wrong Momentum Equation in Tensorflow's Kernel

I believe I found a slight error in the multiplication of the learning rate
Momentum Optimization has the form:

Where epsilon is the learning rate and p is the momentum.
Reference: Ning Qian's Momentum Paper (1999) http://brahms.cpmc.columbia.edu/publications/momentum.pdf
In tensorflow/core/kernel/training_ops.cc, lines 68 and 69 (ApplyMomentum) we find:
accum = accum * momentum() + grad;
var -= accum * lr();
Expanding this, we get:
var -= (accum*momentum() + grad) * lr();
// =>
var -= accum*momentum()*lr() + grad*lr();
Notice how the momentum variable is being multiplied by the learning rate, but this should not be the case. The correct form is:
accum = accum * momentum() + grad * lr();
var -= accum;
Here's my pull request fixing this: #904