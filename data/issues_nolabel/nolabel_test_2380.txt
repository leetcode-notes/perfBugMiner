[skflow] Added support for different parameters per layer in dnn

Added support for per layer configuration of activation function and
dropout probabilities. Example usage as per following code:
def model(X, y):
    l3 = skflow.ops.dnn(
        X,
        hidden_units=[10, 20],
        activation=[tf.nn.tanh, tf.nn.relu6]
    )
    return skflow.models.linear_regression(l3, y)

regressor = skflow.TensorFlowEstimator(
    model_fn=model,
    n_classes=0,
    steps=50000,
    learning_rate=0.1,
    batch_size=128,
    verbose=1
)

regressor.fit(X_t, Y_t)
Tested with single activation function and with multiple ones that
nothing crashes. Seem to be working correctly