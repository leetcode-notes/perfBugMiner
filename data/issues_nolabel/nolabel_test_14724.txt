Using GPU mnist_deep.py throws OOM when allocating tensor with shape...

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No, I am using the mnist_deep.py with tensorflow 1.4.0
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 & Tensorflow 1.4.0 binary installation, Linux Ubuntu 16.04 & Tensorflow 1.4.0 built form source
TensorFlow installed from (source or binary): Windows 10 installed with TF binary, Linux Ubuntu 16.04 TF built from source
TensorFlow version (use command below): 1.4.0
Python version: 3.6.2 on Windows 10, 3.5.2 on Linux
Bazel version (if compiling from source): 0.7.0
GCC/Compiler version (if compiling from source): 5.4.0
CUDA/cuDNN version: CUDA 8.0, CuDNN 6.0
GPU model and memory: For Windows 10: NVIDIA GeForce 940MX, For Linux: HW similar to NVIDIA Jetson TX2
Exact command to reproduce: python mnist_deep.py

Describe the problem
The mnist_deep.py sample given in Tensorflow examples/tutorials works fine when run on CPU. But when the same example is run using GPU, an OOM occurs when trying to allocate memory for tensor (specifically 10000) in both the cases. It does not matter if one increases/decreases the number of iterations to train the model, the OOM occurs even after a single iteration is executed.
The other examples like mnist.py, mnist_softmax.py, mnist_softmax_xla.py, etc. runs properly without any issues on the GPU. I have also tried to use the config_proto options but none of them seem to help.
Source code / logs

Windows 10:
tensor_name="edge_75_Mean_1", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]()]]
Caused by op 'conv1/Conv2D', defined at:
  File "mnist_deep.py", line 176, in 
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File "C:\Program Files\Python36\lib\site-packages\tensorflow\python\platform\app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "mnist_deep.py", line 137, in main
    y_conv, keep_prob = deepnn(x)
  File "mnist_deep.py", line 63, in deepnn
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
  File "mnist_deep.py", line 105, in conv2d
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
  File "C:\Program Files\Python36\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py", line 630, in conv2d
    data_format=data_format, name=name)
  File "C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\ops.py", line 2956, in create_op
    op_def=op_def)
  File "C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\ops.py", line 1470, in init
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28]
         [[Node: conv1/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/device:GPU:0"](reshape/Reshape, conv1/Variable/read)]]
         [[Node: Mean_1/_7 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_75_Mean_1", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]]

####Linux:
tensor_name="edge_75_Mean_1", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]()]]
Caused by op 'conv1/Conv2D', defined at:
  File "mnist_deep.py", line 176, in 
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File "C:\Program Files\Python36\lib\site-packages\tensorflow\python\platform\app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "mnist_deep.py", line 137, in main
    y_conv, keep_prob = deepnn(x)
  File "mnist_deep.py", line 63, in deepnn
    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
  File "mnist_deep.py", line 105, in conv2d
    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
  File "C:\Program Files\Python36\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py", line 630, in conv2d
    data_format=data_format, name=name)
  File "C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\ops.py", line 2956, in create_op
    op_def=op_def)
  File "C:\Program Files\Python36\lib\site-packages\tensorflow\python\framework\ops.py", line 1470, in init
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[10000,32,28,28]
         [[Node: conv1/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/device:GPU:0"](reshape/Reshape, conv1/Variable/read)]]
         [[Node: Mean_1/_7 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_75_Mean_1", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]]

Further detailed logs can be attached if needed. Your help and pointers to solve this will be much appreciated.