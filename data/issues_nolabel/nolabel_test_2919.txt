feed_dict performance

I have been experimenting with different way of reading data in tensorflow, namely:

input ops / queues
feed_dict / placeholders

I am finding that feed_dict is much slower on my alexnet benchmark. I have adapted the alexnet benchmark code from the convnet-benchmarks. You can find my benchmarking code here. The main diff is the addition of a feed_dict flag which switches between using tf.Variable and tf.Placeholder for the inputs/labels.
In all my tests, I only run the fprop.
My first test was running the benchmark on a GPU using NCHW:
feed_dict=True: 102 ms/minibatch
feed_dict=False 28 ms/minibatch

As you can see, with feed_dict=False, it matches the benchmark, but with feed_dict=True, it is 4-5x slower. You can find the full output for feed_dict=True here
and feed_dict=False here. These contain yappi profiling output which shows that the bottleneck does not seem to be in the python code. I have also attached the tf timeline output and would appreciate if you can tell me how to interpret it in chrome://tracing.
timeline_with_feed_dict.json.txt
timeline_without_feed_dict.json.txt
I also ran the same test on CPU using NHWC:
feed_dict=True: 727 ms/minibatch
feed_dict=False: 664 ms/minibatch

So using feed_dict appears to have a constant/one time cost.
I was able to gain almost 2x speedup by changing this line from np.array to np.asarray, but feed_dict is still quite slow.
Please let me know what your thoughts are about this and whether feed_dict is supposed to be this much slower than a pipeline using tfrecords/queues.