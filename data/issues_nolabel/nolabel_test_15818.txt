Tensorflow Object Detection using Tensorflow Mobile

I am trying to use a custom model in the TF-Detect Android Demo.
model: ssd_mobilenet_v1_coco
The model is trained on 8 classes. After exporting the model I've optimised it using Tensorflow-Mobile.
bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
    --in_graph=frozen_inference_graph.pb \
    --out_graph=optimized_inf_graph.pb \
    --inputs='image_tensor' \
    --outputs='detection_boxes detection_scores detection_classes num_detections' \
    --transforms='fold_batch_norms  fold_old_batch_norms  quantize_weights'

The optimised graph is giving proper output in my local system, but when it's integrated in the application there is no output shown in the screen. But when I'm using the unoptimised graph (frozen_inference_graph.pb) in the application, it's working fine. I'm getting outputs.What am I doing wrong here?
Have I written custom code: No
OS Platform and Distribution: Mac OS Sierra
TensorFlow installed from: Virtualenv installation
TensorFlow version: 1.4
Bazel version: Build label: 0.7.0-homebrew
CUDA/cuDNN version: NA
GPU model and memory: NA
Exact command to reproduce:

Trained a ssd_mobilenet_v1_coco model using google cloud ml for 8 classes
Exported the frozen graph from checkpoints using the below command set:

python export_inference_graph.py --input_type image_tensor \
     --pipeline_config_path training/ssd_inception_v2_coco.config \
     --trained_checkpoint_prefix training/model.ckpt-200000 \
     --output_directory frozen_graph/

export_inference_graph.py is the python script provided in here https://github.com/tensorflow/models/blob/master/research/object_detection/export_inference_graph.py. Tested the frozen_inference_graph.py in my local system, it's working fine.

Used the below command to convert the frozen_inference_graph.py to optimized graph:

bazel-bin/tensorflow/tools/graph_transforms/transform_graph \
    --in_graph=<path to frozen_inference_graph.pb> \
    --out_graph=<path where optimized_inf_graph.pb will be stored> \
    --inputs='image_tensor' \
    --outputs='detection_boxes detection_scores detection_classes num_detections' \
    --transforms='fold_batch_norms  fold_old_batch_norms  quantize_weights'

Tested the optimized_inf_graph.pb graph in my local system. It's working fine.


Copied the optimized_inf_graph.pb in tensorflow/tensorflow/examples/android/assets/ folder. Also, copied my_labels.txt file in the assets folder.


Replaced ssd_mobilenet_v1_android_export.pb with optimized_inf_graph.pb in DetectorActivity.java file


Replaced coco_labels_list.txt with my_labels.txt in DetectorActivity.java file
Tf Detect:
private static final String TF_OD_API_MODEL_FILE =
      "file:///android_asset/optimized_inf_graph.pb";
  private static final String TF_OD_API_LABELS_FILE = "file:///android_asset/coco_labels_list.txt";

My Version:
private static final String TF_OD_API_MODEL_FILE =
      "file:///android_asset/ssd_mobilenet_v1_android_export.pb";
  private static final String TF_OD_API_LABELS_FILE = "file:///android_asset/my_labels.txt";


Installed on my phone: LG G4