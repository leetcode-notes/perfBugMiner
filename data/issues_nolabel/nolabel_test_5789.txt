Improve CUDA peer to peer access to support Amazon P2 instances

If you try to run Tensorflow on a machine that has more than 8 GPU you will receive an error or Warning saying: CUDA_ERROR_TOO_MANY_PEERS.
From the Nvidia forums seems that this is documented behavior:
http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#peer-to-peer-memory-access

Peer-to-peer memory access must be enabled between two devices by calling cudaDeviceEnablePeerAccess() as illustrated in the following code sample. Each device can support a system-wide maximum of eight peer connections.

TF is doing a full NxN peer access map, each 16x16 and that would explain the error on 16 gpus machines.
The challenge is figuring out which GPUs should peer with each other.
We do the full NxN right now since we don't yet have a better answer about the physical topology of the devices.  (E.g., how do you know that the first 8 are all physically the first die, and the second 8 are all physically the second die?)  If such an API exists and we can query it reliably, that might be a better solution.
All the code is in one file: gpu_device.cc
related Issues:

#5362