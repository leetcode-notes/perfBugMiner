For loop over 'NoneType' TensorFlow Dimensions

I'm implementing a new type of NN in TensorFlow. The difference is in the evaluation function, so instead of calling tf.matmul(), I call my own function, which we'll call My_Function(A).
A snippet of the code can be seen below, where A is the tensor on the left being multiplied by this new NN implementation, which is on the right. The equivalent tensorflow code would be tf.matmul(A, this_new_NN).
def My_Function(self, A):
    dims = A.get_shape().as_list()
    shape = [dims[0], self.m] # Defining shape of resulting tensor
    X = tf.placeholder(tf.float32, shape=[shape[0], shape[1]])
    result = tf.zeros(tf.shape(X), dtype=tf.float32)
    for xyz in self.property:
        # Do some computation between A and xyz, xyz is a property of this_new_NN
        # resulting to temp_H with dimension [shape[0], xyz.m] of type tf.tensor
        dims_H = temp_H.get_shape().as_list()
        indices = [[i,j] for i in range(0, dims_H[0]) for j in range(xyz.k, xyz.k+dims_H[1])]
        # indices is a list of indices to update in "result"
        values = tf.reshape(temp_H, [-1]) # Values in temp_H as 1D list
        delta = tf.SparseTensor(indices, values, shape)
        result += tf.sparse_tensor_to_dense(delta)
    return result

Now the problem I'm having is in the line where I calculate the indices, where I'm getting the error
TypeError: 'NoneType' object cannot be interpreted as an integer
Now, I understand that this error means that you cannot iterate a for loop over a type of None, but the problem I have is the test set and the training set have different values for batch_size. This means that when I go to create result, the first dimension is unknown which is why it is of type None.
But, to get the indices that I have to update in result, I have to use a for loop to generate those values as a list to feed into delta which I'm creating as a tf.SparseTensor so it can be added to result.
My question is, what is the best way to get the indices? I have tried replacing dims_H[0] in the for loop with a tf.placeholder(tf.int32) object instead, where I would then just pass the size when I run the session, but I get the error of
TypeError: 'Tensor' object cannot be interpreted as an integer
Any help would be greatly appreciated.
Edit:
Just for reference, this code is called in the following way, where M is the pre-built new NN composed with tf.Variable values.
Y1 = tf.nn.relu(M.My_Function(A) + B1)
where B1 is the offset for this layer, and A is the input layer.
Edit2:
result should be a zero tensor every time My_Function is called. However, I have a suspicion that it is preserving the values of result with each function call. If this is right, please let me know what I need to do to change that.
Edit3:
When defining A it is defined as
X1 = tf.placeholder(tf.float32, [None, 28, 28, 1])
A = tf.reshape(X1, [-1, 28*28])

As the dimensions of A change between the training data and test data.