Tensorflow Lite demo app for Android: add support for floating point models as Inception-v3

Although the new Lite interface does support float models as well, the current Android demo app does only support quantized models. Furthermore, it isn't obvious to transfer the code from the quantized version to the floating point model. Based on this discussion I integrated the Inception-v3 slim model as an alternative to the existing MobileNet.
Remaining TODO:
The confidence scores returned by the inception net are not in [0,1] yet. Besides that, the inference itself seems to work. So the correct results are listed on top, but the confidence score isn't normalized. Maybe the given model doesn't include a Softmax layer and ends with the logits? I'm not sure about this. Any help is appreciated.