Converting numpy array to TFRecord is slow

FloatList and Feature is slow for numpy array.
Saving numpy arrays with np.load and np.save is much faster than Converting to TFRecord and reading it back.
while profiling the code, I found that half of the time is spent in _floats_feature.
tf.train.FloatList is taking 1/3 of the time.
How to speed this up?
System information

Below snippet of code to convert numpy array is much slow compared  np.save, np.load:
**OS Platform and Distribution: Linux Ubuntu 16.04
TensorFlow version (use command below): 1.4.0
Python version: 2.7.12

Source code / logs
import tensorflow as tf
import numpy as np



def floatme(value):
    return tf.train.FloatList(value=value)

def _floats_feature(value):
    return tf.train.Feature(float_list=floatme(value))

tfr_filename = "deleteme.tfr"
data = [" ".join(np.random.randint(0, 1000, size=4005).astype(str)) for i in range(10000)]
with tf.python_io.TFRecordWriter(tfr_filename) as writer:
    print('Converting to vectors')
    vectors = [np.fromstring(line, dtype=int, sep=' ', count=4004+1) for line in data]
    print('Converting to examples')
    for i, vec in enumerate(vectors):
        # Create an example protocol buffer
        example = tf.train.Example(features=tf.train.Features(feature={
            'label': _floats_feature([vec[4004], vec[4004]<1.0]),
            'data' : _floats_feature(vec[:4004]),
            }))
        writer.write(example.SerializeToString())






ncalls
tottime
percall
cumtime
percall
filename:lineno(function)




232810
49.887
0
49.887
0
convert_train_dataset_tfrecord.py:76(floatme)


116405
20.095
0
20.095
0
{numpy.core.multiarray.fromstring}


232810
13.328
0
63.216
0
convert_train_dataset_tfrecord.py:79(_floats_feature)