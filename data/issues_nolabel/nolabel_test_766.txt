Running TensorFlow on GTX 480 (Compute capability 2.0)

I'm trying to make tensorflow run on an older GPU (GTX 480). So I removed the compute checking condition in gpu_device.cc like this:
       // Only GPUs with no less than the minimum supported compute capability is
      // accepted.
      //if (device_capability < min_supported_capability) {
      //  LOG(INFO) << "Ignoring gpu device "
      //            << "(" << GetShortDeviceDescription(i, desc) << ") "
      //            << "with Cuda compute capability " << device_capability
      //            << ". The minimum required Cuda capability is "
      //            << min_supported_capability << ".";
      //  continue;
      //}
And run the cifar10_train.py
I got the errors as following:
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:67] Creating bin of max chunk size 2.00GiB
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 2424 get requests, put_count=2259 evicted_count=1000 eviction_rate=0.442674 and unsatisfied allocation rate=0.521865
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110
W tensorflow/core/common_runtime/executor.cc:1075] 0x206ad80 Compute status: Invalid argument: Indices are not valid: not lexicographically sorted or containing repeats.
     [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT32, validate_indices=true, _device="/job:localhost/replica:0/task:0/cpu:0"](concat/_195, SparseToDense/output_shape/_197, SparseToDense/sparse_values/_199, SparseToDense/default_value/_201)]]
W tensorflow/core/common_runtime/executor.cc:1075] 0x35962a0 Compute status: Invalid argument: Indices are not valid: not lexicographically sorted or containing repeats.
     [[Node: SparseToDense = SparseToDense[T=DT_FLOAT, Tindices=DT_INT32, validate_indices=true, _device="/job:localhost/replica:0/task:0/cpu:0"](concat/_195, SparseToDense/output_shape/_197, SparseToDense/sparse_values/_199, SparseToDense/default_value/_201)]]
     [[Node: SparseToDense/_203 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/gpu:0", send_device="/job:localhost/replica:0/task:0/cpu:0", send_device_incarnation=1, tensor_name="edge_474_SparseToDense", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"]()]]

I'm guessing if tensorflow is trying to allocate more memory than supported?