RNN: InvalidArgumentError when adding InitialState

Please go to Stack Overflow for help and support:
System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.  The current stock examples are pre-TF1.0 and do not run.  I have already posted an issue regarding them. (#9294 (comment))
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): TF1.1.0
Bazel version (if compiling from source): n/a
CUDA/cuDNN version: 5.1
GPU model and memory: p2-xlarge with 12GiB
Exact command to reproduce:

When training a simple two layer RNN, if I do not include the initialstate, the graph trains properly, if I add the initialstate, then I get the following error.
Brief code (full code below):
    initial_state = lstm_cells.zero_state(batch_size, tf.float32) 
    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)

Error message (full message below):
InvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]
	 [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]
	 [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_16414_Mean_1", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]

If I print the initial_state variable, I get this:
(LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState_1/zeros_1:0' shape=(2500, 75) dtype=float32>))

If I print the state producted by static_rnn call:
(LSTMStateTuple(c=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_0/basic_lstm_cell/add_1:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_0/basic_lstm_cell/mul_2:0' shape=(2500, 75) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_1/basic_lstm_cell/add_1:0' shape=(2500, 75) dtype=float32>, h=<tf.Tensor 'RNN/rnn/multi_rnn_cell_299/cell_1/basic_lstm_cell/mul_2:0' shape=(2500, 75) dtype=float32>))

Here is the full message:
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-15-5e6d1756b352> in <module>()
     90         Xin   : X_test,
     91         Ytrue : one_hot(y_test, LabelMax),
---> 92         keep_prob: 1.0
     93     }
     94 )

/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    776     try:
    777       result = self._run(None, fetches, feed_dict, options_ptr,
--> 778                          run_metadata_ptr)
    779       if run_metadata:
    780         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    980     if final_fetches or final_targets:
    981       results = self._do_run(handle, final_targets, final_fetches,
--> 982                              feed_dict_string, options, run_metadata)
    983     else:
    984       results = []

/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1030     if handle is None:
   1031       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
-> 1032                            target_list, options, run_metadata)
   1033     else:
   1034       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1050         except KeyError:
   1051           pass
-> 1052       raise type(e)(node_def, op, message)
   1053 
   1054   def _extend_graph(self):

InvalidArgumentError: ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]
	 [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]
	 [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_16414_Mean_1", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]

Caused by op u'RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat', defined at:
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/runpy.py", line 174, in _run_module_as_main
    "__main__", fname, loader, pkg_name)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/runpy.py", line 72, in _run_code
    exec code in run_globals
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py", line 3, in <module>
    app.launch_new_instance()
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/traitlets/config/application.py", line 658, in launch_instance
    app.start()
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelapp.py", line 474, in start
    ioloop.IOLoop.instance().start()
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/ioloop.py", line 177, in start
    super(ZMQIOLoop, self).start()
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/ioloop.py", line 887, in start
    handler_func(fd_obj, events)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/stack_context.py", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py", line 440, in _handle_events
    self._handle_recv()
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py", line 472, in _handle_recv
    self._run_callback(callback, msg)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py", line 414, in _run_callback
    callback(*args, **kwargs)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tornado/stack_context.py", line 275, in null_wrapper
    return fn(*args, **kwargs)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py", line 276, in dispatcher
    return self.dispatch_shell(stream, msg)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py", line 228, in dispatch_shell
    handler(stream, idents, msg)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/kernelbase.py", line 390, in execute_request
    user_expressions, allow_stdin)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/ipkernel.py", line 196, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/ipykernel/zmqshell.py", line 501, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py", line 2821, in run_ast_nodes
    if self.run_code(code, result):
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/IPython/core/interactiveshell.py", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "<ipython-input-14-eaca1bbf91d8>", line 48, in <module>
    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py", line 197, in static_rnn
    (output, state) = call_cell()
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn.py", line 184, in <lambda>
    call_cell = lambda: cell(input_, state)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py", line 953, in __call__
    cur_inp, new_state = cell(cur_inp, cur_state)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py", line 241, in __call__
    concat = _linear([inputs, h], 4 * self._num_units, True)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/contrib/rnn/python/ops/core_rnn_cell_impl.py", line 1048, in _linear
    res = math_ops.matmul(array_ops.concat(args, 1), weights)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py", line 1034, in concat
    name=name)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py", line 519, in _concat_v2
    name=name)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 768, in apply_op
    op_def=op_def)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 2336, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/home/ubuntu/anaconda2/envs/py27/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 1228, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [20,75] vs. shape[1] = [2500,75]
	 [[Node: RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/split, RNN/MultiRNNCellZeroState/BasicLSTMCellZeroState/zeros_1, RNN/rnn/multi_rnn_cell/cell_0/basic_lstm_cell/basic_lstm_cell_1/concat/axis)]]
	 [[Node: Mean_1/_9 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_16414_Mean_1", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]()]]

Here is the network creation code:
# Clear the graph memory
tf.reset_default_graph()

# Graph input/output
Xin   = tf.placeholder(tf.float32, [None, n_steps, n_input] , name= "Xin")
Ytrue = tf.placeholder(tf.float32, [None, n_classes]        , name= "Ytrue")

# Graph weights
weights={}
weights['Pre' ] = tf.Variable(tf.random_normal([n_input     , n_hiddenPre ]), name="Wght_Pre") # Hidden layer weights
weights['LSTM'] = tf.Variable(tf.random_normal([n_hiddenPre , n_hidden    ]), name="Wght_LSTM") # Hidden layer weights
weights['Post'] = tf.Variable(tf.random_normal([n_hidden    , n_hiddenPost]), name="Wght_Post")
weights['out' ] = tf.Variable(tf.random_normal([n_hiddenPost, n_classes   ]), name="Wght_Out")

biases={}
biases['Pre' ] = tf.Variable(tf.random_normal([n_hiddenPre ]), name="Bias_Pre")
biases['LSTM'] = tf.Variable(tf.random_normal([n_hidden    ]), name="Bias_LSTM")
biases['Post'] = tf.Variable(tf.random_normal([n_hiddenPost]), name="Bias_Post")
biases['out' ] = tf.Variable(tf.random_normal([n_classes   ]), name="Bias_Out")

Xnew = prepareX(Xin)

with tf.name_scope('DensePre'):
    Xpre = tf.matmul(Xnew, weights['Pre']) + biases['Pre']
    keep_prob  = tf.placeholder(tf.float32)
    Xpre_drop = tf.nn.dropout(Xpre, keep_prob)

    # Linear activation
    Xnew = tf.matmul(Xpre_drop, weights['LSTM']) + biases['LSTM']

with tf.name_scope('RNN'): 
    # Split data because rnn cell needs a list of inputs for the RNN inner loop
    Xnew = tf.split(Xnew, n_steps, axis=0) 
    # new shape: n_steps * (batch_size, n_hidden)

    # Can use one or more LSTM layers
    lstm_cell1  = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)
    lstm_cell2  = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)
    lstm_cells  = tf.contrib.rnn.MultiRNNCell([lstm_cell1,lstm_cell2], state_is_tuple=True)
    #RNN_outputs, state = lstm_cells(Xnew, state=state)  # this code fails, so used line above without state
    
    # The following lines are for the bidirectional RNN, but effort was blocked due to an opaque error message
    #  lstm_cell_back   = tf.contrib.rnn.BasicLSTMCell(n_hidden, state_is_tuple=True)
    #  lstm_cells_back  = tf.contrib.rnn.MultiRNNCell([lstm_cell_back] * 2, state_is_tuple=True)

    # Get LSTM cell output
    initial_state = lstm_cells.zero_state(batch_size, tf.float32) # Not used, but should be!
    RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32, initial_state=initial_state)
    #RNN_outputs, state = tf.contrib.rnn.static_rnn(lstm_cells, inputs=Xnew, dtype=tf.float32)
    print(initial_state)
    print(state)

with tf.name_scope('DensePost'):
    Xnew = tf.matmul(RNN_outputs[-1], weights['Post']) + biases['Post']
    Xnew = tf.nn.dropout(Xnew, keep_prob)
     
with tf.name_scope('DenseOut'):
    # Linear activation
    Ypred        = tf.add(tf.matmul(Xnew, weights['out']),biases['out'], name="Ypred_raw")
    # Compute softmax result
    YpredSoftMax = tf.nn.softmax(Ypred   , dim =1, name="prediction")
    YpredIndex   = tf.argmax(YpredSoftMax, axis=1, name="predIndex" )
# Loss, optimizer and evaluation; Regularization term
l2 = lambda_loss_amount * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.trainable_variables()) 
# L2 loss prevents this overkill neural network to overfit the data
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Ypred, labels=Ytrue)) + l2 # Softmax loss
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost) # Adam Optimizer

correct_pred = tf.equal(tf.argmax(Ypred,1), tf.argmax(Ytrue,1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))