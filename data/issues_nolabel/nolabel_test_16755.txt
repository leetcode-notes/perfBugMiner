Multilayer CNN Softmax Script Error

Hi, I transferred your script for the Softmax regression and Multilayer CNN from your guide:
https://www.tensorflow.org/versions/r0.12/tutorials/mnist/pros/.
I get the following error whether I am running just the simple Softmax regression model or the full Multilayer CNN. Seems like an issue with the arguments used for the cross_entropy, but I don't know what the issue is...could you please help?
ValueError                                Traceback (most recent call last)
 in ()
39     # between the target and the softmax activation function applied to the model's prediction.
40
---> 41 cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))
42
43     # Note that tf.nn.softmax_cross_entropy_with_logits internally applies the softmax
~\Anaconda2\envs\tensorflow\lib\site-packages\tensorflow\python\ops\nn_ops.py in softmax_cross_entropy_with_logits(_sentinel, labels, logits, dim, name)
1742   """
1743   _ensure_xent_args("softmax_cross_entropy_with_logits", _sentinel,
-> 1744                     labels, logits)
1745
1746   # TODO(pcmurray) Raise an error when the labels do not sum to 1. Note: This
~\Anaconda2\envs\tensorflow\lib\site-packages\tensorflow\python\ops\nn_ops.py in _ensure_xent_args(name, sentinel, labels, logits)
1696   if sentinel is not None:
1697     raise ValueError("Only call %s with "
-> 1698                      "named arguments (labels=..., logits=..., ...)" % name)
1699   if labels is None or logits is None:
1700     raise ValueError("Both labels and logits must be provided.")
ValueError: Only call softmax_cross_entropy_with_logits with named arguments (labels=..., logits=..., ...)
Here is my script (essentially copied from the guide):
Multilayer CNN using Tensorflow
Load Data
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
Start Tensorflow InteractiveSession
import tensorflow as tf
sess = tf.InteractiveSession()
Build Softmax regression model. Define our model and training loss function.
# creating nodes for the input images and target output classes

x = tf.placeholder(tf.float32, shape=[None, 784])
y_ = tf.placeholder(tf.float32, shape=[None, 10])
sess.run(tf.global_variables_initializer())
Weight initialization
def weight_variable(shape):
initial = tf.truncated_normal(shape, stddev=0.1)
return tf.Variable(initial)
def bias_variable(shape):
initial = tf.constant(0.1, shape=shape)
return tf.Variable(initial)
Convolutional and pooling operations
Our convolutions uses a stride of one and are zero padded so that
the output is the same size as the input. Our pooling is plain
old max pooling over 2x2 blocks. To keep our code cleaner, let's
also abstract those operations into functions.
def conv2d(x, W):
return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')
def max_pool_2x2(x):
return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],
strides=[1, 2, 2, 1], padding='SAME')
Implement first convolutional layer. t will consist of convolution,
followed by max pooling. The convolution will compute 32 features
for each 5x5 patch. Its weight tensor will have a shape of [5, 5, 1, 32].
The first two dimensions are the patch size, the next is the number of
input channels, aTo apply the layer, we first reshape x to a 4d tensor, with the second and third dimensions corresponding to image width and height, and the final dimension corresponding to the number of color channels.nd the last is the number of output channels. We will
also have a bias vector with a component for each output channel.
W_conv1 = weight_variable([5, 5, 1, 32])
b_conv1 = bias_variable([32])
To apply the layer, we first reshape x to a 4d tensor, with the second
and third dimensions corresponding to image width and height, and the
final dimension corresponding to the number of color channels.
x_image = tf.reshape(x, [-1,28,28,1])
Then convolve x_image with the weight tensor, add the bias, apply the
ReLU function, and finally max pool. The max_pool_2x2 method will reduce
the image size to 14x14.
h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)
h_pool1 = max_pool_2x2(h_conv1)
Second convolutional layer.
In order to build a deep network, we stack several layers of this type.
The second layer will have 64 features for each 5x5 patch.
W_conv2 = weight_variable([5, 5, 32, 64])
b_conv2 = bias_variable([64])
h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
h_pool2 = max_pool_2x2(h_conv2)
Densely connected layer.
Now that the image size has been reduced to 7x7, we add a fully-connected
layer with 1024 neurons to allow processing on the entire image. We
reshape the tensor from the pooling layer into a batch of vectors,
multiply by a weight matrix, add a bias, and apply a ReLU.
W_fc1 = weight_variable([7 * 7 * 64, 1024])
b_fc1 = bias_variable([1024])
h_pool2_flat = tf.reshape(h_pool2, [-1, 7764])
h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
Dropout
To reduce overfitting, we will apply dropout before the readout layer.
We create a placeholder for the probability that a neuron's output is
kept during dropout. This allows us to turn dropout on during training,
and turn it off during testing. TensorFlow's tf.nn.dropout op
automatically handles scaling neuron outputs in addition to masking them,
so dropout just works without any additional scaling.
keep_prob = tf.placeholder(tf.float32)
h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)
Readout layer.  one layer softmax regression.
W_fc2 = weight_variable([1024, 10])
b_fc2 = bias_variable([10])
y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2
Train and Evaluate model.
cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_conv, y_))
train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)
correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
sess.run(tf.global_variables_initializer())
for i in range(20000):
batch = mnist.train.next_batch(50)
if i%100 == 0:
train_accuracy = accuracy.eval(feed_dict={
x:batch[0], y_: batch[1], keep_prob: 1.0})
print("step %d, training accuracy %g"%(i, train_accuracy))
train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})
print("test accuracy %g"%accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))