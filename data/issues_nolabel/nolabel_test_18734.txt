tensorflow::ops::SoftmaxCrossEntropyWithLogits has apparently backwards order to its public attributes

System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
macOS 10.13.3 clang 900.0.39.2 and CentOS Linux 7 gcc-4.8.5


TensorFlow installed from (source or binary):
master


TensorFlow version (use command below):
I have not actually installed the python pip package, but the source tree is a current checkout of master.


Python version:
N/A using the C++ API


Bazel version (if compiling from source):
macOS Build label: 0.11.1-homebrew and Centos Linux 7 Build label: 0.11.1- (@non-git)


GCC/Compiler version (if compiling from source):
macOS clang 900.0.39.2 and CentOS Linux 7 gcc-4.8.5


CUDA/cuDNN version:
N/A


GPU model and memory:
N/A


Exact command to reproduce:
Please read the description below


Describe the problem
When trying to track down why code in pull request #14727 is failing an issue came to light. The gradient testing code in the C++ API would not correctly test C++ gradient code that had been shown to be a faithful reproduction of the python equivalent. It seems that the public attributes "loss" and "backprop" are reversed from their operation output order. @suharshs asked that a new issue be created to track this problem.
Source code / logs
Take a look at the comments in pull request #14727