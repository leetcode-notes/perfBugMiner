How to get the gradients of activations?

In cifar10 example, the gradients of parameters can be got:
grads_and_vars = opt.compute_gradients(loss)
for grad, var in grads_and_vars:
# ...
Is there any way to get the gradients of activations(not the parameters)ï¼Œ and watch them in Tensorboard?