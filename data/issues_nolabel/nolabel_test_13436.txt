"Variable rnn/basic_rnn_cell/kernel already exists, disallowed." error while defining dynamic_rnn

I was writing a simple code to define an RNN and the code goes thus:
n_steps = 28
n_inputs = 28
n_neurons = 150
n_outputs = 10
n_epochs = 100
batch_sz = 150
l_rate = 0.001

X0 = tf.placeholder(tf.float32, [None, n_steps, n_inputs])
Y0 = tf.placeholder(tf.int32, [None])
init_state = tf.zeros([n_steps, n_inputs])

basic_r_cell = rnn.BasicRNNCell(num_units = n_neurons)
ouputs, states = tf.nn.dynamic_rnn(basic_r_cell, X0, initial_state = init_state)

logits = layers.fully_connected(states, n_outputs, activation_fn = None)

Executing the above code gave the below error with traceback:
> ---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-67-05674d7f7864> in <module>()
     16 
     17 basic_r_cell = rnn.BasicRNNCell(num_units = n_neurons)
---> 18 ouputs, states = tf.nn.dynamic_rnn(basic_r_cell, X0, initial_state = init_state)
     19 
     20 logits = layers.fully_connected(states, n_outputs, activation_fn = None)

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn.py in dynamic_rnn(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)
    572         swap_memory=swap_memory,
    573         sequence_length=sequence_length,
--> 574         dtype=dtype)
    575 
    576     # Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn.py in _dynamic_rnn_loop(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)
    735       loop_vars=(time, output_ta, state),
    736       parallel_iterations=parallel_iterations,
--> 737       swap_memory=swap_memory)
    738 
    739   # Unpack final output if not using output tuples.

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\control_flow_ops.py in while_loop(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name)
   2768     context = WhileContext(parallel_iterations, back_prop, swap_memory, name)
   2769     ops.add_to_collection(ops.GraphKeys.WHILE_CONTEXT, context)
-> 2770     result = context.BuildLoop(cond, body, loop_vars, shape_invariants)
   2771     return result
   2772 

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\control_flow_ops.py in BuildLoop(self, pred, body, loop_vars, shape_invariants)
   2597       self.Enter()
   2598       original_body_result, exit_vars = self._BuildLoop(
-> 2599           pred, body, original_loop_vars, loop_vars, shape_invariants)
   2600     finally:
   2601       self.Exit()

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\control_flow_ops.py in _BuildLoop(self, pred, body, original_loop_vars, loop_vars, shape_invariants)
   2547         structure=original_loop_vars,
   2548         flat_sequence=vars_for_body_with_tensor_arrays)
-> 2549     body_result = body(*packed_vars_for_body)
   2550     if not nest.is_sequence(body_result):
   2551       body_result = [body_result]

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn.py in _time_step(time, output_ta_t, state)
    720           skip_conditionals=True)
    721     else:
--> 722       (output, new_state) = call_cell()
    723 
    724     # Pack state if using state tuples

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn.py in <lambda>()
    706 
    707     input_t = nest.pack_sequence_as(structure=inputs, flat_sequence=input_t)
--> 708     call_cell = lambda: cell(input_t, state)
    709 
    710     if sequence_length is not None:

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in __call__(self, inputs, state, scope)
    178       with vs.variable_scope(vs.get_variable_scope(),
    179                              custom_getter=self._rnn_get_variable):
--> 180         return super(RNNCell, self).__call__(inputs, state)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\layers\base.py in __call__(self, inputs, *args, **kwargs)
    439         # Check input assumptions set after layer building, e.g. input shape.
    440         self._assert_input_compatibility(inputs)
--> 441         outputs = self.call(inputs, *args, **kwargs)
    442 
    443         # Apply activity regularization.

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in call(self, inputs, state)
    256   def call(self, inputs, state):
    257     """Most basic RNN: output = new_state = act(W * input + U * state + B)."""
--> 258     output = self._activation(_linear([inputs, state], self._num_units, True))
    259     return output, output
    260 

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _linear(args, output_size, bias, bias_initializer, kernel_initializer)
   1015         _WEIGHTS_VARIABLE_NAME, [total_arg_size, output_size],
   1016         dtype=dtype,
-> 1017         initializer=kernel_initializer)
   1018     if len(args) == 1:
   1019       res = math_ops.matmul(args[0], weights)

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
   1063       collections=collections, caching_device=caching_device,
   1064       partitioner=partitioner, validate_shape=validate_shape,
-> 1065       use_resource=use_resource, custom_getter=custom_getter)
   1066 get_variable_or_local_docstring = (
   1067     """%s

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
    960           collections=collections, caching_device=caching_device,
    961           partitioner=partitioner, validate_shape=validate_shape,
--> 962           use_resource=use_resource, custom_getter=custom_getter)
    963 
    964   def _get_partitioned_variable(self,

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\variable_scope.py in get_variable(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)
    358           reuse=reuse, trainable=trainable, collections=collections,
    359           caching_device=caching_device, partitioner=partitioner,
--> 360           validate_shape=validate_shape, use_resource=use_resource)
    361     else:
    362       return _true_getter(

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\rnn_cell_impl.py in _rnn_get_variable(self, getter, *args, **kwargs)
    181 
    182   def _rnn_get_variable(self, getter, *args, **kwargs):
--> 183     variable = getter(*args, **kwargs)
    184     trainable = (variable in tf_variables.trainable_variables() or
    185                  (isinstance(variable, tf_variables.PartitionedVariable) and

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\variable_scope.py in _true_getter(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)
    350           trainable=trainable, collections=collections,
    351           caching_device=caching_device, validate_shape=validate_shape,
--> 352           use_resource=use_resource)
    353 
    354     if custom_getter is not None:

c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\ops\variable_scope.py in _get_single_variable(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)
    662                          " Did you mean to set reuse=True in VarScope? "
    663                          "Originally defined at:\n\n%s" % (
--> 664                              name, "".join(traceback.format_list(tb))))
    665       found_var = self._vars[name]
    666       if not shape.is_compatible_with(found_var.get_shape()):

ValueError: Variable rnn/basic_rnn_cell/kernel already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:

  File "c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\framework\ops.py", line 1269, in __init__
    self._traceback = _extract_stack()
  File "c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\framework\ops.py", line 2506, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "c:\users\antunnug\appdata\local\programs\python\python35\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 767, in apply_op
    op_def=op_def)