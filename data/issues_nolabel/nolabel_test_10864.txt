Feature Request: Sequence to Sequence Bucketing/Batching

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Sierra Version 10.12.5
TensorFlow version (use command below): v1.2.0-rc2-21-g12f033d 1.2.0

Describe the feature
tf.contrib.training.bucket_by_sequence_length() and tf.contrib.training.bucket() are useful for creating batches of similar-length sequences for training dynamic RNNs. I'd like to be able to create batches of similar-length (input sequence, output sequence) pairs to train Sequence to Sequence models with dynamic encoders and dynamic decoders. I may be wrong, but as far as I can tell, there is no easy way to adapt either of the current bucketing functions to create batches like this. The seq2seq translate tutorial relies on a method def get_batch(self, data, bucket_id) to get such batches, but I think it'd be nicer if TensorFlow had a built-in function that didn't rely on a custom implementation and that integrated nicely with FIFOQueues for reading data.