Using tf.estimator.Estimator with save_checkpoint_steps leads to Tensorboard warnings

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 4.4.0-104-generic
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): v1.4.0-rc1-11-g130a514 1.4.0
Python version: 3.6.4
CUDA/cuDNN version: 8.0.61
GPU model and memory: GeForce GTX TITAN X

Describe the problem
When using tf.estimator.train_and_evaluate(...) with an tf.estimator.Estimator configurated with tf.contrib.learn.RunConfig(save_checkpoints_steps=10, ...), a CheckpointSaverHook will be created automatically. This CheckpointSaverHook will save the graph and graph_def to the summary writer every time it is triggered (see CheckpointSaverHook.before_run).
Basic code example:

estimator = tf.estimator.Estimator(
    model_fn, model_dir, params,
    config=tf.estimator.RunConfig(
        save_checkpoints_steps=100, 
        save_summary_steps=100
    )
)
train_spec = tf.estimator.TrainSpec(train_fn)
eval_spec = tf.estimator.TrainSpec(eval_fn)
tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)

When starting Tensorboard on the written summary, it will output a hundreds of warnings because of multiple graph defs in the summary which I guess slows it down a lot on startup:

W0117 18:47:30.278879 Reloader tf_logging.py:86] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.
W0117 18:47:30.279753 Reloader tf_logging.py:86] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.

I see there might be issues when using multiple graphs, but for a single graph this seems unpracticable.
Related stack overflow discussion: https://stackoverflow.com/questions/48316888