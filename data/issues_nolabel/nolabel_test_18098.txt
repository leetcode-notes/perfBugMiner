[tfgan] Add one sided wasserstein gradient penalty

This PR adds an optional argument to tf.contrib.gan.losses.wasserstein_gradient_penalty which allows for a one sided wasserstein gradient penalty.
The paper On the regularization of Wasserstein GANs presents theoretical arguments why using a weaker regularization term is preferable over the two sided gradient penalty and shows experimental results supporting these arguments.
For reference, here is the code used in the paper.
/cc @joel-shor @sguada