seq2seq tutorial example not working for python 3.4/3.5

I am trying to get the sequence-to-sequence Tensorflow tutorial (https://www.tensorflow.org/versions/r0.11/tutorials/seq2seq/index.html) up and running, but after downloading the WMT data, I am facing an error upon creating the vocabulary:
>> python3 translate.py --data_dir ~/tf-data/
Preparing WMT data in /home/user/tf-data/
Creating vocabulary /home/user/tf-data/vocab40000.fr from data /home/user/tf-data/giga-fren.release2.fixed.fr
Traceback (most recent call last):
  File "translate.py", line 290, in <module>
    tf.app.run()
  File "/home/user/tensorflow3/lib/python3.5/site-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File "translate.py", line 287, in main
    train()
  File "translate.py", line 147, in train
    FLAGS.data_dir, FLAGS.en_vocab_size, FLAGS.fr_vocab_size)
  File "/home/user/tensorflow3/lib/python3.5/site-packages/tensorflow/models/rnn/translate/data_utils.py", line 271, in prepare_wmt_data
    create_vocabulary(fr_vocab_path, train_path + ".fr", fr_vocabulary_size, tokenizer)
  File "/home/user/tensorflow3/lib/python3.5/site-packages/tensorflow/models/rnn/translate/data_utils.py", line 140, in create_vocabulary
    tokens = tokenizer(line) if tokenizer else basic_tokenizer(line)
  File "/home/user/tensorflow3/lib/python3.5/site-packages/tensorflow/models/rnn/translate/data_utils.py", line 109, in basic_tokenizer
    words.extend(_WORD_SPLIT.split(space_separated_fragment))
TypeError: cannot use a bytes pattern on a string-like object

Operating System: Ubuntu 16.04.1 LTS
I tried running on two different systems (Python 3.4.3, Python 3.5.2), and the same error arises.
I am running an up-to-date, CPU-only version of Tensorflow 0.11.0rc0 (for the appropriate version of Python 3.4/3.5) in a virtualenv, with an up-to-date version of the github repository.
My hunch is that this is related to a similar issue (#1432) that had been previously fixed, but this error is not identical, so am not sure if this is new.
Any insight would be much appreciated!