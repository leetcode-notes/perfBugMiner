TensorFlow : Machine Translation example Segmentation fault (Core dumped)

GitHub issues are for bugs / installation problems / feature requests.
For general support from the community, see StackOverflow.
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.
For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
Environment info
Operating System: AWS X2-large GPU instance. Ubuntu
Installed version of CUDA 7.5 and cuDNN: 7.5.18
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
If installed from binary pip package, provide:

Which pip package you installed.
The output from python -c "import tensorflow; print(tensorflow.__version__)". - 0.8.0

If installed from sources, provide the commit hash:
Steps to reproduce

Running the translate.py script from tensorflow/modles/rnn/translate path
It downloads the files, unzip's the files
prepares the data - > creates the vocabulary for English and French data -> tockenizes the data -> train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size)
In train_set = read_data(en_train, fr_train, FLAGS.max_train_data_size) there is a crash bacause of out of memory.

What have you tried?

Tried to give smaller batch size. varied from 32,64 ...512

log
segmentation fault(core dumped)
I tried to run gdb and when I back traced I found this
PyObject_Malloc (nbytes=<optimized out) at ../objects/obmalloc.c 934
How can I run Machine Translation example on a smaller dataset.
Logs or other output that would be helpful
(If logs are large, please upload as attachment).