A unexpected read op is in my pb, It make convertion to dlc fail

I want to conver the pb to dlc. but fail.
I find a unexpected read op between the const and the op.
why ? how can I remove the read op ?
conver error message:
/home/nubiaml/snpe-sdk/snpe-1.2.2/lib/python/converters/tensorflow/layers/eltwise.py:105: RuntimeWarning: error_code=1002; error_message=Layer paramter value is invalid. Layer layer2/Mul: at least two inputs required, have 1; error_component=Model Validation; line_no=582; thread_id=140151840044864
output_name)
/home/nubiaml/snpe-sdk/snpe-1.2.2/lib/python/converters/tensorflow/layers/eltwise.py:83: RuntimeWarning: error_code=1002; error_message=Layer paramter value is invalid. Layer output/output: at least two inputs required, have 1; error_component=Model Validation; line_no=582; thread_id=140151840044864
output_name)
the code which save the pb:
`import tensorflow as tf
from tensorflow.python.framework.graph_util import convert_variables_to_constants
with tf.name_scope("input"):
X = tf.placeholder(tf.float32, shape=(None, 1), name="input");
with tf.name_scope("layer2"):
a = tf.Variable(tf.zeros([1, 1], tf.float32), name="a");
ax = X * a;
with tf.name_scope("output"):
b = tf.Variable(tf.zeros([1, 1], tf.float32), name="b");
h = tf.add(ax, b, name="output");
y = tf.placeholder(tf.float32, shape=(None, 1), name="y");
J = tf.reduce_mean(tf.square(h-y))/2;
optimizer = tf.train.GradientDescentOptimizer(0.1);
train = optimizer.minimize(J, var_list=[a, b]);
sess = tf.Session();
sess.run(tf.global_variables_initializer());
for i in range(10000):
sess.run([train, J], feed_dict={X:[[1], [2]], y:[[1], [2]]})
print(sess.run([a, b]));
graph = convert_variables_to_constants(sess, sess.graph_def, ["output/output"])
tf.train.write_graph(graph, '.', 'graph.pb', as_text=False)
sess.close();`