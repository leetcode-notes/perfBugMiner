FusedBatchNorm & Conv2D backwards doesn't support zero batch size

Most ops in TF work well with tensors with zero elements. However, convolution fusedbatchnorm with cudnn gives the following error:
2017-11-17 08:00:20.835113: F tensorflow/stream_executor/cuda/cuda_dnn.cc:444] could not convert BatchDescriptor {count: 0 feature_map_count: 1024 spatial: 28 28  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX} to cudnn tensor descriptor: CUDNN_STATUS_BAD_PARAM 

I would expect it checks and returns a 4D tensor with zero batch-size. Currently I have to work around it by tf.cond.