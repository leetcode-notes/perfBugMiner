RMSPropOptimizer incompatible with embedding layers.

Description
RMSPropOptimizer does not work with models utilizing embedding layers, which appears to be a consequence of it not implementing _apply_sparse. The other optimizers all implement _apply_sparse, so I assume this is an oversight.
Environment info
Operating System: Ubuntu 14.04 LTS
Installed from source with hash: 03bff43
Steps to reproduce
import numpy as np
import tensorflow as tf

sess = tf.Session()

weights = tf.get_variable('weights', [100, 32], 'float32', trainable=True)
words = tf.constant(np.arange(100, dtype='int32'))
logits = tf.nn.embedding_lookup(weights, words)
labels = tf.constant(np.arange(100, dtype='int64') % 32)
loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels)
optimizer = tf.train.RMSPropOptimizer(0.001)
step = optimizer.minimize(loss)

Logs
log.txt