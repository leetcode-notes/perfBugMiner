Out of GPU Memory -- Only 1 LSTM layer on 980 TI

Hey TF,
I have been using your translate model from your seq2seq tutorial and everything seems to work great.
However, I have encountered a substantial problem. On my 980 TI with 6gb of memory:

5 GRU layers, 512 cells, batch size 32 -- works
1 GRU layer, 1024 cells, batch size 2 -- barely works (tried batch size of 2, 4, 8, 16)

In Keras, I could run 2 GRU layers each with 2048 cells on my the 6gb memory. So the question I have is: how is this possible? What is taking up so much memory when you increase the cell size?
I have a second 980 TI as well. I was really hoping I could put one layer 2048 cells on each card. Thanks again!