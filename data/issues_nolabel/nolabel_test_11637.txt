when i train a GAN model AdamOptimizer get ValueError

with tf.variable_scope(tf.get_variable_scope(),reuse=None):
    d_optim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5).minimize(d_loss, var_list=d_vars, global_step=global_step)
    g_optim = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=0.5).minimize(g_loss, var_list=g_vars, global_step=global_step)

i set reuse=None but it still has ValueError: Variable d_bn2/beta/Adam/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
i even tried set it to False ,but it still has the error
is that a bug in version r1.2?