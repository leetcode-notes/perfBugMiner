To be able to epoch num info from tf.train.string_input_producer

In cifar10 example, we want learning rate decay base on epoch num, the code there use NUM_INSTANCES/batch_size to get steps per epoch, but I wonder if we can directly use epoch num during training ?
It is usefull when you have big train data you do not know it's size pre, like on hdfs.
I've posted one quesion on stack overflow
[(http://stackoverflow.com/questions/39101150/how-to-get-epoch-num-info-from-tf-train-string-input-producer)]
looks like
tf.get_default_graph().get_tensor_by_name('input_train/input_producer/limit_epochs/epochs:0')
does not fit the need.
Any suggestions, or it is not possible to get epoch num directly ?