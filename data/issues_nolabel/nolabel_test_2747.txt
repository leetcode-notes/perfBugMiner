Immediate execution mode with graph caching.

Implementation of immediate mode execution in TensorFlow. The idea is to wrap original tensorflow API, but provide session/run management logic so that commands execute immediately, and graph caching to avoid modifying graph when same op is run repeatedly. Data is kept in TensorFlow runtime whenever possible using persistent tensors and transferred to Python runtime on demand when needed for printing/control flow.
import tensorflow as tf
from tensorflow.contrib import immediate

tfi = immediate.Env(tf).tf        # wraps "tf" namespace, saves it as "tfi"
val1 = tfi.ones((3,))             # creates tensor on GPU
val2 = val1 + val1                # runs into tf.add, keeps result on GPU
val3 = tfi.ones((2, 2, 2, 2))
val4 = tfi.nn.conv2d(val3, val3, [1, 1, 1, 1], "VALID")   # run CuDNN conv2d
if (tfi.reduce_sum(val3)>0.):     # runs reduce_sum on GPU, transfers bool to CPU
  print(val4)                     # transfers whole tensor to CPU for display


This is a single commit rebase of a previous pull request from #2346
@keveman @yuanbyu