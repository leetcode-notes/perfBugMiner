LayerNormBasicLSTMCell causes `bias key not found in checkpoint` when layer_norm=False

When initializing LayerNormBasicLSTMCell, it has a parameter layer_norm which controls whether we want to enable layer norm or not. I assume layer_norm=True should be set during training and layer_norm=False for evaluation. However, if I use this in an Estimator, due to the following line

  
    
      tensorflow/tensorflow/contrib/rnn/python/ops/rnn_cell.py
    
    
         Line 1331
      in
      a2d9b3b
    
    
    
    

        
          
           if not self._layer_norm: 
        
    
  


it will not initialize the bias term because layer_norm=True, resulting in a NotFoundError when loading the saved checkpoint with layer_norm=False.
What should be the expected behavior of this? Should this cell applies the bias anyway regardless the layer_norm? If we do not use the bias during training, I see no points to use it during inference.