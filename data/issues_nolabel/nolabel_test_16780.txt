Trying to allocate large output tensor in custom op leads to multiple evaluation of Compute method

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS X 10.13.2
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): 1.5.0
Python version: 2.7.14
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: CPU-version of Tensorflow
GPU model and memory:
Exact command to reproduce: make

Describe the problem
I wrote a custom op. During debugging i've noticed then Compute method from my op fired multiple times during single op.eval() call.
My quest lead me to row:
OP_REQUIRES_OK(ctx, ctx->allocate_output(0, TensorShape({output_size}), &values_tensor));
If output_size is small (e.g. 1000), my op works well and executes one time.
If output_size is big (e.g. 15000000), my op executes multiple times.
Source code / logs
There are 3 files in archive:

custom op source code
demo eval script
makefile config to build op and run eval

issue.zip