LSTMStateTuple without get_shape() method

I have a problem when building seq2seq model with attention based on the LSTM cell, using TensorFlow r0.9 on OS X.
I find that the LSTMCell generates a LSTMStateTuple state if the state_is_tuple parameter is set to True (the rnn_cell.py code seems to encourage this setting). But when I feed the output to an attention_decoder as the initial_state, the attention() function in seq2seq.py calls the _linear() function in rnn_cell.py, and _linear() calls the get_shape() function of the initial_state variable, and the program reports "AttributeError: 'LSTMStateTuple' object has no attribute 'get_shape'".
Could you please help me find if I am missing some important steps in building seq2seq with attention based on the LSTM cell, or should LSTMStateTuple support the get_shape() function?
(The error does not appear when I set state_is_tuple=False.)
Thank you!