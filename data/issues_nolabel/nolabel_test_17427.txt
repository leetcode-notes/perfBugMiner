Feature Request: Train Using Multiple GPUs with Tensorflow in a Tower-like Fashion for tensorflow 1.4

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
N/A
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 8.1
TensorFlow installed from (source or binary):
Binary
TensorFlow version (use command below):
1.4
Python version:
3.6
Bazel version (if compiling from source):
N/A
GCC/Compiler version (if compiling from source):
N/A
CUDA/cuDNN version:
8.0
GPU model and memory:
2 NVIDIA GeForce GTX 1070 (8 GB each)
-Exact command to reproduce:
N/A

Describe the problem
I tried training my model with a large batch size that is supposed to be enough just for two GPUs but I encounter out of memory errors. I'm using the Estimator API and I was wondering if it handles multi-gpu training like in this example using the cifar_10 dataset. If it doesn't, it would be nice to have the Estimator API handle multi-gpu training such that we can use larger batch sizes.
Source code / logs
Here's the architecture of the model I trained.
{
  "network":[
    {"layer_type": "input_layer", "name": "inputs", "shape": [-1, 168, 168, 1]},
    {"layer_type": "l2_normalize", "axis": [1, 2]},
    {"layer_type": "conv2d", "num_filters": 16, "kernel_size": [3, 3]},
    {"layer_type": "max_pool2d", "pool_size": [2, 2]},
    {"layer_type": "l2_normalize", "axis": [1, 2]},
    {"layer_type": "conv2d", "num_filters": 32, "kernel_size": [3, 3]},
    {"layer_type": "max_pool2d", "pool_size": [2, 2]},
    {"layer_type": "l2_normalize", "axis": [1, 2]},
    {"layer_type": "dropout", "keep_prob": 0.5},
    {"layer_type": "conv2d", "num_filters": 64, "kernel_size": [3, 3]},
    {"layer_type": "max_pool2d", "pool_size": [2, 2]},
    {"layer_type": "l2_normalize", "axis": [1, 2]},
    {"layer_type": "dropout", "keep_prob": 0.5},
    {"layer_type": "collapse_to_rnn_dims"},
    {"layer_type": "birnn", "num_hidden": 128, "cell_type": "LSTM"},
    {"layer_type": "dropout", "keep_prob": 0.5}
  ],
  "output_layer": "ctc_decoder",
  "loss": "ctc",
  "metrics": ["label_error_rate"],
  "learning_rate": 0.001,
  "optimizer": "adam"
}

The image dimensions are 168x168 px and the working batch size is 240 which I would like to double.