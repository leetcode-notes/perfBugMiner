Running two Models in two GPUs for prediction in c++

System information

**Have I written custom code  (as opposed to using a stock example script provided in TensorFlow): N/A
**OS Platform and Distribution (e.g., Debian 9.1):
**TensorFlow installed from (source bazel):
**TensorFlow version (use command below) 1.7:
**Python version 3.6:
**Bazel version (if compiling from source) 0.11:
**GCC/Compiler version (if compiling from source GCC)6.3:
**CUDA/cuDNN version 9.1. cudnn 7.1:
**GPU model and memory 2 GPU GTX 1080 TI, 11GB:
**Exact command to reproduce: compiling by c++

Describe the problem
i would like to use two gpus at the same time for make a preduction of two models by using this of code: session_options.config.mutable_gpu_options()->set_visible_device_list("0"); unfortunatlly i got this error (Invalid allocator type: 0):
2018-04-25 14:35:17.895671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1423] Adding visible gpu devices: 0
2018-04-25 14:35:17.895717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:911] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-25 14:35:17.895722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:917]      0
2018-04-25 14:35:17.895727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:930] 0:   N
2018-04-25 14:35:17.895961: E tensorflow/core/common_runtime/gpu/process_state.cc:125] Invalid allocator type: 0
2018-04-25 14:35:17.895977: E tensorflow/core/common_runtime/direct_session.cc:167] Internal: Failed to get memory allocator for TF GPU 0 with 10913103872 bytes of memory.
Source code / logs
session_options.config.mutable_gpu_options()->set_visible_device_list("0");   --->error is here
session_options.config.mutable_gpu_options()->set_allow_growth(true);
session.reset(tensorflow::NewSession(tensorflow::SessionOptions(session_options)));