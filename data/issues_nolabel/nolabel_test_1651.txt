Support for inter-example-dependent labels?

This is likely the wrong place for this, but I've run into a dead end on other websites.
I have a somewhat unusual learning task: the "labels" for my examples (i.e., images) are actually relations between specific images. For instance, suppose each batch consists of 2*n images, where the pair (i, j) has label 1 while the pair (j, i) has label -1. Suppose most (i.e., the vast majority) pairs possible from the set of images lack any label, and as such random sampling will only rarely yield even a single relation to train on. Therefore, in this example, each batch consists of a set 2N images, N pairs of which are known to have some relation.
TensorFlow is so flexible it's easy to design a net that can compute the appropriate loss function. However, creating the input is problematic,requiring many queue objects (why do readers only accept queues in TensorFlow instead of outputs from previous nodes?!). Assuming that I have some set of files which are serialized examples, each a list of the form {file1: <...>, file2: <...>, label: <...>}, is there a simple way to serve them to the net as a tensor of shape 2N * W * H * C (with image i and image i + 1 belonging to a single relation, where i is (0, 2, 4, 6, ...) i.e., [relation_n_image_1, relation_n_image_2, relation_m_image_1, ...])? My current creation, individual components of which work but works as a whole only in theory, employs 5 queue objects of various kinds and does not shuffle perfectly.
Will more flexible readers be implemented in the future, or is there something I'm missing?