MonitoredTrainingSession supports partial restore from checkpoint

As mentioned in #6604 , MonitoredTrainingSession is preferred to Supervisor, I think it is useful to support partial restoration from checkpoint files in MonitoredTrainingSession.
The main idea is bypassing checkpoint restoration of SessionManager, and adding a new CheckpointRestorerHook to restore data from checkpoint, after tf.Session is created and init_op is run.
A new ctor parameter restore_var_list=None added to explicitly specify which part of variables to be restored. If not set, all variables are restored by default behavior of Saver.
This way the user can train a model, save checkpoint file, change the model a bit and fine-tune the new model by specifying restore_var_list when he/she continues training.