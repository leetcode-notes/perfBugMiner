Resource exhausted error in the middle of training

I train the inception v1 (slim) model on my own data set. 269 classes total.
The max training step is 60435 and batch size is 256 as below
--max_number_of_steps=60435
--batch_size=256
The model runs under GPU mode and I have 4 Tian X GPUs, with each has 12G GPU memory.
The Resource exhausted error happen after at least 46831 trainning steps, since i can see the last check point file is model.ckpt-46831.
I do not know why the issue happen in the middle, but not at very beginning of the training process.
The error log report by Tensor Fow is as below:
//other lines above.
I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 11.16GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats:
Limit:                 12049707828
InUse:                 11984328960
MaxInUse:              12038083584
NumAllocs:               248036306
MaxAllocSize:           2831155200
W tensorflow/core/common_runtime/bfc_allocator.cc:274] ************************************************************************************************_xx
W tensorflow/core/common_runtime/bfc_allocator.cc:275] _Ran out of memory trying to allocate 39.81MiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:968] Resource exhausted: OOM when allocating tensor with shape[256,832,7,7]
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors.ResourceExhaustedError'>, OOM when allocating tensor with shape[256,112,112,64]
[[Node: InceptionV1/InceptionV1/Conv2d_1a_7x7/BatchNorm/moments/sufficient_statistics/SquaredDifference = SquaredDifference[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"](InceptionV1/InceptionV1/Conv2d_1a_7x7/Conv2D, InceptionV1/InceptionV1/Conv2d_1a_7x7/BatchNorm/Add)]]
[[Node: InceptionV1/InceptionV1/MaxPool_5a_2x2/MaxPool/_1231 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_3156_InceptionV1/InceptionV1/MaxPool_5a_2x2/MaxPool", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]]
Caused by op u'InceptionV1/InceptionV1/Conv2d_1a_7x7/BatchNorm/moments/sufficient_statistics/SquaredDifference', defined at:
File "train_image_classifier.py", line 585, in 
tf.app.run()
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
sys.exit(main(sys.argv[:1] + flags_passthrough))
File "train_image_classifier.py", line 482, in main
clones = model_deploy.create_clones(deploy_config, clone_fn, [batch_queue])
File "/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/tensorflow/models/slim/deployment/model_deploy.py", line 195, in create_clones
outputs = model_fn(_args, *_kwargs)
File "train_image_classifier.py", line 466, in clone_fn
logits, end_points = network_fn(images)
File "/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/tensorflow/models/slim/nets/nets_factory.py", line 103, in network_fn
return func(images, num_classes, is_training=is_training)
File "/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/tensorflow/models/slim/nets/inception_v1.py", line 288, in inception_v1
net, end_points = inception_v1_base(inputs, scope=scope)
File "/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/tensorflow/models/slim/nets/inception_v1.py", line 61, in inception_v1_base
net = slim.conv2d(inputs, 64, [7, 7], stride=2, scope=end_point)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 177, in func_with_args
return func(_args, *_current_args)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py", line 445, in convolution2d
outputs = normalizer_fn(outputs, *_normalizer_params)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 177, in func_with_args
return func(_args, **current_args)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py", line 250, in batch_norm
mean, variance = nn.moments(inputs, axis, shift=shift)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn.py", line 835, in moments
y, axes, shift=shift, keep_dims=keep_dims, name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn.py", line 762, in sufficient_statistics
v_ss = math_ops.squared_difference(x, shift)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py", line 2347, in squared_difference
result = _op_def_lib.apply_op("SquaredDifference", x=x, y=y, name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 749, in apply_op
op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2386, in create_op
original_op=self._default_original_op, op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1298, in init
self._traceback = _extract_stack()
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[256,112,112,64]
[[Node: InceptionV1/InceptionV1/Conv2d_1a_7x7/BatchNorm/moments/sufficient_statistics/SquaredDifference = SquaredDifference[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"](InceptionV1/InceptionV1/Conv2d_1a_7x7/Conv2D, InceptionV1/InceptionV1/Conv2d_1a_7x7/BatchNorm/Add)]]
[[Node: InceptionV1/InceptionV1/MaxPool_5a_2x2/MaxPool/_1231 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_3156_InceptionV1/InceptionV1/MaxPool_5a_2x2/MaxPool", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]]
Traceback (most recent call last):
File "train_image_classifier.py", line 585, in 
tf.app.run()
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
sys.exit(main(sys.argv[:1] + flags_passthrough))
File "train_image_classifier.py", line 581, in main
sync_optimizer=optimizer if FLAGS.sync_replicas else None)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/slim/python/slim/learning.py", line 781, in train
raise
File "/usr/lib/python2.7/contextlib.py", line 35, in exit
self.gen.throw(type, value, traceback)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py", line 969, in managed_session
self.stop(close_summary_writer=close_summary_writer)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py", line 797, in stop
stop_grace_period_secs=self._stop_grace_secs)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py", line 386, in join
six.reraise(*self._exc_info_to_raise)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py", line 296, in stop_on_exception
yield
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/coordinator.py", line 481, in run
self.run_loop()
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py", line 999, in run_loop
self._sv.global_step])
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 717, in run
run_metadata_ptr)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 915, in _run
feed_dict_string, options, run_metadata)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 965, in _do_run
target_list, options, run_metadata)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 985, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.ResourceExhaustedError: OOM when allocating tensor with shape[256,112,112,64]
[[Node: InceptionV1/InceptionV1/Conv2d_1a_7x7/BatchNorm/moments/sufficient_statistics/SquaredDifference = SquaredDifference[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"](InceptionV1/InceptionV1/Conv2d_1a_7x7/Conv2D, InceptionV1/InceptionV1/Conv2d_1a_7x7/BatchNorm/Add)]]
[[Node: InceptionV1/InceptionV1/MaxPool_5a_2x2/MaxPool/_1231 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_3156_InceptionV1/InceptionV1/MaxPool_5a_2x2/MaxPool", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]]
Caused by op u'InceptionV1/InceptionV1/Conv2d_1a_7x7/BatchNorm/moments/sufficient_statistics/SquaredDifference', defined at:
File "train_image_classifier.py", line 585, in 
tf.app.run()
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
sys.exit(main(sys.argv[:1] + flags_passthrough))
File "train_image_classifier.py", line 482, in main
clones = model_deploy.create_clones(deploy_config, clone_fn, [batch_queue])
File "/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/tensorflow/models/slim/deployment/model_deploy.py", line 195, in create_clones
outputs = model_fn(_args, *_kwargs)
File "train_image_classifier.py", line 466, in clone_fn
logits, end_points = network_fn(images)
File "/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/tensorflow/models/slim/nets/nets_factory.py", line 103, in network_fn
return func(images, num_classes, is_training=is_training)
File "/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/tensorflow/models/slim/nets/inception_v1.py", line 288, in inception_v1
net, end_points = inception_v1_base(inputs, scope=scope)
File "/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/tensorflow/models/slim/nets/inception_v1.py", line 61, in inception_v1_base
net = slim.conv2d(inputs, 64, [7, 7], stride=2, scope=end_point)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 177, in func_with_args
return func(_args, *_current_args)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py", line 445, in convolution2d
outputs = normalizer_fn(outputs, *_normalizer_params)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py", line 177, in func_with_args
return func(_args, **current_args)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.py", line 250, in batch_norm
mean, variance = nn.moments(inputs, axis, shift=shift)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn.py", line 835, in moments
y, axes, shift=shift, keep_dims=keep_dims, name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn.py", line 762, in sufficient_statistics
v_ss = math_ops.squared_difference(x, shift)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_math_ops.py", line 2347, in squared_difference
result = _op_def_lib.apply_op("SquaredDifference", x=x, y=y, name=name)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 749, in apply_op
op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2386, in create_op
original_op=self._default_original_op, op_def=op_def)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1298, in init
self._traceback = _extract_stack()
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[256,112,112,64]
[[Node: InceptionV1/InceptionV1/Conv2d_1a_7x7/BatchNorm/moments/sufficient_statistics/SquaredDifference = SquaredDifference[T=DT_FLOAT, _device="/job:localhost/replica:0/task:0/gpu:0"](InceptionV1/InceptionV1/Conv2d_1a_7x7/Conv2D, InceptionV1/InceptionV1/Conv2d_1a_7x7/BatchNorm/Add)]]
[[Node: InceptionV1/InceptionV1/MaxPool_5a_2x2/MaxPool/_1231 = _Recvclient_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_3156_InceptionV1/InceptionV1/MaxPool_5a_2x2/MaxPool", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/cpu:0"]]