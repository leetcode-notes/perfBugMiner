Problem with parameters use_bias=True and bias_initializer=None

Please go to Stack Overflow for help and support:
https://stackoverflow.com/questions/tagged/tensorflow
If you open a GitHub issue, here is our policy:

It must be a bug or a feature request.
The form below must be filled out.
It shouldn't be a TensorBoard issue. Those go here.

Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.3 LTS
TensorFlow installed from (source or binary): pip install
TensorFlow version (use command below): tensorflow (1.3.0)
Python version: Python 3.5
Bazel version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
You can obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the problem
Something weird is happening when I'm using both the parameter use_bias and bias_initializer like this:
import numpy as np
import tensorflow as tf
tf.reset_default_graph()
inp = np.ones((1, 2, 2, 1))
inputs_ = tf.constant(inp, dtype=tf.float32)
n_filters = 1
conv2d_tp = tf.layers.conv2d_transpose(inputs_, n_filters, [3, 3], 
                                       kernel_initializer=tf.ones_initializer(),
                                       use_bias=True,
                                       bias_initializer=None,
                                       strides=(1, 1),
                                       padding='same')


with tf.Session() as sess:
    tf.global_variables_initializer().run()
    out = sess.run(conv2d_tp)
    print(out)
And I got output like this(may differ at different runtime):
[[[[ 3.28321671]
[ 3.28321671]]
[[ 3.28321671]
[ 3.28321671]]]]
As far as I'm concerned, the output element should all be integers, not floating numbers. I know setting the use_bias to True doesn't agree with setting bias_initializer to None in the first place since it's contradictory. But bad things happen when we ignore the use_bias and use the default value, at the same time setting the bias_initializer to None.
Source code / logs
The source code above should be enough to reproduce the output.