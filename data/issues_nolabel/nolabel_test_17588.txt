AttentionWrapper bug with shape inference

This is my source code, which receives an integer sequence, delete odd numbers, and copy the remaining even number sequence twice. For example, input: [1, 2, 3, 4, 5, 6], output: [2, 4, 6, 2, 4, 6]. Of course, padding is used during training.
If I comment L124 out, the code runs very well. However, if this line is enabled, it will raise the following error:

ValueError: The shape for decoder/decoder/while/Merge_7:0 is not an invariant for the loop. It enters the loop with shape (64, 50), but has shape (?, 50) after one iteration. Provide shape invariants using either the shape_invariants argument of tf.while_loop or set_shape() on the loop variables.

This line is intended to disable input feeding scheme in paper "Effective Approaches to Attention-based Neural Machine Translation", which is the default behavior of AttentionWrapper.
Currently both my batch_size and num_steps are placeholders. If I fix the batch size, i.e.: change placeholders to
encoder_inputs = tf.placeholder(shape=[batch_size, None], dtype=tf.int32, name='encoder_inputs')
decoder_targets = tf.placeholder(shape=[batch_size, None], dtype=tf.int32, name='decoder_targets')
decoder_inputs = tf.placeholder(shape=[batch_size, None], dtype=tf.int32, name='decoder_inputs')
encoder_length = tf.placeholder(shape=[batch_size], dtype=tf.int32, name='encoder_length')
decoder_length = tf.placeholder(shape=[batch_size], dtype=tf.int32, name='decoder_length')

, everything works fine again.
The code is so simple, so probably it is a bug with shape inference.