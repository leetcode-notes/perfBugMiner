Building with XLA throws 'error: non-constant-expression cannot be narrowed from type 'std::vector<se::DeviceMemoryBase>::size_type' (aka 'unsigned long') to 'long long' in initializer list'

What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
#5143
bazelbuild/bazel#596
#4103
http://stackoverflow.com/questions/39157631/tensorflow-build-error-with-bazel
http://stackoverflow.com/questions/37313212/tensorflow-bazel-build-failing
http://stackoverflow.com/questions/34941620/unable-to-build-tensorflow-from-source-with-bazel-22nd-january-2016
http://stackoverflow.com/questions/38603017/tensorflow-install-bazel-build-error-failed-package-loads
Unfortunately none of these posts report similar errors.
Environment info
Operating System:
Mac OSX Sierra
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
Neither are installed on my system:
~/tensorflow master*
❯ ls -l /path/to/cuda/lib/libcud*
ls: /path/to/cuda/lib/libcud*: No such file or directory

If installed from binary pip package, provide:

A link to the pip package you installed:
The output from python -c "import tensorflow; print(tensorflow.__version__)".

If installed from source, provide

The commit hash (git rev-parse HEAD)

~/tensorflow master*
❯ git rev-parse HEAD
8cac382a5425d64f3083cb5adec525baa163e18e


The output of bazel version

~/tensorflow master*
❯ bazel version
Warning: ignoring LD_PRELOAD in environment.
............
Build label: 0.4.4-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Feb 2 01:05:15 2017 (1485997515)
Build timestamp: 1485997515
Build timestamp as int: 1485997515

If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I simply followed these instructions. This was my interaction with the configure script:
~/tensorflow master* 4m 13s
❯ ./configure
Please specify the location of python. [Default is /usr/local/bin/python]: 
Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] y
XLA JIT support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages
Please input the desired Python library path to use.  Default is [/usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages]

Using python library path: /usr/local/Cellar/python/2.7.13/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages
Do you wish to build TensorFlow with OpenCL support? [y/N] n
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] n
No CUDA support will be enabled for TensorFlow
Configuration finished
Warning: ignoring LD_PRELOAD in environment.
Extracting Bazel installation...
..........................................................
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
Warning: ignoring LD_PRELOAD in environment.
..........................................................
INFO: All external dependencies fetched successfully.

I then ran
~/tensorflow master* 1m 35s
❯ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package

and got the following error
ERROR: /Users/ethan/tensorflow/tensorflow/compiler/xla/service/BUILD:406:1: C++ compilation of rule '//tensorflow/compiler/xla/service:allocation_tracker' failed: cc_wrapper.sh failed: error executing command external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG ... (remaining 105 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
tensorflow/compiler/xla/service/allocation_tracker.cc:178:54: error: non-constant-expression cannot be narrowed from type 'std::vector<se::DeviceMemoryBase>::size_type' (aka 'unsigned long') to 'long long' in initializer list [-Wc++11-narrowing]
        ShapeUtil::GetSubshape(allocation->shape(), {i}),
                                                     ^
tensorflow/compiler/xla/service/allocation_tracker.cc:178:54: note: insert an explicit cast to silence this issue
        ShapeUtil::GetSubshape(allocation->shape(), {i}),
                                                     ^
                                                     static_cast<long long>( )
1 error generated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build

What other attempted solutions have you tried?
Because XLA seemed to be causing the error, I tried building without it and the build was successful.
Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).


It does look like bazel is recording a log but I couldn't find it.


I posted the full output of bazel build in this gist.