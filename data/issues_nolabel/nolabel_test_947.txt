sparse_softmax_cross_entropy_with_logits fails when labels is a placeholder

Running the following results in ValueError: Shapes (?, 1) and (?,) must have the same rank:
 import tensorflow as tf
 from tensorflow.python.ops.nn import sparse_softmax_cross_entropy_with_logits as sparse_ce

 logits = tf.placeholder('float32', (None, 32))
 labels = tf.placeholder('int64', (None, 1))
 loss = tf.reduce_mean(sparse_ce(logits, labels))

Making the minibatch dimension explicit makes no difference: ValueError: Shapes (32, 1) and (32,) must have the same rank.
When I run the unit test for this function there is no problem, but I note that the unit test passes NumPy ndarrays, which are converted to constant tensors. Playing around a bit it seems it fails whenever labels is a placeholder.