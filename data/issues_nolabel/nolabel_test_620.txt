Question about MNIST For ML Beginners, the model definition?

https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html#mnist-for-ml-beginners
In the tutorial for beginner, the model definition flipped from original equation, as say it is a small trick to deal with x being a 2D tensor.

First, we multiply x by W with the expression tf.matmul(x, W). This is flipped from when we multiplied them in our equation, where we had Wx, as a small trick to deal with x being a 2D tensor with multiple inputs. We then add b, and finally apply tf.nn.softmax.

Why say it is a small trick ?  Both definition should be equivalent right?
As below
Model definition:
(1) $y = Wx + b$
Shape: (10, n) = (10, 784) x (784, n) + (10, n)
(2) $y = xW + b$
Shape: (n, 10) = (n, 784) x (784, 10) + (n, 10)
I change the downloaded code mnist_softmax.py code to model (1) version and run it, I found that the accuracy is lower than model (2)?
Anyone could tell me the reason?