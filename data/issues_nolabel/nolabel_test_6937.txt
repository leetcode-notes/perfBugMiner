Confusing arg name for sequence_loss

Sorry if this is noise, but it's just a minor suggestion to make the API better (before the release of TensorFlow 1.0 where it will be much more difficult to change)
For the function sequence_loss on the master branch, the name of the parameter softmax_loss_function seems to imply that only softmax based loss are compatible which is not true (for instance tf.nn.sigmoid_cross_entropy_with_logits works too). Maybe the name was that just to indicate the default behavior but I think it is misleading.
Why not simply call the parameter loss_function ? It's more representative of what the parameter really does.