Can I back-propagate the already calculated gradients w.r.t the outputs to all the parameters, and then apply the gradients to the whole network?

I can get the gradients w.r.t the outputs of the network(calculated by python or other ways), Can I just back-propagate the gradients w.r.t the outputs to all the parameters, and then apply them to the whole network?