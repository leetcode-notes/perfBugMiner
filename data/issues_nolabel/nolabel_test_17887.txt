How does the line of code ensure that total_loss are computed after finishing update_ops?

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): ('v1.7.0-rc0-11-g8fded78', '1.7.0-rc1')
Python version: Python 2.7.12
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

Hi, there may be a bug in create_train_op().
In the newest tensorflow code, the line (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/training/python/training/training.py#L428) intends to make sure that total_loss is computed after finishing update_ops.
I think it wants to make sure that the total_loss is computed with up-to-date values of variables after update_ops.
However, my question is that the total_loss is defined elsewhere. There is just a reference to total_loss, which should not make the control_dependencies effective. So how does it work? Is it possible the total_loss is computed with stale values of variables before update_ops?
Thank you very much:-).