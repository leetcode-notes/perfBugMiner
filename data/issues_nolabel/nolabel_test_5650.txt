Problem running word2vec_optimized on Amazon GPU machine

I've not found anyone reporting this specific issue. I'm trying to run tensorflow word2vec script on a aws
gpu machine through docker-nvidia container and getting this error:
log.txt
Environment info
Operating System: ubuntu 16.10 on a g2.2xlarge aws machine. Nvidia driver version 367.57
Installed version of CUDA and cuDNN:
running on docker-nvidia tensorflow-0.11.0-gpu machine
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
./usr/local/nvidia/lib64/libcuda.so
./usr/local/nvidia/lib64/libcuda.so.1
./usr/local/nvidia/lib64/libcuda.so.367.57
./usr/local/cuda-7.5/targets/x86_64-linux/lib/stubs/libcuda.so
./usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudadevrt.a
./usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart_static.a
./usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5
./usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so.7.5.18
./usr/local/cuda-7.5/targets/x86_64-linux/lib/libcudart.so
./usr/local/cuda-7.5/extras/Debugger/lib64/libcudacore.a
./usr/local/cuda-7.5/extras/Debugger/include/libcudacore.h
./usr/lib/x86_64-linux-gnu/libcudnn_static_v5.a
./usr/lib/x86_64-linux-gnu/libcudnn.so.5.1.3
./usr/lib/x86_64-linux-gnu/libcudnn_static.a
./usr/lib/x86_64-linux-gnu/libcudnn.so.5
./usr/lib/x86_64-linux-gnu/libcudnn.so
If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
this is the command I executed and first lines of output:
´python word2vec_optimized.py --train_data text8 --eval_data questions-words.txt --save_path train´
What other attempted solutions have you tried?
Tryed to run the same code on a docker tensorflow-0.10.0 machine (without gpu libraries) and obtained
similar error.
Logs or other output that would be helpful
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GRID K520
major: 3 minor: 0 memoryClockRate (GHz) 0.797
pciBusID 0000:00:03.0
Total memory: 3.94GiB
Free memory: 3.91GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus id: 0000:00:03.0)
I tensorflow/models/embedding/word2vec_kernels.cc:200] Data file: text8 contains 100000000 bytes, 17005207 words, 253854 unique words, 71290 unique frequent words.
Data file:  text8
Vocab size:  71290  + UNK
Words per epoch:  17005207
Eval analogy file:  questions-words.txt
Questions:  17827
Skipped:  1717
W tensorflow/core/framework/op_kernel.cc:940] Failed precondition: Attempting to use uninitialized value global_step
[[Node: AssignAdd = AssignAdd[T=DT_INT32, _class=["loc:@global_step"], use_locking=false, _device="/job:localhost/replica:0/task:0/cpu:0"](global_step, AssignAdd/value)]]