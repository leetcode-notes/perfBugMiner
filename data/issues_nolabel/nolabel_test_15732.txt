Missing OpKernel when using selective registration header

I use the bazel-bin/tensorflow/python/tools/print_selective_registration_header to find out all necessary ops and kernels for my test.pb, and then compile them into a android executable
bazel build test/test:test_run --copt=-DSELECTIVE_REGISTRATION --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=armeabi-v7a
The ops_to_register.h is as follows
// This file was autogenerated by print_selective_registration_header.py
#ifndef OPS_TO_REGISTER
#define OPS_TO_REGISTER
constexpr inline bool ShouldRegisterOp(const char op[]) {
  return false
     || (strcmp(op, "Add") == 0)
     || (strcmp(op, "AddN") == 0)
     || (strcmp(op, "ApplyGradientDescent") == 0)
     || (strcmp(op, "Assign") == 0)
     || (strcmp(op, "AssignAdd") == 0)
     || (strcmp(op, "BiasAdd") == 0)
     || (strcmp(op, "BiasAddGrad") == 0)
     || (strcmp(op, "BroadcastGradientArgs") == 0)
     || (strcmp(op, "ConcatOffset") == 0)
     || (strcmp(op, "ConcatV2") == 0)
     || (strcmp(op, "Const") == 0)
     || (strcmp(op, "ExpandDims") == 0)
     || (strcmp(op, "Fill") == 0)
     || (strcmp(op, "Floor") == 0)
     || (strcmp(op, "FloorMod") == 0)
     || (strcmp(op, "Gather") == 0)
     || (strcmp(op, "Identity") == 0)
     || (strcmp(op, "L2Loss") == 0)
     || (strcmp(op, "MatMul") == 0)
     || (strcmp(op, "Minimum") == 0)
     || (strcmp(op, "Mul") == 0)
     || (strcmp(op, "Neg") == 0)
     || (strcmp(op, "NoOp") == 0)
     || (strcmp(op, "Pack") == 0)
     || (strcmp(op, "Placeholder") == 0)
     || (strcmp(op, "PlaceholderWithDefault") == 0)
     || (strcmp(op, "PreventGradient") == 0)
     || (strcmp(op, "RandomUniform") == 0)
     || (strcmp(op, "RealDiv") == 0)
     || (strcmp(op, "Reshape") == 0)
     || (strcmp(op, "ScatterSub") == 0)
     || (strcmp(op, "Shape") == 0)
     || (strcmp(op, "Sigmoid") == 0)
     || (strcmp(op, "SigmoidGrad") == 0)
     || (strcmp(op, "Size") == 0)
     || (strcmp(op, "Slice") == 0)
     || (strcmp(op, "Softmax") == 0)
     || (strcmp(op, "SparseSoftmaxCrossEntropyWithLogits") == 0)
     || (strcmp(op, "Split") == 0)
     || (strcmp(op, "SplitV") == 0)
     || (strcmp(op, "Sqrt") == 0)
     || (strcmp(op, "Squeeze") == 0)
     || (strcmp(op, "StridedSlice") == 0)
     || (strcmp(op, "Sub") == 0)
     || (strcmp(op, "Sum") == 0)
     || (strcmp(op, "Tanh") == 0)
     || (strcmp(op, "TanhGrad") == 0)
     || (strcmp(op, "Tile") == 0)
     || (strcmp(op, "TopKV2") == 0)
     || (strcmp(op, "Unpack") == 0)
     || (strcmp(op, "VariableV2") == 0)
     || (strcmp(op, "ZerosLike") == 0)
     || (strcmp(op, "_Recv") == 0)
     || (strcmp(op, "_Send") == 0)
  ;
}
#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)


    namespace {
      constexpr const char* skip(const char* x) {
        return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;
      }

      constexpr bool isequal(const char* x, const char* y) {
        return (*skip(x) && *skip(y))
                   ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))
                   : (!*skip(x) && !*skip(y));
      }

      template<int N>
      struct find_in {
        static constexpr bool f(const char* x, const char* const y[N]) {
          return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);
        }
      };

      template<>
      struct find_in<0> {
        static constexpr bool f(const char* x, const char* const y[]) {
          return false;
        }
      };
    }  // end namespace
    constexpr const char* kNecessaryOpKernelClasses[] = {
"BinaryOp< CPUDevice, functor::add<float>>",
"AddNOp< CPUDevice, float>",
"ApplyGradientDescentOp<CPUDevice, float>",
"AssignOpT<CPUDevice, ::tensorflow::int64>",
"AssignOpT<CPUDevice, float>",
"DenseUpdateOp<CPUDevice, ::tensorflow::int64, DenseUpdateType::ADD>",
"BiasOp<CPUDevice, float>",
"BiasGradOp<CPUDevice, float>",
"BCastGradArgsOp",
"ConcatOffsetOp",
"ConcatV2Op<CPUDevice, ::tensorflow::int32>",
"ConcatV2Op<CPUDevice, float>",
"ConstantOp",
"ExpandDimsOp",
"FillOp<CPUDevice, float>",
"UnaryOp< CPUDevice, functor::floor<float>>",
"BinaryOp< CPUDevice, functor::safe_floor_mod<int32>>",
"GatherOp<CPUDevice, float, int32>",
"IdentityOp",
"L2LossOp<CPUDevice, float>",
"MatMulOp<CPUDevice, float, false >",
"BinaryOp< CPUDevice, functor::minimum<float>>",
"BinaryOp< CPUDevice, functor::mul<float>>",
"UnaryOp< CPUDevice, functor::neg<float>>",
"NoOp",
"PackOp<CPUDevice, ::tensorflow::int32>",
"PackOp<CPUDevice, float>",
"PlaceholderOp",
"IdentityOp",
"IdentityOp",
"PhiloxRandomOp<CPUDevice, random::UniformDistribution< random::PhiloxRandom, float> >",
"BinaryOp< CPUDevice, functor::div<float>>",
"ReshapeOp",
"ScatterUpdateOp< CPUDevice, float, int32, scatter_op::UpdateOp::SUB>",
"ShapeOp<int32>",
"UnaryOp< CPUDevice, functor::sigmoid<float>>",
"SimpleBinaryOp< CPUDevice, functor::sigmoid_grad<float>>",
"SizeOp<int32>",
"SliceOp<CPUDevice, ::tensorflow::int32>",
"SliceOp<CPUDevice, float>",
"SoftmaxOp<CPUDevice, float>",
"SparseSoftmaxXentWithLogitsOp<CPUDevice, float, int32>",
"SplitOpCPU<float>",
"SplitVOpCPU<float, int32>",
"UnaryOp< CPUDevice, functor::sqrt<float>>",
"SqueezeOp",
"StridedSliceOp<CPUDevice, ::tensorflow::int32>",
"StridedSliceOp<CPUDevice, float>",
"BinaryOp< CPUDevice, functor::sub<float>>",
"ReductionOp<CPUDevice, float, Eigen::internal::SumReducer<float>>",
"UnaryOp< CPUDevice, functor::tanh<float>>",
"SimpleBinaryOp< CPUDevice, functor::tanh_grad<float>>",
"TileOp<CPUDevice>",
"TopK<float>",
"UnpackOp<CPUDevice, float>",
"VariableOp",
"ZerosLikeOp< CPUDevice, float>",
"RecvOp",
"SendOp",
};
#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))

#define SHOULD_REGISTER_OP_GRADIENT false
#endif

However, when I try to run the executable on my Android device, it says some kernels are missed.
Error creating graph: Invalid argument: No OpKernel was registered to support Op 'Placeholder' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: OnlineTraining/Model/Placeholder_1 = Placeholder[dtype=DT_FLOAT, shape=[2000,400]]()]]

How can I generate a complete file for this? If necessary I can also upload the test.pb file for testing.