segfault in perftools::gputools::StreamExecutor::DeviceMemoryUsage - on a busy gpu

I'm using tensorflow 0.9.0rc0 with cuda 7.5 on Tesla K40c .
The GPU I'm specifying via device_id and
    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.7, allow_growth=True)
    sess_cfg = tf.ConfigProto(allow_soft_placement=True, gpu_options=gpu_options)

is running under a heavy load now (multiple instances of tf are working with it in parallel, so it has 70-80% gpu voltage), but still has ~20-30% free memory, so I wanted to run a one more tiny script.
If I run the script under gdb, I get:
Program received signal SIGSEGV, Segmentation fault.
0x00007fffd51237a1 in perftools::gputools::StreamExecutor::DeviceMemoryUsage(long long*, long long*) const ()
   from /data2/users/usman/anaconda2/envs/tfpy3/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so

is it indeed "out of resources" or there's something wrong with the installation? Shouldn't it somehow signalize about those problems in user code, rather than just segfaulting?