Different dynamic rnn output depending on batch_size

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, own code
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 6.7 and Windows 10
TensorFlow installed from (source or binary):  by pip install
Bazel version:  N/A
TensorFlow installed from (source or binary):  by pip install
TensorFlow version (use command below): ('v1.4.0-rc0-21-g1e25994', '1.4.0-rc1')
on CentOS ; 1.8.0 on Windows
Python version: 2.7 on CentOS ; 3 on Windows
CUDA/cuDNN version: CUDA 8.0/cuDNN 6 on CentOS; CUDA 9.0/cuDNN 7.1 on Windows
GPU model and memory: NVidia Tesla K80 on CentOS ; GeForce GTX 1050 Ti 4GB on Windows
Exact command to reproduce: Example below, tested in jupyter-notebook from anaconda 5.1 (i think so)
ipykernel==4.8.2
ipython==5.6.0
jupyter==1.0.0
jupyter-client==5.2.3
jupyter-console==5.2.0
jupyter-core==4.4.0
jupyter-tensorboard==0.1.6

Describe the problem
Context:  I'm trying to create a syntactic parser with NN classifier which defines state of next parsing step. Batch size is dynamic and equals to parsing steps count during training, but on prediction i feed into NN only 1 state per parsing step, so batch size=1. When i found that i lost some prediction accuracy i started to dig and that's what i found.
Problem: hidden states of dynamic LSTM  are a bit different when batch size is 1 and >1. The difference between them is small, about 0.0000001, but since i have several LSTM in NN, it affects the output of network. And interesting that if batch size is 2, 3 or more, the outputs are equal, but they are not if batch size is 1. And last one, it's ok with input with small dimensions, like [batch_size, 4, 4], but not when i have [batch size, 4, >10]
I wrote some test example to represent this. It worked for me on 2 systems.
Source code / logs
import numpy as np
import tensorflow as tf

config = tf.ConfigProto(allow_soft_placement=True)
config.gpu_options.allow_growth = True
sess = tf.InteractiveSession(config=config)

model_config = {}
model_config["n_hidden"]=10
model_config["lstmStacks"]=2
wordsCount = 4

gatherOut = tf.placeholder(shape=(None,None,model_config["n_hidden"]), dtype=tf.float32)
inp_l1_length = tf.placeholder(shape=(None, ), dtype=tf.int32,name="inp_l1_length")

cell = tf.contrib.rnn.LSTMCell(model_config["n_hidden"])
lstm_layer, lstm_states = tf.nn.dynamic_rnn(cell, gatherOut, sequence_length=inp_l1_length, dtype=tf.float32)    
listOut = lstm_states[1]

sess.run(tf.global_variables_initializer())

inpArr = np.random.uniform(high=1,low=0,size=(1,wordsCount, model_config["n_hidden"]))

res1 = sess.run(listOut, feed_dict= {
    gatherOut: inpArr,
    inp_l1_length: [1]
})

res2 = sess.run(listOut, feed_dict= {
    gatherOut: np.tile(inpArr,(2,1,1)),
    inp_l1_length: [1,1]
})

res3 = sess.run(listOut, feed_dict= {
    gatherOut: np.tile(inpArr,(3,1,1)),
    inp_l1_length: [1,1,1]
})

(res1[0]==res2[0]).all()  # False
(res2[:2]==res3[:2]).all()  # True
(res2[-1]==res3[-1]).all()  # True