Fix for the IOU metric

Previously the IOU metric under estimated the true value as described here
This pull request proposes a fix following the suggestion of @aquariusjay. The score is now only taking into account classes that actually appear in the sample.
The new code works like this:
a) We compute how many classes appear in the sample.
b) We compute the score for every class. If the denominator is 0 then the nominator will be 0 as well! To avoid a zero division we set the denominator to 1 so the result will be 0/1=0.
c) Instead of taking the mean over all scores we sum up all scores and divide by the previously computed number of classes in the sample.