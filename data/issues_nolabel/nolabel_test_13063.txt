XLA representation of batch normalization has changed since TF 1.3

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
TensorFlow installed from (source or binary): source (commit 1f19b8c)
TensorFlow version (use command below): ('v1.3.0-rc1-2173-g36813d5', '1.4.0-dev')
Python version: Python 2.7.12
Bazel version (if compiling from source): Build label: 0.5.3
CUDA/cuDNN version: no
GPU model and memory: no
Exact command to reproduce: cannot provide

Describe the problem
I use Tensorflow compiled from sources (last commit 1f19b8c) with XLA JIT compilation enabled. My inference network uses batch normalization. When I visualize the HLO cluster dumped into the dot file with graphviz I see that batch normalization operation is translated differently in TF 1.3 and TF master. In the master branch the result is like this:

But in the 1.3 branch all these instructions were merged into a single broadcast with a constant parameter. Looks like the translation behavior has been changed by commit 7359fec. This introduces a kind of regression since these instructions can be pre-calculated because the input is constant (as it was done in 1.3).
Source code / logs
In order to reproduce the issue run the Inception V3 network from slim models zoo with variables converted to constants and marked with XLA compile flag.