Getting Error - Exception: No data provided for "activation_2"  Need data for each key in: ['input2', 'aux_input', 'input1']

I am trying to concatenate auxiliary inputs with a siamese lstm.  I have verified the siamese lstm works fine, but cannot add in the auxiliary inputs.  Pleae see code below.
embedding_layer = Embedding(nb_words, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False)
shared_lstm = Bidirectional(LSTM(num_lstm))
sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32', name='input1')
embedded_sequences_1 = embedding_layer(sequence_1_input)
x1 = shared_lstm(embedded_sequences_1)
sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32',name='input2')
embedded_sequences_2 = embedding_layer(sequence_2_input)
y1 = shared_lstm(embedded_sequences_2)
merged_lstm = merge([x1,y1], mode='concat')
merged_lstm = Dropout(rate_drop_dense)(merged_lstm)
merged_lstm = BatchNormalization()(merged_lstm)
auxiliary_output = Dense(1, activation='sigmoid', name='aux_output')(merged_lstm)
auxiliary_input = Input(shape=(aux_train.shape[1],),name='aux_input')
foo = Activation('linear')(auxiliary_input)
merged = merge([merged_lstm,foo],mode='concat')
merged = Dropout(rate_drop_dense)(merged)
merged = BatchNormalization()(merged)
merged = Dense(num_dense, activation=act)(merged)
merged = Dropout(rate_drop_dense)(merged)
merged = BatchNormalization()(merged)
final = Dense(1, activation='sigmoid', name='main_output')(merged)
train = aux_train.as_matrix()
model = Model(input=[sequence_1_input,sequence_2_input,auxiliary_input], output=[final,auxiliary_output])
model.compile(loss={'main_output': 'binary_crossentropy', 'aux_output': 'binary_crossentropy'}, optimizer='nadam', metrics=['acc'], loss_weights=[1., 0.2])
hist = model.fit({'input1': data_1, 'input2': data_2, 'aux_input': train}, {'main_output':labels, 'aux_output':labels}, validation_split=VALIDATION_SPLIT, nb_epoch=50, batch_size=1024, shuffle=True,class_weight=class_weight,callbacks=[early_stopping, model_checkpoint])