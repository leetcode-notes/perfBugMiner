zombie process resulting from using many GPUs

I run the example cifar10_multi_gpu_train.py on a PC equipped with 4 GPUs. Somehow the program occupies 4 GPUs, but only the first GPU is doing computation.
When I hit ctrl + c, the python scripts did not terminate, and I found zombie process using htop (the zombie process is associated with command python). After that I have to reboot using "reboot -nf" to gain access to GPUs. Tensorflow was installed from source (https://github.com/tensorflow/tensorflow.git).
  File "cifar10_multi_gpu_train.py", line 270, in <module>
    tf.app.run()
  File "/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "cifar10_multi_gpu_train.py", line 266, in main
    train()
  File "cifar10_multi_gpu_train.py", line 236, in train
    _, loss_value = sess.run([train_op, loss])
  File "/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 373, in run
    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)
  File "/home/pc/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 433, in _do_run
    target_list)
KeyboardInterrupt

However, if I do export CUDA_VISIBLE_DEVICES=0 before running the example to limit it to one GPU, I am able to terminate the python scripts normally using ctrl + c.
nvidia-smi

htop