Correction to word2vec exercise.

In its existing form, 2 * skip_window training examples for the skip gram model are incorrect because they draw context words from both the beginning and end of data.
I have an individual CLA with Google already.