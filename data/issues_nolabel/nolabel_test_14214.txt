do fine tuning with my own image size

I would like to do transfer learning and fine tuning with some pretrained model in tensorflow.contrib.slim. I searched some examples about this. However, almost all of these examples will resize images to the specified size that the model needs. For example, 224×224 is the size that vgg16 needed. Will it be possible to set my own image size? Like 512×512. In keras, I can do this like following:
`base_model= VGG16(include_top=False, input_shape=(512, 512, 3))` 

Up till now, I have not found the solution, can this be down in tensorflow and slim?