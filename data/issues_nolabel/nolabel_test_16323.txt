Does Broadcast in TF copy first or just do ops along the axis

For example, we have
tensor a with shape (100, 100, 5) and tensor b with shape (1, 1, 5)
when running
c = tf.multiply(a, b)
Is b first copied 100 * 100 times for the big dot multiply with a (GPU memory consuming),
or the dot multiply is done with the original b along axis 0 and 1?
The tf.multiply page refers to numpy multiply that says it won't copy, just loop.
https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html
I guess it's copied first that I run into GPU memory problem by adjusting a bit the b.
How's it implemented in TF? Couldn't find the source gen_math_ops
Issue template update:
Have I written custom code No
OS Platform and Distribution: Windows 10 x64 Home version
TensorFlow installed from pip (anaconda with python 3.6.3)
TensorFlow version: 1.4.1
Bazel version: N/A
CUDA/cuDNN version: CUDA 8.0, cuDNN 6
GPU model and memory: GTX 1050Ti, 4 GB memory (3.3 GB available)
Exact command to reproduce N/A (not relevant to the question)