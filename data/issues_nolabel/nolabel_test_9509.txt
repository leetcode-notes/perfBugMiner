Tensorflow with XLA hangs with both GPU and CPU at ~0% usage when training.

I am using the newest tensorflow which I built from source as of yesterday in an attempt to fix this issue.  Originally I had a source build of tensorflow 1.1.0.  I am running Ubuntu 16.04 with CUDA 8 and CUDNN 5.  My GPU is a GTX 1080.
The problem I am having is when I try to train my character based translator model using the XLA compiler.  The code makes it all the way through the initialize variables, etc up to the first run command which contains my train step and then just freezes.  Both my GPU and CPU are idle.  I attached gdb to my process and it seems to be stuck waiting for some sort of notification.  My model builds and runs fine if I am running it without training in predict mode but still with XLA.  It also runs fine if I train it without XLA.  Just the combo of XLA and training is the issue.
I attached to this my code plus some sample training data.  This problem should be reproducible by running the train.py.
CharacterTranslator.zip