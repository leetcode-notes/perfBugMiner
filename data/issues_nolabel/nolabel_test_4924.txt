Using xavier_initializer causes pyglet to fail to display

Using tf.contrib.layers.xavier_initializer causes pyglet GLX initialization (and therefore gym) to fail. The stack trace is attached. It is not at all clear how calling xavier_initializer can cause GLX initialization to fail.
$ python test.py # See test.py below.
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
[2016-10-12 14:09:54,402] Making new env: Pong-v0
Traceback (most recent call last):
  File "test.py", line 11, in <module>
    env.render()
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/gym/core.py", line 192, in render
    return self._render(mode=mode, close=close)
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/gym/envs/atari/atari_env.py", line 119, in _render
    from gym.envs.classic_control import rendering
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/gym/envs/classic_control/rendering.py", line 23, in <module>
    from pyglet.gl import *
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/gl/__init__.py", line 236, in <module>
    import pyglet.window
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/window/__init__.py", line 1816, in <module>
    gl._create_shadow_window()
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/gl/__init__.py", line 205, in _create_shadow_window
    _shadow_window = Window(width=1, height=1, visible=False)
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/window/xlib/__init__.py", line 163, in __init__
    super(XlibWindow, self).__init__(*args, **kwargs)
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/window/__init__.py", line 504, in __init__
    config = screen.get_best_config(template_config)
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/canvas/base.py", line 161, in get_best_config
    configs = self.get_matching_configs(template)
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/canvas/xlib.py", line 179, in get_matching_configs
    configs = template.match(canvas)
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/gl/xlib.py", line 29, in match
    have_13 = info.have_version(1, 3)
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/gl/glx_info.py", line 86, in have_version
    client_version = self.get_client_version().split()[0]
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/gl/glx_info.py", line 118, in get_client_version
    return asstr(glXGetClientString(self.display, GLX_VERSION))
  File "/home/jay/.virtualenvs/dqn-tf/lib/python3.4/site-packages/pyglet/compat.py", line 88, in asstr
    return s.decode("utf-8")
AttributeError: 'NoneType' object has no attribute 'decode'

Here is my environment information.
Operating system: Ubuntu 14.04.5
CUDA 7.5 and CuDNN 5.1.3 See cuda-versions.txt for details.
Python 3.4, Gym 0.4.2, Pyglet 1.2.4
TensorFlow 0.11.0rc0 installed from https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc0-cp34-cp34m-linux_x86_64.whl.
Here is some minimal code that exhibits the problem (this is the test.py that causes the stack trace above.) Everything is fine until the random call tries to set up GLX.
import gym
import random
import tensorflow as tf

xavier_init = tf.contrib.layers.xavier_initializer()

env = gym.make('Pong-v0')
env.reset()
for _ in range(90):
    env.step(random.randint(0, env.action_space.n - 1))
    env.render()

Commenting the xavier_init line fixes the problem.