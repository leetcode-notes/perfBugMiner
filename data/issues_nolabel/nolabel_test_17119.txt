Apparent thread-safety issue in tensorflow/core/kernels/queue_op.h

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.3
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): ('v1.6.0-rc1-277-g993006fa76', '1.6.0-rc1')
Python version: Python 2.7.14
Bazel version (if compiling from source): 0.10.1-homebrew
GCC/Compiler version (if compiling from source): 4.2.1
CUDA/cuDNN version: 9.1 / 7.0.5
GPU model and memory: NVIDIA GeForce GT 750M with 2 GB device memory (CUDA compute capability 3.0)
Exact command to reproduce: N/A

Describe the problem
Clang warns about a thread-safety issue in tensorflow/core/kernels/queue_op.h at lines 46 and 47 which warnings appear to be valid.
Here is the code around that line:
  void Compute(OpKernelContext* context) override {
    ResourceOpKernel<QueueInterface>::Compute(context);
    if (resource_ && context->track_allocations()) {                          // Line 46
      context->record_persistent_memory_allocation(resource_->MemoryUsed());  // Line 47
    }
  }
No lock is held on mu_.
If there is no thread safety issue, I think that a comment should be added to explain why, as it's not clear.
Source code / logs
./tensorflow/core/kernels/queue_op.h:46:9: warning: reading variable 'resource_' requires holding mutex 'mu_' [-Wthread-safety-analysis]
    if (resource_ && context->track_allocations()) {
        ^
./tensorflow/core/kernels/queue_op.h:47:52: warning: reading variable 'resource_' requires holding mutex 'mu_' [-Wthread-safety-analysis]
      context->record_persistent_memory_allocation(resource_->MemoryUsed());
                                                   ^