tensorflow best practice model exploration record keeping

I understand that we're trying to keep questions to StackOverflow. But, since subjective questions are off-topic for SO, I wasn't sure were to put questions about best practices.
to the point: As a matter of record keeping during model exploration, what are best (I'll settle for sustainable) practices for record keeping of tf graph and parameters of previously tried models?
I'm doing a fair bit of model exploration, but this has resulted in an unsustainable number of model#.py files... Every time I tweak the model involving a graph or parameter change, I feel like I have to keep that .py file for eternity. I have a great workflow for checkpoint saving and loading, but I can't just load up my model from the checkpoint file; I need to have some documentation of what the graph structure and parameters are that actually generated this checkpoint file.
Thanks,
Chris Snyder