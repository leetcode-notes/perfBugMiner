Intermittent CUDA_ERROR_ILLEGAL_ADDRESS errors during back propagation for some networks when using XLA.

Summary
In playing around with the XLA JIT compiler I've experienced intermittent CUDA_ERROR_ILLEGAL_ADDRESS errors during back propagation for some network structures. While other structures may also fail, I can confirm that this happens with simple fully-connected networks when dropout is applied to the hidden units. I have not, however, observed errors when not using XLA or when using XLA, but no hidden dropout.
Environment info


Operating System: Ubuntu 14.04 LTS


GPU: Titan X


NVIDIA driver: 375.26


CUDA: 8.0


cuDNN: 5.1


see also: cuda_libs.txt


bazel: 4.3


TensorFlow: f8fcd85


XLA: Yes


TensorFlow compile command:
bazel build --copt=-march=native -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package


Minimal reproducible example
See https://gist.github.com/nryant/8cea9bb79d7bdb965167e917d8d5aa8b for the script test_dropout.py, which repeatedly builds a small network consisting of a single hidden layer of 512 units and performs 100 fprop/bprop steps. It accepts three command line arguments:

--bprop enables backpropagation (by default, only forward propagation is performed)
--xla enables XLA at the session level
--dropout specifies the dropout proportion

Also see log files produced from running the script with various arguments:

No XLA, fprop + bprop, and dropout: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-noxla_fprop_bprop_dropout-log
XLA and fprop: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop-log
XLA, fprop, and dropout: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop_dropout-log
XLA, fprop + bprop, and dropout: https://gist.github.com/nryant/83829ada37a9b0c221a76184c5e232fa#file-xla_fprop_bprop_dropout-log

The only combination for which we ever observe an error is XLA, fprop + bprop, and dropout, which pretty reliable blows up in the first few iterations.