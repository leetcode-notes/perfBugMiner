Segmentation fault when using Intel MKL with np.linalg.svd

System information
I am running this on the Graham supercomputer of Compute Canada. I tested the bug on computation nodes but it also appears on login nodes without GPUs.

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux - CentOS 7
TensorFlow installed from (source or binary): Custom build with Intel MKL I guess?
TensorFlow version (use command below): b'v1.3.0-0-g9e76bf3' 1.3.0
Python version: Python 3.5.2 (default, Jun 25 2016, 21:38:40) [GCC 5.4.0] on linux
Bazel version (if compiling from source):
CUDA/cuDNN version: 7.5
GPU model and memory: Tesla P100
Exact command to reproduce:

import numpy as np
import tensorflow as tf

a = np.ones((64,256))
u, _, v = np.linalg.svd(a, full_matrices=False)

Without the import tensorflow as tf, the bug doesn't appear.
You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
tf_env.txt
Describe the problem
So basically, when using Intel MKL with the python code above you get a segmentation fault. Without the import tensorflow as tf, the bug doesn't appear. Strangely, when I change the size of the 2nd axis of matrix a to below 201, it works (at some point that I tested, it was 188). When setting the shape of the matrix a to something bigger like (64,256), it just using all CPUs without returning anything as if it was in a deadlock or something. When setting MKL_NUM_THREADS to 1, both bugs disappear. This bug report seems related to all of these issues: #9234 #13004 #11724 #10005. They are not identical to this problem but really similar so this bug report is just to let you know another symptom related to the same problem.
Source code / logs
tf_env.txt
gdb_segfault.txt