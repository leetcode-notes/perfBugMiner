Query in lower-level versions of Get/Put involved in EncodeFixed/DecodeFixed

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): 'v1.2.1-0-gb4957ff', '1.2.1'
Python version:  2.7.12
Bazel version (if compiling from source): 0.4.5
CUDA/cuDNN version: No GPU
GPU model and memory: No GPU
Exact command to reproduce: Run tests from core module.

The problem
While checking coding_test.cc , came across a sub test - TEST(Coding, EncodingOutput) which tests that encoding routines generate little-endian encodings.
This test is passing on a big endian machine. So while debugging realized that the EncodeFixed/DecodeFixed functions from coding.cc and raw_coding.h encode/decode buf values on big endian incorrectly i.e. the character buffer writing happens in the same way as on a little-endian machine.
After I made the required changes to correct the same, although 1 test of my interest(TEST(TensorBundleTest, Checksum)) now passes, I could see many others failing on big endian with errors like:

Data loss: block checksum mismatch: perhaps your file is in a different file format and you need to use a different restore operator?
"Data loss: corrupted record at 19"
Segmentation fault
Invalid argument: sample_rate must be in (0, 2^32), got: 0

So looks like this change is breaking too many things here.
Can anyone help in understanding why the correction is causing so many issues?
Will this change involve too many changes in TensorFlow code to support big endian?