MonitoredTrainingSession aborts without error or exeption

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04.3
TensorFlow installed from (source or binary):
binary, pip install
TensorFlow version (use command below):
v1.4.0-19-ga52c8d9 1.4.1
Python version:
Python 3.6.3 :: Anaconda, Inc.
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
cuda_8.0.61.2, libcudnn.so.6.0.21
GPU model and memory:
Titan-X, 32GB
Exact command to reproduce:
During some training runs, this script just ends after few epochs with printing 'eval done'. It doesn't print any error nor an exception. In other runs, with the same setup in runs through. How could this happen that the for-loop stops even the epochs is smaller than 100?

Edit: I tried it also without the try-except block around the MonitoredTrainingSession, but it was the same: no exception, no error, epoch ~ 15 and printing "eval done"
    tf.logging.set_verbosity(tf.logging.INFO)
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'

    listener_eval = ExampleCheckpointSaverListener(fun_after_save=eval_model)
    listener_generate = ExampleCheckpointSaverListener(fun_after_save=generate)
    hooks_train = [
      tf.train.SummarySaverHook(output_dir=model_path, save_secs=60, scaffold=scaffold_train),
      tf.train.LoggingTensorHook(train_log_tensors, every_n_secs=30),
      tf.train.CheckpointSaverHook(checkpoint_dir=model_path, save_secs=600, scaffold=scaffold_train,
                                   listeners=[listener_eval, listener_generate])
    ]

    try:
      with tf.train.MonitoredTrainingSession(is_chief=True, checkpoint_dir=model_path, save_checkpoint_secs=None,
                                             hooks=hooks_train, save_summaries_secs=None, save_summaries_steps=None,
                                             config=sess_config, scaffold=scaffold_train, log_step_count_steps=1000, stop_grace_period_secs=20) as sess:

        for epochs in range(0, 100):
          print(epochs)
          try:
            while True:
              sess.run([train_op])
          except tf.errors.OutOfRangeError as e:
            print("Epoch %d end." % epochs)
            sess.run(train_reader.iterator.initializer)
    except:
      print("MonitoredTrainingSession")
      print(sys.exc_info())

    print("eval done")
tf_env.txt