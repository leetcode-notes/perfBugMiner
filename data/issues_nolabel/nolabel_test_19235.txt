Bottleneck retrained model predicts one class after applying transforms and opimize_for_inference.

Summary :
Have I written custom code - Mostly using the retrain script from the tensorflow for poets tutorial. I added custom code to validate network but didn't change the training procedure.
OS Platform and Distribution -  Windows 7 x64. Training and evaluation is done on a windows machine using Anconda python distribution. Once I freeze the model I then copy it to a linux box with CentOS 7 x86_64 to do the transformation. The transformed model is then copied back to the windows box for further analysis before deployment.
TensorFlow installed from - anaconda cloud
TensorFlow version - 1.2.1
Bazel version - 0.8.1
CUDA/cuDNN version - 8 / 7
GPU model and memory - GTX 970 4GB
Exact command to reproduce - N/A
I have asked the same question on stackoverflow
https://stackoverflow.com/questions/50243492/inception-v3-retrained-model-incorrect-predictions-after-using-optimize-for-infe/50263837#50263837
and opencv help
http://answers.opencv.org/question/191168/inception-v3-retrained-model-incorrect-predictions-after-using-optimize_for_inference-and-graph_transform-tools/
I can really use some suggestions:

I followed the tensorflow for poets tutorial to retrain inception V3 for 3-class image task

https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0


The network fits the data well and i'm able to validate the frozen model using tensorflow python which predicts unseen samples at 97 % accuracy


The frozen model has to be integrated to a legacy application which uses opencv::DNN module. To get the forzen model ready I applied



optimize_for_inference
graph_transforms with " remove_nodes(op=PlaceholderWithDefault) strip_unused_nodes(type=float, shape="1,299,299,3") sort_by_execution_order" flags


Loaded transformed model with opencv and run some more validation before deployment. The transformed version could not match (not even close) the trained original model.  It mostly predicts a single class.

I used opencv blobFromImage function with swapRB set to true.
I tried to normalize input by subtracting ImageNet mean as well as my training set mean. Unsuccessful in both cases.
I just have no idea what is causing for the model to be so different after its transformed.
Thanks for your time