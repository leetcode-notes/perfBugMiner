Using tensorflow lite invoke inference with multiple input tensors and specifying input node?

System information
Have I written custom code: Yes
OS Platform and Distribution: Ubuntu  16.04
TensorFlow installed from: source:Yes
TensorFlow version: 1.7.0
Python version: 3.6
Bazel version: 0.11.1
GCC/Compiler version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Describe the problem
I converted my tflite model foo.tflite with multiple input arrays flag , I got two inputs (decoded_sample_data: FLOAT32[],decoded_sample_data:1 FLOAT32[])
When invoke inference , I refer to
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/apis.md
float* input = interpreter->typed_input_tensor(0)
My question:
Can  I assign the data to specific input node  like tensorflow mobile method
ex:
private static final String INPUT_DATA_NAME = "decoded_sample_data:0";
private static final String SAMPLE_RATE_NAME = "decoded_sample_data:1"; inferenceInterface.feed(SAMPLE_RATE_NAME, sampleRateList);
inferenceInterface.feed(INPUT_DATA_NAME, floatInputBuffer, RECORDING_LENGTH, 1)
inferenceInterface.run(outputScoresNames);
Thank you!