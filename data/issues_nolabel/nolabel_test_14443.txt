fix the distributed training problem for the estimator api

Current version will fail as I tried to use the tf.estimator.train_and_evaluate api for distributed training on the same machine. All the gpus will be occupied even when I  set session_config.gpu_options.allow_growth = True for tf.estimator.RunConfig.