tf.control_dependencies does not respect fed nodes

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 1.3.0
Python version: 2.7.13
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A

Describe the problem
TLDR: I have a node X which has a control dependency on Y. I do session.run(fetches=[X], feed_dict={Y: value}). TensorFlow still tries to run Y despite it already being fed.
More details:
Consider the following code:
import tensorflow as tf

p = tf.placeholder(tf.float32, name='p')
q = tf.add(p, 2.0)
with tf.control_dependencies([q]):
  r = tf.constant(1.0)

sess = tf.Session()
sess.run(r, feed_dict={q: 5})

# InvalidArgumentError: You must feed a value for placeholder tensor 'p' with dtype float

I would have expected the sess.run call to succeed because I'm already feeding q.