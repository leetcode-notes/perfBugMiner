move dropout to later chapters where it can truly work

@Sohl-Dickstein
This is to replace #1620 ,
remove dropout in the very beginning tutorial on MNIST since it doesn't work in that network architecture,
and move it to Tensorflow Mechanics 101, where it can truly work and we give more detailed explanation on dropout:
After all training epochs, the accuracy on test data will be around 98.5%. However if we remove dropout in the network architecture, the accuracy will decrease to 98.2%. This is because dropout can reduce the effect of overfitting. If we do not have dropout, the accuracy on training data will eventually become 100%, however the accuracy on test data will soon increase to 98.2% but get stalled there. By adding dropout, the accuracy on training data increase slower, but the generalization ability will become better.