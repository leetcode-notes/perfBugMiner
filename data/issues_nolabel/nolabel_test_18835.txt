Issue with building the Hexagon HVX DSP toolchain with TF

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 14.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.8r
Python version:  2.7
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source): 4.8.4
CUDA/cuDNN version: 8
GPU model and memory: GTX 1060
Exact command to reproduce:

Describe the problem
@satok16 @tensorflower-gardener , Could you please clarify the different version-combination of tools to use in an HVX-TF toolchain. It can save many people's effort to find and match these together. You have already mentioned in HVX_TF, that for Qualcomm SDK 3.0, the compatible nnlib version is Aug-2017-commit. However, some features are missing there and we need to use the latest version with SDK 3.3.3, however, these libraries (nnlib, libcontroller, TF-(sub)makefiles) don't match, thus it has become a messy process to figure out which is related to what version.
1) A sample error compiling libcontroller after compiling nnlib with latest SDK (3.3.3):
src_impl/hexagon_controller.c: In function 'hexagon_controller_AppendNode':
src_impl/hexagon_controller.c:484:70: error: 'hexagon_nn_output' has no member named 'max_size'
     pos += snprintf(&output_param_buf[pos], 500, "(%d), ", outputs[i].max_size);
                                                                      ^
make[1]: *** [android_Release/hexagon_controller.o] Error 1
make[1]: Leaving directory `~/Qualcomm/Hexagon_SDK/3.3.3/examples/common/hexagon_controller'
make: *** [tree] Error 2


2) If I use your suggested commit and SDK 3.0, this is the output I am having:
native : hexagon_graph_execution_test.cc:129 Read /data/local/tmp/img_299x299.bmp, size = 269156bytes
native : hexagon_graph_execution_test.cc:135 header size = 54
native : hexagon_graph_execution_test.cc:137 image size = 40
native : hexagon_graph_execution_test.cc:139 width = 299
native : hexagon_graph_execution_test.cc:141 height = -299
native : hexagon_graph_execution_test.cc:286 Ioading image finished.
native : hexagon_graph_execution_test.cc:185 Loading image finished.
native : hexagon_graph_execution_test.cc:189 Copy data to tensor.
native : hexagon_graph_execution_test.cc:307 Run graph
Init hexagon with max attributes (Controller version = 101)
native : hexagon_control_wrapper.cc:104 Add input: Mul, 0
native : hexagon_control_wrapper.cc:127 Allocate inout buffer
native : hexagon_control_wrapper.cc:304 Setup graph completed
Prepare failed! returned 0xffffffff

NN Id = -755923072
Execute graph!
Execution failed!
execute got err: -1

NN Id = -755923072
Execution failed
NN Id = -755923072
Failed to read data.
native : hexagon_graph_execution_test.cc:313 Output byte size = 4032
native : hexagon_graph_execution_test.cc:314 Output shape = [1,1008]
native : graph_transfer_utils.cc:47 === Dump ranking ===
native : graph_transfer_utils.cc:50 0: 1000, dumbbell, 0
native : graph_transfer_utils.cc:50 1: 999, carbonara, 0
native : graph_transfer_utils.cc:50 2: 998, stole, 0
native : graph_transfer_utils.cc:50 3: 997, rubber eraser, 0
native : graph_transfer_utils.cc:50 4: 996, coffee mug, 0
native : graph_transfer_utils.cc:50 5: 995, flagpole, 0
native : graph_transfer_utils.cc:50 6: 994, parallel bars, 0
native : graph_transfer_utils.cc:50 7: 993, cheeseburger, 0
native : graph_transfer_utils.cc:50 8: 992, bubble, 0
native : graph_transfer_utils.cc:50 9: 991, beaker, 0
Finalize hexagon
[       OK ] GraphTransferer.RunInceptionV3OnHexagonExampleWithTfRuntime (5848 ms)
[----------] 1 test from GraphTransferer (5848 ms total)

[----------] Global test environment tear-down
[==========] 1 test from 1 test case ran. (5849 ms total)
[  PASSED  ] 1 test.

  YOU HAVE 5 DISABLED TESTS

3)  Also in the toturial, you did not mention anything about downloading/using an inception-v3 frozen-quantized model. If one follows the building each library from the source, where is the part related to use the [tensorflow_inception_v3_stripped_optimized_quantized.pb] ? Since, when I test with my custom quantized_frozen inception-v3 model, (renaming it to be the same as the original 2016 file (tensorflow_inception_v3_stripped_optimized_quantized.pb), I have the error output as:
...
native : hexagon_graph_execution_test.cc:533 Ioading image finished.
t1(loading image time)=0.026770
native : hexagon_graph_execution_test.cc:546 Build fused graph
native : remote_fused_graph_execute_utils.cc:259 Error during inference: Not found: FeedInputs: unable to find feed output Mul
native : graph_transfer_utils.cc:110 Check failed: status.ok()
Aborted


Thanks.