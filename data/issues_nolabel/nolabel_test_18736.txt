tensorflow/core/framework/allocator.cc:101] Allocation of X exceeds 10% of system memory. #18735

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): 1.7.0
Python version: Python 3.5.2
Bazel version (if compiling from source): 0.11.1
GCC/Compiler version (if compiling from source): 5.4.0
CUDA/cuDNN version: no
GPU model and memory: no
Exact command to reproduce:

Describe the problem
My server has 32gb of RAM, but tensorflow uses only 10% of that memory.
It returns the message:
<<tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.>>
Is it possible to increase this percentage?
Source code / logs
SOURCE CODE:
import keras
from keras import regularizers
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, ZeroPadding2D, add
from keras.models import Model
from keras.layers.core import Layer, Dense, Dropout, Activation, Flatten, Reshape
from keras.regularizers import l2
from keras.utils import np_utils
from keras.callbacks import TensorBoard
from sklearn.model_selection import train_test_split
import numpy as np
import h5py
import time
file_train = 'features/files_train_test/train_inceptionv3_doc2vec.npy'
file_test = 'features/files_train_test/test_inceptionv3_doc2vec.npy'
x_train = np.load(file_train)
x_test = np.load(file_test)
print('shape train: ',x_train.shape,'shape test: ', x_test.shape)
print('size train: ', len(x_train), 'size test: ', len(x_test))
print('prod train: ',np.prod(x_train.shape[1:]), 'prod test: ', np.prod(x_test.shape[1:]))
x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))
x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))
print('shape train: ',x_train.shape,'shape test: ', x_test.shape)
epochs = 10
batch_size = 32
input_size = x_train.shape[1]
output_size = x_train.shape[1]
hidden_size = x_train.shape[1]
file_name = 'features/files_reduce/sparse/autoencoder_inceptionv3_doc2vec_'
x = Input(shape=(input_size,))
h = Dense(hidden_size, activation='relu', activity_regularizer=regularizers.l1(10e-5))(x)
r = Dense(output_size, activation='sigmoid')(h)
autoencoder = Model(inputs=x, outputs=r)
autoencoder.compile(optimizer='adam', loss='mse')
autoencoder.summary()
autoencoder.fit(x_train
,x_train
,batch_size=batch_size
,epochs=epochs
,verbose=1
,validation_data=(x_test, x_test))
autoencoder.save(file_name+name_full)
print('Save encode' + file_name+name_full)
===============================================================================
OUTPUT:
Using TensorFlow backend.
shape train:  (21248, 49452) shape test:  (5313, 49452)
size train:  21248 size test:  5313
prod train:  49452 prod test:  49452
shape train:  (21248, 49452) shape test:  (5313, 49452)
Layer (type)                      | Output Shape              | Param

input_1 (InputLayer)         | (None, 49452)             | 0
dense_1 (Dense)              | (None, 49452)             | 2445549756
dense_2 (Dense)              | (None, 49452)             | 2445549756

Total params: 4,891,099,512
Trainable params: 4,891,099,512
Non-trainable params: 0
Train on 21248 samples, validate on 5313 samples
Epoch 1/10
2018-04-20 11:22:08.069764: W tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.
2018-04-20 11:22:12.089390: W tensorflow/core/framework/allocator.cc:101] Allocation of 9782001216 exceeds 10% of system memory.