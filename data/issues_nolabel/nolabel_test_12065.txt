Feature Request - Seq2Seq Inference Helper w/o Embeddings

tf.contrib.seq2seq has two Helper classes to use during inference, SampleEmbeddingHelper and GreedyEmbeddingHelper. However, both make use of embeddings, which is unhelpful when building sequence-to-sequence models that operate on non-embedded target sequences (my target sequence already consists of meaningful vectors).
I'd like a new Helper class that pipes the output of the decoder RNN at one time step into the decoder RNN at the following time step. It should permit the start_tokens to be vectors (tensors?) and the end_token to be a vector (tensor?) as well. Right now, I'm attempting to use ScheduledOutputTrainingHelper with sampling_probability set equal to 1.0, but I'm struggling to get it to work. Something like a simple OutputInferenceHelper would be very nice :)
If there already exists an easy way to do what I'm suggesting, please let me know!