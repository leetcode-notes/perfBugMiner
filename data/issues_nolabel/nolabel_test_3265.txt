Change is_training of tf.contrib.layers.batch_norm to conditional function

tf.contrib.layers.batch_norm is using is_training as a python boolean variable so I may have to define two different ops which share its variables by using reuse=True to the second op.
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L209
However, I think it is better to use tf.placeholder or other tensor variables as is_training and use tf.cond to dynamically change training and testing phase without defining two different ops. Or is there any better usage of using tf.contrib.layers.batch_norm that I couldn't think of? Also, is tf.contrib.layers.fully_connected ready to use batch_norm as a normalizer_fn (because I guess this is still in contrib for several months)?