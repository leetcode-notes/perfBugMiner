time and memory cost more and more while using keras.backend.ctc_decoder()

memory not released bug with tf.python.ops.gen_ctc_ops  both with ctc_greedy_decoder and ctc_beam_search_decoder...
import time

from keras import backend as K

start_time = time.time()
while True:
     y_pred  = K.ctc_decode(args)
     cost_time = time.time()-start_time
     print 'cost time', cost_time   # time cost more and more with the same input args. why ??!! 
 ...
when using  K.ctc_decode() in a large loop, time cost longer  loop become larger...

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 14.04
TensorFlow installed from (source or binary): source ( pip install -U tensorflow)
TensorFlow version (use command below): (1.1.0)
Bazel version (if compiling from source):
CUDA/cuDNN version: None ( same problem occured if has CUDA7.5)
GPU model and memory: None ( same problem occured with GPU of 32G)
Exact command to reproduce:

function in file  tensorflow.python.ops.ctc_ops.py
Please help, thank you very much!