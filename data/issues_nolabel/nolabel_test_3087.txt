tensorbaord graph broken for multi-gpu (cifar10 example)

GitHub issues are for bugs / installation problems / feature requests.
For general support from the community, see StackOverflow.
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.
For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
Environment info
CentOS 6 (64 bit) + NVidia K80
Installed version of CUDA and cuDNN:
CUDA 7.5, cuDNN v4
If installed from binary pip package, provide:

Which pip package you installed.
The lateset (0.9 with GPU)
The output from python -c "import tensorflow; print(tensorflow.__version__)".
0.9.0

Steps to reproduce

Locate the cifar10 example https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/image/cifar10
run "python cifar10_multi_gpu_train.py --num_gpus=2"
Check the tensorboard results from events. The "GRAPHS" doesn't look right

What have you tried?

I tried to run the single GPU version of cifar10 example "python cifar10_train.py", Tensorboard graph looks normal
I tried "python cifar10_multi_gpu_train.py --num_gpus=1", Tensorboard graph broken
I didn't try a early version of tensorflow this time, but I remember the Tensorboard used to work with the cifar10 multi-gpu example

Logs or other output that would be helpful
(If logs are large, please upload as attachment).