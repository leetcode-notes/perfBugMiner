No OpKernel was registered to support Op 'FIFOQueueV2' with these attrs.

Description
I'm trying to use the Inception-ResNet-V2 model from TF-slim in the Android demo app. I'm now seeing the following inference exception:
E/TensorFlowInferenceInterface: Inference exception: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'FIFOQueueV2' with these attrs.  Registered devices: [CPU], Registered kernels:
                                                                                 <no registered kernels>
                                                                               
                                                                               	 [[Node: batch/fifo_queue = FIFOQueueV2[capacity=128, component_types=[DT_FLOAT, DT_UINT8, DT_INT64], container="", shapes=[[299,299,3], [299,299,3], []], shared_name=""]()]]

To ensure this issue does not come from my build, I've download the latest libtensorflow_inference.so from Jenkins. I've verified that this library still provides the same exception.
I'm not familiar with the error message but it seems the Op FIFOQueueV2 is defined in fifo_queue_op.cc. Can someone help take a look?