Bazel can't find cudnn.h, ignores cudnn directory specified in configuration

cuda-inst.txt
System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 27 x64
TensorFlow installed from (source or binary): Source/Release
TensorFlow version (use command below): 1.6.0-rc0
Python version: 3.6
Bazel version (if compiling from source): 1.10
GCC/Compiler version (if compiling from source): 6.4.0
CUDA/cuDNN version: CUDA 9.1, cudNN 7.0.5
GPU model and memory: GTX 1060
Exact command to reproduce:

bazel build --config=opt --config=cuda --incompatible_load_argument_is_label=false //tensorflow/tools/pip_package:build_pip_package
Relevant cudnn files are located at:
/usr/include/cuda/cudnn.h
/usr/lib64/libcudnn.so
/usr/lib64/libcudnn.so.7
/usr/lib64/libcudnn.so.7.0.5

and should be included:
export LD_LIBRARY_PATH="/usr/include/cuda/cupti:/usr/include/cuda:/usr/lib64"
Describe the problem
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 1063
		_create_local_cuda_repository(repository_ctx)
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 917, in _create_local_cuda_repository
		_get_cuda_config(repository_ctx)
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 672, in _get_cuda_config
		_cudnn_version(repository_ctx, cudnn_install_base..., ...)
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 397, in _cudnn_version
		_find_cudnn_header_dir(repository_ctx, cudnn_install_base...)
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 646, in _find_cudnn_header_dir
		auto_configure_fail(("Cannot find cudnn.h under %s" ...))
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 152, in auto_configure_fail
		fail(("\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: Cannot find cudnn.h under /lib64
WARNING: Target pattern parsing failed.
ERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 1063
		_create_local_cuda_repository(repository_ctx)
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 917, in _create_local_cuda_repository
		_get_cuda_config(repository_ctx)
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 672, in _get_cuda_config
		_cudnn_version(repository_ctx, cudnn_install_base..., ...)
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 397, in _cudnn_version
		_find_cudnn_header_dir(repository_ctx, cudnn_install_base...)
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 646, in _find_cudnn_header_dir
		auto_configure_fail(("Cannot find cudnn.h under %s" ...))
	File "/home/torstein/progs/tensorflow-1.6.0-rc0/third_party/gpus/cuda_configure.bzl", line 152, in auto_configure_fail
		fail(("\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: Cannot find cudnn.h under /lib64
INFO: Elapsed time: 0.060s
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/tools/pip_package

I have tried specifying /usr, /usr/include and /usr/include/cuda as cudnn-path when running ./configure. The configurator detects cudnn.h and does not complain.
If I specify /usr, bazel complains it can't find cudnn.h under /usr.
If I specify anything else, bazel seems intent to look under lib64 for whatever reason and does not find it. I did bazel clean between reconfigurations. Have also tried bazel with --action_env="LD_LIBRARY_PATH=${LD_LIBRARY_PATH}"
Have attached full install paths for cuda, cudnn, cupti (rpm -ql):
cuda-inst.txt
Configuration log:
WARNING: Running Bazel server needs to be killed, because the startup options are different.
You have bazel 0.10.0- (@non-git) installed.
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3
Found possible Python library paths:
  /usr/lib/python3.6/site-packages
  /usr/lib64/python3.6/site-packages
  /usr/local/lib/python3.6/site-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3.6/site-packages]
Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: Y
jemalloc as malloc support will be enabled for TensorFlow.
Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n
No Google Cloud Platform support will be enabled for TensorFlow.
Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n
No Hadoop File System support will be enabled for TensorFlow.
Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.
Do you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: n
No Apache Kafka Platform support will be enabled for TensorFlow.
Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
No XLA JIT support will be enabled for TensorFlow.
Do you wish to build TensorFlow with GDR support? [y/N]: n
No GDR support will be enabled for TensorFlow.
Do you wish to build TensorFlow with VERBS support? [y/N]: n
No VERBS support will be enabled for TensorFlow.
Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n
No OpenCL SYCL support will be enabled for TensorFlow.
Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 9.1
Please specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr
Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 
Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr]:/usr/include/cuda
Do you wish to build TensorFlow with TensorRT support? [y/N]: n
No TensorRT support will be enabled for TensorFlow.
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]6.1
Do you want to use clang as CUDA compiler? [y/N]: n
nvcc will be used as CUDA compiler.
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: /usr/bin/cuda-gcc
Do you wish to build TensorFlow with MPI support? [y/N]: n
No MPI support will be enabled for TensorFlow.
Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]: 
Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding "--config=<>" to your build command. See tools/bazel.rc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=tensorrt    	# Build with TensorRT support.
Configuration finished