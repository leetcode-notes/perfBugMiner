Distributed Tensorflow  using MPI

Please go to Stack Overflow for help and support:
https://stackoverflow.com/questions/tagged/tensorflow
If you open a GitHub issue, here is our policy:
I have tried stackflow and Google group discussion forum but could  get any reply or comment

It must be a bug or a feature request.
The form below must be filled out.
It shouldn't be a TensorBoard issue. Those go here.

Here's why we have that policy: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

System information


OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Redhat 7.4


TensorFlow installed from (source or binary):
from source with MPI


TensorFlow version (use command below):
1.41


Python version:
2.7.14


Bazel version (if compiling from source):


GCC/Compiler version (if compiling from source):
GCC 6.0


CUDA/cuDNN version:
8.0/6.5


GPU model and memory:
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.81                 Driver Version: 384.81                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K20Xm         Off  | 00000000:08:00.0 Off |                    0 |
| N/A   34C    P0    61W / 235W |      0MiB /  5699MiB |     72%      Default |
+-------------------------------+----------------------+----------------------+


+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Exact command to reproduce:

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
You can obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
I am using the following  script to launch distributed computing.
#! /bin/bash
module load openmpi/3.0.0-gnu
host=$(hostname -s)
if [[ $host == "node06" ]]; then
echo "statring Node 6"
python tf_dis_2.py --job_name="ps" --task_index=0
elif [[ $host == "node07" ]]; then
echo "starting Node 7 as worker"
python tf_dis_2.py --job_name="worker" --task_index=0
elif [[ $host == "node08" ]]; then
echo "starting Node 8 as worker"
python tf_dis_2.py --job_name="worker" --task_index=1
fi

I am running it on slurm  with three nodes.
srun -N 3 -n 3 --gres=gpu:1 -w node[06-08] test.sh
I am using MPI instead of GPRC.
I am getting the following message:

srun -N 3 -n 3 --gres=gpu:1 -w node[06-08] test.sh
statring Node 6
starting Node 8 as worker
starting Node 7 as worker
2018-01-15 11:34:59.961617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: Tesla K20Xm major: 3 minor: 5 memoryClockRate(GHz): 0.732
pciBusID: 0000:08:00.0
totalMemory: 5.57GiB freeMemory: 5.49GiB
2018-01-15 11:34:59.961674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K20Xm, pci bus id: 0000:08:00.0, compute capability: 3.5)
E0115 11:35:00.020327488   36133 ev_epoll1_linux.c:1051]     grpc epoll fd: 22
2018-01-15 11:35:00.026716: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> node06:2222}
2018-01-15 11:35:00.026760: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> node07:2223, 1 -> localhost:2224}
2018-01-15 11:35:00.029261: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2224
2018-01-15 11:35:00.439045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: Tesla K20Xm major: 3 minor: 5 memoryClockRate(GHz): 0.732
pciBusID: 0000:08:00.0
totalMemory: 5.57GiB freeMemory: 5.49GiB
2018-01-15 11:35:00.439124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K20Xm, pci bus id: 0000:08:00.0, compute capability: 3.5)
E0115 11:35:00.497022377   13701 ev_epoll1_linux.c:1051]     grpc epoll fd: 22
2018-01-15 11:35:00.503585: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> localhost:2222}
2018-01-15 11:35:00.503622: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> node07:2223, 1 -> node08:2224}
2018-01-15 11:35:00.505803: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2222
2018-01-15 11:33:39.681311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties:
name: Tesla K20Xm major: 3 minor: 5 memoryClockRate(GHz): 0.732
pciBusID: 0000:08:00.0
totalMemory: 5.57GiB freeMemory: 5.49GiB
2018-01-15 11:33:39.681375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Tesla K20Xm, pci bus id: 0000:08:00.0, compute capability: 3.5)
E0115 11:33:39.739196190   46236 ev_epoll1_linux.c:1051]     grpc epoll fd: 22
2018-01-15 11:33:39.745655: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> node06:2222}
2018-01-15 11:33:39.745697: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2223, 1 -> node08:2224}
2018-01-15 11:33:39.747692: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2223
Abid Malik
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
Variables initialized ...
Traceback (most recent call last):
File "tf_dis_2.py", line 102, in 
sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),logdir="/tmp/train_logs",global_step=global_step,init_op=init_op)
File "/home/amalik/.local/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py", line 336, in init
self._verify_setup()
File "/home/amalik/.local/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py", line 885, in _verify_setup
"their device set: %s" % op)
ValueError: When using replicas, all Variables must have their device set: name: "weights/Variable"
op: "VariableV2"
attr {
key: "container"
value {
s: ""
}
}
attr {
key: "dtype"
value {
type: DT_FLOAT
}
}
attr {
key: "shape"
value {
shape {
dim {
size: 784
}
dim {
size: 100
}
}
}
}
attr {
key: "shared_name"
value {
s: ""
}
}
2018-01-15 11:33:41.719083: E tensorflow/core/distributed_runtime/master.cc:269] Master init: Unavailable: Endpoint read failed
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
Variables initialized ...
Traceback (most recent call last):
File "tf_dis_2.py", line 114, in 
with sv.prepare_or_wait_for_session(server.target) as sess:
File "/home/amalik/.local/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py", line 708, in prepare_or_wait_for_session
init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
File "/home/amalik/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py", line 273, in prepare_session
config=config)
File "/home/amalik/.local/lib/python2.7/site-packages/tensorflow/python/training/session_manager.py", line 205, in _restore_checkpoint
saver.restore(sess, ckpt.model_checkpoint_path)
File "/home/amalik/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py", line 1666, in restore
{self.saver_def.filename_tensor_name: save_path})
File "/home/amalik/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 889, in run
run_metadata_ptr)
File "/home/amalik/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1120, in _run
feed_dict_tensor, options, run_metadata)
File "/home/amalik/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1317, in _do_run
options, run_metadata)
File "/home/amalik/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1336, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnavailableError: Endpoint read failed
srun: error: node08: task 2: Exited with exit code 1
srun: error: node07: task 1: Exited with exit code 1
Why is it crashing? I have been trying to solve this for the last three weeks by putting it on different forums and groups. However, could not get any reply. I would be grateful if someone can guide me. I apologize in advance if this is not the right forum.
Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

``
from future import print_function
import tensorflow as tf
import sys
import time
print("Abid Malik")
parameter_servers = ["node06:2222"]
workers = ["node07:2223","node08:2224"]
cluster = tf.train.ClusterSpec({"ps":parameter_servers, "worker":workers})
tf.app.flags.DEFINE_string("job_name", "", "Either 'ps' or 'worker'")
tf.app.flags.DEFINE_integer("task_index", 0, "Index of task within the job")
FLAGS = tf.app.flags.FLAGS
server = tf.train.Server(
cluster,
job_name=FLAGS.job_name,
task_index=FLAGS.task_index)
batch_size = 100
learning_rate = 0.0005
training_epochs = 20
logs_path = "/tmp/mnist/1"
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
if FLAGS.job_name == "ps":
server.join()
elif FLAGS.job_name == "worker":
    with tf.device(tf.train.replica_device_setter(worker_device="/job:worker/task:%d" % FLAGS.task_index,cluster=cluster)):
          
            global_step = tf.get_variable('global_step',[],initializer = tf.constant_initializer(0), trainable = False)

          
    with tf.name_scope('input'):
          
              x = tf.placeholder(tf.float32, shape=[None, 784], name="x-input")
           
              y_ = tf.placeholder(tf.float32, shape=[None, 10], name="y-input")

            
    tf.set_random_seed(1)
    with tf.name_scope("weights"):
                    W1 = tf.Variable(tf.random_normal([784, 100]))
                    W2 = tf.Variable(tf.random_normal([100, 10]))

           
    with tf.name_scope("biases"):
                    b1 = tf.Variable(tf.zeros([100]))
                    b2 = tf.Variable(tf.zeros([10]))

           
    with tf.name_scope("softmax"):
                    # y is our prediction
                    z2 = tf.add(tf.matmul(x,W1),b1)
                    a2 = tf.nn.sigmoid(z2)
                    z3 = tf.add(tf.matmul(a2,W2),b2)
                    y  = tf.nn.softmax(z3)

           
    with tf.name_scope('cross_entropy'):
                    # this is our cost
                    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))

         
    with tf.name_scope('train'):

grad_op = tf.train.GradientDescentOptimizer(learning_rate)
train_op = grad_op.minimize(cross_entropy, global_step=global_step)
    with tf.name_scope('Accuracy'):
                    # accuracy
                    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))
                    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))


    tf.summary.scalar("cost", cross_entropy)
    tf.summary.scalar("accuracy", accuracy)

    saver = tf.train.Saver()
   
    summary_op = tf.summary.merge_all()
    init_op = tf.global_variables_initializer()
    print("Variables initialized ...")

    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),logdir="/tmp/train_logs",global_step=global_step,init_op=init_op)


    begin_time = time.time()
    frequency = 100
    with sv.prepare_or_wait_for_session(server.target) as sess:
            # create log writer object (this will log on every machine)
            writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())

            # perform training cycles
            start_time = time.time()
            for epoch in range(training_epochs):

                    # number of batches in one epoch
                    batch_count = int(mnist.train.num_examples/batch_size)

                    count = 0
                    for i in range(batch_count):
                            batch_x, batch_y = mnist.train.next_batch(batch_size)

                            # perform the operations we defined earlier on batch
                            _, cost, summary, step = sess.run([train_op, cross_entropy, summary_op, global_step], feed_dict={x: batch_x, y_: batch_y})
                            writer.add_summary(summary, step)

                            count += 1
                            if count % frequency == 0 or i+1 == batch_count:
                                    elapsed_time = time.time() - start_time
                                    start_time = time.time()
                                    print("Step: %d," % (step+1),
                                                            " Epoch: %2d," % (epoch+1),
                                                            " Batch: %3d of %3d," % (i+1, batch_count),
                                                            " Cost: %.4f," % cost,
                                                            " AvgTime: %3.2fms" % float(elapsed_time*1000/frequency))
                                    count = 0


            print("Test-Accuracy: %2.2f" % sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))
            print("Total Time: %3.2fs" % float(time.time() - begin_time))
            print("Final Cost: %.4f" % cost)

    sv.stop()
    print("done")

``