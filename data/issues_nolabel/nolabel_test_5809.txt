multi-GPU training?

We are trying to scale up one of the detection deep learning architecture written in Tensorflow for multi-GPU training. Here's the link to the architecture.
We need specific help in understanding the properties of the gradients such as shape, type and more importantly ways to access the same so that it can be built on two GPUs separately and synchronize like in the cifar_multi_gpu training..
This is the grad step in build function and we would like to access in train function:
if H['clip_norm'] <= 0:
grads = tf.gradients(loss['train'], tvars)
else:
grads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])
We have the following functions in the train and build model steps in the overall architecture.
def build(H, q):
'''
Build full model for training, including forward / backward passes,
optimizers, and summary statistics.
'''
arch = H
solver = H["solver"]
os.environ['CUDA_VISIBLE_DEVICES'] = str(solver.get('gpu', ''))

#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)
gpu_options = tf.GPUOptions()
config = tf.ConfigProto(gpu_options=gpu_options)

learning_rate = tf.placeholder(tf.float32)
if solver['opt'] == 'RMS':
    opt = tf.train.RMSPropOptimizer(learning_rate=learning_rate,
                                    decay=0.9, epsilon=solver['epsilon'])
elif solver['opt'] == 'Adam':
    opt = tf.train.AdamOptimizer(learning_rate=learning_rate,
                                    epsilon=solver['epsilon'])
elif solver['opt'] == 'SGD':
    opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
else:
    raise ValueError('Unrecognized opt type')
loss, accuracy, confidences_loss, boxes_loss = {}, {}, {}, {}
for phase in ['train', 'test']:
    # generate predictions and losses from forward pass
    x, confidences, boxes = q[phase].dequeue_many(arch['batch_size'])
    flags = tf.argmax(confidences, 3)


    grid_size = H['grid_width'] * H['grid_height']

    (pred_boxes, pred_confidences,
     loss[phase], confidences_loss[phase],
     boxes_loss[phase]) = build_forward_backward(H, x, phase, boxes, flags)
    pred_confidences_r = tf.reshape(pred_confidences, [H['batch_size'], grid_size, H['rnn_len'], arch['num_classes']])
    pred_boxes_r = tf.reshape(pred_boxes, [H['batch_size'], grid_size, H['rnn_len'], 4])


    # Set up summary operations for tensorboard
    a = tf.equal(tf.argmax(confidences[:, :, 0, :], 2), tf.argmax(pred_confidences_r[:, :, 0, :], 2))
    accuracy[phase] = tf.reduce_mean(tf.cast(a, 'float32'), name=phase+'/accuracy')

    if phase == 'train':
        global_step = tf.Variable(0, trainable=False)

        tvars = tf.trainable_variables()
        if H['clip_norm'] <= 0:
            grads = tf.gradients(loss['train'], tvars)
        else:
            grads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])
        train_op = opt.apply_gradients(zip(grads, tvars), global_step=global_step)
    elif phase == 'test':
        moving_avg = tf.train.ExponentialMovingAverage(0.95)
        smooth_op = moving_avg.apply([accuracy['train'], accuracy['test'],
                                      confidences_loss['train'], boxes_loss['train'],
                                      confidences_loss['test'], boxes_loss['test'],
                                      ])

        for p in ['train', 'test']:
            tf.scalar_summary('%s/accuracy' % p, accuracy[p])
            tf.scalar_summary('%s/accuracy/smooth' % p, moving_avg.average(accuracy[p]))
            tf.scalar_summary("%s/confidences_loss" % p, confidences_loss[p])
            tf.scalar_summary("%s/confidences_loss/smooth" % p,
                moving_avg.average(confidences_loss[p]))
            tf.scalar_summary("%s/regression_loss" % p, boxes_loss[p])
            tf.scalar_summary("%s/regression_loss/smooth" % p,
                moving_avg.average(boxes_loss[p]))

    if phase == 'test':
        test_image = x
        # show ground truth to verify labels are correct
        test_true_confidences = confidences[0, :, :, :]
        test_true_boxes = boxes[0, :, :, :]

        # show predictions to visualize training progress
        test_pred_confidences = pred_confidences_r[0, :, :, :]
        test_pred_boxes = pred_boxes_r[0, :, :, :]

        def log_image(np_img, np_confidences, np_boxes, np_global_step, pred_or_true):
            
            merged = train_utils.add_rectangles(H, np_img, np_confidences, np_boxes,
                                                use_stitching=True,
                                                rnn_len=H['rnn_len'])[0]
            
            num_images = 10
            img_path = os.path.join(H['save_dir'], '%s_%s.jpg' % ((np_global_step / H['logging']['display_iter']) % num_images, pred_or_true))
            misc.imsave(img_path, merged)
            return merged

        pred_log_img = tf.py_func(log_image,
                                  [test_image, test_pred_confidences, test_pred_boxes, global_step, 'pred'],
                                  [tf.float32])
        true_log_img = tf.py_func(log_image,
                                  [test_image, test_true_confidences, test_true_boxes, global_step, 'true'],
                                  [tf.float32])
        tf.image_summary(phase + '/pred_boxes', tf.pack(pred_log_img),max_images=10)
        tf.image_summary(phase + '/true_boxes', tf.pack(true_log_img),max_images=10)

summary_op = tf.merge_all_summaries()

return (config, loss, accuracy, summary_op, train_op,
        smooth_op, global_step, learning_rate)

def train(H, test_images):
'''
Setup computation graph, run 2 prefetch data threads, and then run the main loop
'''
if not os.path.exists(H['save_dir']): os.makedirs(H['save_dir'])

ckpt_file = H['save_dir'] + '/save.ckpt'
with open(H['save_dir'] + '/hypes.json', 'w') as f:
    json.dump(H, f, indent=4)

x_in = tf.placeholder(tf.float32)
confs_in = tf.placeholder(tf.float32)
boxes_in = tf.placeholder(tf.float32)
q = {}
enqueue_op = {}
for phase in ['train', 'test']:
    dtypes = [tf.float32, tf.float32, tf.float32]
    grid_size = H['grid_width'] * H['grid_height']
    shapes = (
        [H['image_height'], H['image_width'], 3],
        [grid_size, H['rnn_len'], H['num_classes']],
        [grid_size, H['rnn_len'], 4],
        )
    q[phase] = tf.FIFOQueue(capacity=30, dtypes=dtypes, shapes=shapes)
    enqueue_op[phase] = q[phase].enqueue((x_in, confs_in, boxes_in))

def make_feed(d):
    return {x_in: d['image'], confs_in: d['confs'], boxes_in: d['boxes'],
            learning_rate: H['solver']['learning_rate']}

def thread_loop(sess, enqueue_op, phase, gen):
    for d in gen:
        sess.run(enqueue_op[phase], feed_dict=make_feed(d))

(config, loss, accuracy, summary_op, train_op,
 smooth_op, global_step, learning_rate) = build(H, q)

saver = tf.train.Saver(max_to_keep=None)
writer = tf.train.SummaryWriter(
    logdir=H['save_dir'],
    flush_secs=10
)

with tf.Session(config=config) as sess:
    tf.train.start_queue_runners(sess=sess)
    for phase in ['train', 'test']:
        # enqueue once manually to avoid thread start delay
        gen = train_utils.load_data_gen(H, phase, jitter=H['solver']['use_jitter'])
        d = gen.next()
        sess.run(enqueue_op[phase], feed_dict=make_feed(d))
        t = tf.train.threading.Thread(target=thread_loop,
                             args=(sess, enqueue_op, phase, gen))
        t.daemon = True
        t.start()

    tf.set_random_seed(H['solver']['rnd_seed'])
    sess.run(tf.initialize_all_variables())
    writer.add_graph(sess.graph)
    weights_str = H['solver']['weights']
    if len(weights_str) > 0:
        print('Restoring from: %s' % weights_str)
        saver.restore(sess, weights_str)
    else:
        init_fn = slim.assign_from_checkpoint_fn(
              '%s/data/inception_v1.ckpt' % os.path.dirname(os.path.realpath(__file__)),
              [x for x in tf.all_variables() if x.name.startswith('InceptionV1') and not H['solver']['opt'] in x.name])
        init_fn(sess)

    # train model for N iterations
    start = time.time()
    max_iter = H['solver'].get('max_iter', 10000000)
    for i in xrange(max_iter):
        display_iter = H['logging']['display_iter']
        adjusted_lr = (H['solver']['learning_rate'] *
                       0.5 ** max(0, (i / H['solver']['learning_rate_step']) - 2))
        lr_feed = {learning_rate: adjusted_lr}

        if i % display_iter != 0:
            # train network
            batch_loss_train, _ = sess.run([loss['train'], train_op], feed_dict=lr_feed)
        else:
            # test network every N iterations; log additional info
            if i > 0:
                dt = (time.time() - start) / (H['batch_size'] * display_iter)
            start = time.time()
            (train_loss, test_accuracy, summary_str,
                _, _) = sess.run([loss['train'], accuracy['test'],
                                  summary_op, train_op, smooth_op,
                                 ], feed_dict=lr_feed)
            writer.add_summary(summary_str, global_step=global_step.eval())
            print_str = string.join([
                'Step: %d',
                'lr: %f',
                'Train Loss: %.2f',
                'Softmax Test Accuracy: %.1f%%',
                'Time/image (ms): %.1f'
            ], ', ')
            print(print_str %
                  (i, adjusted_lr, train_loss,
                   test_accuracy * 100, dt * 1000 if i > 0 else 0))

        if global_step.eval() % H['logging']['save_iter'] == 0 or global_step.eval() == max_iter - 1:
            saver.save(sess, ckpt_file, global_step=global_step)

Thanks in advance!