Source-compiled .whl package is much slower in training

Recently, from my experiment, I found that running inception model using the .whl file generated by myself is much slower than using .whl file downloaded directly from the $TF_BINARY_URL.
Environment info
Operating System: ubuntu14.04
CUDA: cuda7.5
CUDNN: cudnn 5
I followed the instructions
./configure
bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
And I got tensorflow-0.9.0-py2-none-any.whl to install using:
pip install /home/dl/bxl/tensorflow/tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whl
(the name of this .whl file is automatically generated )
Then I downloaded the inception model related files to train following the instructions:
cd ~/models/inception
bazel build inception/imagenet_train
bazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=64 --train_dir=/tmp/imagenet_train --data_dir=/data1/ImageNet
From the information printed out, I found that the speed is 8.5 samples/sec. (In the first several lines printed out, it saysï¼š
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally,
from which I guess CUDA/CuDNN are automatically loaded)
However, if I replace the .whl file by that directly downloaded from the $TF_BINARY_URL provided in www.tensorflow.org ( tensorflow-0.9.0-cp27-none-linux_x86_64.whl, which uses CuDNN4 and cuda7.5), and reinstall it using pip, and restart a new process to train the inception model using the same code.
I got that the training speed was 20.2 samples/sec, which is nearly 2.5x faster than my first training using the .whl package generated by myself.
So it is very difficult to explain. Because I use CUDNN5, I expect my version is faster, but in fact, it is 2.5x slower....
Does anyone know why??
Thanks in advance.