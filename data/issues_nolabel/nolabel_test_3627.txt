Tensorflow inability to kill processes using more than 1 GPU

Environment info
Operating System: Ubuntu 14.04
Installed version of CUDA and cuDNN:
CUDA 7.5
CUDNNv4
GPUs:
2x Tesla K40x
2x GeForce GTX K40c
The output from python -c "import tensorflow; print(tensorflow.__version__)":
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.9.0
This problem is specific to running tensorflow with multiple GPUs. When I try to restart the notebook in jupyter, if I have more than one GPU visible via os.environ["CUDA_VISIBLE_DEVICES"], the notebook freezes up, and I can no longer run nvidia-smi.
This problem does not exist when using a single GPU or no GPU on the same network.