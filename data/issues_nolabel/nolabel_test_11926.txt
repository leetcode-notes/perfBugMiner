How to understand multithreading in tf queue?

Tensorflow provides us two ways to implement reading data.
The first way, use many reader, such as tf.TextLineReader, one reader per thread.
The second way, use just one reader and multithreading of enqueue ops, for example we can use tf.train.shuffle_batch and set num_threads greater than 1.
I can't understand the second way, we just have one reader to load data(perhaps a thread), why we need so many threads to enqueue? And for the first way, we should use tf.train.shuffle_batch_join, there is no num_threads parameter we can set, so I think the first way is understandable. Can anyone give me some explanation for why we need one reader but many threads to enqueue?