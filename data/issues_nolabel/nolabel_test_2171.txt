TF-Learn early stopping monitor doesn't disable dropout

I'm training a custom CNN model that uses dropout for regularization. I'm using tf-learn r0.8 (skflow)  ValidationMonitor as follows.
from tensorflow.contrib.learn.python.learn import monitors
m = monitors.ValidationMonitor(X_validate, Y_validate, 0, print_steps=100, 
    early_stopping_rounds=500)
regressor.fit(X_train, Y_train, monitor=monitor)
I noticed that after early stopping is triggered, the validation error I calculate on the final model is significantly different from what the ValidationMonitor reports as the best validation error. To narrow the problem I set early_stopping_rounds = 1 but even then the difference between the "best" validation error and the one calculated on the final model was too large. Large enough to make the early stopping feature unusable for my case.
I tracked the issue down to the fact that ValidationMonitor calculates the validation error without disabling dropouts, which is why the results were so different from what you'd get from calling model.predict(). I implemented a fix here.
I'd appreciate it if one of the maintainers reviews it and confirms that it's the right fix. If so, I'll create a pull request.
waleedka/tensorflow@ee095f8