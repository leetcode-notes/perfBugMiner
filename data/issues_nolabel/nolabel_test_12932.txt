Turning on grappler makes SLIM Resnet_v1_50 slower on AWS K80

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
TensorFlow installed from (source or binary):source binary link here
TensorFlow version (use command below): 1.3+ the sha-hash is in the link to download the binary I compiled.
Python version: 2.7
Bazel version (if compiling from source): 4.5
CUDA/cuDNN version: cuDNN 6 / CUDA 8
GPU model and memory: K80 on AWS p2.8xlarge
Exact command to reproduce: Running SLIM from tensorflow/models/slim I used the following command: CUDA_VISIBLE_DEVICES=1 python train_image_classifier.py --train_dir=${TRAIN_DIR} --dataset_name=imagenet --dataset_split_name=train --dataset_dir=${DATASET_DIR} --model_name=resnet_v1_50 --num_clones=1 --optimizer=sgd --batch_size=64 --max_number_of_steps=110

I added the following code to train_image_classifier.py:
    rewrite_options = rewriter_config_pb2.RewriterConfig()
    rewrite_options.optimizers.append('constfold')
    rewrite_options.optimizers.append('layout')
    graph_options = tf.GraphOptions(rewrite_options=rewrite_options, infer_shapes=True)
    config = tf.ConfigProto(graph_options=graph_options)

    ###########################
    # Kicks off the training. #
    ###########################
    slim.learning.train(
        train_tensor,
        session_config=config,


I used this binary to test and it includes the sha-hash.  The build was done from head on 09-SEP-2017 using this command bazel build -c opt --copt=-march="haswell" --config=cuda //tensorflow/tools/pip_package:build_pip_package
For /configure.  I did not include XLA I did all of the defaults with the exception of adding CUDA and cuDNN.  Nothing additional was included.
With out grappler I get 1.5 seconds per step and with grappler 2.0 seconds per step.  There is some variance of plus or minus .1 but it is definitely slower in my testing which was not expected.
Edited: I was running v1 but I think v2 gave a very similar result.