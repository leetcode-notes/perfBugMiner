Fix broken AttentionMechanism docstrings

Currently, for all AttentionMechanisms, the memory_sequence_length arg does not get formatted correctly in the docs, making it easy to miss.
I believe this is because the (optional) modifier is not preceded by a colon, as in the other (working) args.