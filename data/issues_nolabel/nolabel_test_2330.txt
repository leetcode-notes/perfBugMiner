softmax_classifier input argument not right?

The softmax_classifier in losses_ops.py file seems not right to me. I haven't done any test yet, but just look at the the input argument definition, the tensor_in and weight are not compatible for matrix multiplication.
====== begin ============
tensor_in: Input tensor, [batch_size, feature_size], features.
labels: Tensor, [batch_size, n_classes], labels of the output classes.
weights: Tensor, [batch_size, feature_size], linear transformation
matrix.
biases: Tensor, [batch_size], biases.
======== end ==============
Their inner dimensions do not match for matmul in xw_plus_b function.
Also, since it is done in a batch, isn't it we should use batch_matmul?