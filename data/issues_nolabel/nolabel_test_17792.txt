optimizer.apply_gradients fails inside tfe.defun

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
TensorFlow installed from (source or binary): colab
TensorFlow version (use command below): unknown 1.6.0
Python version: 3.6.3
Exact command to reproduce: Colab: https://drive.google.com/file/d/1zj9IMWKF58TuEQRKt9DpETr24Z1sy9z0/view?usp=sharing

Describe the problem
optimizer.apply_gradients doesn't seem to work inside eager mode's tfe.defun.  The colab contains full details, but the relevant part of the exception is
/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/optimizer.py in _get_processor(v)
    180   if context.in_eager_mode():
    181     return _DenseResourceVariableProcessor(v)
--> 182   if v.op.type == "VarHandleOp":
    183     return _DenseResourceVariableProcessor(v)
    184   if isinstance(v, variables.Variable):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in op(self)
    601   def op(self):
    602     """The op for this variable."""
--> 603     return self._handle.op
    604 
    605   def eval(self, session=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in op(self)
    836   @property
    837   def op(self):
--> 838     raise AttributeError("op not supported for Eager Tensors.")
    839 
    840   @property

AttributeError: op not supported for Eager Tensors.

The problem is presumably that optimizer.py's eager mode logic is disabled by defun's graph mode.
Source code / logs
Reproducing colab: https://drive.google.com/file/d/1zj9IMWKF58TuEQRKt9DpETr24Z1sy9z0/view?usp=sharing