distribute tensorflow chief node OOM

sorry to trouble.
my model has 6 conv layer and a softmax layer. kernel size is 3*3, channel is 192, num class is 300.
I run a distribute model with 20 Tesla K40m.
when I run one ps job and 5 worker job, everything is fine. But when I run a ps job and 19 worker jobs in 20 PC, when the chief node Initialize for node 15, it gets the OOM error.
I don't know how to deal with it.
Anyone can help me?