"SAME" padding for ConvNet doesn't work as expected !

Hi folks,
When I want to reimplement the paper VDCNN for Text Classification, I need to do padding=1 with filter_kernel=3 to keep the same input's dimension between ConvNet in the model.  When I use padding 'SAME', the result isn't well expected. There's a problem in the height_size_output. It seems doesn't do element-wise product of block convnet 72x3 between the input & the filter.
By the way, there's no problem of height_size_output using the padding 'VALID'. It seems that it did. However, its width_size_output is reduced by 2.
In my intuition, padding 'VALID' behave much more properly like in the paper, but how can I pad 1 to both the left & right of the 2D input before doing ConvNet ?

import tensorflow as tf
data = tf.placeholder("float", shape=[1, 72, 1014, 1])

filter_shape = [72, 3, 1, 64]
W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.05), name="W")

conv = tf.nn.conv2d(data, W, padding='SAME')
print(conv.get_shape())  # prints (1, 72, 1014, 64), but should be (1, 1, 1014, 64)
conv = tf.nn.conv2d(data, W, padding='VALID')
print(conv.get_shape())  # prints (1, 1, 1012, 64), but should be (1, 1, 1014, 64)