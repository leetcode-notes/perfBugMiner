per_process_gpu_memory_fraction causes memory error

I wrote an LSTM model in tensorflow and use a Saver to create a checkpoint after each epoch. So far so good. However, when I add the option per_process_gpu_memory_fraction=0.9 to the session, it runs out of memory when I save the model right after the first epoch. I have a GeForce Titan X with 12GB of memory; tf uses a bit more than half of it (see below).
Interestingly, if I do not save the model, it does not crash (at least not after the first epoch). Also,



per_process_gpu_memory_fraction
memory used
crashes




0.9
7377MiB
yes


0.8
7288MiB
yes


0.5
6272MiB
no


not set
6955MiB
no

I forgot with what parameters, but I also saw the program survive the first epoch, only to crash after the fifth.
I have modified the ptf_word_lm.py in tensorflow/models, so that it can be used to reproduce the error. It does not crash with per_process_gpu_memory_fraction=0.8, as my model is a bit different, but it does at 0.9. Please call the script with --model medium.
On the surface, I only see a Dst tensor is not initialized error, but as described in #7025, it is a sign of a memory error. Also, in tf 0.11, it returned with a proper out of memory error, but I have updated to 1.0 since, as I hoped this bug had been fixed there. Apparently not.
What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I couldn't find anything similar.
Environment info
environment.txt
If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
See ptb_word_lm.py in this branch
What other attempted solutions have you tried?
--
Logs or other output that would be helpful
log_err.txt