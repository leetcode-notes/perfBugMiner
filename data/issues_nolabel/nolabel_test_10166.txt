OOM error when initializing float tensors 1/2 the size of the VRAM (in bytes)

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 14.04 (64 bit)
TensorFlow installed from (source or binary): pip install tensorflow-gpu
TensorFlow version (use command below):  ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')
Bazel version (if compiling from source): N/A
CUDA/cuDNN version: 8.0/5.1.10-1
GPU model and memory: K40 / 12 GB (also GTX 980 / 4 GB)
Exact command to reproduce:

time CUDA_VISIBLE_DEVICES=1 python memory_usage.py
TF encounters OOM when I try to initialize an array half the size of the VRAM, but only when it's a FLOAT type (float16, float32, float64). This happens even when trainable=False.
I checked via nvidia-smi that no other process is using the GPU.
import tensorflow as tf

vram = 12 * 1024 ** 3 # 12 GB

def use_half_vram(dtype):
    n = vram // dtype.size // 2
    x = tf.get_variable('x', shape=[n], dtype=dtype, \
        initializer=tf.constant_initializer(7), trainable=False)
    with tf.Session() as sess:
        sess.run(tf.global_variables_initializer())

# use_half_vram(tf.uint8) # OK
# use_half_vram(tf.int32) # OK
# use_half_vram(tf.int64) # OK
# use_half_vram(tf.float16) # OOM
use_half_vram(tf.float32) # OOM
# use_half_vram(tf.float64) # OOM