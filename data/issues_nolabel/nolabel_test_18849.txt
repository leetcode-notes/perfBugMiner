CUPTI events are missing from tf.train.Server

System information

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): r1.7, r1.6, r1.5
Python version: 3.6
Bazel version (if compiling from source): 0.11.0
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 9.1/7.1.3, 9.0/7.0.5
GPU model and memory: K80/V100/GTX TITAN
Exact command to reproduce: See the description

Describe the problem
I am collecting runtime tracing using tf.RunOptions.FULL_TRACE. When a direct session is used (master=None), CUPTI events (/stream:* devices) are included in tf.RunMetadata. However, a remote (grpc) session does not have any. Is there a particular reason behind it?
For example the following script has the CUPTI:
import tensorflow as tf
import tensorflow.contrib.slim.nets as nets

model, _ = nets.resnet_v2.resnet_v2_50(tf.random_uniform([16,299,299,3]))

with tf.train.MonitoredTrainingSession() as sess:
     run_metadata = tf.RunMetadata()
     sess.run(model.op, run_metadata=run_metadata, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE))

print([d.device for d in run_metadata.step_stats.dev_stats])
assert any(["stream:all" in d.device for d in run_metadata.step_stats.dev_stats])
The example output on my device is:
['/device:GPU:0/stream:7', '/device:GPU:0/memcpy', '/device:GPU:0/stream:25', '/device:GPU:0/stream:24', '/device:GPU:0/stream:13', '/job:localhost/replica:0/task:0/device:GPU:0', '/device:GPU:0/stream:18', '/device:GPU:0/stream:all', '/device:GPU:0/stream:23', '/device:GPU:0/stream:31', '/device:GPU:0/stream:20', '/device:GPU:0/stream:22', '/device:GPU:0/stream:19', '/device:GPU:0/stream:21']

However, the following example does not have any CUPTI events:
import tensorflow as tf
import tensorflow.contrib.slim.nets as nets

server = tf.train.Server(tf.train.ClusterSpec({"worker":["localhost:2222"]}), "worker", 0)
model, _ = nets.resnet_v2.resnet_v2_50(tf.random_uniform([16,299,299,3]))

with tf.train.MonitoredTrainingSession(master="grpc://localhost:2222") as sess:
     run_metadata = tf.RunMetadata()
     sess.run(model.op, run_metadata=run_metadata, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE))

print([d.device for d in run_metadata.step_stats.dev_stats])
assert any(["stream:all" in d.device for d in run_metadata.step_stats.dev_stats])
The following is the output on my device:
['/job:worker/replica:0/task:0/device:GPU:0']
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AssertionError

I have tried this with multiple version of TensorFlow (r1.7, r1.6, r1.5) and both grpc_tensorflow_server and tf.train.Server.