Given one input tensor, why tf.nn.max_pool generate two tensors?

with tf.name_scope('layer3'):
conv3_weights = tf.Variable(tf.truncated_normal(
[3, 3, 128, 256], stddev=0.1))
variable_summaries(conv3_weights, 'layer3' + '/weights')
conv3_biases = tf.Variable(tf.constant(0.1, shape=[256]))
variable_summaries(conv3_biases, 'layer3' + '/biases')
conv3 = tf.nn.conv2d(pool2,
conv3_weights,
strides=[1, 1, 1, 1],
padding='SAME')
tf.histogram_summary('layer3'+'/pre_activations', conv3)
relu3 = tf.nn.relu(tf.nn.bias_add(conv3, conv3_biases))
tf.histogram_summary('layer3'+'/activations', relu3)
print relu3.get_shape()
pool3 = tf.nn.max_pool(relu3,
ksize=[1, 2, 2, 1],
strides=[1, 2, 2, 1],
padding='SAME')
tf.histogram_summary('layer3'+'/pool', pool3)
print pool3.get_shape()
When using TensorBoard to visualize the graph, I find the output of the layer3 are two tensors. I am puzzled why does it happen? Thank you very much!