Feeding tensors doesn't stop gradients flowing through

Consider this code snippet:
a = tf.constant(0)
b = a + 1
c = b * 2
grad, = tf.gradients(c, a)
grad.eval(feed_dict={b: 0})

The result is 2, instead of 0. To obtain the true gradient, one has to wrap the tensor with an tf.cond and feed an additional indicator, which doesn't seem too elegant.
Apologize if I missed something.