confused by device placement on Amazon AWS

First - loving tensorflow.  The tutorials were really great fun to read.   Tensorflow API architecture is clear and amazing.   Hope to do pull requests once I get up to speed.
However, I'm trying to do device placement to do some basic benchmarks to see if it's worth using Amazon at all versus my own computers.  So far, not so promising, but maybe I'm doing something wrong.
From the example here:  http://tensorflow.org/how_tos/using_gpu/index.md
I get the following results.
>>> with tf.device('/cpu:0'):
...   a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
...   b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
...   sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
...   print sess.run(c)
...
I tensorflow/core/common_runtime/gpu/gpu_device.cc:644] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GRID K520, pci bus\
 id: 0000:00:03.0)
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GRID K520, pci bus id: 0000:00:03.0
I tensorflow/core/common_runtime/direct_session.cc:111] Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GRID K520, pci bus id: 0000:00:03.0

b: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:289] b: /job:localhost/replica:0/task:0/cpu:0
a: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:289] a: /job:localhost/replica:0/task:0/cpu:0
MatMul_1: /job:localhost/replica:0/task:0/gpu:0
I tensorflow/core/common_runtime/simple_placer.cc:289] MatMul_1: /job:localhost/replica:0/task:0/gpu:0
[[ 22.  28.]
 [ 49.  64.]]

Looking at that, it looks like it's placing the matmul on the gpu.   I want it on the cpu.  Is that possible?
Also, is matrix_inverse or matmul of say a 5000x5000 matrix a good (but very rough!) benchmark to help evaluate the value of Amazon GPU/CPU large instances?
Thanks again