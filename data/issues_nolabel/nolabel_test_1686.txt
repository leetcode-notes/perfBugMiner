Distributed cluster manager support: Slurm

Per the comment on this introduction, i.e.

N.B. Manually specifying these cluster specifications can be tedious, especially for large clusters. We are working on tools for launching tasks programmatically, e.g. using a cluster manager like Kubernetes. If there are particular cluster managers for which you'd like to see support, please raise a GitHub issue.

Is there is any possibility of supporting Slurm? Forgive my ignorance but I've really only played around with TensorFlow and I've only used Slurm for fairly simple MPI projects, but I recently got access to a cluster with some GPU nodes and I'd like to incorporate TF in my research project. It would be great if I was able to use all the resources I could to speed things along.
If it helps, specific info about the setup can be found here.