breaking change to distributed training moving from TF v1.3 to v1.4: “UnavailableError: Trying to connect an http1.x server”

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
n/a
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Red Hat Enterprise Linux Server release 7.3 (Maipo)
TensorFlow installed from (source or binary):
source
TensorFlow version (use command below):
1.4 (moving from 1,3)
b'v1.4.0-4-g9283868' 1.4.0 in specific
Python version:
Python 3.6.2 :: Anaconda custom (64-bit)
Bazel version (if compiling from source):
0.5.4
GCC/Compiler version (if compiling from source):
gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)
CUDA/cuDNN version:
N/a
GPU model and memory:
N/a
Exact command to reproduce:
see below. Appears to be any distributed training use case with the cluster spec defined as below.

Describe the problem
I believe this could be fairly characterized as a BUG.
I raised (and solved) this issue on stackoverflow here
In short, upgrading from tf v1.3 to 1.4 distributed training broke with the error
"tensorflow.python.framework.errors_impl.UnavailableError: Trying to connect an http1.x server".
I was training across multiple CPU cores all on the same localhost.
The fix was to change the ps to the  string "localhost" explicitly in the cluster spec instead of the IP "127.0.0.1". It stops trying to connect to the localhost via my proxy server (which indeed, was HTTP1.x only i think). I would call this a bug since that IP should be the equivalent, and I'm not sure what other kind of behavior might have inadvertently changed between versions (since this always worked in TF <= 1.3).
To be fair, I'm also not sure if this is a tensorflow or more gRPC specific issue. In either case, the above is a work around for the problem.