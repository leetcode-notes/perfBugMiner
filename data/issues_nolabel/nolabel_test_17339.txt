tf 1.6rc1 feed_dict is slow on multi-socket machines

It seems as if 1.6rc1 introduces a copy in feed_dict on machines with >1 physical socket. Similar to #17233, but this also happens if numpy array is aligned. Fetching array from tensorflow, then feeding it back in happens at single-core memcpy speed. Downgrading to 1.5 restores fast behavior (4x faster)
https://github.com/diux-dev/cluster/blob/master/yuxin_numpy/tf_numpy_benchmark.py
# 1.6 rc1 on p3.16xlarge (2 Xeon V4 sockets) = slow
__git_version__: v1.6.0-rc1-607-g0bde713c06
https://github.com/tensorflow/tensorflow/commit/0bde713c06
python tf_numpy_benchmark.py --benchmark=feed_cpu_tensor --allocator=tf --num-iters=51 # 10.7
feed_cpu_tensor               :   2.5 GB/sec, min: 39.89, median: 40.18, mean: 40.26

# switch to tf 1.5, things are fast
pip install tensorflow
python tf_numpy_benchmark.py --benchmark=feed_cpu_tensor --allocator=tf --num-iters=51 # 10.7
feed_cpu_tensor               :  13.0 GB/sec, min:  7.67, median:  8.88, mean:  9.26

# switch to p3.8xlarge machine (1 socket), and latest TF, things are also fast
# tensorflow.__git_version__ = v1.6.0-rc1-562-g26ae3287a1
python tf_numpy_benchmark.py --benchmark=feed_cpu_tensor --allocator=tf --num-iters=51 # 10.7
feed_cpu_tensor               :  10.5 GB/sec, min:  9.49, median: 10.83, mean: 10.86