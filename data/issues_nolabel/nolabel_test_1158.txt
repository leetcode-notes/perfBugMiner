Kernel version vs DSO version mismatch when running example after bazel build

After successful bazel build, running into error when executing example with gpu. Please suggest on how to resolve. The GPU has been used with MathConvNet (another deep learning package) without this error.
Log:
bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so locally I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally E tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_NO_DEVICE I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: en4113750l I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: en4113750l I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: 352.63 I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module 352.55 Thu Oct 8 15:18:00 PDT 2015 GCC version: gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04) """ I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 352.55 E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:229] kernel version 352.55 does not match DSO version 352.63 -- cannot find working devices in this configuration I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: F tensorflow/cc/tutorials/example_trainer.cc:116] Check failed: ::tensorflow::Status::OK() == (session->Run({{"x", x}}, {"y:0", "y_normalized:0"}, {}, &outputs)) (OK vs. Invalid argument: Cannot assign a device to node 'Const/_2': Could not satisfy explicit device specification '/gpu:0' [[Node: Const/_2 = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 0>, _device="/gpu:0"]()]]) F tensorflow/cc/tutorials/example_trainer.cc:116] Check failed: ::tensorflow::Status::OK() == (session->Run({{"x", x}}, {"y:0", "y_normalized:0"}, {}, &outputs)) (OK vs. Invalid argument: Cannot assign a device to node 'Const/_2': Could not satisfy explicit device specification '/gpu:0' [[Node: Const/_2 = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 0>, _device="/gpu:0"]()]]) F tensorflow/cc/tutorials/example_trainer.cc:116] Check failed: ::tensorflow::Status::OK() == (session->Run({{"x", x}}, {"y:0", "y_normalized:0"}, {}, &outputs)) (OK vs. Invalid argument: Cannot assign a device to node 'Const/_2': Could not satisfy explicit device specification '/gpu:0' [[Node: Const/_2 = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [] values: 0>, _device="/gpu:0"]()]]) Aborted (core dumped)
Specifications:
Ubuntu LTS 14.04
Titan X GPU
CUDA 7.5