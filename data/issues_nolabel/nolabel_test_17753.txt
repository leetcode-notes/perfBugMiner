Quantize to TFLITE mode:how to change the graph to contain min/max information for relu layer.

== cat /etc/issue ===============================================
Linux xxxx 4.13.0-36-generic #40~16.04.1-Ubuntu SMP Fri Feb 16 23:25:58 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
VERSION="16.04.3 LTS (Xenial Xerus)"
VERSION_ID="16.04"
VERSION_CODENAME=xenial
== are we in docker =============================================
No
== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
== uname -a =====================================================
Linux xxxxx 4.13.0-36-generic #40~16.04.1-Ubuntu SMP Fri Feb 16 23:25:58 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux
== check pips ===================================================
numpy (1.14.1)
numpydoc (0.7.0)
protobuf (3.5.2)
tensorflow (1.7.0rc0)
tensorflow-tensorboard (1.5.1)
== check for virtualenv =========================================
False
== tensorflow import ============================================
tf.VERSION = 1.7.0-rc0
tf.GIT_VERSION = b'v1.7.0-rc0-2-ga6f8b22'
tf.COMPILER_VERSION = b'v1.7.0-rc0-2-ga6f8b22'
Sanity check: array([1], dtype=int32)
== env ==========================================================
LD_LIBRARY_PATH /home/user/software_install/TensorRT-3.0.4/lib:/usr/local/cuda/lib64:
DYLD_LIBRARY_PATH is unset
== nvidia-smi ===================================================
Fri Mar 16 11:28:51 2018
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 384.111                Driver Version: 384.111                   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |
|  0%   38C    P8     9W / 200W |    253MiB /  8110MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1132      G   /usr/lib/xorg/Xorg                           139MiB |
|    0      3053      G   compiz                                       111MiB |
+-----------------------------------------------------------------------------+
== cuda libs  ===================================================
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.61
/usr/local/cuda-8.0/doc/man/man7/libcudart.7
/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7
++++++++++Problem+++++++++++
I try to quantize my model. Computation is as follow:
pointwise_conv2d(relu(depthwise_conv2d(x)))
Then, I use tf.contrib.quantize.create_eval_graph() to quantize graph.
However, there is an error when I use lite.toco_convert() to convert model into tflite.
I want to konw how to change the graph to contain min/max information for relu layer.
MSG:
Array conv2_depthwise_relu, which is an input to the Conv operator producing the output array conv2, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.
quant.zip