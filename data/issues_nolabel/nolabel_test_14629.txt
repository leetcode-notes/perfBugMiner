Documentation error in attention_wrapper.py

In tf.contrib.seq2seq.attention_wrapper.py file, in line 295, it should be [batch_size, 1, max_time], instead of [batch_time, ...], hope to fix it soon!! Thanks !!