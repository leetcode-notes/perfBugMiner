Saver unable to restore from checkpoint file although it had successfully restored previously.

I am currently seeing a very strange behavior from using tf.train.Saver. Basically I had previously successfully run my code and restored all the variables from the TensorFlow-slim inception-resnet-v2 model and even obtained my losses and predictions. However, after I added some scopes to exclude in variables_to_restore = slim.get_variables_to_restore(exclude = [...]) , which I successfully run,  when I returned back to using no excluded scope, my code actually fails. It gave me the following error:
NotFoundError (see above for traceback): Tensor name "InceptionResnetV2/Repeat_1/block17_13/Branch_1/Conv2d_0c_7x1/BatchNorm/beta/Adam" not found in checkpoint files ./inception_resnet_v2_2016_08_30.ckpt
Here is the code I run.
with slim.arg_scope(inception_resnet_v2.inception_resnet_v2_arg_scope()):
	logits, end_points = inception_resnet_v2.inception_resnet_v2(image_batch, is_training = False)
	predictions = end_points['Predictions']

#....then the typical building of operations till you get the train_op

variables_to_restore = slim.get_variables_to_restore()
saver = tf.train.Saver(variables_to_restore) #This is the line where the errors appear
def restore_fn(sess):
	return saver.restore(sess, checkpoint_file)
sv = tf.train.Supervisor(logdir = log_dir, summary_op = None, init_fn = restore_fn)

I have even replaced my checkpoint file again and this error persists. Why does this happen?
I strongly suspect it might have been because the original graph has been edited again as I did not encapsulate most of the definitions within a specified graph like with tf.Graph.as_default() as g:, but at the start of my code I have always done tf.reset_default_graph().