Decoding and resizing image is giving unknown tensor shape

I'm trying to load two images, one is .png and another is .jpg, to tensorflow and resize them to 100x100 pixel size using tf.image.pad_to_bounding_box, so that they will be of same size and can be used for training. Here's my code:
import os
import tensorflow as tf

def decode(image_data):
    return tf.image.decode_image(image_data, channels=3)

def adjust_paddig(image_tensor):
    return tf.image.pad_to_bounding_box(image_tensor, offset_height=0, offset_width=0, target_height=100, target_width=100)

def load(images_paths):
    filename_queue = tf.train.string_input_producer(images_paths)
    reader = tf.WholeFileReader()
    _, image_file = reader.read(filename_queue)
    image_tensor = decode(image_file)
    padded_image_tensor = adjust_paddig(image_tensor)
    return padded_image_tensor

if __name__ == '__main__':
    IMAGES_PATH = ["images/1.png","images/2.jpg"] # Both image are of different shape
    class_images_tensor = load(IMAGES_PATH)
    print(class_images_tensor.shape)

But some how the resized image size is not proper. It's displaying height and width but not depth(I mean channels).
Output: (100,100,?) #height, width are 100, but depth is '?'
and Surprisingly, It's giving same output for invalid paths also.
Eg: IMAGES_PATH = ['images/']
What Am I doing wrong? Please help.