tf.concat(-1, list_of_tensors) should fail at graph build time, not eval time

Instead it gives an erroneous result:
>>> tf.concat(-1, [tf.range(3), tf.range(3)])
<tf.Tensor 'concat_2:0' shape=(6, 3) dtype=int32>

When you run .eval() you get the expected error message:
InvalidArgumentError: ConcatOp : Expected concatenating dimensions in the range [0, 1), but got -1
Of course, it would be even better if negative indices counted axes from the end (like in NumPy), but that's a different matter...