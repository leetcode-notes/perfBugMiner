CUDNN_STATUS_BAD_PARAM with included cifar10 model

Environment info
Operating System:
Debian 3.16.7-ckt20-1+deb8u3 (2016-01-17) x86_64 GNU/Linux
Python 2.7
If installed from binary pip package, provide:

Which pip package you installed.
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl
The output from python -c "import tensorflow; print(tensorflow.version)".
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally
0.7.1

Steps to reproduce

Go to /usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10
Run python cifar10_train.py as root
Observe output
F tensorflow/stream_executor/cuda/cuda_dnn.cc:383] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM
Aborted

What have you tried?

Messing with LD_LIBRARY_PATH and making sure all cuda packages are updated to 7.5 (and CudNN 5.0). Training the simple softmax models on GPU is possible.

Logs or other output that would be helpful
(If logs are large, please upload as attachment).
root@leviathan:/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/cifar10# python cifar10_train.py
I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally
... Loads other CUDA libraries as above ...
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: Tesla K40c
major: 3 minor: 5 memoryClockRate (GHz) 0.745
pciBusID 0000:01:00.0
Total memory: 11.25GiB
Free memory: 11.15GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:717] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 1.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 2.0KiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 4.0KiB
... and so on up to 16.00 GB:
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:51] Creating bin of max chunk size 16.00GiB
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:73] Allocating 10.60GiB bytes.
I tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:83] GPU 0 memory begins at 0x5047a0000 extends to 0x7aaa4019a
F tensorflow/stream_executor/cuda/cuda_dnn.cc:383] could not set cudnn filter descriptor: CUDNN_STATUS_BAD_PARAM
Aborted