Unable to specify loss function in tf.contrib.learn.DNNLinearCombinedRegressor

NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.
For general support from the community, see StackOverflow.
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.
For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
Have been unable to find how to specify loss function for both linear and deep components of the DNNLinearCombinedRegressor initializer. Looked in many places including tf.train (initialize optimizer with specific loss function?) and in learn.estimators. Also could not find a solution on stackoverflow or anywhere else through google searches.
Environment info
Operating System: mac OS 10.12.3
Installed version of CUDA and cuDNN: None.
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
If installed from binary pip package, provide:

A link to the pip package you installed:
The output from python -c "import tensorflow; print(tensorflow.__version__)". Version 1.0.0

If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
Have not been able to specify loss function.
What other attempted solutions have you tried?
Tried to create custom estimator using tf.contrib.losses to specify desired loss but unable to combine both deep and wide this way. Would prefer to use the pre-defined linearCombinedRegressor with a loss function specified for each of the linear and deep optimizers. How?
Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).