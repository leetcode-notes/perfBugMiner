Resource exhausted: OOM when allocating tensor with shape, even when batch_size is 1.

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I've registered a new problem for translating English to Swedish, the code is pretty similar to TranslateEndeWmtBpe32k, with Europarl data. I'm able to train with hidden_size: 128, anything over 128 and I get Resource exhausted error, even when batch size is 1. (I'm using hparams: transformer_big).

I notice that previous posts on this issue were solved by reducing the batch size. I'm posting this because reducing batch size wasn't helpful and I'm hoping if someone encountered a similar issue.

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Linux deepnlp01 4.2.0-42-generic #49~14.04.1-Ubuntu SMP Wed Jun 29 20:22:11 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux
4 VERSION="14.04.5 LTS, Trusty Tahr"


TensorFlow installed from (source or binary):
tf.VERSION = 1.4.1 (Installed from source)


Python version:
2.7.6


Bazel version (if compiling from source):
Build label: 0.5.2


GCC/Compiler version (if compiling from source):
c++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4


CUDA/cuDNN version:
nvcc: NVIDIA (R) Cuda compiler driver
Cuda compilation tools, release 8.0, V8.0.61


GPU model and memory:
NVIDIA TITAN X (12GB)


Exact command to reproduce:
USR_DIR=/python2.7/site-packages/tensor2tensor/<new_module>


t2t-trainer 
--data_dir=$DATA_DIR 
--problems=$PROBLEM 
--model=$MODEL 
--hparams_set=$HPARAMS 
--output_dir=$TRAIN_DIR 
--t2t_usr_dir=$USR_DIR
Describe the problem
The data I'm using is parallel corpus English-Swedish, available on http://www.statmt.org/europarl/ . I've created a dictionary myself of about 1,400,000 (1.4 million) words. [The problem persists even if I use a smaller vocab of about 10k words]
I'm able to train with batch_size=1024 and hidden_size=128, if I increase the hidden size to 256, even with batch_size=1, it runs out of memory. I get the following error.
Source code / logs
This is the error I'm encountering:
2018-02-28 05:48:52.977027: W tensorflow/core/framework/op_kernel.cc:1192] Resource exhausted: OOM when allocating tensor with shape[90993,256]

Traceback (most recent call last):
  File "/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer", line 32, in <module>
    tf.app.run()
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer", line 28, in main
    t2t_trainer.main(argv)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py", line 337, in main
    execute_schedule(exp)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py", line 287, in execute_schedule
    getattr(exp, FLAGS.schedule)()
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.py", line 64, in new_func
    return func(*args, **kwargs)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py", line 717, in continuous_train_and_eval
    hooks=self._train_monitors)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py", line 807, in _call_train
    hooks=hooks)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 783, in _train_model
    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 521, in run
    run_metadata=run_metadata)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 892, in run
    run_metadata=run_metadata)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 967, in run
    raise six.reraise(*original_exc_info)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 952, in run
    return self._sess.run(*args, **kwargs)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 1024, in run
    run_metadata=run_metadata)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py", line 827, in run
    return self._sess.run(*args, **kwargs)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 889, in run
    run_metadata_ptr)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1120, in _run
    feed_dict_tensor, options, run_metadata)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1317, in _do_run
    options, run_metadata)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/client/session.py", line 1336, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[90992,256]
         [[Node: training/gradients/AddN_96 = AddN[N=3, T=DT_FLOAT, _class=["loc:@transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_1/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256/shared/concat_grad/tuple/control_dependency_14)]]
         [[Node: training/global_norm/global_norm/_4061 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_24183_training/global_norm/global_norm", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]()]]

Caused by op u'training/gradients/AddN_96', defined at:
  File "/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer", line 32, in <module>
    tf.app.run()
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "/data/tf_venv/2.7/1.4.1_gpu/bin/t2t-trainer", line 28, in main
    t2t_trainer.main(argv)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py", line 337, in main
    execute_schedule(exp)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/bin/t2t_trainer.py", line 287, in execute_schedule
    getattr(exp, FLAGS.schedule)()
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/framework/experimental.py", line 64, in new_func
    return func(*args, **kwargs)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py", line 717, in continuous_train_and_eval
    hooks=self._train_monitors)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/experiment.py", line 807, in _call_train
    hooks=hooks)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 302, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 711, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/estimator/estimator.py", line 694, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py", line 829, in wrapping_model_fn
    use_tpu=use_tpu)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py", line 923, in estimator_model_fn
    loss, num_async_replicas=num_async_replicas)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py", line 927, in estimator_spec_train
    train_op = self.optimize(loss, num_async_replicas=num_async_replicas)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/t2t_model.py", line 351, in optimize
    loss, lr, self.hparams, use_tpu=common_layers.is_on_tpu())
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/optimize.py", line 67, in optimize
    colocate_gradients_with_ops=True)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/optimizers.py", line 241, in optimize_loss
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensor2tensor/utils/optimize.py", line 109, in compute_gradients
    return self._opt.compute_gradients(loss, var_list, **kwargs)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py", line 414, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py", line 533, in gradients
    out_grads = _AggregatedGrads(grads, op, loop_state, aggregation_method)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py", line 872, in _AggregatedGrads
    out_grads[i] = _MultiDeviceAddN(out_grad)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py", line 767, in _MultiDeviceAddN
    summands.append(math_ops.add_n(tensors))
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py", line 2000, in add_n
    return gen_math_ops._add_n(inputs, name=name)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.py", line 220, in _add_n
    "AddN", inputs=inputs, name=name)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 2956, in create_op
    op_def=op_def)
  File "/data/tf_venv/2.7/1.4.1_gpu/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py", line 1470, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[90992,256]
         [[Node: training/gradients/AddN_96 = AddN[N=3, T=DT_FLOAT, _class=["loc:@transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat"], _device="/job:localhost/replica:0/task:0/device:GPU:0"](training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_2/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256_1/shared/concat_grad/tuple/control_dependency_14, training/gradients/transformer/parallel_0_5/transformer/symbol_modality_1455878_256/shared/concat_grad/tuple/control_dependency_14)]]
         [[Node: training/global_norm/global_norm/_4061 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device_incarnation=1, tensor_name="edge_24183_training/global_norm/global_norm", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:CPU:0"]()]]


This is the code that I've modified:
def _get_europarl_ensv_dataset(directory, filename):
    """Extract the EuroParl en-sv corpus `filename` to directory unless it's there."""

    train_path = os.path.join(directory, filename)

    return train_path


@registry.register_problem
class TranslateEnsvEuroparl(translate.TranslateProblem):
    """Problem spec for EuroParl En-Sv translation, BPE version."""

    @property
    def approx_vocab_size(self):
        return 1455877

    @property
    def vocab_filename(self):
        return "vocab.europarl.ensv.txt"

    def get_or_create_vocab(self, data_dir, tmp_dir, force_get=False):
        vocab_filename = os.path.join(data_dir, self.vocab_filename)
        if not tf.gfile.Exists(vocab_filename) and force_get:
            raise ValueError("Vocab %s not found" % vocab_filename)
        return text_encoder.TokenTextEncoder(vocab_filename, replace_oov="UNK")

    def generate_samples(self, data_dir, tmp_dir, dataset_split):
        """Instance of token generator for the WMT en->de task, training set."""
        train = dataset_split == problem.DatasetSplit.TRAIN
        dataset_path = ("europarl-v7.train.sv-en"
                        if train else "europarl-v7.test.sv-en")
        train_path = _get_europarl_ensv_dataset(tmp_dir, dataset_path)

        # Vocab
        token_path = os.path.join(data_dir, self.vocab_filename)
        if not tf.gfile.Exists(token_path):
            token_tmp_path = os.path.join(tmp_dir, self.vocab_filename)
            tf.gfile.Copy(token_tmp_path, token_path)
            with tf.gfile.GFile(token_path, mode="r") as f:
                vocab_data = "<pad>\n<EOS>\n" + f.read() + "UNK\n"
            with tf.gfile.GFile(token_path, mode="w") as f:
                f.write(vocab_data)

        return text_problems.text2text_txt_iterator(train_path + ".en",
                                                    train_path + ".sv")