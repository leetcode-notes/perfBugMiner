Get strange results by running sparse_tensor_dense_matmul_op_test.py

When I run sparse_tensor_dense_matmul_op_test.py with large n,m,k
I get:
% nnz 	 n 	 gpu 	 m 	 k 	 dt(dense) 	 dt(sparse) 	 dt(sparse)/dt(dense)
0.5 	 512 	 True 	 1822 	 4608 	 0.0222946 	 0.0130646 	 0.585998
0.5 	 512 	 True 	 1821 	 4608 	 0.0224976 	 0.0130761 	 0.581222
0.5 	 512 	 True 	 1820 	 4608 	 0.022529 	 0.79513 	 35.2936
0.5 	 512 	 True 	 1819 	 4608 	 0.0217343 	 0.795709 	 36.6107

It is strange that dt(sparse)/dt(dense) are very different when m=1821 -> 1820
BTY, I set the iterations to 10 for time saving...
delta_dense = _timer(sess, ops_fn, 10)
delta_sparse = _timer(sess, ops_fn, 10)