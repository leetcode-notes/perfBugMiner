rnn.bidirectional_rnn  cause a problem

code:
import tensorflow as tf
from tensorflow.models.rnn import rnn,rnn_cell

seq_length = 5
rnn_size = 6
input_data = [[1,2,3,4,5],[6,1,8,9,10],[11,12,1,14,15]]
with tf.device("/cpu:0"):
 embedding = tf.get_variable("embedding", [20, rnn_size])
 result = tf.nn.embedding_lookup(embedding, input_data)
 inputs = tf.split(1,seq_length,result)
 inputs = [tf.squeeze(input_, [1]) for input_ in inputs]

cell_bw = rnn_cell.BasicLSTMCell(rnn_size)
cell_fw = rnn_cell.BasicLSTMCell(rnn_size)
bi = rnn.bidirectional_rnn(cell_fw,cell_bw,inputs,cell_fw.zero_state(3, tf.float32),cell_bw.zero_state(3, tf.float32),sequence_length=5)

with tf.Session() as session:
    tf.initialize_all_variables().run()
    print(session.run(bi))
error:
"Shapes %s and %s must have the same rank" % (self, other))
ValueError: Shapes TensorShape([]) and TensorShape([Dimension(None)]) must have the same rank
it seem that the inputs have a problem, Can you tell me why ?