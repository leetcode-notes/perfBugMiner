Tensorflow gpu vs cpu problem

I am using Tenosrflow 1.0.1. I can run my program tensorflow installed on CPU, but when I run it on different computer tensorflow installed GPU, it says out of memory. What is the problem with the GPU Tensorflow.
What is the reason I can run it on CPU but not on GPU? To run it on GUP I have to decrease the batch size and the image size of my data set. Why has the GPU tensorflow become very poor?
The error message for GPU Tensorflow is :
`2017-05-04 14:24:03.511879: W c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\framework\op_kernel.cc:1152] Resource exhausted: OOM when allocating tensor with shape[1,6000,6000,64]
Traceback (most recent call last):
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 1039, in _do_call
return fn(*args)
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 1021, in _run_fn
status, run_metadata)
File "C:\Users\admin\Anaconda3\lib\contextlib.py", line 66, in exit
next(self.gen)
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\framework\errors_impl.py", line 466, in raise_exception_on_not_ok_status
pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,6000,6000,64]
[[Node: inference/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](sub, inference/conv1_1_w/read)]]
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
File "FCN.py", line 225, in 
tf.app.run()
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py", line 48, in run
_sys.exit(main(_sys.argv[:1] + flags_passthrough))
File "FCN.py", line 196, in main
sess.run(train_op, feed_dict=feed_dict)
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 778, in run
run_metadata_ptr)
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 982, in _run
feed_dict_string, options, run_metadata)
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 1032, in _do_run
target_list, options, run_metadata)
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\client\session.py", line 1052, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[1,6000,6000,64]
[[Node: inference/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](sub, inference/conv1_1_w/read)]]
Caused by op 'inference/Conv2D', defined at:
File "FCN.py", line 225, in 
tf.app.run()
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\platform\app.py", line 48, in run
_sys.exit(main(_sys.argv[:1] + flags_passthrough))
File "FCN.py", line 149, in main
pred_annotation, logits = inference(image, keep_probability)
File "FCN.py", line 84, in inference
image_net = vgg_net(weights, processed_image)
File "FCN.py", line 54, in vgg_net
current = utils.conv2d_basic(current, kernels, bias)
File "C:\Users\admin\Documents\gray\TensorflowUtils.py", line 89, in conv2d_basic
conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding="SAME")
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py", line 403, in conv2d
data_format=data_format, name=name)
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\framework\op_def_library.py", line 768, in apply_op
op_def=op_def)
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py", line 2336, in create_op
original_op=self._default_original_op, op_def=op_def)
File "C:\Users\admin\Anaconda3\lib\site-packages\tensorflow\python\framework\ops.py", line 1228, in init
self._traceback = _extract_stack()
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,6000,6000,64]
[[Node: inference/Conv2D = Conv2D[T=DT_FLOAT, data_format="NHWC", padding="SAME", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device="/job:localhost/replica:0/task:0/gpu:0"](sub, inference/conv1_1_w/read)]]
`