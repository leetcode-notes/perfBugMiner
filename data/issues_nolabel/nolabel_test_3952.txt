Poor results with tensorflow DNNClassifier and cross_val_score

I am using python 3.5, tensorflow 0.10 and its DNNClassifier. If I perform a single training and testing stage, as below, the test result is decent: accuracy = 0.9333
import tensorflow as tf
from tensorflow.contrib import learn
from sklearn.cross_validation import cross_val_score, ShuffleSplit, train_test_split
from sklearn.metrics import accuracy_score
import numpy as np
from sklearn.metrics import accuracy_score
from sklearn import datasets, cross_validation
iris = datasets.load_iris()
feature_columns = learn.infer_real_valued_columns_from_input(iris.data)
x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.20, random_state = 20)
model = learn.DNNClassifier(hidden_units=[5],
n_classes=3,
feature_columns=feature_columns,
)
model.fit(x_train, y_train, steps=1000)
predicted = model.predict(x_test)
print('Accuracy on test set: %f' % accuracy_score(y_test, predicted))
If I use sklearn's cross_val_score, then the final results is much poorer, about 0.33 accuracy:
model = learn.DNNClassifier(hidden_units=[5],
n_classes=3,
feature_columns=feature_columns,
)
scores = cross_val_score(estimator=model,
X=iris.data,
y=iris.target,
scoring = 'accuracy',
cv=5,
fit_params={'steps': 1000},
)
print(scores)
print(np.mean(scores))
The scores ad their mean are:
[ 0.          0.33333333  1.          0.33333333  0.        ]
0.333333333333
What's wrong with my code in cross validation estimation?