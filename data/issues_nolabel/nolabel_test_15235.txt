Loss should change depending on the number of epochs chosen even if I set the seed?

Hi colleagues,
I am using Keras to train different NNs. I would like to know why if I increment the epochs, the result until the same number of epochs is not the same for the evolution of loss. I am using shuffle=False, and np.random.seed(2017), tf.set_random_seed(2017), and I have check that if I repeat with the same number of epochs, the result is the same, so the random initialization is working. After the epochs training, I am deleting the ANN so the training begins at 0 again.
Here I attach the picture of the resulting training with 10 epochs:

And here I attach the picture of the resulting training with 8 epochs:

Also, I would like to know why the training time is not exactly (8/10) the 10 epochs attempt and how is it possible that some of them have less accuracy with 2 more epochs!
Here is the link to open code Jupyter Notebook. GitHub Jupyter Notebook - ANN Comparison
Thanks a lot!