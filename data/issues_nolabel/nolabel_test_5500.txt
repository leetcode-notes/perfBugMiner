tf.case unexpected behaviour with tf.placeholder in predicate

I am using a tf.case to distinguish between N different cases to return exactly one of N output tensors. Crucially, I am using a tf.placeholder in the predicates. The toy example below exemplifies my code:
import tensorflow as tf

N = 6
length = tf.placeholder(dtype=tf.int32, shape={})

tensors =[tf.constant(i * 100) for i in range(N)]
default = lambda: tf.constant(-2)
predicates = [(tf.equal(length, tf.constant(i, dtype=tf.int32)), lambda: tensors[i]) for i in range(N)]

mycase = tf.case(predicates, default, exclusive=True)

with tf.Session() as session:
  session.run(tf.initialize_all_variables())

  for l in range(N):
    out = session.run(mycase, feed_dict = {length : l})
    print("output %d\t(length = %d)" % (out,l))
As output I would expect
output 0	(length = 0)
output 100	(length = 1)
output 200	(length = 2)
output 300	(length = 3)
output 400	(length = 4)
output 500	(length = 5)

However, I get
output 500	(length = 0)
output 500	(length = 1)
output 500	(length = 2)
output 500	(length = 3)
output 500	(length = 4)
output 500	(length = 5)


Comparing a constant to a placeholder usually does not cause problems. Am I stretching something too far by emulating such dynamic behaviour using case plus palceholder?
Setup: Ubuntu 14.04, tensorflow 0.11.0rc2 from the provided tensorflow-0.11.0rc2-cp34-cp34m-linux_x86_64.whl