string_input_producer num_epochs not working as expected

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OSX 10.12.6
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.2.1
Python version: 3.6
Bazel version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:

Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.
Reading a (csv) file with string_input_producer() / start_queue_runners() works up to a certain limit. Using tf.train.shuffle_batch(), only the first N lines of the file are read.
Also, num_epochs seems limited to a certain number (30 without batching, lower with batch).
Source code / logs
Simple script for reading a csv file / training a linear model. The code WORKS. But it does NOT respond to changes in num_epochs / the number of steps printed at the end is not what we expect to see.
csv file: (model: W=-1, b=1 , y=Wx+b)
2,-1
3,0
4,1
5,2
(repeated)
import tensorflow as tf

W = tf.Variable([.3], dtype=tf.float32)
b = tf.Variable([-.3], dtype=tf.float32)
x = tf.placeholder(tf.float32, name="x")
y = tf.placeholder(tf.float32)
linear_model = tf.add(W * x, b, name="model")
squared_deltas = tf.square(linear_model - y)
loss = tf.reduce_sum(squared_deltas)

train = tf.train.AdamOptimizer(1e-3).minimize(loss)

# reading input
filename_queue = tf.train.string_input_producer(["/tmp/input.csv"], num_epochs=100)
reader = tf.TextLineReader(skip_header_lines=0)
_, csv_row = reader.read(filename_queue)
record_defaults = [[0.], [0.]]
col_x, col_label = tf.decode_csv(csv_row, record_defaults=record_defaults)
features = tf.stack([col_x])

with tf.Session() as sess:
  sess.run(tf.local_variables_initializer())
  sess.run(tf.global_variables_initializer())
  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(coord=coord)
  n = 0
  while True:
    try:
      n += 1
      inp, lab = sess.run([features, col_label])
      sess.run(train, feed_dict={x:inp, y:lab})
    except tf.errors.OutOfRangeError:
      break
    finally:
      coord.request_stop()
  coord.join(threads)
  print(n)

with batch: adding those lines in reading input
batch_size = 20
min_after_dequeue = 10000
col_x, col_label = tf.decode_csv(csv_row, record_defaults=record_defaults)
capacity = 3 * min_after_dequeue + batch_size
x_batch, label_batch = tf.train.shuffle_batch(
    [col_x, col_label], batch_size=batch_size, capacity=capacity,
    min_after_dequeue=min_after_dequeue)