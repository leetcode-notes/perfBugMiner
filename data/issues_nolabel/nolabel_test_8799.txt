Ensuring positive definite covariance matrix in tensorflow

Hi all,
I have the problem how to ensure psd property of covariance matrix in tensorflow. so I map the rnn outputs to the $\mu$ and $\Sigma$ of a MVN. So here I have to make the covariance psd, I tried to use matrix exponential, but it is not implemented in tensorflow, and I tried SVD, but then my loss function is not differentiable. So I tried to use $LL^{T} + \alpha |$, but still the program has bugs that the Sigma matrix is not invertible. Any suggestions for this problem? Thanks in advance!
def get_lossfunc(mu, Sigma,input_data):
    loss = 0
    for i in range(len(mu)):
        muC = tf.squeeze(mu[i])
        SigmaC = Sigma[i]
        inputC = input_data[i]
        SigmaC = tf.matmul(SigmaC, tf.transpose(SigmaC)) + tf.eye(10)
#         s,u,v = tf.svd(Sigma[0])
#         SigmaC = tf.matmul(tf.matmul(u,tf.diag(tf.exp(s))),v)
        dist = tf.contrib.distributions.MultivariateNormalFull(muC, SigmaC)
        loss += -tf.log(dist.pdf(inputC))
#         print loss
    return loss