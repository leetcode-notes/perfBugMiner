iOS example running bug

Environment info
Operating System: iOS
Steps to reproduce

Follow the contrib/makefile/README to install the tensorflow iOS core lib
Download the graph .pb files and copy them in the .xcodeproj
Run the example, an error is logged

Logs or other output that would be helpful
Running model failed:Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs
    [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]

Is there a modification to do to the building of the lib to include jpeg ops?
Other notes:

the version of Eigen downloaded in the Makefile is not the same as the one configured in the .xcodeproj (the include path uses another version hash), I kept the one from the Makefile
after downloading http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz as indicated in the README, the .pb and .txt files don't have the same names as the ones in the iOS examples, I renamed them, although I'm not sure if the examples refer to the same model

Those last issues seem fixed by a9d1af0#diff-05f2ac6ab411cf0c1e4ad1d7b96caf22R45