A bug when applying MultiRNNCell?

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): This code is very similar to an official example
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): pip install tensorflow
TensorFlow version (use command below): b'unknown' 1.4.0
Python version: Python 3.5.2 :: Anaconda 4.2.0 (64-bit)
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
GPU model and memory:
Exact command to reproduce:

You can collect some of this information using our environment capture script:
https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh
You can obtain the TensorFlow version with
python -c "import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)"
Describe the problem
tf.nn.MultiRNNCell sometimes doesn't work.
It raises an issue like this:
ValueError: Dimensions must be equal, but are 64 and 96 for 'lstm/rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul_1' (op: 'MatMul') with input shapes: [128,64], [96,128].
Source code / logs
import tensorflow as tf
import numpy as np
hidden_layer_size = 32
embed = tf.zeros((128, 6, 64), dtype=tf.float32)
num_LSTM_layers = 2
with tf.variable_scope("lstm"):
lstm_cell = tf.contrib.rnn.BasicLSTMCell(hidden_layer_size, forget_bias=1.0)
cell = tf.contrib.rnn.MultiRNNCell(cells=[lstm_cell]*num_LSTM_layers, state_is_tuple=True)
outputs, states = tf.nn.dynamic_rnn(cell, embed, dtype=tf.float32)

Error:
ValueError: Dimensions must be equal, but are 64 and 96 for 'lstm/rnn/while/rnn/multi_rnn_cell/cell_0/cell_0/basic_lstm_cell/MatMul_1' (op: 'MatMul') with input shapes: [128,64], [96,128].