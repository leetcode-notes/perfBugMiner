How to run custom encoder-decoder in Tensorflow using available APIs?

I need to run a encoder-decoder model in Tensorflow. I see that using the available APIs basic_rnn_seq2seq(encoder_input_data, decoder_input_data, lstm_cell) etc., an encoder-decoder system can be created. However, few pertaining issues are:

How can we enter the embeddings such as word2vec in such model? I am
aware that we can do embedding lookup but as per the API
encoder_input_data is a list of 2D Tensor of size batch_size x
input_size. How can each word be represented using its respective word embedding in this setup? Even embedding_rnn_seq2seq internally extracts the embeddings. How to give pre-calculated word embeddings as input?
How can we get the cost and perplexity through the API?
In case of test instances, we may not know the corresponding decoder inputs. How to handle such case?