Auto-Parallel excludes update operators of sparse tensors

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 14.04
TensorFlow installed from (source or binary):
source
TensorFlow version (use command below):
r1.3
Bazel version (if compiling from source):
0.4.5
CUDA/cuDNN version:
cuda 8.0/cudnn 5.1.5
GPU model and memory:
Tesla P40
Exact command to reproduce:

Describe the problem
I'm trying to use auto_parallel in grappler, but I found it only controls dense tensors. In the code, only below operators update averaged gradients, but what about 'ScatterSub' for sparse tensors? Do you have a plan to implement it?
const std::set<string> apply_gradients_ops = {"ApplyGradientDescent",
                                                "ApplyProximalGradientDescent",
                                                "ApplyAdadelta",
                                                "ApplyAdagrad",
                                                "ApplyProximalAdagrad",
                                                "ApplyAdagradDA",
                                                "ApplyFtrl",
                                                "ApplyMomentum",
                                                "ApplyAdam",
                                                "ApplyRMSProp",
                                                "ApplyCenteredRMSProp"};

Source code / logs