control_dependencies() maybe fails to mfence when an assign() with different shape occurs

Environment info
Operating System: OS X El Capitan
Installed CPU version (OSX pip package)
tensorflow version: 0.10.0rc0
Steps to reproduce
Consider the following code snippet:
x = tf.Variable(0.)
x_op = tf.assign(x, [1.], validate_shape=False)

with tf.control_dependencies([x_op]):
    plus_op = x+2

tf.initialize_variables([x]).run()
print plus_op.eval()
The expected output is [3], but instead I get 2
What have you tried?
If we don't assign an inconsistent shape (e.g. assign 1 instead of [1]), then things work the way one would expect (output is 3)
If we replace
plus_op = x+2
with
plus_op=x.ref() + 2
then we get the expected output of [3] instead of 2.
I suspect this is because calling ref() may somehow trigger a memory fence which fixes the broken behavior.
Also, it is possible that this is the intended behavior and that I misunderstood control_dependencies(), in which case I apologize.