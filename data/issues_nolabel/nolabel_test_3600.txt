failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED

With the current master branch I receive the following error 20% of the time when training an RNN.

I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:83:00.0
Total memory: 12.00GiB
Free memory: 11.86GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:843] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:83:00.0)
E tensorflow/stream_executor/cuda/cuda_blas.cc:367] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
W tensorflow/stream_executor/stream.cc:1334] attempting to perform BLAS operation using StreamExecutor without BLAS support
I tensorflow/stream_executor/stream.cc:1282] stream 0x76b6890 did not wait for stream: 0x76b5d60
I tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570900
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
I tensorflow/stream_executor/stream.cc:3732] stream 0x76b6890 did not memcpy host-to-device; source: 0x204570b00
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
W tensorflow/core/framework/op_kernel.cc:940] Internal: Blas SGEMM launch failed : a.shape=(455, 12), b.shape=(12, 16), m=455, n=16, k=12
[[Node: RNN/cond/GRUCell/Gates/Linear/MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device="/job:localhost/replica:0/task:0/gpu:0"](RNN/cond/GRUCell/Gates/Linear/concat, RNN/cond/GRUCell/Gates/Linear/MatMul/Switch)]]
F tensorflow/core/common_runtime/gpu/gpu_util.cc:343] CPU->GPU Memcpy failed

Environment info
Scientific Linux 7
cuda 7.5.18
cudnn 5.0.5
$ bazel version
....
Build label: 0.3.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Jun 10 11:38:23 2016 (1465558703)
Build timestamp: 1465558703
Build timestamp as int: 1465558703
$ git rev-parse HEAD
88d9bc1
$ nvidia-smi -L
GPU 0: GeForce GTX TITAN X