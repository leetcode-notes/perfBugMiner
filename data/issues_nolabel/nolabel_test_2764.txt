Run train op multiple times

I have some fairly large batch sizes on which I'd like to take multiple gradient steps. While I could easily do this with a python for loop, I imagine that there might be a more efficient method that doesn't involve transferring the data to gpu on each iteration.
@yaroslavvb has confirmed that putting the train op in the fetch list multiple times doesn't work, and suggested that I could save my input tensors as variables with tf.assign. Unfortunately, this doesn't work for me because my input tensors have variable sizes, and tensorflow variables must have a fixed size.