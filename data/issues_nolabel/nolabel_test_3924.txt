max of two tf.Dimension objects undetermined

Environment info
Operating System: ubuntu 16.04
Installed version of CUDA and cuDNN: None
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
If installed from binary pip package, provide:

Which pip package you installed.
https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
The output from python -c "import tensorflow; print(tensorflow.__version__)".
0.10.0rc0

Steps to reproduce
import tensorflow as tf
max(tf.Dimension(1), tf.Dimension(None))
# => Dimension(1)
max(tf.Dimension(None), tf.Dimension(1))
# => Dimension(None)
I've looked at the code of Dimension class. It defines the comparison between integers and None to return None, causing this undetermined behavior when using max. I suggest that a better way could be to raise an Error when comparing with None or to always set integers to be larger, like python does.