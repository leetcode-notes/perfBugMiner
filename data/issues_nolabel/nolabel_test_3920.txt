about attention_seq2seq function without embedding

we already have a function tf.nn.seq2seq.embedding_attention_seq2seq(), but if i want to use an embedding trained from other model, the function is not convenient, do we have a function like tf.nn.seq2seq.attention_seq2seq() that need an embedding para or the inputs embedded.
Thanks!