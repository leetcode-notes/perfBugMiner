Memory leak in Java API due to missing TF_DeleteStatus

This is a leak confirmed on StackOverflow by ash.
System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.  There's a short example in the above StackOverflow link and a working JUNIT test written in a maven project on github that demonstrates the problem.


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Sierra using TF 1.1, and CentOS7 using both TF 1.1 and TF 1.2_rc0.


TensorFlow installed from (source or binary): binary from Maven


TensorFlow version (use command below): On Mac uses Maven <version>1.1.0</version>, on CentOS7 <version>1.2.0-rc0</version>


Bazel version (if compiling from source): N/A


CUDA/cuDNN version: N/A


GPU model and memory: N/A


Exact command to reproduce: See above for the short example on the StackOverflow link or the full Java file at the github example project.


Describe the problem
Running the example code given causes the process memory (outside the JDK, not heap space) to grow until the process exits.  Leaked was agreed to be in TensorFlow by ash at StackOverflow:

I believe there is indeed a leak (in particular a missing TF_DeleteStatus corresponding to the allocation in JNI code)

Source code / logs
The test file is here within the above reference github project.
Thank you for providing this amazing tool!