Distribution Strategy not working with tf-nightly-gpu for Python3.5

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No, I am using the script https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py provided as an example for DistributionStrategy API
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux  4.13.0-37-generic #42~16.04.1-Ubuntu SMP Wed Mar 7 16:03:28 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux "16.04.4 LTS (Xenial Xerus)"
TensorFlow installed from (source or binary): binary through pip3 install tf-nightly-gpu
tf.VERSION = 1.8.0-dev20180402
tf.GIT_VERSION = v1.7.0-rc1-1091-gc7a04561fb
tf.COMPILER_VERSION = v1.7.0-rc1-1091-gc7a04561fb
Sanity check: array([1], dtype=int32)
TensorFlow version (use command below): v1.7.0-rc1-1091-gc7a04561fb 1.8.0-dev20180402
Python version: 3.5
CUDA/cuDNN version:
CUDA version: 9.0, V9.0.176
#define CUDNN_MAJOR 7
#define CUDNN_MINOR 0
#define CUDNN_PATCHLEVEL 5
GPU model and memory: Quadro M6000 24GB
Exact command to reproduce: python3

Describe the problem
I am trying to test the DistributionStrategy API. In order to do that I downloaded the tensorflow nightly build by executing
pip3 install tf-nightly-gpu
Then I tried to execute the example provided here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distribute/python/examples/simple_estimator_example.py
But it is not working, there is an exception shortly after the script starts to run ( I am copying the stack trace in the next section).
I have tried to do the same using the  tensorflow nightly build for python 2.7 downloaded by executing
pip install tf-nightly-gpu and it works without any problem.
The issue here, is that I would like to integrate this API with my multi-gpu training and inference processes, which are complete written for python3.
I would like to know, if DistributionStrategy API is already supported in for python 3.5 and the problem is that I am using a wrong example. Or, in case it is not supported yet, if there are plans to do it.
Thanks in advance.
Source code / logs
(vtf_nightly_gpu) /ccrespo/mirrored_strategy/src$ python3 mirrored_strategy_test.py
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpmou3ft0t
2018-04-03 16:17:32.334622: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-04-03 16:17:32.686755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties:
name: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114
pciBusID: 0000:03:00.0
totalMemory: 23.90GiB freeMemory: 23.35GiB
2018-04-03 16:17:32.956384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 1 with properties:
name: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114
pciBusID: 0000:04:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-04-03 16:17:33.215141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 2 with properties:
name: Quadro M6000 24GB major: 5 minor: 2 memoryClockRate(GHz): 1.114
pciBusID: 0000:a1:00.0
totalMemory: 23.90GiB freeMemory: 23.78GiB
2018-04-03 16:17:33.215663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2
2018-04-03 16:17:34.314104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-03 16:17:34.314172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2
2018-04-03 16:17:34.314181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N
2018-04-03 16:17:34.314185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N
2018-04-03 16:17:34.314190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N
2018-04-03 16:17:34.315429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:0 with 22663 MB memory) -> physical GPU (device: 0, name: Quadro M6000 24GB, pci bus id: 0000:03:00.0, compute capability: 5.2)
2018-04-03 16:17:34.802106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:1 with 23083 MB memory) -> physical GPU (device: 1, name: Quadro M6000 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)
2018-04-03 16:17:35.250349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/device:GPU:2 with 23083 MB memory) -> physical GPU (device: 2, name: Quadro M6000 24GB, pci bus id: 0000:a1:00.0, compute capability: 5.2)
2018-04-03 16:17:35.726606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0, 1, 2
2018-04-03 16:17:35.726819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:
2018-04-03 16:17:35.726838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 1 2
2018-04-03 16:17:35.726849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N Y N
2018-04-03 16:17:35.726858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 1:   Y N N
2018-04-03 16:17:35.726867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 2:   N N N
2018-04-03 16:17:35.727458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22663 MB memory) -> physical GPU (device: 0, name: Quadro M6000 24GB, pci bus id: 0000:03:00.0, compute capability: 5.2)
2018-04-03 16:17:35.727626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 23083 MB memory) -> physical GPU (device: 1, name: Quadro M6000 24GB, pci bus id: 0000:04:00.0, compute capability: 5.2)
2018-04-03 16:17:35.727819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 23083 MB memory) -> physical GPU (device: 2, name: Quadro M6000 24GB, pci bus id: 0000:a1:00.0, compute capability: 5.2)
Traceback (most recent call last):
File "mirrored_strategy_test.py", line 86, in 
tf.app.run()
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/platform/app.py", line 126, in run
_sys.exit(main(argv))
File "mirrored_strategy_test.py", line 70, in main
estimator.train(input_fn=input_fn, steps=10)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py", line 363, in train
loss = self._train_model(input_fn, hooks, saving_listeners)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py", line 841, in _train_model
return self._train_model_distributed(input_fn, hooks, saving_listeners)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py", line 884, in _train_model_distributed
self.config)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/distribute.py", line 751, in call_for_each_tower
return self._call_for_each_tower(fn, *args, **kwargs)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 254, in _call_for_each_tower
coord.join(threads)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py", line 389, in join
six.reraise(*self._exc_info_to_raise)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/six.py", line 693, in reraise
raise value
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/coordinator.py", line 297, in stop_on_exception
yield
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 248, in _call_for_each_tower
self, *merge_args, **merge_kwargs)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/optimizer.py", line 667, in _distributed_apply
reduced_grads = distribution.batch_reduce("sum", grads_and_vars)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/python/training/distribute.py", line 796, in batch_reduce
return self._batch_reduce(method_string, value_destination_pairs)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py", line 295, in _batch_reduce
value_destination_pairs)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py", line 175, in batch_reduce
return self._batch_reduce(method_string, value_destination_pairs)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py", line 462, in _batch_reduce
[v[0] for v in value_destination_pairs])
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py", line 517, in _batch_all_reduce
method_string)
File "/usr/local/share/methinks/vtf_nightly_gpu/lib/python3.5/site-packages/tensorflow/contrib/distribute/python/cross_tower_ops.py", line 276, in _ungroup_and_make_mirrored
index[i][destinations[d]] = v
TypeError: 'dict_keys' object does not support indexing