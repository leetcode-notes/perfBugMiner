A good and practical feature is removed

batch_size = tf.placeholder([],dtype=tf.int32) 
lstm_cell = rnn.BasicLSTMCell(num_units=hidden_size, forget_bias=1.0, state_is_tuple=True)
init_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)

ValueError: prefix tensor must be either a scalar or vector, but saw tensor

When training and test, I want to use the different batch size. But in zero_state function, the first parameter doesn't support a tensor as input. To my knowledge, I don't meet the error with the version of tensorflow before 1.2. Now I update tensorflow to 1.2.1. I think that using the different batch size is a practical function.
In stackoverflow, a same problem is post, but it is not solved.
https://stackoverflow.com/questions/44961181/drqn-prefix-tensor-must-be-either-a-scalar-or-vector-but-saw-tensor
How can I solve this problem? Thanks!