iOS returns different results in simple and camera examples using retrained inception model

I have retrained the inception model to recognize custom set of images. I have tried the simple and camera examples and replaced the .pb and .txt files with my own files. I am able to get a reliable result of probability of 0.99 when using the simple example (replaced the grace_hopper with my image). However, I got different results when using the camera example. The config I am using is as follows, is there any config I need to make? Thank you.
const int wanted_input_width = 299;
const int wanted_input_height = 299;
const int wanted_input_channels = 3;
const float input_mean = 128.0f;
const float input_std = 128.0f;
const std::string input_layer_name = "Mul";
const std::string output_layer_name = "final_result";