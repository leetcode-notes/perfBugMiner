Feature request: Ability to specify some GPUs and ignore all others

Right now, to specify a particular GPU, I do something like this:
gpu = 0
available_devices = os.environ['CUDA_VISIBLE_DEVICES'].split(',')
os.environ['CUDA_VISIBLE_DEVICES'] = available_devices[gpu]

after which TensorFlow will only allocate resources on the first GPU device. It would be nice to include a native way to do this.
Side note: There isn't much documentation (any?) on device_count, so I'm not sure if it's meant to handle this. Either way, I have experimented with the device_count, but with no luck: if I use device_count = {'GPU': 1}, TensorFlow still allocates memory on all available GPUs.