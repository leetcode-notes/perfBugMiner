What is the best practice for running training and evaluation on the same machine?

I ask the question at stackoverflow. No answer so far, maybe I can find people have similar needs.
Here is the question:
What I want to do?


I only have 1 machine.


I want to evaluate the mode periodically.


What I have now?


use a placeholder. Say I run 1000 step of training by feeding the training data. then I feed in validation dataset for evaluation. put it in a loop.
But as google suggested, placeholder is not a good way for long run training.


So, I use slim dataset to feed in data. Now, the model is bonded with training dataset like this:

 net = slim.conv2d(inputs, 64, [11, 11], 4, padding='VALID',
                            scope='conv1')




I have to construct another model(in another graph) which is bonded with validation dataset.
Is there a better way of doing that?
I know that google is focusing on distribution training on large scale, but I think as tensorflow  is a low-level and flexible framwork. There must be a way can do what I want.