"Convolution" across two matrices

Are there any plans to implement "convolutions" wherein we have a moving patch over a second matrix that acts as a changing filter?
This would be useful for implementing kernels such as this one:
https://papers.nips.cc/paper/5348-convolutional-kernel-networks.pdf
I asked whether a restricted version of this could be achieved by using already existing tf ops on stack overflow. After thinking about it for a while though I don't think there's a way to do this in an efficient manner
For a simple convolution with no strides I could do something like:
filters = tf.extract_image_patches(filter_matrix, [filter_height, filter_width], [1, 1, 1, 1], [1, 1, 1, 1], padding)
filters = tf.reshape(filters, [out_rows * out_cols, filter_height, filter_width, n_channels])
filters = tf.transpose(filters, [1, 2, 3, 0])
tf.conv2d(image, filters, [1, 1, 1, 1], padding)
but it seems inefficient since I'd be generating an intermediate tensor that is going to be about filter_height * filter_width larger than filter_matrix.
If there is a need for such an op but no plans to implement it in the immediate future, I'm happy to look into adding it.