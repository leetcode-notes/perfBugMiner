Sequence-Wise Batch Normalization for RNN's

Hey TF,
Recently, for deep RNN's, sequence wise batch normalization has proven to be very helpful. Deep Speech 2 in section 3.2 explains this in more detail. Sequence-wise batch normalization is described in section 4.1 in Batch Normalized RNNs.
tf.nn.moments is very useful for batch normalization because it gives you the mean and variance. However, in seq2seq setups, we need to do a batch normalization across all timesteps (the entire sequence). Unfortunately, the way seq2seq.py is written, each timestep is within a separate 2D matrix. This means that there is a list of 2d tensors for the entire sequence.
If somehow, tf.nn.moments could be modified to accept lists of tensors (all of the same dimensions), it would be incredibly helpful. This way, we could input the entire list of tensors, and compute the resulting mean and variance for that sequence.
Thanks!