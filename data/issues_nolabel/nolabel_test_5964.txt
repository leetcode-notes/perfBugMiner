Should slim.learning.train and slim.evaluation.evaluation handle OutOfRange gracefully?

I'm finding it very hard train DNN for specific number of epochs unless I precompute number of batches, which is not convenient in streaming case, since TFRecord files don't have # of examples handy.
Should slim.learning.train and slim.evaluation.evaluation handle OutOfRange gracefully?  If that was the case, I could just set num_epochs on my input and max out num_evals.
Happy to send PR if this seems reasonable.