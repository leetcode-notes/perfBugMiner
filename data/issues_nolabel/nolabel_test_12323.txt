tf.device() is allocating all available GPU memory

System information


Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no


OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.1 LTS


TensorFlow installed from (source or binary): source (git repo)


TensorFlow version (use command below): ('unknown', '1.3.0-rc2')
using commit 3686ef0


Python version: Python 2.7.12 (default, Nov 19 2016, 06:48:10)


Bazel version (if compiling from source):
Build label: 0.5.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Jun 6 10:34:11 2017 (1496745251)
Build timestamp: 1496745251
Build timestamp as int: 1496745251


CUDA/cuDNN version: CUDA 8.0 / cuDNN 5.0.5


GPU model and memory: GTX 1080 Ti / 11172MiB


Exact command to reproduce:


$ python
Python 2.7.12 (default, Nov 19 2016, 06:48:10)
[GCC 5.4.0 20160609] on linux2
Type "help", "copyright", "credits" or "license" for more information.
>>> import tensorflow
>>> a = tensorflow.device('/cpu:0')
2017-08-16 18:14:10.490730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:962] Found device 0 with properties:
name: Graphics Device major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:02:00.0
totalMemory: 10.91GiB freeMemory: 3.02GiB
2017-08-16 18:14:10.490782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1052] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: Graphics Device, pci bus id: 0000:02:00.0, compute capability: 6.1)
>>> a
<contextlib.GeneratorContextManager object at 0x7fdf6f0e8790>
>>>
At this point, tensorflow is allocating all of the available GPU memory. This can be checked using nvidia-smi.
Expected behavior is nothing is done with GPU.
I have used tensorflow 1.2.1, which will allocate nothing on GPU until a tf.Session is created. tf.Session also allows setting config.gpu_options.per_process_gpu_memory_fraction to limit the usage of GPU memory.