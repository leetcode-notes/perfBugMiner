Training a model using GPUs across different machines

Hi, if/how can TensorFlow's distributed runtime be used for training a model using GPU resources across machines in a cluster?