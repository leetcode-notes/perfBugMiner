Encountered a training error when using slim with multi-GPU connect by PIX type

Hi all, I encountered a training error when I training model in multi GPU.
The key condition is using slim to write model and training in multi GPU(GTX TITAN X) which connect by PIX type.
How to reproduce:



checkout office code in here




copy code in below(slim model code) and replace it to cifar10.py file. (Because only slim code can reproduce this issue)




start to training: CUDA_VISIBLE_DEVICES=1,0 python cifar10_multi_gpu_train.py --num_gpus=2




an incorrect loss will appear. (Also GPU usage is incorrect)



Note 1: Check GPU info in below. this issue only happend when I using GPU 0,1 or GPU 2,3 or GPU 4,5 or GPU 6,7(connect by PIX). In this case, everything is ok If I using other combinations
Note 2: I can't reproduce this issue in GTX 1080 ti
Thank you so much!
The training error log in below:
linux@172.25.52.02:~/models/tutorials/image/cifar10: CUDA_VISIBLE_DEVICES=1,0 python cifar10_multi_gpu_train.py --num_gpus=2
Filling queue with 20000 CIFAR images before starting to train. This will take a few minutes.
2017-11-09 18:13:02.264529: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are
available on your machine and could speed up CPU computations.
2017-11-09 18:13:06.359127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:05:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
2017-11-09 18:13:06.784690: W tensorflow/stream_executor/cuda/cuda_driver.cc:523] A non-primary context 0x5f00120 exists before initializing the StreamExecutor
. We haven't verified StreamExecutor works with that.
2017-11-09 18:13:06.786072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 1 with properties:
name: GeForce GTX TITAN X
major: 5 minor: 2 memoryClockRate (GHz) 1.076
pciBusID 0000:04:00.0
Total memory: 11.92GiB
Free memory: 11.81GiB
2017-11-09 18:13:06.786507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 1
2017-11-09 18:13:06.786527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y Y
2017-11-09 18:13:06.786592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 1:   Y Y
2017-11-09 18:13:06.786623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:05:00.0)
2017-11-09 18:13:06.786635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX TITAN X, pci bus id: 0000:04:00.0)
2017-11-09 18:13:06.830077: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:1 for node 'tower_1/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-11-09 18:13:06.830125: I tensorflow/core/common_runtime/simple_placer.cc:697] Ignoring device specification /device:GPU:0 for node 'tower_0/fifo_queue_Dequeue' because the input edge from 'prefetch_queue/fifo_queue' is a reference connection and already has a device field set to /device:CPU:0
2017-11-09 18:13:09.804877: step 0, loss = 2.30 (119.9 examples/sec; 1.067 sec/batch)
2017-11-09 18:13:17.096214: step 10, loss = 2.30 (421.3 examples/sec; 0.304 sec/batch)
2017-11-09 18:13:23.708459: step 20, loss = 2.30 (390.0 examples/sec; 0.328 sec/batch)
2017-11-09 18:13:31.362454: step 30, loss = 2.30 (362.5 examples/sec; 0.353 sec/batch)
2017-11-09 18:13:38.225150: step 40, loss = 2.30 (363.3 examples/sec; 0.352 sec/batch)
2017-11-09 18:13:44.695175: step 50, loss = 2.30 (389.8 examples/sec; 0.328 sec/batch)
2017-11-09 18:13:51.994245: step 60, loss = 2.30 (362.5 examples/sec; 0.353 sec/batch)
2017-11-09 18:13:58.623306: step 70, loss = 2.30 (421.2 examples/sec; 0.304 sec/batch)
2017-11-09 18:14:05.480061: step 80, loss = 2.30 (390.6 examples/sec; 0.328 sec/batch)
2017-11-09 18:14:11.952376: step 90, loss = 2.30 (389.2 examples/sec; 0.329 sec/batch)
2017-11-09 18:14:18.375831: step 100, loss = 293778.34 (362.7 examples/sec; 0.353 sec/batch)
Traceback (most recent call last):
  File "cifar10_multi_gpu_train.py", line 283, in <module>
    tf.app.run()
  File "/home/zhangjiguo/.local/lib/python2.7/site-packages/tensorflow/python/platform/app.py", line 48, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File "cifar10_multi_gpu_train.py", line 278, in main
    train()
  File "cifar10_multi_gpu_train.py", line 251, in train
    assert not np.isnan(loss_value), 'Model diverged with loss = NaN'
AssertionError: Model diverged with loss = NaN

My GPU list with command nvidia-smi -L
GPU 0: GeForce GTX TITAN X (UUID: GPU-2c9601fc-369e-fce7-d139-8c7144700def)
GPU 1: GeForce GTX TITAN X (UUID: GPU-eb4d8327-7058-39fe-e510-3437fe258745)
GPU 2: GeForce GTX TITAN X (UUID: GPU-62fbacf7-0120-5c6b-ceea-ad026fddc537)
GPU 3: GeForce GTX TITAN X (UUID: GPU-15be755d-9982-f4f4-4455-1d648d836b6e)
GPU 4: GeForce GTX TITAN X (UUID: GPU-e48fae89-debd-9769-3851-61ba44acd6e1)
GPU 5: GeForce GTX TITAN X (UUID: GPU-f796ad02-e104-04b5-d6c1-ff72d872654f)
GPU 6: GeForce GTX TITAN X (UUID: GPU-7e27fd1e-ba3b-2dd3-6d03-960b8c76a0be)
GPU 7: GeForce GTX TITAN X (UUID: GPU-8de522e7-f375-ab05-28ff-5ddfd9e325b0)

and GPU connection info with command nvidia-smi topo -m
       	GPU0   	GPU1   	GPU2   	GPU3   	GPU4   	GPU5   	GPU6   	GPU7   	mlx4_0 	CPU Affinity
GPU0   	 X     	PIX    	PHB    	PHB    	SOC    	SOC    	SOC    	SOC    	SOC    	0-13,28-41
GPU1   	PIX    	 X     	PHB    	PHB    	SOC    	SOC    	SOC    	SOC    	SOC    	0-13,28-41
GPU2   	PHB    	PHB    	 X     	PIX    	SOC    	SOC    	SOC    	SOC    	SOC    	0-13,28-41
GPU3   	PHB    	PHB    	PIX    	 X     	SOC    	SOC    	SOC    	SOC    	SOC    	0-13,28-41
GPU4   	SOC    	SOC    	SOC    	SOC    	 X     	PIX    	PHB    	PHB    	PHB    	14-27,42-55
GPU5   	SOC    	SOC    	SOC    	SOC    	PIX    	 X     	PHB    	PHB    	PHB    	14-27,42-55
GPU6   	SOC    	SOC    	SOC    	SOC    	PHB    	PHB    	 X     	PIX    	PHB    	14-27,42-55
GPU7   	SOC    	SOC    	SOC    	SOC    	PHB    	PHB    	PIX    	 X     	PHB    	14-27,42-55
mlx4_0 	SOC    	SOC    	SOC    	SOC    	PHB    	PHB    	PHB    	PHB    	 X

Legend:

  X   = Self
  SOC  = Connection traversing PCIe as well as the SMP link between CPU sockets(e.g. QPI)
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe switches (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing a single PCIe switch
  NV#  = Connection traversing a bonded set of # NVLinks

slim model code: (Please replace these code to cifar10.py)
def inference(images):
	# reimplement by slim
    slim = tf.contrib.slim
    conv1 = slim.conv2d(images, 64, [5, 5], scope='conv1',
                       weights_regularizer=slim.l2_regularizer(0.0),
                       weights_initializer=tf.truncated_normal_initializer(stddev=0.1),
                       activation_fn=tf.nn.relu)
    pool1 = slim.max_pool2d(conv1, [3, 3], 2, padding='SAME', scope='poll1')
    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')
    conv2 = slim.conv2d(norm1, 64, [5, 5], scope='conv2',
                       weights_regularizer=slim.l2_regularizer(0.0),
                       weights_initializer=tf.truncated_normal_initializer(stddev=5e-2),
                       biases_initializer=tf.constant_initializer(0.1),
                       activation_fn=tf.nn.relu)
    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm2')
    pool2 = slim.max_pool2d(norm2, [3, 3], 2, padding='SAME', scope='poll2')
    flatten2 = slim.flatten(pool2)
    local3 = slim.fully_connected(flatten2, 384, scope='local3',
                       weights_regularizer=slim.l2_regularizer(0.004),
                       weights_initializer=tf.truncated_normal_initializer(stddev=0.04),
                       biases_initializer=tf.constant_initializer(0.1),
                       activation_fn=tf.nn.relu)
    local4 = slim.fully_connected(local3, 192, scope='local4',
                       weights_regularizer=slim.l2_regularizer(0.004),
                       weights_initializer=tf.truncated_normal_initializer(stddev=0.04),
                       biases_initializer=tf.constant_initializer(0.1),
                       activation_fn=tf.nn.relu)
    softmax_linear = slim.fully_connected(local4, NUM_CLASSES, scope='softmax_linear',
                       weights_regularizer=slim.l2_regularizer(0.0),
                       weights_initializer=tf.truncated_normal_initializer(stddev=1/192.0),
                       biases_initializer=tf.constant_initializer(0.0),
                       activation_fn=None)
    return softmax_linear

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):CentOS Linux release 7.2.1511
TensorFlow installed from (source or binary):source
TensorFlow version (use command below):Tensorflow 1.2.0/ 1.0.1
Python version: 2.7
Bazel version (if compiling from source): 1.4.5
GCC/Compiler version (if compiling from source):4.8.5
CUDA/cuDNN version:CUDA 8.0 and cuDNN 5.0
GPU model and memory:TITAN X with 12GB
Exact command to reproduce: