does tensorflow take all resource from GPU, making other CUDA code slow ?

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I have a custom CUDA code but not register into Tensorflow OP
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04
TensorFlow installed from (source or binary):
binary: by "pip3 install --upgrade tensorflow-gpu"
TensorFlow version (use command below):
tensorflow-gpu (1.7.0)
Python version:
Python 3.5.2
Bazel version (if compiling from source): 0.11.0
GCC/Compiler version (if compiling from source):
gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609
CUDA/cuDNN version: CUDA 9.0 cuDNN 7
GPU model and memory:
Exact command to reproduce:

Describe the problem
I have a cuda lib build from C++ for post-processing after predict result by tensorflow model.
I use following way to make python able to use cuda code from C++
lib = ctypes.cdll.LoadLibrary(my.so)
If I test the cuda code alone without tensorflow. it work fine.
But when tensorflow is used in my project, my cuda code become 10 times slower....
My  time log is in cuda .so lib, so it's no way that the gap come from python to .so  wrap.
I have try to set the fraction of GPU memory to be allocated in tensorflow by:
# Assume that you have 12GB of GPU memory and want to allocate ~4GB:
gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)
sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))
but useless....
so I wonder does tensorflow take all resource from GPU, making other CUDA code slow ?
the only solution is make my cuda code as a tensorflow OP by register?
Any suggestion? Thanks~~~
----------------------Update----------------------
I have tested following way to set gpu_options, but still useless....
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)