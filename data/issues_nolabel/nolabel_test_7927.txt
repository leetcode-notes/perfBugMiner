tf.nn.rnn_cell.DropoutWrapper() drops out across time-steps

at class DropoutWrapper(RNNCell): it seems dropout is implemented across all inputs and outputs without any implementation options.
Would like to have the option for rnn dropout where one 'dropout mask' is generated and is then applied to each time step. On the next batch, a new mask is generated. This method is described in:
(https://arxiv.org/pdf/1512.05287.pdf)
There a few other dropout methods that have been published recently including one from google.
(https://www.aclweb.org/anthology/C/C16/C16-1165.pdf)
And also 'zoneout' which is mentioned in Issue #2789.
Are there any plans to incorporate these advances?
-Brad