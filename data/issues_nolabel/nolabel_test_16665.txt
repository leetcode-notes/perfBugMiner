Android: No OpKernel was registered to support Op 'Min' with these attrs when using custom TensorFlow library built with SELECTIVE_REGISTRATION

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. See below
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS High Sierra
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): 1.5.0
Python version: 2.7.10
Bazel version (if compiling from source): 0.7.0-homebrew
GCC/Compiler version (if compiling from source): 4.2.1

Describe the problem
When running a custom TensorFlow library built with SELECTIVE_REGISTRATIONand running our quantized model on Android we see this crash log:
 java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Min' with these attrs.  Registered devices: [CPU], Registered kernels:
 <no registered kernels>

 [[Node: mul_2_eightbit/mul_2/y/min = Min[T=DT_FLOAT, Tidx=DT_INT32, keep_dims=false](mul_2_eightbit/mul_2/y/reshape, mul_2_eightbit/mul_2/y/reduction_dims)]]
 at org.tensorflow.Session.run(Native Method)
 at org.tensorflow.Session.access$100(Session.java:48)
 at org.tensorflow.Session$Runner.runHelper(Session.java:298)
 at org.tensorflow.Session$Runner.run(Session.java:248)
 at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:230)
 at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:197)
 at io.cometapp.tensortest.models.yolo.YoloClassifier.predict(YoloClassifier.java:81)
 at io.cometapp.tensortest.ClassifierActivity$4.run(ClassifierActivity.java:713)
 at java.lang.Thread.run(Thread.java:764)
Here is how we build the custom TensorFlow Library
bazel build -c opt --copt="-DSELECTIVE_REGISTRATION" --copt="-DSUPPORT_SELECTIVE_REGISTRATION" --copt="-DTENSORFLOW_DISABLE_META" --copt="-D__ANDROID_TYPES_FULL__" //tensorflow/contrib/android:libtensorflow_inference.so --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --cpu=armeabi-v7a
If we do not use --copt="-DSELECTIVE_REGISTRATION" --copt="-DSUPPORT_SELECTIVE_REGISTRATION", we are able to run the model successfully.
Here is the ops_to_register.h that we use
// This file was autogenerated by print_selective_registration_header.py
#ifndef OPS_TO_REGISTER
#define OPS_TO_REGISTER

    namespace {
      constexpr const char* skip(const char* x) {
        return (*x) ? (*x == ' ' ? skip(x + 1) : x) : x;
      }

      constexpr bool isequal(const char* x, const char* y) {
        return (*skip(x) && *skip(y))
                   ? (*skip(x) == *skip(y) && isequal(skip(x) + 1, skip(y) + 1))
                   : (!*skip(x) && !*skip(y));
      }

      template<int N>
      struct find_in {
        static constexpr bool f(const char* x, const char* const y[N]) {
          return isequal(x, y[0]) || find_in<N - 1>::f(x, y + 1);
        }
      };

      template<>
      struct find_in<0> {
        static constexpr bool f(const char* x, const char* const y[]) {
          return false;
        }
      };
    }  // end namespace
    constexpr const char* kNecessaryOpKernelClasses[] = {
"ConcatV2Op<CPUDevice, float>",
"ConstantOp",
"DequantizeOp<CPUDevice, quint8>",
"IdentityOp",
"ReductionOp<CPUDevice, float, Eigen::internal::MaxReducer<float>>",
"BinaryOp< CPUDevice, functor::maximum<float>>",
"ReductionOp<CPUDevice, float, Eigen::internal::MinReducer<float>>",
"NoOp",
"PadOp<CPUDevice, float>",
"PlaceholderOp",
"QuantizeV2Op<CPUDevice, quint8>",
"QuantizedBiasAddOp<quint8, quint8, qint32>",
"QuantizedConv2DOp<quint8, quint8, qint32, Im2ColConvFunctor>",
"QuantizedMaxPoolingOp<CPUDevice, quint8>",
"QuantizedMulOp<quint8, qint32>",
"BinaryOp< CPUDevice, functor::div<float>>",
"RequantizationRangeOp",
"RequantizeOp<qint32, quint8>",
"ReshapeOp",
"BinaryOp< CPUDevice, functor::sub<float>>",
"RecvOp",
"SendOp",
};
#define SHOULD_REGISTER_OP_KERNEL(clz) (find_in<sizeof(kNecessaryOpKernelClasses) / sizeof(*kNecessaryOpKernelClasses)>::f(clz, kNecessaryOpKernelClasses))

constexpr inline bool ShouldRegisterOp(const char op[]) {
  return false
     || isequal(op, "ConcatV2")
     || isequal(op, "Const")
     || isequal(op, "Dequantize")
     || isequal(op, "Identity")
     || isequal(op, "Max")
     || isequal(op, "Maximum")
     || isequal(op, "Min")
     || isequal(op, "NoOp")
     || isequal(op, "Pad")
     || isequal(op, "Placeholder")
     || isequal(op, "QuantizeV2")
     || isequal(op, "QuantizedBiasAdd")
     || isequal(op, "QuantizedConv2D")
     || isequal(op, "QuantizedMaxPool")
     || isequal(op, "QuantizedMul")
     || isequal(op, "RealDiv")
     || isequal(op, "RequantizationRange")
     || isequal(op, "Requantize")
     || isequal(op, "Reshape")
     || isequal(op, "Sub")
     || isequal(op, "_Recv")
     || isequal(op, "_Send")
  ;
}
#define SHOULD_REGISTER_OP(op) ShouldRegisterOp(op)

#define SHOULD_REGISTER_OP_GRADIENT false
#endif