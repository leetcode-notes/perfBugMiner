Why does one graph affects the cost of the other graph althongh the two graphs do not have any relationship?

I have got a strange problem, the first code is as below:
with tf.device('/gpu:0'):
    local3_value = np.load("local3.npy")
    weights4 = np.load("weights4.npy")
    biases4 = np.load("biases4.npy")
    weights3 = np.load("weights4.npy")
    biases3 = np.load("biases4.npy")
    with tf.variable_scope('local3') as scope:
        local3 = tf.matmul(local3_value, weights3)
    with tf.variable_scope('local4') as scope:
        local4 = tf.nn.relu(tf.matmul(local3_value, weights4)+biases4, name = scope.name)

    with tf.Session(config=tf.ConfigProto(log_device_placement=True))as sess:
        sess.run(local3)
        start_time  = time.time()
        predictions = sess.run(local4)
        duration = time.time() - start_time
    print(duration)
The duration is 0.244572162628
The second code is as below:
with tf.device('/gpu:0'):
    local3_value = np.load("local3.npy")
    weights4 = np.load("weights4.npy")
    biases4 = np.load("biases4.npy")
    weights3 = np.load("weights4.npy")
    biases3 = np.load("biases4.npy")
    with tf.variable_scope('local3') as scope:
        local3 = tf.nn.softplus(weights3)
    with tf.variable_scope('local4') as scope:
        local4 = tf.nn.relu(tf.matmul(local3_value, weights4)+biases4, name = scope.name)


    with tf.Session(config=tf.ConfigProto(log_device_placement=True))as sess:
        sess.run(local3)
        start_time  = time.time()
        predictions = sess.run(local4)
        duration = time.time() - start_time
        print(duration)
The duration is 0.0679910182953
The only difference between these two codes is the local3 layer. Why the graph of local3 affects the cost of graph of loca4? These two graphs do not have any relationship.