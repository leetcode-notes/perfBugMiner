GPU usage is extremely unstable in distributed setup on aws

Environment info
Operating System: Ubuntu 14.04
Installed version of CUDA and cuDNN:  CUDA 7.5, cuDNN 4.0
If installed from binary pip package, provide:
Installed from the following pip package: (0.10.0rc)
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0rc0-cp27-none-linux_x86_64.whl
Steps to reproduce
I'm running distributed tf with GPU on 3 machines (the ps machine doesn't have GPU). The commands to start the cluster:
On ps machine0:
python async.py \
--job_name='ps' \
--task_id=0 \
--ps_hosts='machine0:2222' \
--worker_hosts='machine1:2222,machine2:2222'

On g2.2xlarge machine 1:
python async.py \
--job_name='worker' \
--task_id=0 \
--ps_hosts='machine0:2222' \
--worker_hosts='machine1:2222,machine2:2222'

On g2.2xlarge machine 2:
python async.py \
--job_name='worker' \
--task_id=1 \
--ps_hosts='machine0:2222' \
--worker_hosts='machine1:2222,machine2:2222'

The code:  async.txt
For the first few thousands of iteration, it worked perfectly fine, but the GPU usage drop to almost 0 after that. (actually it fluctuated a lot from 80 -> 50 ->0 ->80)
What have you tried?

I tried to restart the works and it worked for a few rounds then the problem come over again.

Logs or other output that would be helpful
The log after restart. The speed for the first few rounds is ~0.36 sec/batch and the GPU usage is ~90%. But the speed drop down to ~1 sec/batch quickly.
2016-08-25 20:04:08.950429: step 110 (global_step 8318), loss = 0.85 (354.3 examples/sec; 0.361 sec/batch)
2016-08-25 20:04:12.356555: step 120 (global_step 8338), loss = 0.77 (381.3 examples/sec; 0.336 sec/batch)
2016-08-25 20:04:15.832075: step 130 (global_step 8358), loss = 0.93 (369.8 examples/sec; 0.346 sec/batch)
2016-08-25 20:04:19.269496: step 140 (global_step 8377), loss = 0.92 (345.1 examples/sec; 0.371 sec/batch)
2016-08-25 20:04:22.709284: step 150 (global_step 8398), loss = 1.00 (383.3 examples/sec; 0.334 sec/batch)
2016-08-25 20:04:26.071762: step 160 (global_step 8418), loss = 0.75 (464.1 examples/sec; 0.276 sec/batch)
2016-08-25 20:04:29.580850: step 170 (global_step 8438), loss = 0.99 (359.5 examples/sec; 0.356 sec/batch)
2016-08-25 20:04:33.029791: step 180 (global_step 8457), loss = 1.04 (357.4 examples/sec; 0.358 sec/batch)
2016-08-25 20:04:36.491314: step 190 (global_step 8478), loss = 0.93 (358.7 examples/sec; 0.357 sec/batch)
2016-08-25 20:04:39.939553: step 200 (global_step 8498), loss = 1.08 (358.7 examples/sec; 0.357 sec/batch)
2016-08-25 20:04:43.318268: step 210 (global_step 8518), loss = 1.09 (363.6 examples/sec; 0.352 sec/batch)
2016-08-25 20:04:46.716990: step 220 (global_step 8538), loss = 0.98 (411.3 examples/sec; 0.311 sec/batch)
2016-08-25 20:04:50.069852: step 230 (global_step 8557), loss = 0.95 (433.2 examples/sec; 0.295 sec/batch)
2016-08-25 20:04:53.607222: step 240 (global_step 8577), loss = 1.02 (364.5 examples/sec; 0.351 sec/batch)
2016-08-25 20:04:57.162343: step 250 (global_step 8597), loss = 0.96 (357.5 examples/sec; 0.358 sec/batch)
2016-08-25 20:05:00.765804: step 260 (global_step 8617), loss = 1.07 (329.9 examples/sec; 0.388 sec/batch)
2016-08-25 20:05:04.435059: step 270 (global_step 8637), loss = 0.85 (332.6 examples/sec; 0.385 sec/batch)
2016-08-25 20:05:08.196024: step 280 (global_step 8656), loss = 0.89 (306.1 examples/sec; 0.418 sec/batch)
2016-08-25 20:05:12.412322: step 290 (global_step 8676), loss = 1.10 (268.2 examples/sec; 0.477 sec/batch)
2016-08-25 20:05:21.793992: step 300 (global_step 8696), loss = 0.72 (119.5 examples/sec; 1.071 sec/batch)
2016-08-25 20:05:32.548282: step 310 (global_step 8716), loss = 0.80 (119.6 examples/sec; 1.070 sec/batch)
2016-08-25 20:05:43.400207: step 320 (global_step 8736), loss = 1.03 (116.0 examples/sec; 1.104 sec/batch)
2016-08-25 20:05:54.547412: step 330 (global_step 8755), loss = 0.84 (114.6 examples/sec; 1.117 sec/batch)
2016-08-25 20:06:05.457404: step 340 (global_step 8775), loss = 1.09 (119.4 examples/sec; 1.072 sec/batch)
2016-08-25 20:06:16.434271: step 350 (global_step 8795), loss = 0.83 (115.2 examples/sec; 1.111 sec/batch)
2016-08-25 20:06:27.296998: step 360 (global_step 8815), loss = 0.90 (116.7 examples/sec; 1.097 sec/batch)
2016-08-25 20:06:38.130229: step 370 (global_step 8835), loss = 0.99 (119.2 examples/sec; 1.074 sec/batch)
2016-08-25 20:06:48.918992: step 380 (global_step 8855), loss = 1.09 (115.5 examples/sec; 1.108 sec/batch)
2016-08-25 20:07:00.132937: step 390 (global_step 8874), loss = 0.87 (119.0 examples/sec; 1.076 sec/batch)