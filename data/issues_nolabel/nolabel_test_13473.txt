StochasticTensor strange behavior

I've noticed strange behavior of StochasticTensor. Please, look at this peace of code:
inputs = tf.placeholder(shape=(1, 10, ), name="inputs", dtype=tf.float32)

outputs = tf.layers.dense(inputs, units=10, use_bias=False, activation=tf.nn.sigmoid)
outputs = st.StochasticTensor(distributions.Bernoulli(probs=outputs, dtype=tf.int32))
outputs = tf.reshape(outputs, shape=(-1, ))

init_op = tf.group(
    tf.global_variables_initializer(),
    tf.local_variables_initializer()
)

with tf.Session() as sess:
    sess.run(init_op)
    x = np.random.rand(1, 10)
    
    tf.set_random_seed(2017)
    z1 = sess.run(outputs, feed_dict={inputs: x})
    
    tf.set_random_seed(2017)
    z2 = sess.run(outputs, feed_dict={inputs: x})

print(z1)
print(z2)

As the result I get:
[1 0 1 0 0 1 1 1 0 0] [0 1 0 1 0 1 0 1 1 1]
But numpy sampling has another behavior:
    np.random.seed(2017)
    x = np.random.randint(0, 10, size=10)

    np.random.seed(2017)
    y = np.random.randint(0, 10, size=10)

    print(x)
    print(y)

And (again) the result:
[9 6 8 2 3 7 8 0 8 6] [9 6 8 2 3 7 8 0 8 6]
Is it an issue?
P.S.
Tensorflow v1.3.0-rc2-20-g0787eee