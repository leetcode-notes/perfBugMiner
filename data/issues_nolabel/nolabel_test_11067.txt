Feature Request: How to Access Attention Weights of Attention Wrapper

OS: macOS Sierra version 10.12.5
TensorFlow Version: v1.2.0-rc2-21-g12f033d 1.2.0
This is a two-part request related to tensorflow.contrib.seq2seq. I would like the ability to visualize the attention weights of the AttentionWrapper, but I'm hampered by the lack of examples and I'm struggling to infer the input for BahdanauAttention's __call__ method's argument previous_alignments.
First, could someone clarify how to access the attention weights?
Second, would it be possible to add some tool that visualizes the attention weights (possibly to TensorBoard)?