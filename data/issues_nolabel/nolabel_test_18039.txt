Error building contrib/nccl on CentOS 6.5 on 1.7.0-rc1

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 6.5
TensorFlow installed from (source or binary): Source
TensorFlow version (use command below): 1.7.0-rc1 release
Python version: 3.6.4
Bazel version (if compiling from source): 0.11.1- (non-git)
GCC/Compiler version (if compiling from source): gcc (GCC) 4.8.2 20140120 (Red Hat 4.8.2-15)
CUDA/cuDNN version: CUDA: 7.5 cuDNN: 6.0
GPU model and memory: NVIDIA Tesla K20m
Exact command to reproduce: bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --action_env="LD_LIBRARY_PATH=${LD_LIBRARY_PATH}"

Describe the problem
Tensorflow fails to build from source release 1.7.0-rc1 with error from nccl_ops.cc
I took the following steps:
source /opt/rh/devtoolset-2/enable
cd /tmp
wget https://github.com/tensorflow/tensorflow/archive/v1.7.0-rc1.tar.gz
tar -xvf v1.7.0-rc1.tar.gz
cd /tensorflow-1.7.0.-rc1
export TEST_TMPDIR=/tmp/tf-build
export JAVA_HOME=/usr/java/jdk1.8.0_66/
./configure

Found possible Python library paths:
  /home/mack0242/.pyenv/versions/3.6.4/lib/python3.6/site-packages
Please input the desired Python library path to use.  Default is [/home/mack0242/.pyenv/versions/3.6.4/lib/python3.6/site-packages]

Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: n
No jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n
No Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n
No Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Apache Kafka Platform support? [y/N]: n
No Apache Kafka Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: n
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: n
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 7.5

Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 

Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 6.0

Please specify the location where cuDNN 6 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:

Do you wish to build TensorFlow with TensorRT support? [y/N]: n
No TensorRT support will be enabled for TensorFlow.

Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]3.5

Do you want to use clang as CUDA compiler? [y/N]: n
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /opt/rh/devtoolset-2/root/usr/bin/gcc]: 

Do you wish to build TensorFlow with MPI support? [y/N]: n
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]: 

Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding "--config=<>" to your build command. See tools/bazel.rc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
Configuration finished

export LD_LIBRARY_PATH=/opt/rh/devtoolset-2/root/usr/lib64:/opt/rh/devtoolset-2/root/usr/lib:/opt/rh/devtoolset-2/root/usr/lib64:/opt/rh/devtoolset-2/root/usr/lib:/usr/local/cuda/lib64
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package   --action_env="LD_LIBRARY_PATH=${LD_LIBRARY_PATH}"

Source code / logs
Build fails at this point:
INFO: From Compiling tensorflow/contrib/nccl/kernels/nccl_ops.cc:
tensorflow/contrib/nccl/kernels/nccl_ops.cc(207): error: no instance of overloaded function "tensorflow::TensorShapeUtils::MakeShape" matches the argument list
            argument types are: (Eigen::TensorMap<Eigen::Tensor<const tensorflow::int32, 1, 1, long>, 16, Eigen::MakePointer>, tensorflow::TensorShape *)

1 error detected in the compilation of "/tmp/tmpxft_00001aab_00000000-7_nccl_ops.cpp1.ii".
ERROR: /tmp/tensorflow-1.7.0-rc1/tensorflow/contrib/nccl/BUILD:23:1: output 'tensorflow/contrib/nccl/_objs/python/ops/_nccl_ops_gpu/tensorflow/contrib/nccl/kernels/nccl_ops.pic.o' was not created
ERROR: /tmp/tensorflow-1.7.0-rc1/tensorflow/contrib/nccl/BUILD:23:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 362.889s, Critical Path: 67.25s
FAILED: Build did NOT complete successfully

So it looks like a parameter type problem here: nccl_ops.cc