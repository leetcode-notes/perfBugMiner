Distributed tensorflow hang when turning from Async to Sync

I follow Distributed tensorflow to port our RNN to multi-GPU cards. I start 4 processes and each process run on a different GPU card.
After solving the issue, I could run it on my 4 GPU cards server in Asynchronized mode.
Then I change my code to Synchronized mode by adding only the following code:
optimizer = tf.train.SyncReplicasOptimizer(
optimizer,
replicas_to_aggregate = 4,
replica_id = FLAGS.task_index,
total_num_replicas = 4
#variable_averages = exp_moving_averager,    # Remove this for simple.
#variables_to_average = variables_to_average # Remove this for simple.
)
Then the job will hang in session.run(...)
Is there any other thing needed to change when switch from Async mode to Sync mode?
Thanks a lot in advance!