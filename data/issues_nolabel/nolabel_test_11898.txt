Update the graph used in quantization tutorial

Another fix to quantization tutorial after #11285
Currently, following the steps in the quantization tutorial will lead to weird results as pointed out in #11181. This is because the graph file and the evaluation script are unmatched.
From this image recognition tutorial, there are two pretrained graphs with two evaluation scripts.

classify_image_graph_def.pb in inception-2015-12-05.tgz is to be used with the (older) classify_image.py.
inception_v3_2016_08_28_frozen.pb in inception_v3_2016_08_28_frozen.pb.tar.gz is to be used with label_image.

The weird results came from using classify_image_graph_def.pb with label_image. The graphs are different (see also models#1314), especially in the last layer. The two scripts extract information from the last layer in different ways, so it works with its corresponding graph but not the other.
Further changes?

In the image recognition tutorial (source), the usage of Python API points to option 1 (above) but the C++ API points to option 2. This might cause confusion as the two graphs/scripts are not equivalent. Now that there's a python implementation of the newer label_image by @freedomtan, should we update the tutorial to use this python implementation instead?
Should this graph transform README be updated as well? Currently it uses the 2015 pre-trained graph, hence --inputs='Mul' --outputs='softmax'. If it is updated to the 2016 graph, these should instead say --inputs=input --outputs=InceptionV3/Predictions/Reshape_1.