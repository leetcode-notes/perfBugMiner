tf.while_loop giving unexpected result when used with tf.assign() during run time

NOTE: Issues that are not bugs or feature requests will be closed. Please ask usage questions on StackOverflow.
You must complete this information or else your issue will be closed

Have I written custom code (as opposed to using a stock example script provided in TensorFlow)?: Yes
TensorFlow installed from (source or binary)?: binary
TensorFlow version: 1.0.0
Bazel version (if compiling from source): NA
CUDA/cuDNN version:  NA
GPU Model and Memory: NA
Exact command to reproduce:

Describe the problem clearly
tf.while_loop with is not working as expected when used with tf.assign()
In the below example code, the reset_x operation seems to be preventing the variable 'x' from updating as per per logic in loop1. if I print the output after loop1 has been run, I can see that x is still zero. However I I confirmed that the loop is working by printing output of loop1. It seems resent_x op is being used inside the tf.while_loop() during run time instead of only resetting x back to 0 after loop has finished. If I were to remove reset_x then the variable x is getting updated by the loop.
body = lamda x: tf.assign_add(x,1)
loop1 = tf.while_loop(cond,body, [x])
x_op = tf.reduce_sum(tf.abs(x))
reset_x = tf.assign(x,[0])
with tf.Session() as sess:
......
......
for in range (100):
sess.run(loop1)
print(sess.run(x))
sess.run(x_op)
sess.run(reset_x)
Source Code / Logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full-traceback. Large logs and files should be attached. Try to reproducible test-case code the bare-minimum necessary to generate the problem