embedding variable in ptb_word_lm.py

In ptb_word_lm.py I see that for word2vec vectors we are doing:
embedding = tf.get_variable(
"embedding", [vocab_size, size], dtype=data_type())
inputs = tf.nn.embedding_lookup(embedding, input_.input_data)
but where is the variable embedding created? Is it random or is it pretrained?