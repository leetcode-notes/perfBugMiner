[AUC] result of tf.metrics.auc doesnot match with sklearn's

My tensorflow version is ('v1.3.0-rc1-4263-gc81acfb', '1.4.0-rc1'), and the system is Rehat with gcc version 4.8.5 20150623 (Red Hat 4.8.5-16). I run the program use CPU only.
I wrote a NN  use tensorflow for binary classification. I create the an auc_op in the following way:
net = input_layer(features,) # get dense input layer from features
for layer_id in xrange(1, num_layer):
    net  = tf.add(tf.matmul(net, self._weights[layer_id]), self._bias[layer_id])
    if layer_id < num_layer - 1: # output layer without activation function to get `wx + b`
        net =tf.nn.relu(net)
logits = net
labels = tf.expand_dims(tf.cast(tf.convert_to_tensor(labels), dtype = tf.float32), axis = -1)
auc_op = tf.metrics.auc(labels = labels, predictions = tf.sigmoid(logits), num_thresholds = 102400)
I run the auc_op like this:
for step in xrange(1, self._max_steps + 1):
    auc = self._sess.run(auc_op)
I also keep all the logits and labels in each step and concatenate them, then call sklearn like this:
from sklearn.metrics import roc_auc_score
roc_auc_score(labels, sigmoid(logits))
Are there anything wrong in the way I use tf.metrics.auc? When I run the auc_op, it returns a tuple with two values and I don't which one is the correct auc. But both of them are not equal with sklearn's.
I once wrote an program to calculate auc and it was exactly the same with sklearn's even in 1M data, thus I tend to think sklearn's result is the ground truth.