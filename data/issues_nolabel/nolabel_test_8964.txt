Is there a bug in tf.layers.batch_normalization?

Since TF 1.0 API came out, I have been trying to use tf.layers.batch_normalization instead of the version in tf.contrib.layers. However, I found this layer works abnormally in my case.
Here is my simple code that uses tf.layers.batch_normalization.
output = tf.nn.bias_add(tf.matmul(input_tensor, self._weight), self._bias)

  if self._use_batch_norm:
       output = tf.layers.batch_normalization(
             output,
             momentum=0.9,
             training=training,
             name=self._name + "_bn",
             reuse=reuse
        )

 output = tf.nn.relu(output)

However, when I enabled the batch_normalization on this layer. I found that my model maps all raw data to a single point in the hidden representation space. When I disabled batch_normalization, this cannot happen at all.
Here is a final view of my data in the latent space:
array([[ 0.46338093,  0.53661913],
[ 0.46339276,  0.53660733],
[ 0.46329296,  0.53670704],
...,
[ 0.4633435 ,  0.53665644],
[ 0.46335611,  0.53664398],
[ 0.4633027 ,  0.53669727]], dtype=float32)
The input data are generated from a multivariate gaussian distribution so that their hidden representations should be different as well. I searched the usage of this function on stackoverflow but the example is so trivial and it doesn't help. I think there may be a bug in this layer object or I may misuse it somehow.
In the contrib.layers's version, the batch_norm layer should be linked with update_ops collection. But I read the source code of this implementation and it seems that it is not necessary. Is there anyone has some thoughts on this?