No clear documentation about how optimizer works through tf.tile()

If some one uses this type of code for batch learning,
w1=tf.get_variable("W1", [300,300], dtype=tf.float32, initializer=init) W1=tf.tile(tf.expand_dims(w1,axis=0), [batch_size,1,1], name="batch_W1") x1=tf.placeholder(name="context",dtype=tf.float32,shape=[None,None,300]) ; y=tf.matmul(x1,W1)
how the optimizer will combine the gradients from W1 [batch_size,300,300] to w1[300,300]?
I asked this question in stackoverflow also but none replied.
https://stackoverflow.com/questions/48933564/is-this-the-appropriate-way-to-set-up-weights-in-batch-learning-in-tensorflow