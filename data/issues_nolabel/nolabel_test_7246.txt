Pool Allocator Problem

I was running LSTM having 2 layers and 64 nodes in each layer running in batch mode with small data size. I am unable to figure out the problem. I am getting warning like
tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1323 get requests, put_count=2336 evicted_count=1000 eviction_rate=0.428082 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 6326 get requests, put_count=5369 evicted_count=2000 eviction_rate=0.372509 and unsatisfied allocation rate=0.470123
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 193 to 212
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1415 get requests, put_count=2440 evicted_count=1000 eviction_rate=0.409836 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1590 get requests, put_count=3623 evicted_count=2000 eviction_rate=0.552029 and unsatisfied allocation rate=0
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1137 get requests, put_count=2186 evicted_count=1000 eviction_rate=0.457457 and unsatisfied allocation rate=0
Because of which code runs very slow.
Machine 1
Configuration as follows:
Environment Information (we've tried several different permutations):
OS: CentOS 7.2
CUDA: 8.0.44 and 7.5.17
CUDNN: 5.1 and 5.0
Tensorflow: 0.11.0rc0, 0.11.0, 0.12.1, 1.0.0rc0
Nvidia drivers: 352.39, 367.48
GPU:Tesla k80
servers with 2 K80 cards each (2 GPUs per card, for a total of 4 GPUs per machine).
If I run the same code on different machine the code runs fine without any warning:
Machine 2
OS:Ubuntu 16.04.1 LTS
CUDA: 8.0
CUDNN: 5.0
Tensorflow:0.12.1
Nvidia drivers: 367.48
GPU:GeForce GTX TITAN.