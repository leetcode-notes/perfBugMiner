BUG: Arithmetic computations that should be identical are not?

System information
System information
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.13.4
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): v1.8.0-0-g93bc2e2072 1.8.0
Python version: 3.5.4
Bazel version (if compiling from source): 0.11.1
GCC/Compiler version (if compiling from source): 9.1.0
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A
Describe the problem
I'm running two versions of a NN which I expect to produce identical results, but they don't.
The first version contains as part of the computation:
x = [0.0*a + 1.0*b, 1.0*a + 0.0*b]
The second contains instead:
x = [b, a]
The two runs produce different results. (a and b are both matrices).
I'm using a constant seed for the random noise input, and I've verified that multiple runs of either of the two above cases produce identical results. Just changing from one case to the other produces different results. The results are not broken in either case (i.e. both cases produce reasonable output), just different.
This seems like a bug to me.
Thanks
EDIT:
I've also found that doing:
x = 1.0 * a
x = 1.0 * (1.0 * a)
x = tf.identity(a)
All give different results.
Looking at this: #14675
Apparently the problem is I've made a change to the computation graph.
I still think this is a bug so I'm going to leave this here. It's very frustrating when obvious things don't work as expected.