how to restore the certain variable_scope Variables into another certain variable_scope?

Now I have trained a model A and I need two model A instances because one of them just is fixed and untrainable for outputting and another is trainable for next network. I design two variable_scope A_train and A_untrain, I pre-trained A model in variable_scope A_untrain and restore the model also in this scope, code like:
saver_untrain = tf.train.Saver(tf.get_collection(
                                   tf.GraphKeys.GLOBAL_VARIABLES,
                                   'A_untrain'))
saver_path = '~/models/model.ckpt'
# here pre-train model A
saver_untrain.save(sess, saver_path)
Now I need to restore the same model A parameters into the same model in scope A_train, but I cannot follow the previous code because the ckpt files restore the params like A_untrain/input_w1 instread of A_train/input_w1. I want to know if there is a solution to my problem OR a better solution to make two instances which one is trainable and another is untrainable. Thanks a lot.
EDIT_1: I know I can realize my need use code like:
saver_train = tf.train.Saver({'A_untrain/input_w1': A_train.input_w1})
but it will be unpractical when my variables amount is large, so I need to use the variable_scope to restore instead of the specific variables' names.