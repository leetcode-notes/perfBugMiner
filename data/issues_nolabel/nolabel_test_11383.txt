Feeding TensorArray when running a session using feed_dict

Currently there is no way to define a placeholder for a tf.TensorArray. A solution is to zero-pad a tf.Tensor and then unstack and slice it into a tf.TensorArray. However, this adds unpadding overhead which would have to be done for every batch.
A possible change would be to add a new placeholder type for feeding a tf.TensorArray to the graph, for example called tf.tensor_array_placeholder.
This could work as follows:
# Define an input TensorArray with three elements
ta_input = tf.tensor_array_placeholder(dtype=tf.float32, size=3)
# Take the second element from the TensorArray
ta_second = ta.read(1)
# Sum its values
result = tf.reduce_sum(ta_second)

with tf.Session() as sess:
    run_result = sess.run(
        [result],
        # Feed raw values into ta_input. These could also be NumPy arrays
        { ta_input: [[1, 2, 3], [4, 5], [6, 7, 8, 9]] })

   print(run_result)  # Should print 9