Using different optimizers on a trained model leads to poor test accuracy.

I have trained a convolutional neural network model using AdamOptimizer. The test accuracy is pretty good. This was expected since the validation loss was decreasing while training.
Now I restored the model weights using saver.restore() method, but this time I built the model with RMSPropOptimizer just for experimenting. Please note that I DID NOT RETRAIN THE MODEL. To my surprise, the test accuracy was horrible with the new optimizer. The accuracy becomes good again when I use the previously used AdamOptimizer.
This is peculiar in the sense that the train_op should not affect the test data results.
Below is the sample code I used for calculating the test accuracy. Please note I did not run the train_op here.
accuracies = []

# Data generator
for batchx, batchy in dataLoader.next_validation():
    # Run the graph.
    pred = sess.run(model['prediction'], 
                        feed_dict={
                            model['sensor_data']: batchx,
                            model['label']: batchy
                        })
        
    accuracies.append(np.count_nonzero(pred == label) / pred.shape[0] * 100)

accuracies = np.array(accuracies)
print("Average Validation set accuracy: {} %".format(accuracies.mean()))

Am I missing something here? Or is this a possible bug?