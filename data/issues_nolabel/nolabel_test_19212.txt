Add `AppendFloat16ArrayToTensorProto` to acclerate `tf.constant` for float16

Related with #19180.
It seems that cython doesn't support np.float16_t by now, we use np.uint16 instead.
The conversion still be time-consuming (25 times slower than float32), however it is better than original slow implementation (260 times slower than float32).
Performance comparison:
before:
float32: 0.0535 sec
float16: 13.7567 sec

after:
float32: 0.0496 sec
float16: 1.0815 sec

script:
import time
images = np.random.rand(128, 100, 100, 3)
imagesFloat16 = images.astype(np.float16)
imagesFloat32 = images.astype(np.float32)

start = time.time()
constant_op.constant(imagesFloat32)
end = time.time()
print("float32: {0:.4f} sec".format(end - start))

start = time.time()
constant_op.constant(imagesFloat16)
end = time.time()
print("float16: {0:.4f} sec".format(end - start))