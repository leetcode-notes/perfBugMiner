failed to allocate tensors on mobile device

System information
I minimize the model to very simple model with one input, convolution layer and pool is the output.
I work on Ubuntu 16.04
I compile TensorFlow Lite from source with Bazel
TensorFlow version is 1.8
Python 3.6
Bazel version 0.10.0
GCC/Compiler version - gcc (Ubuntu 5.4.0-6ubuntu1~16.04.6) 5.4.0 20160609
Working on CPU
Describe the problem
I am trying to run my Tensorflow model on samsung galaxy s9,
I trained model with TensorFlow freeze it and convert it to .tflite model file with toco.
I am running CPP program on the phone according to documentation and load the .tflite model file:
std::unique_ptr<tflite::FlatBufferModel> model(tflite::FlatBufferModel::BuildFromFile(modelFile));
if (!model) {
    printf("Failed to mmap model %s\n", g_modelFile);
}
model->error_reporter();
tflite::ops::builtin::BuiltinOpResolver resolver;
std::unique_ptr<tflite::Interpreter> interpreter;
tflite::InterpreterBuilder(*model, resolver)(&interpreter);
if (!interpreter) {
    printf("Failed to construct interpreter\n");
}
interpreter->UseNNAPI(false);
if (interpreter->AllocateTensors() != kTfLiteOk) {
    printf("Failed to allocate tensors!\n");
}

I succeed to initialize the model but failed to run interpreter->AllocateTensors()
There is no print of why it failed to allocate the tensors, just my print that the function failed
if (interpreter->AllocateTensors() != kTfLiteOk) {
    printf("Failed to allocate tensors!\n");
}

I minimized my model to include only reshape, convolution layer and pool and still failed to run AllocateTensors
Output with debug information:
resolved reporter
tensors size: 8
nodes size: 3
inputs: 1
input(0) name: patches
input(1) name: (null)
Reshape, 237552, 1, 0.000000, 0
Reshape/shape, 16, 2, 0.000000, 0
conv1/Relu, 1861632, 1, 0.000000, 0
conv1/convolution_bias, 128, 1, 0.000000, 0
conv1/kernel, 3456, 1, 0.000000, 0
input/patches-input, 237552, 1, 0.000000, 0
output, 465408, 1, 0.000000, 0
patches, 4, 1, 0.000000, 0
Failed to allocate tensors!