transform_graph quantize_weights doesn't compile on windows

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

I'm executing a command from documentation, and I don't think that my custom model is part of the issue.

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Windows Server 2012 R2 64-bit

TensorFlow installed from (source or binary):

Latest master (7/7/2017) compiled with bazel and msvc

TensorFlow version (use command below):

commit 1e03785 (July 6 21:55:34 2017 -0400)

Python version:

3.5.3 Anaconda 64-bit

Bazel version (if compiling from source):

0.5.1

CUDA/cuDNN version:

CPU Only

GPU model and memory:

CPU Only (CPU is dual socket Xeon E5-2687W v2)

Exact command to reproduce:

$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)
fold_batch_norms
fold_old_batch_norms
quantize_weights'

Describe the problem
I originally asked this question on StackOverflow and I was recommended to file a bug report:
https://stackoverflow.com/questions/44955491/tensorflow-transform-graph-doesnt-have-quantize-weights
The transform_graph program in tensorflow does not include the quantize_weights transform. If I execute the command above without the quantize_weights transform it works correctly.
Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
$ bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=/c/Users/name/git-repos/project/input/file.pb --out_graph=/c/Users/name/git-repos/project/input/file_q.pb --inputs='image_tensor' --outputs='detection_boxes,detection_scores,detection_classes' --transforms='fold_constants(ignore_error=true)
fold_batch_norms
fold_old_batch_norms
quantize_weights'

2017-07-06 13:21:10.361492: I C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:263] Applying fold_constants
2017-07-06 13:21:10.476001: W C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-07-06 13:21:13.241688: I C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:263] Applying fold_batch_norms
2017-07-06 13:21:16.088969: I C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:263] Applying fold_old_batch_norms
2017-07-06 13:21:16.650913: E C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:209] Transform 'quantize_weights' not recognized.
2017-07-06 13:21:16.650934: E C:\tools\msys64\tmp\_bazel_name\avtc4yfu\execroot\tensorflow\tensorflow\tools\graph_transforms\transform_graph.cc:210] usage: C:\Users\name\git-repos\tensorflow\bazel-bin\tensorflow\tools\graph_transforms\transform_graph.exe
Flags:
        --in_graph=""                           string  input graph file name
        --out_graph=""                          string  output graph file name
        --inputs=""                             string  inputs
        --outputs=""                            string  outputs
        --transforms=""                         string  list of transforms
        --output_as_text=false                  bool    whether to write the graph in text protobuf format

Transforms are:
add_default_attributes
backport_concatv2
backport_tensor_array_v3
fold_batch_norms
fold_constants
fold_old_batch_norms
freeze_requantization_ranges
fuse_pad_and_conv
fuse_resize_and_conv
fuse_resize_pad_and_conv
insert_logging
obfuscate_names
remove_attribute
remove_device
remove_nodes
rename_attribute
rename_op
set_device
sort_by_execution_order
sparsify_gather
strip_unused_nodes