compile tensorflow r1.8 occured error

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 17.10
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): r1.8
Python version:  python 3.6
Bazel version (if compiling from source): 0.11.1
GCC/Compiler version (if compiling from source): GCC-6，G++-6
CUDA/cuDNN version: CUDA 9.1（include patch1/2/3），cuDNN 7.1
GPU model and memory: gtx 1060ti，6GB； gtx 1080ti，11GB
Exact command to reproduce:
bazel build --config=opt --config=cuda --cxxopt="-D_GLIBCXX_USE_CXX11_ABI=0" //tensorflow/tools/pip_package:build_pip_package

Describe the problem
lately，I had try install tensorflow r1.8 from source but unsuccessful，then I tryed to compile tf r1.6 it is normal, and my friend also try to install tensorflow r1.8 from source was successful, which difference enviroment between us are CUDA/cuDNN and gcc/g++, he use CUDA 8.0/cuDNN 5.0 and gcc-5/g++5.
compile tf r1.8 occured error log as below：
/usr/include/c++/6/tuple:484:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_MoveConstructibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
     }
 ^
/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]':
/usr/include/c++/6/tuple:626:362:   required by substitution of 'template<class ... _UElements, typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(_UElements&& ...) [with _UElements = {std::tuple<int, int, int>}; typename std::enable_if<(((std::_TC<(sizeof... (_UElements) == 1), int, int, int>::_NotSameTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>()) && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && (3ul >= 1)), bool>::type <anonymous> = <missing>]'
./tensorflow/stream_executor/dnn.h:891:91:   required from here
/usr/include/c++/6/tuple:489:65: error: mismatched argument pack lengths while expanding 'std::is_convertible<_UElements&&, _Elements>'
       return __and_<is_convertible<_UElements&&, _Elements>...>::value;
                                                                 ^~~~~
/usr/include/c++/6/tuple:490:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_ImplicitlyMoveConvertibleTuple() [with _UElements = {std::tuple<int, int, int>}; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
     }
 ^
/usr/include/c++/6/tuple: In instantiation of 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]':
/usr/include/c++/6/tuple:686:422:   required by substitution of 'template<class ... _UElements, class _Dummy, typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> > constexpr std::tuple< <template-parameter-1-1> >::tuple(std::tuple<_Args1 ...>&&) [with _UElements = {int, int, int}; _Dummy = void; typename std::enable_if<((std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_MoveConstructibleTuple<_UElements ...>() && std::_TC<(1ul == sizeof... (_UElements)), int, int, int>::_ImplicitlyMoveConvertibleTuple<_UElements ...>()) && std::_TC<(std::is_same<_Dummy, void>::value && (1ul == 1)), int, int, int>::_NonNestedTuple<tuple<_Elements ...>&&>()), bool>::type <anonymous> = <missing>]'
./tensorflow/stream_executor/dnn.h:891:91:   required from here
/usr/include/c++/6/tuple:495:244: error: wrong number of template arguments (4, should be 2)
       return  __and_<__not_<is_same<tuple<_Elements...>,
                                                                                                                                                                                                                                                    ^    
/usr/include/c++/6/type_traits:1558:8: note: provided for 'template<class _From, class _To> struct std::is_convertible'
     struct is_convertible
        ^~~~~~~~~~~~~~
/usr/include/c++/6/tuple:502:1: error: body of constexpr function 'static constexpr bool std::_TC<<anonymous>, _Elements>::_NonNestedTuple() [with _SrcTuple = std::tuple<int, int, int>&&; bool <anonymous> = true; _Elements = {int, int, int}]' not a return-statement
     }
 ^
ERROR: /home/andy/TF/tensorflow/tensorflow/contrib/nccl/BUILD:23:1: output 'tensorflow/contrib/nccl/_objs/python/ops/_nccl_ops_gpu/tensorflow/contrib/nccl/kernels/nccl_ops.pic.o' was not created
ERROR: /home/andy/TF/tensorflow/tensorflow/contrib/nccl/BUILD:23:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 1037.698s, Critical Path: 28.30s
FAILED: Build did NOT complete successfully

my configure of r1.7 and r1.8 is below:
(python3) andy@andy:~/TF/tensorflow$ ./configure 
WARNING: Running Bazel server needs to be killed, because the startup options are different.
You have bazel 0.11.1 installed.
Please specify the location of python. [Default is /home/andy/python3/bin/python]: 


Traceback (most recent call last):
  File "<string>", line 1, in <module>
AttributeError: module 'site' has no attribute 'getsitepackages'
Found possible Python library paths:
  /home/andy/python3/lib/python3.6/site-packages
Please input the desired Python library path to use.  Default is [/home/andy/python3/lib/python3.6/site-packages]

Do you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: 
jemalloc as malloc support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n
No Google Cloud Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Hadoop File System support? [Y/n]: n
No Hadoop File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: n
No Amazon S3 File System support will be enabled for TensorFlow.

Do you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: n
No Apache Kafka Platform support will be enabled for TensorFlow.

Do you wish to build TensorFlow with XLA JIT support? [y/N]: 
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with GDR support? [y/N]: 
No GDR support will be enabled for TensorFlow.

Do you wish to build TensorFlow with VERBS support? [y/N]: 
No VERBS support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 9.0]: 9.1


Please specify the location where CUDA 9.1 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: 7


Please specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:


Do you wish to build TensorFlow with TensorRT support? [y/N]: 
No TensorRT support will be enabled for TensorFlow.

Please specify the NCCL version you want to use. [Leave empty to default to NCCL 1.3]: 


Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size. [Default is: 6.1]


Do you want to use clang as CUDA compiler? [y/N]: 
nvcc will be used as CUDA compiler.

Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/x86_64-linux-gnu-gcc-6]: 


Do you wish to build TensorFlow with MPI support? [y/N]: 
No MPI support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding "--config=<>" to your build command. See tools/bazel.rc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
Configuration finished