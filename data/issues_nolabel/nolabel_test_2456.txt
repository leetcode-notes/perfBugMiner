Problem in distributed parameter server

Environment info
Running the distributed tensorflow on GCE kubernetes cluster using the demo with the default images.
Steps to reproduce

Run the demo with hidden_units = 100
Run the demo with  hidden_units = 500

What have you tried?

Restart all the pods (this worked)

Logs or other output that would be helpful
Traceback (most recent call last):
  File "/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py", line 250, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py", line 203, in main
    with sv.prepare_or_wait_for_session(FLAGS.worker_grpc_url, config=sess_config) as sess:
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py", line 685, in prepare_or_wait_for_session
    config=config, init_feed_dict=self._init_feed_dict)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py", line 163, in prepare_session
    sess.run(init_op, feed_dict=init_feed_dict)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 340, in run
    run_metadata_ptr)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 564, in _run
    feed_dict_string, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 637, in _do_run
    target_list, options, run_metadata)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py", line 659, in _do_call
    e.code)
tensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [100,10] rhs shape= [500,10]
     [[Node: layer2/weights/Variable/Assign = Assign[T=DT_FLOAT, _class=["loc:@layer2/weights/Variable"], use_locking=true, validate_shape=true, _device="/job:ps/replica:0/task:1/cpu:0"](layer2/weights/Variable, layer2/weights/truncated_normal_S19)]]
Caused by op u'layer2/weights/Variable/Assign', defined at:
  File "/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py", line 250, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 30, in run
    sys.exit(main(sys.argv))
  File "/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py", line 157, in main
    y = nn_layer(hidden1, FLAGS.hidden_units, 10, 'layer2', act=tf.nn.softmax)
  File "/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py", line 115, in nn_layer
    weights = weight_variable([input_dim, output_dim])
  File "/home/zeyu/gocode/src/github.com/caicloud/BigData/distributed-tensorflow/runner/demo/mnist_replica.py", line 85, in weight_variable
    return tf.Variable(initial)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py", line 209, in __init__
    dtype=dtype)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py", line 308, in _init_from_args
    validate_shape=validate_shape).op
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py", line 40, in assign
    use_locking=use_locking, name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py", line 655, in apply_op
    op_def=op_def)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 2154, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1154, in __init__
    self._traceback = _extract_stack()

The error happened at the init time, and it seems that the log suggests the parameter server didn't clean up the information from previous job:
tensorflow.python.framework.errors.InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [100,10] rhs shape= [500,10]