sigmoid_cross_entropy Docstring bug

Describe the problem
Tf.losses.sigmoid_cross_entory parameter description of label indicates it has to be "integer" and in range (0,1). There are no integers between (0,1) so that seems really difficult to abide by.
It seems that in the code it does not need to be integer and the range should be [0, 1].
https://www.tensorflow.org/api_docs/python/tf/losses/sigmoid_cross_entropy
P.S. Why does softmax_cross_entropy assume one-hot encoding? For instance in distillation your labels are softmax outputs (floats in [0, 1]).