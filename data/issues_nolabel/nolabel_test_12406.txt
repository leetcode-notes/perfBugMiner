compilation error

On Ubuntu 16.04 with gcc5
./configure
You have bazel 0.5.3 installed.
Please specify the location of python. [Default is /usr/bin/python]:
Found possible Python library paths:
/usr/local/lib/python2.7/dist-packages
/usr/lib/python2.7/dist-packages
Please input the desired Python library path to use. Default is [/usr/local/lib/python2.7/dist-packages]
Using python library path: /usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with MKL support? [y/N]
No MKL support will be enabled for TensorFlow
Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -march=native]:
Do you wish to use jemalloc as the malloc implementation? [Y/n]
jemalloc enabled
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N]
No Hadoop File System support will be enabled for TensorFlow
Do you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N]
No XLA support will be enabled for TensorFlow
Do you wish to build TensorFlow with VERBS support? [y/N]
No VERBS support will be enabled for TensorFlow
Do you wish to build TensorFlow with OpenCL support? [y/N]
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Do you want to use clang as CUDA compiler? [y/N]
nvcc will be used as CUDA compiler
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 8
Please specify the location where CUDA 8 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Invalid path to CUDA 8 toolkit. /usr/local/cuda/lib64/libcudart.so.8 cannot be found
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 8
Please specify the location where CUDA 8 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Invalid path to CUDA 8 toolkit. /usr/local/cuda/lib64/libcudart.so.8 cannot be found
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:
Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 6.0]: 7.0.1
Please specify the location where cuDNN 7.0.1 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /usr/lib/x86_64-linux-gnu/
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: "6.1"]:
Do you wish to build TensorFlow with MPI support? [y/N]
MPI support will not be enabled for TensorFlow
Configuration finished
BUILD:39:1: C++ compilation of rule '//tensorflow/stream_executor:cuda_platform' failed (Exit 1)
tensorflow/stream_executor/cuda/cuda_dnn.cc: In instantiation of 'cudnnStatus_t perftools::gputools::cuda::wrap::WrapperShim__cudnnSetRNNDescriptor::operator()(perftools::gputools::cuda::CUDAExecutor*, Args ...) [with Args = {cudnnRNNStruct*, int, int, cudnnDropoutStruct*, cudnnRNNInputMode_t, cudnnDirectionMode_t, cudnnRNNMode_t, cudnnDataType_t}]':
tensorflow/stream_executor/cuda/cuda_dnn.cc:1021:50: required from here
tensorflow/stream_executor/cuda/cuda_dnn.cc:140:38: error: cannot convert 'cudnnRNNStruct*' to 'cudnnHandle_t {aka cudnnContext*}' for argument '1' to 'cudnnStatus_t cudnnSetRNNDescriptor(cudnnHandle_t, cudnnRNNDescriptor_t, int, int, cudnnDropoutDescriptor_t, cudnnRNNInputMode_t, cudnnDirectionMode_t, cudnnRNNMode_t, cudnnRNNAlgo_t, cudnnDataType_t)'
cudnnStatus_t retval = ::__name(args...);
^
tensorflow/stream_executor/cuda/cuda_dnn.cc:234:3: note: in expansion of macro 'PERFTOOLS_GPUTOOLS_CUDNN_WRAP'
__macro(cudnnSetRNNDescriptor)