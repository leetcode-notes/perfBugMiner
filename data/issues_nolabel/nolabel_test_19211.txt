TensorRT engine requires consistent batch size

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, custom SSD model
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): nvidia gpu cloud docker container 18.04 for V100
from source for 1080 Ti
TensorFlow version (use command below): 1.7.0
Python version: 2.7
Bazel version (if compiling from source): 0.11.1
GCC/Compiler version (if compiling from source): 5.4.0
CUDA/cuDNN version: 9 / 7
GPU model and memory: V100 (16GB) 1080Ti (11GB)
Exact command to reproduce: N/A

Source code / logs
Run TF-TRT with custom SSD and got the following message:
F tensorflow/contrib/tensorrt/shape_fn/trt_shfn.cc:52] TensorRT engine requires consistent batch size
After commenting out the line 52 in trt_shfn.cc and recompile with bazel, the model ran properly and output expected results. Suspect that this dimension check has a bug and does not cover all the cases.
Use the code example from here and modify to load custom SSD model.