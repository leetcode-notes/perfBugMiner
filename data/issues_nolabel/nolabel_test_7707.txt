estimator with batch size and data feeding

Could you provide an example of using the high-level API Estimators with placeholders and feeding batches  like for a basic use:
for step in xrange(max_steps):
batch_of_inputs,batch_of_targets= get_batch_from_disk(step) # e.g. batches are stored as list where step is and index of the list
feed_dict = {x:batch_of_inputs,y:batch_of_targets}
_, loss_value = sess.run([train_op, loss],
feed_dict=feed_dict)
How to do the same with Estimator API?
Estimator takes batch_size, steps, input_fuc or feed_fun as an argument and but it is not clear for me how to implement a function which will load data of batch size  e.g. in every iteration from disk?