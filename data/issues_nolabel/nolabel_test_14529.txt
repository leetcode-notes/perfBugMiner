[feature request]time out option for tf.Data.from_generator

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10/7
TensorFlow installed from (source or binary):
pip installed tensorflow-gpu binary
TensorFlow version (use command below):
1.40
Python version:
3.5/3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version:
CUDA8/cuDNN6.0
GPU model and memory:
gtx980m(8g)/Quadro 4000M(8g)
Exact command to reproduce:
from_generator

Describe the problem
Unnecessary background:
I previously using a customized python function to load (one epoch of) images from disc, perform pre-processing and data augmentation and return as generator, and feed into corresponding placeholder via feed_dict. This function worked out fine for 100,000+ steps.
I recently refactored my codes using tf.Data and put the exact same function into the tf.Data.from_generator function. However, the pipeline would stuck indefinitely every 200 epochs (3,000 steps) or so, just before it should break out from "except tf.errors.OutOfRangeError:"; also it's not throwing any exception which could be cached by "except Exception as e". However, by manually pressing "enter", the program would continue to run while dumping out a full screen of getNext() error messages from previous runs. Unfortunately I can not supply any customized pre-processing functions and data to help you debug this "bug", and I am not sure it's reproduce-able with a reduced example, since the occurrence seems rather arbitrary.
Feature wish:
I am hoping for a time out feature for the general tf.Data class to break out from bad loops.
I suppose any customized solution would involve using standalone thread which could interfere with tf threadpool, therefore this feature must be supported in the tf scope.