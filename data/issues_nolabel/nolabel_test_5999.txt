distributed seq2seq used SyncReplicasOptimizerV2 question

Now I want to change seq2seq to distributed mode used SyncReplicasOptimizerV2. I've been trying for a few daysï¼Œbut still can't work out. this is my code,one file is seq2seq_train.py,on file is seq2seq_model.py
I try to run in 1 ps and 2 worker
the error is:
Traceback (most recent call last):
File "/home/test/replicas_seq2seq_v4/seq2seq_train.py", line 188, in 
tf.app.run()
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 43, in run
sys.exit(main(sys.argv[:1] + flags_passthrough))
File "/home/test/replicas_seq2seq_v4/seq2seq_train.py", line 82, in main
task_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)
File "/home/test/replicas_seq2seq_v4/seq2seq_model.py", line 221, in init
self.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py", line 720, in prepare_or_wait_for_session
init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py", line 251, in prepare_session
self._local_init_op, msg))
RuntimeError: Init operations did not make model ready.  Init op: init, init fn: None, local_init_op: name: "sync_replicas_3/group_deps"
op: "NoOp"
input: "^sync_replicas_3/group_deps/NoOp"
input: "^sync_replicas_3/group_deps/NoOp_1"
input: "^sync_replicas_3/group_deps/NoOp_2"
device: "/job:worker/task:0"
, error: Variables not initialized: sync_rep_local_step, sync_rep_local_step_1, sync_rep_local_step_2
ps:
python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=ps --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000
worker1:
python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --
worker2:
python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=1 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --
seq2seq_train.py
from future import absolute_import
from future import division
from future import print_function
import tempfile
import math
import os
import random
import sys
import time
import json
import numpy as np
from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf
from tensorflow.models.rnn.translate import data_utils
#from tensorflow.models.rnn.translate import seq2seq_model
import seq2seq_model
Flags for defining the tf.train.ClusterSpec
tf.app.flags.DEFINE_string("ps_hosts", "",
"Comma-separated list of hostname:port pairs")
tf.app.flags.DEFINE_string("worker_hosts", "",
"Comma-separated list of hostname:port pairs")
Flags for defining the tf.train.Server
tf.app.flags.DEFINE_string("job_name", "", "One of 'ps', 'worker'")
tf.app.flags.DEFINE_integer("task_index", 0, "Index of task within the job")
tf.app.flags.DEFINE_float("learning_rate", 0.5, "Learning rate.")
tf.app.flags.DEFINE_float("learning_rate_decay_factor", 0.99,
"Learning rate decays by this much.")
tf.app.flags.DEFINE_float("max_gradient_norm", 5.0,
"Clip gradients to this norm.")
tf.app.flags.DEFINE_integer("batch_size", 64,
"Batch size to use during training.")
tf.app.flags.DEFINE_integer("size", 1024, "Size of each model layer.")
tf.app.flags.DEFINE_integer("num_layers", 3, "Number of layers in the model.")
tf.app.flags.DEFINE_integer("en_vocab_size", 40000, "English vocabulary size.")
tf.app.flags.DEFINE_integer("fr_vocab_size", 40000, "French vocabulary size.")
tf.app.flags.DEFINE_string("data_dir", "/tmp/data", "Data directory")
tf.app.flags.DEFINE_string("train_dir", "/tmp", "Training directory.")
tf.app.flags.DEFINE_integer("max_train_data_size", 0,
"Limit on the size of training data (0: no limit).")
tf.app.flags.DEFINE_integer("steps_per_checkpoint", 200,
"How many training steps to do per checkpoint.")
tf.app.flags.DEFINE_boolean("decode", False,
"Set to True for interactive decoding.")
tf.app.flags.DEFINE_boolean("self_test", False,
"Run a self-test if this is set to True.")
FLAGS = tf.app.flags.FLAGS
_buckets = [(5, 10), (10, 15), (20, 25), (40, 50)]
def main(_):
if FLAGS.job_name is None or FLAGS.job_name == "":
raise ValueError("Must specify an explicit job_name")
if FLAGS.task_index is None or FLAGS.task_index =="":
raise ValueError("Must specify an explicit task_index")
ps_hosts = FLAGS.ps_hosts.split(",")
worker_hosts = FLAGS.worker_hosts.split(",")
Create a cluster from the parameter server and worker hosts.
cluster = tf.train.ClusterSpec({"ps": ps_hosts, "worker": worker_hosts})
Create and start a server for the local task.
server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)
num_workers = len(worker_hosts)
server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)
if FLAGS.job_name == "ps":
server.join()
return
is_chief = (FLAGS.task_index == 0)
model = seq2seq_model.Seq2SeqModel(server, FLAGS.en_vocab_size, FLAGS.fr_vocab_size, _buckets,
FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,
FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,num_workers = num_workers,
task_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)
step_time, loss = 0.0, 0.0
current_step = 0
previous_losses = []
print("query -> title:")
en_train = FLAGS.data_dir + "/giga-fren.release2.ids40000.en"
fr_train = FLAGS.data_dir + "/giga-fren.release2.ids40000.fr"
en_dev = FLAGS.data_dir + "/newstest2013.ids40000.en"
fr_dev = FLAGS.data_dir + "/newstest2013.ids40000.fr"
Read data into buckets and compute their sizes.
print ("Reading development and training data (limit: %d)." % FLAGS.max_train_data_size)
dev_set = read_data(en_dev, fr_dev)
train_set = read_train_data(en_train, fr_train, num_workers, FLAGS.max_train_data_size)
train_bucket_sizes = [len(train_set[b]) for b in xrange(len(_buckets))]
train_total_size = float(sum(train_bucket_sizes))
train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size for i in xrange(len(train_bucket_sizes))]
print("finish to load data")
sess = model.session
while True:
random_number_01 = np.random.random_sample()
bucket_id = min([i for i in xrange(len(train_buckets_scale)) if train_buckets_scale[i] > random_number_01])
# Get a batch and make a step.
start_time = time.time()
encoder_inputs, decoder_inputs, target_weights = model.get_batch(train_set, bucket_id)
_, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, False)
step_time += (time.time() - start_time) / FLAGS.steps_per_checkpoint
step_time_now = (time.time() - start_time)
loss += step_loss / FLAGS.steps_per_checkpoint
step_loss_now = step_loss
current_step += 1
print("step: %d" % current_step);

if (True):
  perplexity = math.exp(step_loss) if step_loss < 300 else float('inf')
  print ("global step %d learning rate %.4f step-time %.2f perplexity "
         "%.2f" % (model.global_step.eval(sess), model.learning_rate.eval(sess), step_time_now, perplexity))
  previous_losses.append(step_loss)

  checkpoint_path = os.path.join(train_dir, "translate.ckpt")
  model.saver.save(sess, checkpoint_path, global_step=model.global_step)
  if (current_step %  FLAGS.steps_per_checkpoint == 0):
    for bucket_id in xrange(len(_buckets)):
      if len(dev_set[bucket_id]) == 0:
        print("  eval: empty bucket %d" % (bucket_id))
        continue
      encoder_inputs, decoder_inputs, target_weights = model.get_batch(dev_set, bucket_id)
      _, eval_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, True)
      eval_ppx = math.exp(eval_loss) if eval_loss < 300 else float('inf')
      print("  eval: bucket %d perplexity %.2f" % (bucket_id, eval_ppx))
    step_time, loss = 0.0, 0.0
  sys.stdout.flush()

def read_train_data(source_path, target_path, num_workers, max_size=None):
data_set = [[] for _ in _buckets]
with tf.gfile.GFile(source_path, mode="r") as source_file:
with tf.gfile.GFile(target_path, mode="r") as target_file:
source, target = source_file.readline(), target_file.readline()
counter = 0
while source and target and (not max_size or counter < max_size):
counter += 1
if counter % 1000000 == 0:
print("  reading data line %d" % counter)
sys.stdout.flush()
source_ids = [int(x) for x in source.split()]
target_ids = [int(x) for x in target.split()]
target_ids.append(data_utils.EOS_ID)
# if (counter % num_workers == 0):
if (True):
for bucket_id, (source_size, target_size) in enumerate(_buckets):
if len(source_ids) < source_size and len(target_ids) < target_size:
data_set[bucket_id].append([source_ids, target_ids])
break
source, target = source_file.readline(), target_file.readline()
return data_set
def read_data(source_path, target_path, max_size=None):
data_set = [[] for _ in _buckets]
with tf.gfile.GFile(source_path, mode="r") as source_file:
with tf.gfile.GFile(target_path, mode="r") as target_file:
source, target = source_file.readline(), target_file.readline()
counter = 0
while source and target and (not max_size or counter < max_size):
counter += 1
if counter % 100000 == 0:
print("  reading data line %d" % counter)
sys.stdout.flush()
source_ids = [int(x) for x in source.split()]
target_ids = [int(x) for x in target.split()]
target_ids.append(data_utils.EOS_ID)
for bucket_id, (source_size, target_size) in enumerate(_buckets):
if len(source_ids) < source_size and len(target_ids) < target_size:
data_set[bucket_id].append([source_ids, target_ids])
break
source, target = source_file.readline(), target_file.readline()
return data_set
if name == "main":
tf.app.run()
seq2seq_model.py
Copyright 2015 The TensorFlow Authors. All Rights Reserved.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

"""Sequence-to-sequence model with an attention mechanism."""
from future import absolute_import
from future import division
from future import print_function
import random
import numpy as np
from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf
from tensorflow.models.rnn.translate import data_utils
class Seq2SeqModel(object):
def init(self,
server,
source_vocab_size,
target_vocab_size,
buckets,
size,
num_layers,
max_gradient_norm,
batch_size,
learning_rate,
learning_rate_decay_factor,
num_workers=2,
task_index=0,
replicas_to_aggregate=2,
use_lstm=False,
num_samples=512,
forward_only=False,
dtype=tf.float32):
self.graph = tf.Graph()
self.server = server
self.source_vocab_size = source_vocab_size
self.target_vocab_size = target_vocab_size
self.buckets = buckets
self.batch_size = batch_size
self.num_workers = num_workers 
self.task_index = task_index
self.is_chief = (task_index == 0)
self.num_workers = num_workers
self.replicas_to_aggregate = replicas_to_aggregate

with self.graph.as_default():
  with tf.device("/job:ps/task:0"): 
    self.global_step = tf.Variable(0, trainable=False)
    self.learning_rate = tf.Variable(
        float(learning_rate), trainable=False, dtype=dtype)

  output_projection = None
  softmax_loss_function = None
  # Sampled softmax only makes sense if we sample less than vocabulary size.
  if num_samples > 0 and num_samples < self.target_vocab_size:
    with tf.device("/job:ps/task:0"): 
      w_t = tf.get_variable("proj_w", [self.target_vocab_size, size], dtype=dtype)
      w = tf.transpose(w_t)
      b = tf.get_variable("proj_b", [self.target_vocab_size], dtype=dtype)
    output_projection = (w, b)

    def sampled_loss(inputs, labels):
      with tf.device("/job:worker/task:"+str(self.task_index)):
        labels = tf.reshape(labels, [-1, 1])
        # We need to compute the sampled_softmax_loss using 32bit floats to
        # avoid numerical instabilities.
        local_w_t = tf.cast(w_t, tf.float32)
        local_b = tf.cast(b, tf.float32)
        local_inputs = tf.cast(inputs, tf.float32)
        return tf.cast(
            tf.nn.sampled_softmax_loss(local_w_t, local_b, local_inputs, labels,
                                       num_samples, self.target_vocab_size),
            dtype)
    softmax_loss_function = sampled_loss

  # Create the internal multi-layer cell for our RNN.
  with tf.device("/job:worker/task:"+str(self.task_index)):
    single_cell = tf.nn.rnn_cell.GRUCell(size)
    if use_lstm:
      single_cell = tf.nn.rnn_cell.BasicLSTMCell(size)
    cell = single_cell
    if num_layers > 1:
      cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)

  # The seq2seq function: we use embedding for the input and attention.
  def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):
    with tf.device("/job:worker/task:"+str(self.task_index)):
      return tf.nn.seq2seq.embedding_attention_seq2seq(
          encoder_inputs,
          decoder_inputs,
          cell,
          num_encoder_symbols=source_vocab_size,
          num_decoder_symbols=target_vocab_size,
          embedding_size=size,
          output_projection=output_projection,
          feed_previous=do_decode,
          dtype=dtype)

  # Feeds for inputs.
  with tf.device("/job:worker/task:"+str(self.task_index)):
    self.encoder_inputs = []
    self.decoder_inputs = []
    self.target_weights = []
    for i in xrange(buckets[-1][0]):  # Last bucket is the biggest one.
      self.encoder_inputs.append(tf.placeholder(tf.int32, shape=[None],
                                                name="encoder{0}".format(i)))
    for i in xrange(buckets[-1][1] + 1):
      self.decoder_inputs.append(tf.placeholder(tf.int32, shape=[None],
                                                name="decoder{0}".format(i)))
      self.target_weights.append(tf.placeholder(dtype, shape=[None],
                                                name="weight{0}".format(i)))

    # Our targets are decoder inputs shifted by one.
    targets = [self.decoder_inputs[i + 1]
               for i in xrange(len(self.decoder_inputs) - 1)]
    if forward_only:
      self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(
          self.encoder_inputs, self.decoder_inputs, targets,
          self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),
          softmax_loss_function=softmax_loss_function)
      # If we use output projection, we need to project outputs for decoding.
      if output_projection is not None:
        for b in xrange(len(buckets)):
          self.outputs[b] = [
              tf.matmul(output, output_projection[0]) + output_projection[1]
              for output in self.outputs[b]
          ]
    else:
      self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(
          self.encoder_inputs, self.decoder_inputs, targets,
          self.target_weights, buckets,
          lambda x, y: seq2seq_f(x, y, False),
          softmax_loss_function=softmax_loss_function)

    # Gradients and SGD update operation for training the model.
  with tf.device("/job:worker/task:"+str(self.task_index)):
    params = tf.trainable_variables()
    self.gradient_norms = []
    self.updates = []
  #sync_rep_opt = tf.train.AdamOptimizer(self.learning_rate)
    sgd_opt = tf.train.GradientDescentOptimizer(2.0)
    sync_rep_opt = tf.train.SyncReplicasOptimizerV2(
        sgd_opt, replicas_to_aggregate=replicas_to_aggregate,
        total_num_replicas=num_workers)
    for b in xrange(len(buckets)):
      gradients = tf.gradients(self.losses[b], params)
      clipped_gradients, norm = tf.clip_by_global_norm(gradients,
                                                       max_gradient_norm)
      self.gradient_norms.append(norm)
      self.updates.append(sync_rep_opt.apply_gradients(
          zip(clipped_gradients, params), global_step=self.global_step))

    init_op = tf.global_variables_initializer()
    local_init_op = sync_rep_opt.local_step_init_op
    if self.is_chief:
      local_init_op = sync_rep_opt.chief_init_op
    ready_for_local_init_op = sync_rep_opt.ready_for_local_init_op

    # Chief_queue_runner
    chief_queue_runner = sync_rep_opt.get_chief_queue_runner()
    sync_init_op = sync_rep_opt.get_init_tokens_op(num_workers)

# Creates session for chief.
supervisor = tf.train.Supervisor(
    graph=self.graph,
    is_chief=self.is_chief,
    recovery_wait_secs=1,
    init_op=init_op,
    local_init_op=local_init_op,
    ready_for_local_init_op=ready_for_local_init_op)

sess_config = tf.ConfigProto(
    allow_soft_placement=True,
    log_device_placement=True,
    device_filters=["/job:ps", "/job:worker/task:%d" % self.task_index])


self.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)

# Chief should execute the sync_init_op and start the chief queue runner.
if self.is_chief:
  self.session.run(sync_init_op)
  supervisor.StartQueueRunners(self.session, [chief_queue_runner])

if self.is_chief:
  self.session.run(sync_init_op)
  supervisor.StartQueueRunners(self.session, [chief_queue_runner])

def step(self, session, encoder_inputs, decoder_inputs, target_weights,
bucket_id, forward_only):
"""Run a step of the model feeding the given inputs.
Args:
  session: tensorflow session to use.
  encoder_inputs: list of numpy int vectors to feed as encoder inputs.
  decoder_inputs: list of numpy int vectors to feed as decoder inputs.
  target_weights: list of numpy float vectors to feed as target weights.
  bucket_id: which bucket of the model to use.
  forward_only: whether to do the backward step or only forward.

Returns:
  A triple consisting of gradient norm (or None if we did not do backward),
  average perplexity, and the outputs.

Raises:
  ValueError: if length of encoder_inputs, decoder_inputs, or
    target_weights disagrees with bucket size for the specified bucket_id.
"""
# Check if the sizes match.
encoder_size, decoder_size = self.buckets[bucket_id]
if len(encoder_inputs) != encoder_size:
  raise ValueError("Encoder length must be equal to the one in bucket,"
                   " %d != %d." % (len(encoder_inputs), encoder_size))
if len(decoder_inputs) != decoder_size:
  raise ValueError("Decoder length must be equal to the one in bucket,"
                   " %d != %d." % (len(decoder_inputs), decoder_size))
if len(target_weights) != decoder_size:
  raise ValueError("Weights length must be equal to the one in bucket,"
                   " %d != %d." % (len(target_weights), decoder_size))

# Input feed: encoder inputs, decoder inputs, target_weights, as provided.
input_feed = {}
for l in xrange(encoder_size):
  input_feed[self.encoder_inputs[l].name] = encoder_inputs[l]
for l in xrange(decoder_size):
  input_feed[self.decoder_inputs[l].name] = decoder_inputs[l]
  input_feed[self.target_weights[l].name] = target_weights[l]

# Since our targets are decoder inputs shifted by one, we need one more.
last_target = self.decoder_inputs[decoder_size].name
input_feed[last_target] = np.zeros([self.batch_size], dtype=np.int32)

# Output feed: depends on whether we do a backward step or not.
if not forward_only:
  output_feed = [self.updates[bucket_id],  # Update Op that does SGD.
                 self.gradient_norms[bucket_id],  # Gradient norm.
                 self.losses[bucket_id]]  # Loss for this batch.
else:
  output_feed = [self.losses[bucket_id]]  # Loss for this batch.
  for l in xrange(decoder_size):  # Output logits.
    output_feed.append(self.outputs[bucket_id][l])

outputs = session.run(output_feed, input_feed)
if not forward_only:
  return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.
else:
  return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.

def get_batch(self, data, bucket_id):
"""Get a random batch of data from the specified bucket, prepare for step.
To feed data in step(..) it must be a list of batch-major vectors, while
data here contains single length-major cases. So the main logic of this
function is to re-index data cases to be in the proper format for feeding.

Args:
  data: a tuple of size len(self.buckets) in which each element contains
    lists of pairs of input and output data that we use to create a batch.
  bucket_id: integer, which bucket to get the batch for.

Returns:
  The triple (encoder_inputs, decoder_inputs, target_weights) for
  the constructed batch that has the proper format to call step(...) later.
"""
encoder_size, decoder_size = self.buckets[bucket_id]
encoder_inputs, decoder_inputs = [], []

# Get a random batch of encoder and decoder inputs from data,
# pad them if needed, reverse encoder inputs and add GO to decoder.
for _ in xrange(self.batch_size):
  encoder_input, decoder_input = random.choice(data[bucket_id])

  # Encoder inputs are padded and then reversed.
  encoder_pad = [data_utils.PAD_ID] * (encoder_size - len(encoder_input))
  encoder_inputs.append(list(reversed(encoder_input + encoder_pad)))

  # Decoder inputs get an extra "GO" symbol, and are padded then.
  decoder_pad_size = decoder_size - len(decoder_input) - 1
  decoder_inputs.append([data_utils.GO_ID] + decoder_input +
                        [data_utils.PAD_ID] * decoder_pad_size)

# Now we create batch-major vectors from the data selected above.
batch_encoder_inputs, batch_decoder_inputs, batch_weights = [], [], []

# Batch encoder inputs are just re-indexed encoder_inputs.
for length_idx in xrange(encoder_size):
  batch_encoder_inputs.append(
      np.array([encoder_inputs[batch_idx][length_idx]
                for batch_idx in xrange(self.batch_size)], dtype=np.int32))

# Batch decoder inputs are re-indexed decoder_inputs, we create weights.
for length_idx in xrange(decoder_size):
  batch_decoder_inputs.append(
      np.array([decoder_inputs[batch_idx][length_idx]
                for batch_idx in xrange(self.batch_size)], dtype=np.int32))

  # Create target_weights to be 0 for targets that are padding.
  batch_weight = np.ones(self.batch_size, dtype=np.float32)
  for batch_idx in xrange(self.batch_size):
    # We set weight to 0 if the corresponding target is a PAD symbol.
    # The corresponding target is decoder_input shifted by 1 forward.
    if length_idx < decoder_size - 1:
      target = decoder_inputs[batch_idx][length_idx + 1]
    if length_idx == decoder_size - 1 or target == data_utils.PAD_ID:
      batch_weight[batch_idx] = 0.0
  batch_weights.append(batch_weight)
return batch_encoder_inputs, batch_decoder_inputs, batch_weights