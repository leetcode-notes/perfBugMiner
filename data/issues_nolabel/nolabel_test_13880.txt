RMSProp fails with InteractiveSession() and embed_sequence on GPU

Note:
This works fine if any of the following

without GPU
if use "normal" Session() instead of the interactive one.
if don't do embed_sequence
user other optimiser, not RMSProp

This is the snippet to get the error:
import tensorflow as tf
from tensorflow.contrib import layers, framework
import numpy as np

sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True))
input = tf.placeholder(tf.int64, shape=[None])
optimiser = tf.train.RMSPropOptimizer(0.1)
x = layers.embed_sequence(input, vocab_size=20, embed_dim=5)
loss = tf.reduce_sum(x)
train_op = optimiser.minimize(loss)
sess.run(tf.global_variables_initializer())
sess.run(train_op, feed_dict={input: np.random.randint(10, size=5)})

Gives
2017-10-21 15:12:38.503957: E tensorflow/core/framework/op_segment.cc:53] Create kernel failed: Invalid argument: AttrValue must not have reference type value of float_ref
   for attr 'tensor_type'
  ; NodeDef: EmbedSequence/embeddings/RMSProp_1/_19 = _Recv[_start_time=0, client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_36_EmbedSequence/embeddings/RMSProp_1", tensor_type=DT_FLOAT_REF, _device="/job:localhost/replica:0/task:0/cpu:0"](^RMSProp/learning_rate, ^RMSProp/decay, ^RMSProp/momentum, ^RMSProp/epsilon, ^RMSProp/update_EmbedSequence/embeddings/UnsortedSegmentSum, ^RMSProp/update_EmbedSequence/embeddings/Unique); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
2017-10-21 15:12:38.504081: E tensorflow/core/common_runtime/executor.cc:644] Executor failed to create kernel. Invalid argument: AttrValue must not have reference type value of float_ref
   for attr 'tensor_type'
  ; NodeDef: EmbedSequence/embeddings/RMSProp_1/_19 = _Recv[_start_time=0, client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_36_EmbedSequence/embeddings/RMSProp_1", tensor_type=DT_FLOAT_REF, _device="/job:localhost/replica:0/task:0/cpu:0"](^RMSProp/learning_rate, ^RMSProp/decay, ^RMSProp/momentum, ^RMSProp/epsilon, ^RMSProp/update_EmbedSequence/embeddings/UnsortedSegmentSum, ^RMSProp/update_EmbedSequence/embeddings/Unique); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
   [[Node: EmbedSequence/embeddings/RMSProp_1/_19 = _Recv[_start_time=0, client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_36_EmbedSequence/embeddings/RMSProp_1", tensor_type=DT_FLOAT_REF, _device="/job:localhost/replica:0/task:0/cpu:0"](^RMSProp/learning_rate, ^RMSProp/decay, ^RMSProp/momentum, ^RMSProp/epsilon, ^RMSProp/update_EmbedSequence/embeddings/UnsortedSegmentSum, ^RMSProp/update_EmbedSequence/embeddings/Unique)]]
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1327, in _do_call
    return fn(*args)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1306, in _run_fn
    status, run_metadata)
  File "/usr/lib/python3.5/contextlib.py", line 66, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: AttrValue must not have reference type value of float_ref
   for attr 'tensor_type'
  ; NodeDef: EmbedSequence/embeddings/RMSProp_1/_19 = _Recv[_start_time=0, client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_36_EmbedSequence/embeddings/RMSProp_1", tensor_type=DT_FLOAT_REF, _device="/job:localhost/replica:0/task:0/cpu:0"](^RMSProp/learning_rate, ^RMSProp/decay, ^RMSProp/momentum, ^RMSProp/epsilon, ^RMSProp/update_EmbedSequence/embeddings/UnsortedSegmentSum, ^RMSProp/update_EmbedSequence/embeddings/Unique); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
   [[Node: EmbedSequence/embeddings/RMSProp_1/_19 = _Recv[_start_time=0, client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_36_EmbedSequence/embeddings/RMSProp_1", tensor_type=DT_FLOAT_REF, _device="/job:localhost/replica:0/task:0/cpu:0"](^RMSProp/learning_rate, ^RMSProp/decay, ^RMSProp/momentum, ^RMSProp/epsilon, ^RMSProp/update_EmbedSequence/embeddings/UnsortedSegmentSum, ^RMSProp/update_EmbedSequence/embeddings/Unique)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rmsprop_fail.py", line 19, in <module>
    sess.run(train_op, feed_dict={input: np.random.randint(10, size=5)})
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 895, in run
    run_metadata_ptr)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1321, in _do_run
    options, run_metadata)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: AttrValue must not have reference type value of float_ref
   for attr 'tensor_type'
  ; NodeDef: EmbedSequence/embeddings/RMSProp_1/_19 = _Recv[_start_time=0, client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_36_EmbedSequence/embeddings/RMSProp_1", tensor_type=DT_FLOAT_REF, _device="/job:localhost/replica:0/task:0/cpu:0"](^RMSProp/learning_rate, ^RMSProp/decay, ^RMSProp/momentum, ^RMSProp/epsilon, ^RMSProp/update_EmbedSequence/embeddings/UnsortedSegmentSum, ^RMSProp/update_EmbedSequence/embeddings/Unique); Op<name=_Recv; signature= -> tensor:tensor_type; attr=tensor_type:type; attr=tensor_name:string; attr=send_device:string; attr=send_device_incarnation:int; attr=recv_device:string; attr=client_terminated:bool,default=false; is_stateful=true>
   [[Node: EmbedSequence/embeddings/RMSProp_1/_19 = _Recv[_start_time=0, client_terminated=false, recv_device="/job:localhost/replica:0/task:0/cpu:0", send_device="/job:localhost/replica:0/task:0/gpu:0", send_device_incarnation=1, tensor_name="edge_36_EmbedSequence/embeddings/RMSProp_1", tensor_type=DT_FLOAT_REF, _device="/job:localhost/replica:0/task:0/cpu:0"](^RMSProp/learning_rate, ^RMSProp/decay, ^RMSProp/momentum, ^RMSProp/epsilon, ^RMSProp/update_EmbedSequence/embeddings/UnsortedSegmentSum, ^RMSProp/update_EmbedSequence/embeddings/Unique)]]

If remove the allow_soft_placement then get:
Traceback (most recent call last):
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1327, in _do_call
    return fn(*args)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1306, in _run_fn
    status, run_metadata)
  File "/usr/lib/python3.5/contextlib.py", line 66, in __exit__
    next(self.gen)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py", line 466, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'gradients/EmbedSequence/embedding_lookup_grad/ToInt32': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'
Colocation Debug Info:
Colocation group had the following types and devices:
SparseApplyRMSProp: CPU
UnsortedSegmentSum: GPU CPU
Gather: GPU CPU
StridedSlice: GPU CPU
Unique: GPU CPU
Shape: GPU CPU
Cast: GPU CPU
Identity: GPU CPU
VariableV2: GPU CPU
Const: GPU CPU
	 [[Node: gradients/EmbedSequence/embedding_lookup_grad/ToInt32 = Cast[DstT=DT_INT32, SrcT=DT_INT64, _class=["loc:@EmbedSequence/embeddings"]](gradients/EmbedSequence/embedding_lookup_grad/Shape)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "rmsprop_fail.py", line 19, in <module>
    sess.run(train_op, feed_dict={input: np.random.randint(10, size=5)})
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 895, in run
    run_metadata_ptr)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1124, in _run
    feed_dict_tensor, options, run_metadata)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1321, in _do_run
    options, run_metadata)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py", line 1340, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device for operation 'gradients/EmbedSequence/embedding_lookup_grad/ToInt32': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'
Colocation Debug Info:
Colocation group had the following types and devices:
SparseApplyRMSProp: CPU
UnsortedSegmentSum: GPU CPU
Gather: GPU CPU
StridedSlice: GPU CPU
Unique: GPU CPU
Shape: GPU CPU
Cast: GPU CPU
Identity: GPU CPU
VariableV2: GPU CPU
Const: GPU CPU
	 [[Node: gradients/EmbedSequence/embedding_lookup_grad/ToInt32 = Cast[DstT=DT_INT32, SrcT=DT_INT64, _class=["loc:@EmbedSequence/embeddings"]](gradients/EmbedSequence/embedding_lookup_grad/Shape)]]

Caused by op 'gradients/EmbedSequence/embedding_lookup_grad/ToInt32', defined at:
  File "rmsprop_fail.py", line 15, in <module>
    train_op = optimiser.minimize(loss)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py", line 315, in minimize
    grad_loss=grad_loss)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/optimizer.py", line 386, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py", line 542, in gradients
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py", line 348, in _MaybeCompile
    return grad_fn()  # Exit early
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py", line 542, in <lambda>
    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_grad.py", line 365, in _GatherGrad
    params_shape = math_ops.to_int32(params_shape)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py", line 797, in to_int32
    return cast(x, dtypes.int32, name=name)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py", line 716, in cast
    return gen_math_ops.cast(x, base_type, name=name)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py", line 450, in cast
    result = _op_def_lib.apply_op("Cast", x=x, DstT=DstT, name=name)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py", line 767, in apply_op
    op_def=op_def)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

...which was originally created as op 'EmbedSequence/embedding_lookup', defined at:
  File "rmsprop_fail.py", line 11, in <module>
    x = layers.embed_sequence(input, vocab_size=20, embed_dim=5)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/layers/python/layers/encoders.py", line 142, in embed_sequence
    return embedding_ops.embedding_lookup(embeddings, ids)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py", line 294, in embedding_lookup
    transform_fn=None)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py", line 123, in _embedding_lookup_and_transform
    result = _gather_and_clip(params[0], ids, max_norm, name=name)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py", line 57, in _gather_and_clip
    embs = array_ops.gather(params, ids, name=name)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py", line 2409, in gather
    validate_indices=validate_indices, name=name)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py", line 1219, in gather
    validate_indices=validate_indices, name=name)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py", line 767, in apply_op
    op_def=op_def)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 2630, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py", line 1204, in __init__
    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access

InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'gradients/EmbedSequence/embedding_lookup_grad/ToInt32': Could not satisfy explicit device specification '' because the node was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'
Colocation Debug Info:
Colocation group had the following types and devices:
SparseApplyRMSProp: CPU
UnsortedSegmentSum: GPU CPU
Gather: GPU CPU
StridedSlice: GPU CPU
Unique: GPU CPU
Shape: GPU CPU
Cast: GPU CPU
Identity: GPU CPU
VariableV2: GPU CPU
Const: GPU CPU
	 [[Node: gradients/EmbedSequence/embedding_lookup_grad/ToInt32 = Cast[DstT=DT_INT32, SrcT=DT_INT64, _class=["loc:@EmbedSequence/embeddings"]](gradients/EmbedSequence/embedding_lookup_grad/Shape)]]

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.3 LTS
TensorFlow installed from (source or binary): docker
TensorFlow version (use command below): 1.3.0
Python version: 3.5
CUDA/cuDNN version:
Cuda compilation tools, release 8.0, V8.0.61
GPU model and memory:
Tesla K80