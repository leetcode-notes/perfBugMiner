tf.contrib.learn.estimator each call to predict() reloads the model

What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
None
Environment info
Operating System:
OSX & Ubuntu 14.04
If possible, provide a minimal reproducible example - Explanation
Each call to estimator.predict() completely reloads the model, which is very slow. Is there any mechanism to maintain the model in GPU/memory for consecutive calls?
I understand that large arrays can be passed to the function for simultaneous predictions, but my use case is for slowly arriving data which must be processed quickly. Is there a mechanism for decreasing the 'start-up' time of this function?
What other attempted solutions have you tried?
Looked through API docs & source code for alternative solutions