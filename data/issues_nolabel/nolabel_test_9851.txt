Issue with tf.nn.max_pool

I am a little confused about the implementation of tf.nn.max_pool() function. Below it's a toy example.
import tensorflow as tf
import numpy as np

def weight_variable(shape, name):
	initial = tf.truncated_normal(shape, stddev = 0.1)
	return tf.Variable(initial, name = name)


xe_ = tf.placeholder(tf.float32, shape = (None, 4, 20, 1))
W_conv1 = weight_variable([4, 10, 1, 10], 'W_conv1')

layer0 = tf.nn.conv2d(xe_, W_conv1, strides = [1,1,1,1], padding='VALID')
layer1 = tf.nn.relu(layer0)
layer2 = tf.nn.max_pool(layer1, ksize = (1,1,5,1), strides = (1,1,5,1), padding='SAME')



sess = tf.Session()
sess.run(tf.global_variables_initializer())

np.random.seed(0)
sample  = np.random.rand(1,4,20,1)
mat1 = layer1.eval(feed_dict = {xe_: sample}, session = sess)
mat2 = layer2.eval(feed_dict = {xe_: sample}, session = sess)

np.max(mat1[0,0,0:5,:],axis=0)-mat2[0,0,0,:]

Here I just want to perform a convolution operation with ten 4*10 filters on a single 4*20 image with only one channel. After the convolution ,there is a ReLU activation layer, followed with a max pooling layer. For the max pooling layer, the window size is just 1*5 and the stride comes with the same size. sample is just a random image with desired size. mat1 and mat2 are the output after sample going through these designed layers, conv2d+ReLU and conv2d+ReLU+max_pool respectively.
Am I supposed to get an all-zero array from the last line of the code np.max(mat1[0,0,0:5,:],axis=0)-mat2[0,0,0,:]. Please point out if I understand tf.nn.max_pool() in a wrong way. Great thanks.
Environment info

Ubuntu  14.04.5 LTS
Python 2.7.6
cuda 8, V8.0.44
cudnn 5.1.3
TensorFlow 1.0.1
GeForce GTX 1080