Freeze pb model will not remove is_training flag of bn attr and it is moreover still set as true

Using /tensorflow/python/framework/graph_util_impl.py # convert_variables_to_constants to freeze graph to pb model will not remove is_training flag of batch_normalization as well as fused batch_normalization ops (tf.layers.batch_normalziation) in the inference graph.  Moreover, the is_training flag is still set as true. This issue will not cause any errors to use the pb model on Android. However, it will cause converting errors to tflite model by toco. Is it possible to optimize this conversion tool to resolve the problem in further versions.
Following is the node output of the pb model during loading:
name: "convolution_layer/block_layer1/batch_normalization/FusedBatchNorm"
op: "FusedBatchNorm"
input: "convolution_layer/block_layer1/conv2d/Conv2D"
input: "batch_normalization/gamma/read"
input: "batch_normalization/beta/read"
input: "convolution_layer/block_layer1/batch_normalization/Const"
input: "convolution_layer/block_layer1/batch_normalization/Const_1"
attr {
key: "T"
value {
type: DT_FLOAT
}
}
attr {
key: "data_format"
value {
s: "NHWC"
}
}
attr {
key: "epsilon"
value {
f: 0.0010000000475
}
}
attr {
key: "is_training"
value {
b: true
}
}