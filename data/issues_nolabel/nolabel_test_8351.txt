how to avoid generating large metagraph?

If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
x_nparray = $VERY_LARGE_NP_ARRAY(bigger than 2G)
x = tf.Variable(init_value=x_nparray)
saver=tf.Saver()
with tf.Session() as sess:
saver.save(sess, 'path/to/save')
that would generate very large metagraph binary file, when i try to restore the model, it would failed because of the meta graph file size exceed  the protobuf limit size.
I cannot reduce the size of x_nparray, because it's generated by other training system like caffe.
What other attempted solutions have you tried?
set bigger limit byte of protobuf, however, the x_nparray is bigger than 3G, while the largest limit i can set is 2G.