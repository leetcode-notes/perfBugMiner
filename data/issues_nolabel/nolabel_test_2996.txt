tf.reduce_sum(a) is slow

For large vectors, cost of tf.reduce_sum(a) is dominated by cost of range that's called to construct list of reduction indices.
Summing up 10k elements 1500 times, I get about 0.8 seconds spent in _sum while 2 seconds is spent in range. Also, transferring all those indices to sum probably slows things down. This only happens when static graph optimizations don't apply. Will update with reproducible benchmark in a bit