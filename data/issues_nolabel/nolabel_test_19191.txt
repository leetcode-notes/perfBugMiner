GPU cannot use in C++ API when using libtensorflow_cc.so

My purpose is using C++ api with libtensorflow_cc.so for detection.
First , compile the libtensorflow_cc.so.
I do like;
1   ./configure.       I choose CUDA support, and cuda 9.1 and cudnn 7 is used.
2 bazel the tensorflow .     bazel build -c opt --config=cuda //tensorlfow:libtensorflow_cc.so.
At last ,complete sucessfully.
My code like:
#include <tensorflow/core/protobuf/meta_graph.pb.h>
#include <tensorflow/core/public/session.h>
#include <tensorflow/core/graph/default_device.h>
#include <tensorflow/core/graph/graph_def_builder.h>
tensorflow::GraphDef GraphDef;
tensorflow::Session* Session = nullptr;
1 void LoadGraph()
2 {
3 // Read in the protobuf graph we exported
4 tensorflow::Status Status;
5
6 Status = tensorflow::ReadBinaryProto(tensorflow::Env::Default(), "my_model.pb", &GraphDef);
7 if (!Status.ok())
8 {
9 printf("Error reading graph definition from %s: %s\n", "my_model.pb", Status.ToString().c_str());
10 return false;
11 }
12
13 Session = tensorflow::NewSession(tensorflow::SessionOptions());
14 if (Session == nullptr)
15 {
16 printf("Could not create Tensorflow session.\n");
17 return false;
18 }
19
20 graph::SetDefaultDevice("/device:GPU:0",&GraphDef);
21 // Add the graph to the session
22 Status = Session->Create(GraphDef);
23 if (!Status.ok())
24 {
25 printf("Error creating graph: %s\n", Status.ToString().c_str());
26 return false;
27 }
28 }
But the code will be get an error.   The line 25 will be run.  That is say in line 23, Status.ok() = false.
Segmentation fault(core dumped)..   I do not know how to deal with it.
Can anyone help me? Thank you very much!  Please to me soon !