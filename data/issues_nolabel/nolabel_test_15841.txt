MultiRNNCell with attention cause Dimensions error

when i use MultiRNNCell  and attention for decoding,it goes to

ValueError: Dimensions must be equal, but are 2048 and 3072 for 'read/decode/seq_decode/while/BasicDecoderStep/seq_decode/attention_wrapper/attention_wrapper/multi_rnn_cell/cell_0/cell_0/lstm_cell/MatMul_1' (op: 'MatMul') with input shapes: [?,2048], [3072,4096].

I trace the code,and found it maybe a bug:
https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/ops/rnn_cell_impl.py:
line:1066 calls to LSTMCell(line:600),its _linear1 is initialization from the first LSTMCELL, and will not initialization from the second LSTMCELL. my first LSTMCELL input is with attention.its shape is (?, emb+attention)
but,my second LSTMCELL input is without attention because it called in the while loop, which shape is (?, emb).,When second LSTMCELL use _linear1 is initialization from the first LSTMCELL,it goes to this error