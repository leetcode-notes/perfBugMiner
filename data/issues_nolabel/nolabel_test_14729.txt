Unhelpful error for dynamic_rnn in version 1.4.0

This code:
import tensorflow as tf

x = tf.constant([
		[[0,0],[5,0],[1,0],[1,0],[2,3],[4,0]],
		[[0,0],[0,0],[1,3],[2,0],[0,0],[0,0]]
	], dtype=tf.int32) #changing this to tf.float32 solves the problem


cell = tf.nn.rnn_cell.LSTMCell(num_units=15) 
initial_state = cell.zero_state(tf.shape(x)[0], dtype=tf.float32)
outputs, state = tf.nn.dynamic_rnn(cell, x, initial_state=initial_state, dtype=tf.float32)

init_op = tf.group(tf.global_variables_initializer(),
		tf.local_variables_initializer())

with tf.Session() as sess:
	sess.run(init_op)
	print(sess.run([outputs, state]))
Does not work, because the inputs to the LSTM are integers and they need to be float. However, in version 1.4.0 I get this error:
ValueError: Initializer for variable rnn/lstm_cell/kernel/ is from inside a control-flow construct, such as a loop or conditional. When creating a variable inside a loop or conditional, use a lambda as the initializer.

Which has nothing to do with what is wrong with the code. Version 1.2.0 however, generates this error which correctly refers to the problem:
TypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int32, float32] that don't all match.