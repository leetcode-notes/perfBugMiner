Zero volatile GPU-Util but high GPU Memory Usage

Hi I am running a model implemented by tensorflow with only one GPU, the GPU usage is 95% while the volatile GPU-Util is 0.
Specifically I have Tesla k40m with cuda 7.0 and cudnn 6.5v2 installed on Centos 7.0. There are three files: data_loader.py, model.py and train.py in my project. In the train.py I firstly declared
" with tf.device('/gpu:0'):" and then sess.run([train_op]). When I run the code, errors raised:
"tensorflow/core/common_runtime/gpu/gpu_init.cc:45] cannot enable peer access from device ordinal 0 to device ordinal 2"
On the other hand, I installed tensorflow with Pip.
Any help are more than welcome.