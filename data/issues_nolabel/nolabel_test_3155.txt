More clear error message required

Tensorflow 0.9.0
Trying to load and execute that graph+checkpoint from C++ API: https://cloud.mail.ru/public/5yk3/No887jqS8
Model was prepared using 'freeze_graph.py'
Code based on Tensorflow examples(graph contains no input layer):
std::string output_layer = "output_node"; std::vector<tensorflow::Tensor> outputs; tensorflow::Status run_status = session->Run({{}},{output_layer}, {}, &outputs); if (!run_status.ok()) { LOG(ERROR) << "Running model failed: " << run_status; return; } tensorflow::string status_string = run_status.ToString(); NSLog(@"%s",status_string.c_str());
Error:

Running model failed: Invalid argument: No OpKernel was registered to support Op 'PaddingFIFOQueue' with these attrs
[[Node: batch/padding_fifo_queue = PaddingFIFOQueuecapacity=32, component_types=[DT_FLOAT], container="", shapes=[[-1,-1,3]], shared_name=""]]

And that's all. Nothing that can help me to understand what to do with the error. The only information I was able to find is that the error might be due to GPU only operation, but same model runs fine from python in CPU only mode.
Clearly don't know what to do with this error message. Created stackoverflow question http://stackoverflow.com/questions/38155086/no-opkernel-was-registered-to-support-op-paddingfifoqueue-with-these-attrs And hope for some insights.
I think that it would be very useful to elaborate on this kind of errors in run_status.