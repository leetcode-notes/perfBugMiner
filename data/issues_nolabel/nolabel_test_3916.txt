some change to Mnist_softmax.py

Environment info
Operating System:
ubuntu 14.0
Installed version of CUDA and cuDNN:
(please attach the output of ls -l /path/to/cuda/lib/libcud*):
ls -l /path/to/cuda/lib/libcud
If installed from binary pip package, provide:
-rw-r--r-- 1 root root 322936  8月 16  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16  8月 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19  8月 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336  8月 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192  8月 16  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a

Which pip package you installed.
pip 1.5.4 from /usr/lib/python2.7/dist-packages (python 2.7)
The output from python -c "import tensorflow; print(tensorflow.__version__)".
0.10.0rc0

Steps to reproduce
1.When i run the original ~/Tensorflow Modles/tensorflow-master/tensorflow/examples/tutorials/mnist/mnist_softmax.py ,i got accuray :91.9%
2.But after i change follow code:
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))
y = tf.nn.softmax(tf.matmul(x, W) + b)
to:
W1 = tf.Variable(tf.zeros([784, 1000]))
b1 = tf.Variable(tf.zeros([1000]))
W2 = tf.Variable(tf.zeros([1000, 10]))
b2 = tf.Variable(tf.zeros([10]))
h1=tf.nn.sigmoid(tf.matmul(x, W1) + b1)
y = tf.nn.softmax(tf.matmul(h1, W2) + b2)
the accuracy was down to about 30%
and it seemed that no or very little convergence happened even after changed the learning rate.
why?what happened?Could somebody help me?