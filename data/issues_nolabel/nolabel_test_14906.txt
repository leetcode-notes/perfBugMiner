Functionality Available?: Dataset Input perform slicing along time axis

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7
TensorFlow installed from (source or binary): from pip
TensorFlow version (use command below): 1.3
Python version: 3.6
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: 8.0, 6.1
GPU model and memory: k2200
Exact command to reproduce:

Describe the problem
Currently, as many suggested, when we want to train LSTM to predict the values of next time step, we would better slice all the samples along time axis to tuples of (lookback numbers of values, target predicted values) as (x, y), then store all these in a variable in RAM or as data file in disk. Then we build dataset to point to either form. However, this method makes LSTM stateless. Currently, our scheme to stateful LSTM is as follows:
for an input signal [1, 2, 3, 4, 5, 6, ..., 9, 10, 11]
we initialize LSTM and set state to 0.
feed ([1, 2, 3], 4) to train (tf.nn.dynamic_rnn), then feed ([2, 3, 4], 5) ....... ([8, 9, 10], 11), until end of this sequence.
In this batch, we have a number (Batch size, like 32) of signals like this and they will be processed in parallel in GPU by TF.
In the next batch of new signal samples, we reset LSTM with initial state being 0. And then repeat this process.
In this way, we think that given [8, 9, 10] to the model to predict next value (as 11), it is helpful for the model to choose whether to utilize the information of its current state (whether it is at beginning of a series of signal, zero initial; or it is at middle of a signal sequence).
Currently, before version 1.4, we built two generators, one (batch generator) is to generate a batch of signals. The other (time slicer) is to generate (x, y) [shape of (batch size, max time step, number of features) ] along time axis by using the data yield by the batch generator.
In version 1.4, we find Dataset, Estimator and Experiment pipeline powerful. Is there a way to implement the same idea using such pipeline?
Thanks!