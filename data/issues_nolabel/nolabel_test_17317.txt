How to Split up/Unstack/Partition a dynamic 3D Tensor into subtensors?

In this code from google , sequence loss is being calculated by passing in 3 variables : logits , weights and targets.
How logits are defined:

logits: A Tensor of shape
[batch_size, sequence_length, num_decoder_symbols] and dtype float.
The logits correspond to the prediction across all classes at each
timestep.

My intentions were to get 3 different tensors of shapes batch_size , sequence_length and dec_symbols  and then use them in tf.scan (using sequence_length as elems)
If I print the logits tensor , this is what i get :

shape=(?, ?, 300)

Which means tf.unstack is out of the equation(as it has a variable shape)
So my first question is , is it even possible ?
If yes , any suggestions ?
Thanks !
PS: Maybe Google can add a swap_memory parameter to the seq2seq.sequence_loss function ,to avoid OOM errors while calculating losses [which is what we are trying to overcome using an iterator inside]