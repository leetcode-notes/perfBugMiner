Initializer for Input->H & H->H weight matrices for RNNCells

This modification allows initializer (with trainability) for the Input -> Hidden and Hidden to Hidden layer when using the _linear function. Currently, only BasicRNNCell has the new arguments in it's call function, but this could easily be solved. The motivation for such a modification is that it would easily allow different weight architecture for each component of the cell. For example, one could have a one-to-one connection from input -> H, all-to-all from H -> H and one-to-one for H->Output. One could also easily create sparse weight matrices for the input->H and H->H.
Example code:
# Initializer ~ 1st matrix acts as an index for which unit is trainable, 2st is the weight of the units
init  = [ tf.constant(np.identity(n_input+n_hidden), dtype = 'float32'), tf.random_normal([n_input+n_hidden,1]) ]

# Whether matrix1 and matrix2 are trainable
train = [False, True]

#Creating cell
cell  = rnn_cell.BasicRNNCell(n_hidden, initializer = init, trainable = train)

#Executing cell
outputs, states = rnn.rnn(cell, Input, initial_state=_istate, dtype=tf.float32)