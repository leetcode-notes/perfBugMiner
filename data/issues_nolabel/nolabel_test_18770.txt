Configuring TFLite(Android) to use all CPU's?

System information

Have I written custom code (yes):
OS Platform and Distribution (Android Things):
TensorFlow installed from (source):
TensorFlow version (1.8.0-rc0):
Python version:  2.7
Bazel version (0.12.0):
GCC/Compiler version (5.4.0):
CUDA/cuDNN version: 9.1/7.1
GPU model and memory: GTX1080 8G
Exact command to reproduce:

Describe the problem
I use Raspberry Pi3 + Android Things + TFLite + MobileNet to make a image classifier sample, base this Android Things Image Classifier tutorial.


I monitor the cpu by adb shell top and find it only use 1 CPU with quant model when inference, and 2 CPU with unquant model.
So how to configuring TFLite(Android) to use all CPUs?


Another question, maybe impact the question above, on the introduction of TFLite, it say:

On select Android devices, the Interpreter will use the Android Neural Networks API for hardware acceleration, or default to CPU execution if none are available.

You know, Raspberry has a GPU(Broadcom VideoCore IV), so how to use it? has it been used?


Source code / logs
Android Things Image Classifier tutorial.