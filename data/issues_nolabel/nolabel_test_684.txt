CUDA_ERROR_NO_DEVICE with Tesla K40c

Hi,
I'm trying to use TF on a machine with 40 CPUs and 1 Tesla K40c.
The machine is running openSUSE 13.2 and has CUDA 7 and cuDNN 6.5 installed.
Problem
When trying to run a simple test script
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
print sess.run(hello)
a = tf.constant(10)
b = tf.constant(32)
print sess.run(a+b)

I get this output + the error "CUDA_ERROR_NO_DEVICE":
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcudnn.so.6.5 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcuda.so locally
I tensorflow/stream_executor/dso_loader.cc:101] successfully opened CUDA library libcurand.so.7.0 locally
I tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 40
E tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_NO_DEVICE
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: ml-login2
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: ml-login2
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: 346.46
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: """NVRM version: NVIDIA UNIX x86_64 Kernel Module  346.46  Tue Feb 17 17:56:08 PST 2015
GCC version:  gcc version 4.8.3 20140627 [gcc-4_8-branch revision 212064] (SUSE Linux) 
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 346.46
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:226] kernel version seems to match DSO: 346.46
I tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 
I tensorflow/core/common_runtime/direct_session.cc:58] Direct session inter op parallelism threads: 40
Device mapping: no known devices.
I tensorflow/core/common_runtime/direct_session.cc:134] Device mapping:

Const: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:304] Const: /job:localhost/replica:0/task:0/cpu:0
Hello, TensorFlow!
Const_2: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:304] Const_2: /job:localhost/replica:0/task:0/cpu:0
Const_1: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:304] Const_1: /job:localhost/replica:0/task:0/cpu:0
add: /job:localhost/replica:0/task:0/cpu:0
I tensorflow/core/common_runtime/simple_placer.cc:304] add: /job:localhost/replica:0/task:0/cpu:0

What I've tried
I've tried reinstalling the CUDA toolkit, installing TF from source, but all resulted in the same error.
nvidia-smi properly finds the GPU and I can successfully run GPU computations through C code that depends on CUDA. It seems that somehow TF can't detect the GPU.
Is this a known issue with k40c GPUs and is there a fix?
Thanks!
-Stephan