Using keras layers within an Estimator either causes training where it shouldn't or corrupts weights

System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian 3.16.36
TensorFlow installed from (source or binary): Binary
TensorFlow version (use command below): ('v1.4.0-19-ga52c8d9', '1.4.1')
Python version: 2.7.9
Bazel version (if compiling from source):
GCC/Compiler version (if compiling from source):
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: See gist

Describe the problem
Hey there,
So I have a tf.keras model that for use on Amazon SageMaker I'm trying to convert into an Estimator. I know there's tf.keras.estimator.model_to_estimator but, I'm having separate issues with that.
In the easily run reproduction here I have (as a demonstration) a tf.keras.layers.Embedding which is initialized with all zeros and has trainable=False. Followed by that is a Dense layer with use_bias=False because I couldn't figure out how to get predictions out of an Estimator without training it first (and I can't train nothing apparently). Since all of the embeddings are zero however and can't be trained, the Dense layer should always produce a zero, even after training it. Instead, it produces garbage!
In fact, I've taken a few steps to ensure that no training takes place, although ideally I'd be able to just run the estimator without training:

I've set the loss to be 0 initially (l2_norm of what should start out as 0)
Optimize with SGD using a learning rate of 0
One training example that should have zero loss...

The output I actually get is very much non-zero. If I inspect the embed/embeddings:0 tensor in tfbdg, I see this:
array([[ 0.14387012,  0.83495581,  0.44025695,  0.25154734,  0.7214781 ,  0.40229702,  0.82108581,  0.12210274,  0.43861651,  0.39615464],                
       [ 0.81636655,  0.48157215,  0.48987687,  0.48775947,  0.62187696,  0.25421095,  0.64555049,  0.97305572,  0.53352964,  0.34286666],                
       [ 0.82881641,  0.80365777,  0.4596678 ,  0.21614265,  0.22256434,  0.07986271,  0.92880177,  0.64946997,  0.89239001,  0.13793337],                
       [ 0.98491704,  0.15281868,  0.77106941,  0.30048406,  0.86042607,  0.88010466,  0.64362776,  0.70185173,  0.49912012,  0.61521161]], dtype=float32)

Even though it shouldn't have budged from all zeroes!
So, something about how I'm doing this is fundamentally broken. I suspect that the issue is in line 61 where I start a new Session -- however this appears to be necessary, since I need to ensure that the keras backend is using the same Graph as tensorflow.get_default_graph() due to the peculiarities of how the Estimator calls the model_fn.
Notably those values hold between:

Runs of the estimator
Successive runs with the same tf.set_random_seed value

The latter makes me think that somehow the Embedding layer is receiving a gradient despite my best efforts, although it's hard to test this versus some sort of memory corruption.
If you need me to provide any more information let me know -- I'm sure I've left something out.