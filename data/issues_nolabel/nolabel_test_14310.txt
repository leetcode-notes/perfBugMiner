ONNX Support (Run ONNX nodes using TF)

As per #12888.
Authors of ONNX-TF package: Arpith Jacob, Tian Jin, Gheorghe-Teodor Bercea from IBM Research.
Objective
We are porting a subset of our package of ONNX-TF from here https://github.com/tjingrant/onnx-tf. Specifically, we want to enable users to do the following:
import tensorflow as tf
import numpy as np
from onnx import helper
from onnx.onnx_pb2 import TensorProto

X = np.random.randn(3, 2).astype(np.float32)
Y_ref = np.clip(X, 0, np.inf)

node_def = helper.make_node(
  "Relu", ["X"], ["X"])

graph_def = helper.make_graph(
  [node_def],
  name="test",
  inputs=[helper.make_tensor_value_info("X", TensorProto.FLOAT, [3, 2])],
  outputs=[helper.make_tensor_value_info("X", TensorProto.FLOAT, [3, 2])])

input_dict, output_dict = tf.contrib.onnx.prepare(helper.make_model(graph_def))
with tf.Session() as sess:
  out = sess.run(output_dict['X'], feed_dict={input_dict['X']: X})

np.testing.assert_almost_equal(out, Y_ref)

Current support for ONNX:
This implementation passes all the backend tests here https://github.com/onnx/onnx/blob/master/onnx/backend/test.py except for RNN. It supports all the models in the ONNX model zoo (https://github.com/onnx/models).
What we will be doing:
We are still working on fixing some of the tests as well as clearing as many TODO's as we can.
The ONNX RNN API changed very recently and we may do another PR for RNN support.
We'd like your opinions:
We have not imported the ONNX package dependency (https://github.com/onnx/onnx) as we'd like to get TF team's opinion regarding whether/how we should import ONNX package dependency. The benefit is that we can check for the legality of ONNX node/graph declaration. Also we need a bunch of Proto definition like GraphProto/TensorProto.
@arpith-jacob, @doru1004